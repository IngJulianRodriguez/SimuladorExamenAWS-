[
  {
    "q": "Una empresa de telecomunicaciones planea migrar su aplicación local a una instancia EC2 en AWS. Se ha asignado un bloque CIDR IPv6 a la VPC de producción de la compañía. La política de seguridad exige que solo se permita la comunicación saliente sobre IPv6 entre la instancia y el internet, pero se debe evitar que la instancia inicie una conexión entrante con IPv6. La nueva arquitectura también debe permitir la inspección del flujo de tráfico y el filtrado de tráfico.\n¿Qué debe hacer un arquitecto de soluciones para cumplir con estos requisitos?",
    "o": [
      "Lanzar la instancia EC2 en una subred pública y adjuntar un Internet Gateway a la VPC para permitir la comunicación saliente sobre IPv6 a internet. Utilizar Traffic Mirroring para configurar las reglas necesarias de inspección y filtrado de tráfico",
      "Lanzar la instancia EC2 en una subred privada y adjuntar un Egress-Only Internet Gateway a la VPC para permitir la comunicación saliente sobre IPv6 a internet. Utilizar AWS Network Firewall para configurar las reglas necesarias de inspección y filtrado de tráfico",
      "Lanzar la instancia EC2 en una subred privada y adjuntar un NAT Gateway a la VPC para permitir la comunicación saliente sobre IPv6 a internet. Utilizar AWS Firewall Manager para configurar las reglas necesarias de inspección y filtrado de tráfico",
      "Lanzar la instancia EC2 en una subred privada y adjuntar un Endpoint de AWS PrivateLink a la VPC para controlar la comunicación saliente sobre IPv6 a internet. Utilizar Amazon GuardDuty para configurar las reglas necesarias de inspección y filtrado de tráfico"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nLanzar la instancia EC2 en una subred privada y adjuntar un Egress-Only Internet Gateway a la VPC para permitir la comunicación saliente sobre IPv6 a internet. Utilizar AWS Network Firewall para configurar las reglas necesarias de inspección y filtrado de tráfico - Egress-Only Internet Gateway permite la comunicación saliente sobre IPv6 desde instancias en una subred privada a internet, evitando conexiones entrantes. Al combinarlo con AWS Network Firewall, se pueden configurar reglas detalladas de inspección de tráfico y filtrado, cumpliendo con los requisitos de seguridad.\n\nEgress-Only Internet Gateway es ideal para permitir tráfico saliente sobre IPv6 mientras se bloquean las conexiones entrantes, protegiendo la instancia de accesos no autorizados.\nAWS Network Firewall proporciona capacidades avanzadas de inspección de tráfico, como detección de intrusiones (IPS) y filtrado de dominios no deseados, fortaleciendo la postura de seguridad.\nEsta configuración es adecuada para cumplir con políticas de seguridad estrictas que requieren comunicación unidireccional sobre IPv6.\n\n\nOpciones incorrectas:\n\nLanzar la instancia EC2 en una subred pública y adjuntar un Internet Gateway a la VPC para permitir la comunicación saliente sobre IPv6 a internet. Utilizar Traffic Mirroring para configurar las reglas necesarias de inspección y filtrado de tráfico - Internet Gateway permite tanto tráfico entrante como saliente, lo que no cumple con el requisito de evitar conexiones entrantes sobre IPv6. Traffic Mirroring se utiliza para copiar tráfico de red para análisis, no para inspección y filtrado.\n\nLanzar la instancia EC2 en una subred privada y adjuntar un Endpoint de AWS PrivateLink a la VPC para controlar la comunicación saliente sobre IPv6 a internet. Utilizar Amazon GuardDuty para configurar las reglas necesarias de inspección y filtrado de tráfico - PrivateLink conecta de forma privada servicios dentro de AWS, pero no controla la comunicación saliente a internet. Además, Amazon GuardDuty ofrece monitoreo de amenazas, no reglas de inspección y filtrado de tráfico en tiempo real.\n\nLanzar la instancia EC2 en una subred privada y adjuntar un NAT Gateway a la VPC para permitir la comunicación saliente sobre IPv6 a internet. Utilizar AWS Firewall Manager para configurar las reglas necesarias de inspección y filtrado de tráfico - NAT Gateway traduce direcciones IPv4 privadas a IPv4 públicas para comunicación saliente, pero no es compatible con IPv6. Además, AWS Firewall Manager se utiliza para gestionar reglas de firewall a escala en múltiples cuentas, pero no realiza inspección de tráfico.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/vpc/latest/userguide/egress-only-internet-gateway.html\n\nhttps://docs.aws.amazon.com/vpc/latest/userguide/configure-subnets.html\n\nhttps://docs.aws.amazon.com/vpc/latest/userguide/vpc-internet-gateway.html"
  },
  {
    "q": "Un sistema de gestión de contenido (CMS) está alojado en un grupo de instancias EC2 On-Demand con autoescalado que utilizan Amazon Aurora como base de datos. Actualmente, el sistema almacena los documentos que los usuarios suben en uno de los volúmenes EBS adjuntos.\nTu gerente ha notado que el rendimiento del sistema es bastante lento y te ha pedido mejorar la arquitectura del sistema.\nEn este escenario, ¿qué harías para implementar un sistema de archivos compartido, escalable y altamente disponible compatible con POSIX?",
    "o": [
      "Usar EFS",
      "Actualizar tus volúmenes EBS existentes a Provisioned IOPS SSD Volumes",
      "Crear un bucket de S3 y usarlo como almacenamiento para el CMS",
      "Usar ElastiCache"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nUsar EFS - Amazon Elastic File System (EFS) proporciona almacenamiento de archivos elástico, escalable y altamente disponible que es compatible con POSIX. Se puede montar en múltiples instancias EC2, lo que permite el acceso compartido y concurrente a los documentos de archivos. Además, EFS está diseñado para ser escalable y distribuir automáticamente los datos en múltiples zonas de disponibilidad, garantizando alta disponibilidad y durabilidad.\n\nEFS es ideal para arquitecturas distribuidas y escalables, como servidores web y sistemas de gestión de contenido, donde múltiples instancias EC2 necesitan acceso concurrente a un sistema de archivos compartido.\nEFS soporta operaciones de sistema de archivos como creación de directorios, bloqueo de archivos y permisos de usuario/grupo.\nProporciona escalabilidad automática, ajustándose a la carga de trabajo sin necesidad de aprovisionamiento manual de capacidad.\n\n\nOpciones incorrectas:\n\nActualizar tus volúmenes EBS existentes a Provisioned IOPS SSD Volumes - Provisioned IOPS SSD en EBS mejora el rendimiento de I/O, pero EBS es un almacenamiento conectado a una instancia EC2 individual y no se puede compartir de manera simultánea entre múltiples instancias en diferentes zonas de disponibilidad.\n\nCrear un bucket de S3 y usarlo como almacenamiento para el CMS - Amazon S3 es un almacenamiento de objetos y no proporciona un sistema de archivos compatible con POSIX. No permite operaciones comunes de sistema de archivos como bloqueo de archivos, lo cual es necesario para un CMS que requiere acceso compartido.\n\nUsar ElastiCache - ElastiCache es un servicio de almacenamiento en memoria que mejora el rendimiento de las aplicaciones mediante el almacenamiento en caché, pero no es un almacenamiento de archivos ni proporciona compatibilidad con POSIX.\n\nReferencias:\n\nhttps://aws.amazon.com/efs/"
  },
  {
    "q": "Una agencia espacial privada necesita procesar imágenes satelitales de ultra alta resolución. Requiere un volumen de almacenamiento en bloque persistente para realizar los cálculos intensivos con estas imágenes, mientras que los archivos originales deben almacenarse en un almacenamiento de objetos. Después de 60 días, los archivos deben moverse a una solución de archivo de bajo costo para almacenamiento a largo plazo.\n¿Qué debes hacer para cumplir con este requisito?",
    "o": [
      "Adjuntar un volumen EBS en la instancia EC2 para procesamiento. Guardar archivos en Amazon S3 y moverlos a S3 Glacier Deep Archive después de 60 días",
      "Utilizar volúmenes temporales en la instancia EC2 para procesamiento. Almacenar archivos en Amazon S3 y moverlos a S3 Intelligent-Tiering tras 60 días",
      "Adjuntar un volumen EBS en la instancia EC2. Utilizar Amazon S3 para almacenar los archivos originales y configurar una política de ciclo de vida para trasladarlos a Amazon S3 Glacier después de 60 días",
      "Utilizar AWS Snowball Edge como almacenamiento local para procesamiento. Almacenar los archivos en Amazon S3 y moverlos a S3 Standard-IA después de 60 días"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nAdjuntar un volumen EBS en la instancia EC2. Utilizar Amazon S3 para almacenar los archivos originales y configurar una política de ciclo de vida para trasladarlos a Amazon S3 Glacier después de 60 días - Amazon EBS es ideal para procesamiento intensivo, como imágenes satelitales, gracias a su alto rendimiento y persistencia. Amazon S3 permite almacenar de forma duradera los archivos originales, y aplicar una política de ciclo de vida que los mueva a S3 Glacier tras 60 días es óptimo para reducir costos en archivado a largo plazo.\n\nOpciones incorrectas:\n\nUtilizar volúmenes temporales en la instancia EC2 para procesamiento. Almacenar archivos en Amazon S3 y moverlos a S3 Intelligent-Tiering tras 60 días - El almacenamiento efímero no garantiza persistencia y puede resultar en pérdida de datos al reiniciar la instancia. Además, S3 Intelligent-Tiering está pensado para datos con patrones de acceso impredecibles, no archivado específico.\n\nAdjuntar un volumen EBS en la instancia EC2 para procesamiento. Guardar archivos en Amazon S3 y moverlos a S3 Glacier Deep Archive después de 60 días - Glacier Deep Archive es más económico que Glacier, pero introduce mayor latencia de recuperación. A menos que se requiera archivado muy prolongado sin acceso frecuente, Glacier estándar ofrece un mejor equilibrio entre costo y accesibilidad.\n\nUtilizar AWS Snowball Edge como almacenamiento local para procesamiento. Almacenar los archivos en Amazon S3 y moverlos a S3 Standard-IA después de 60 días - Snowball Edge es más adecuado para entornos desconectados o migraciones físicas masivas. No es necesario en este escenario basado completamente en la nube. Además, S3 Standard-IA no es la clase más adecuada para archivado a largo plazo.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AmazonEBS.html\n\nhttps://aws.amazon.com/s3/storage-classes/"
  },
  {
    "q": "Una aplicación de gestión de inversiones está compuesta por un grupo de Auto Scaling de instancias EC2, un Application Load Balancer y una instancia RDS MySQL en configuración Multi-AZ Deployments. Para proteger los datos confidenciales de tus clientes, debes garantizar que tu base de datos RDS solo pueda ser accedida utilizando credenciales de perfil específicas en tus instancias EC2 a través de un token de autenticación.\nComo arquitecto de soluciones de la empresa, ¿cuál de las siguientes acciones debes realizar para cumplir con este requisito?",
    "o": [
      "Configurar SSL en tu aplicación para cifrar la conexión de la base de datos con RDS",
      "Crear un rol de IAM y asignarlo a tus instancias EC2, lo que otorgará acceso exclusivo a tu instancia RDS",
      "Habilitar la autenticación de base de datos con IAM (IAM DB Authentication)",
      "Utilizar una combinación de IAM y STS para restringir el acceso a tu instancia RDS mediante un token temporal"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nHabilitar la autenticación de base de datos con IAM (IAM DB Authentication) - Habilitar IAM DB Authentication permite autenticarte en la instancia de base de datos usando credenciales de IAM. Con esta autenticación, no necesitas almacenar contraseñas en la base de datos, ya que utilizas un token de autenticación generado por AWS Signature Version 4. Este token tiene una vida útil de 15 minutos y se puede utilizar con perfiles de instancia de EC2, garantizando que solo instancias autorizadas puedan acceder a la base de datos.\n\nIAM DB Authentication está disponible para MySQL y PostgreSQL en RDS.\nEste método utiliza AWS Signature Version 4 para generar tokens de autenticación, eliminando la necesidad de contraseñas almacenadas.\nSe integra con EC2 Instance Profiles, lo que permite a las aplicaciones autenticarse sin credenciales codificadas.\nOpciones incorrectas:\n\nConfigurar SSL en tu aplicación para cifrar la conexión de la base de datos con RDS - Configurar SSL en la aplicación mejora la seguridad en tránsito, pero no proporciona autenticación basada en tokens, por lo que no cumple con el requisito de utilizar un token de autenticación.\n\nCrear un rol de IAM y asignarlo a tus instancias EC2, lo que otorgará acceso exclusivo a tu instancia RDS - Crear un rol de IAM y asignarlo a las instancias EC2 no es suficiente, ya que aunque se puede otorgar acceso a RDS, es necesario habilitar IAM DB Authentication para utilizar tokens de autenticación.\n\nUtilizar una combinación de IAM y STS para restringir el acceso a tu instancia RDS mediante un token temporal - Utilizar IAM y STS no es aplicable para RDS en este contexto, ya que IAM DB Authentication utiliza tokens generados mediante Signature Version 4 y no requiere el uso de STS para autenticación temporal.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.IAMDBAuth.html"
  },
  {
    "q": "Una aplicación Docker, que se ejecuta en un clúster de ECS detrás de un balanceador de carga, utiliza intensamente DynamoDB. Se te ha pedido que mejores el rendimiento de la base de datos distribuyendo uniformemente la carga de trabajo y utilizando eficientemente el rendimiento aprovisionado.\n¿Cuál de las siguientes opciones considerarías implementar en tu tabla de DynamoDB?",
    "o": [
      "Usar partition keys con atributos de alta cardinalidad, que tienen un gran número de valores distintos para cada ítem",
      "Evitar el uso de una composite primary key, que se compone de una partition key y una sort key",
      "Reducir el número de partition keys en la tabla de DynamoDB",
      "Usar partition keys con atributos de baja cardinalidad, que tienen pocos valores distintos para cada ítem"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nUsar partition keys con atributos de alta cardinalidad, que tienen un gran número de valores distintos para cada ítem - Usar partition keys con atributos de alta cardinalidad es la opción correcta porque ayuda a distribuir uniformemente las solicitudes a través de las particiones de DynamoDB. Cuando una partition key tiene muchos valores únicos (alta cardinalidad), las solicitudes se distribuyen más equitativamente, evitando que ciertas particiones se sobrecarguen. Esto mejora el rendimiento al reducir la posibilidad de 'hot partitions', que pueden limitar el throughput y causar throttling.\n\nEn DynamoDB, la partition key define cómo se distribuyen los datos en las particiones subyacentes.\nUna distribución uniforme de las solicitudes entre las particiones garantiza el uso eficiente del rendimiento aprovisionado.\nLa alta cardinalidad de la partition key minimiza la posibilidad de throttling al balancear la carga de trabajo.\nOpciones incorrectas:\n\nUsar partition keys con atributos de baja cardinalidad, que tienen pocos valores distintos para cada ítem - Usar partition keys con atributos de baja cardinalidad es incorrecto porque conlleva a una distribución desigual de las solicitudes. Si solo hay unos pocos valores distintos, las solicitudes se concentrarán en unas pocas particiones, creando hot partitions y causando throttling.\n\nEvitar el uso de una composite primary key, que se compone de una partition key y una sort key - Evitar el uso de una composite primary key es incorrecto porque una composite key (partition key + sort key) en realidad puede mejorar la distribución y el rendimiento. Esto permite almacenar múltiples ítems con la misma partition key pero con diferentes sort keys, mejorando la escalabilidad y flexibilidad en consultas.\n\nReducir el número de partition keys en la tabla de DynamoDB - Reducir el número de partition keys en la tabla de DynamoDB es incorrecto porque hacer esto llevaría a una mayor concentración de solicitudes en menos particiones, lo que resultaría en hot partitions. Se debe aumentar la diversidad de valores de la partition key para una mejor distribución de carga.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-partition-key-uniform-load.html\n\nhttps://aws.amazon.com/blogs/database/choosing-the-right-dynamodb-partition-key/"
  },
  {
    "q": "Una empresa ha lanzado una aplicación de múltiples niveles. Tanto el nivel web como el nivel de base de datos se ejecutan en instancias de Amazon EC2 dentro de subredes privadas en la misma Zona de Disponibilidad (AZ).\nEl equipo necesita rediseñar la arquitectura para agregar alta disponibilidad (HA) y tolerancia a fallos.\n¿Cuál combinación de pasos debe tomar un arquitecto de soluciones para cumplir este requisito? (Selecciona DOS.)",
    "o": [
      "Agregar las instancias existentes de la aplicación web a un grupo de Auto Scaling detrás de un Application Load Balancer (ALB)",
      "Crear nuevas subredes públicas en la misma AZ para alta disponibilidad y mover el nivel web a las subredes públicas",
      "Crear un grupo de Auto Scaling de Amazon EC2 y un Application Load Balancer (ALB) que abarque múltiples AZs",
      "Crear nuevas subredes privadas en la misma VPC pero en una AZ diferente. Migrar la base de datos a un despliegue Multi-AZ de Amazon RDS",
      "Crear nuevas subredes privadas en la misma VPC pero en una AZ diferente. Crear una base de datos usando Amazon EC2 en una sola AZ"
    ],
    "a": [
      2,
      3
    ],
    "e": "Correcto:\n\nCrear nuevas subredes privadas en la misma VPC pero en una AZ diferente. Migrar la base de datos a un despliegue Multi-AZ de Amazon RDS - Crear subredes privadas adicionales en una segunda Zona de Disponibilidad y migrar la base de datos a un despliegue Multi-AZ de Amazon RDS proporciona redundancia en el nivel de base de datos. Si una AZ falla, la instancia secundaria de RDS entra automáticamente en servicio sin pérdida de datos ni interrupciones significativas.\n\nCrear un grupo de Auto Scaling de Amazon EC2 y un Application Load Balancer (ALB) que abarque múltiples AZs - Implementar un grupo de Auto Scaling de EC2 junto con un Application Load Balancer distribuye el tráfico entre múltiples AZs. Esto garantiza que, si una zona falla, las instancias en otra zona puedan continuar manejando las solicitudes, manteniendo la disponibilidad del nivel de aplicación.\n\nOpciones incorrectas:\n\nCrear nuevas subredes privadas en la misma VPC pero en una AZ diferente. Crear una base de datos usando Amazon EC2 en una sola AZ - Crear una base de datos en EC2 en una sola AZ no ofrece redundancia. Si esa AZ falla, la base de datos se vuelve inaccesible, comprometiendo la alta disponibilidad.\n\nAgregar las instancias existentes de la aplicación web a un grupo de Auto Scaling detrás de un Application Load Balancer (ALB) - Colocar las instancias actuales en un grupo de Auto Scaling dentro de una sola AZ no proporciona tolerancia a fallos. La alta disponibilidad requiere instancias distribuidas entre múltiples zonas.\n\nCrear nuevas subredes públicas en la misma AZ para alta disponibilidad y mover el nivel web a las subredes públicas - Mover el nivel web a subredes públicas dentro de la misma AZ no mejora la disponibilidad. Si la zona falla, tanto las subredes públicas como las privadas dejarán de estar operativas, eliminando todo el nivel web.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-increase-availability.html\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html"
  },
  {
    "q": "Un ingeniero cloud de una empresa quiere detectar y remediar el compromiso de servicios como instancias de Amazon EC2 y buckets de Amazon S3.\n¿Qué servicio de AWS puede usar el administrador para proteger a la empresa contra ataques?",
    "o": [
      "Amazon Cognito",
      "Amazon GuardDuty",
      "Amazon Inspector",
      "Amazon Macie"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nAmazon GuardDuty - Amazon GuardDuty proporciona detección continua de amenazas utilizando inteligencia de seguridad, machine learning y análisis de comportamiento. Puede identificar actividades maliciosas o no autorizadas, como el compromiso de instancias EC2 o buckets S3. Además, puede integrarse con CloudWatch Events y Lambda para automatizar respuestas ante incidentes.\n\nOpciones incorrectas:\n\nAmazon Macie - Amazon Macie se utiliza para identificar y proteger datos sensibles almacenados en Amazon S3, pero no detecta intrusiones o compromisos de recursos.\n\nAmazon Inspector - Amazon Inspector evalúa vulnerabilidades y desviaciones respecto a mejores prácticas de seguridad, pero no está diseñado para detectar actividad maliciosa en tiempo real.\n\nAmazon Cognito - Amazon Cognito se usa para gestionar la autenticación y el acceso de usuarios en aplicaciones, no para detección de amenazas.\n\nReferencias:\n\nhttps://aws.amazon.com/guardduty/features/\n\nhttps://docs.aws.amazon.com/guardduty/latest/ug/what-is-guardduty.html"
  },
  {
    "q": "Una aplicación consta de múltiples instancias EC2 en subredes privadas distribuidas en diferentes zonas de disponibilidad. La aplicación utiliza un solo NAT Gateway para descargar parches de software de Internet hacia las instancias. Se requiere proteger la aplicación de un solo punto de falla si el NAT Gateway falla o si la zona de disponibilidad en la que está implementado queda inactiva.\n¿Cómo debería el Solutions Architect rediseñar la arquitectura para que sea más altamente disponible y rentable?",
    "o": [
      "Crear tres NAT Gateways en cada zona de disponibilidad. Configurar la tabla de rutas en cada subred privada para garantizar que las instancias utilicen el NAT Gateway en la misma zona de disponibilidad",
      "Crear dos NAT Gateways en cada zona de disponibilidad. Configurar la tabla de rutas en cada subred pública para garantizar que las instancias utilicen el NAT Gateway en la misma zona de disponibilidad",
      "Crear un NAT Gateway en cada zona de disponibilidad. Configurar la tabla de rutas en cada subred privada para garantizar que las instancias utilicen el NAT Gateway en la misma zona de disponibilidad",
      "Crear un NAT Gateway en cada zona de disponibilidad. Configurar la tabla de rutas en cada subred pública para garantizar que las instancias utilicen el NAT Gateway en la misma zona de disponibilidad"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nCrear un NAT Gateway en cada zona de disponibilidad. Configurar la tabla de rutas en cada subred privada para garantizar que las instancias utilicen el NAT Gateway en la misma zona de disponibilidad - Crear un NAT Gateway en cada zona de disponibilidad y configurar la tabla de rutas en cada subred privada para garantizar que las instancias utilicen el NAT Gateway en la misma zona de disponibilidad es la opción correcta porque garantiza alta disponibilidad y resiliencia frente a fallas de zona de disponibilidad. Al implementar un NAT Gateway en cada zona de disponibilidad y enrutar el tráfico de las subredes privadas hacia el NAT Gateway en la misma zona, se evita el punto único de falla y se optimizan los costos al utilizar un solo NAT Gateway por zona.\n\nUn NAT Gateway permite que las instancias en subredes privadas accedan a Internet mientras impide conexiones entrantes desde Internet.\nLos NAT Gateways son específicos por zona de disponibilidad, por lo que si se desea alta disponibilidad, es necesario implementar uno en cada zona utilizada por la aplicación.\nAWS gestiona automáticamente la escalabilidad y la alta disponibilidad dentro de cada zona de disponibilidad.\n\n\nOpciones incorrectas:\n\nCrear dos NAT Gateways en cada zona de disponibilidad. Configurar la tabla de rutas en cada subred pública para garantizar que las instancias utilicen el NAT Gateway en la misma zona de disponibilidad - Crear dos NAT Gateways en cada zona de disponibilidad es incorrecto porque implementar dos NAT Gateways por zona es redundante y no mejora la disponibilidad más allá de lo que ofrece un solo NAT Gateway por zona. Esto incrementa los costos innecesariamente.\n\nCrear un NAT Gateway en cada zona de disponibilidad. Configurar la tabla de rutas en cada subred pública para garantizar que las instancias utilicen el NAT Gateway en la misma zona de disponibilidad - Configurar la tabla de rutas en cada subred pública es incorrecto porque las subredes públicas no necesitan un NAT Gateway; las subredes privadas son las que requieren acceso a Internet a través del NAT Gateway.\n\nCrear tres NAT Gateways en cada zona de disponibilidad. Configurar la tabla de rutas en cada subred privada para garantizar que las instancias utilicen el NAT Gateway en la misma zona de disponibilidad - Crear tres NAT Gateways en cada zona de disponibilidad es incorrecto porque es excesivo y no añade valor adicional en términos de disponibilidad o resiliencia. Un NAT Gateway por zona es suficiente debido a la redundancia integrada en la infraestructura de AWS.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html\n\nhttps://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-comparison.html"
  },
  {
    "q": "Una entidad gubernamental está realizando un censo de población y vivienda en la ciudad. La información de cada hogar cargada en su portal en línea se almacena en archivos cifrados en Amazon S3. El gobierno asignó a su Solutions Architect la tarea de establecer políticas de cumplimiento que verifiquen que los datos que contienen información de identificación personal (PII) cumplen con sus estándares de cumplimiento. También deben recibir alertas si hay posibles violaciones de políticas relacionadas con la privacidad de sus buckets S3.\n¿Cuál de las siguientes opciones debería implementar el arquitecto para satisfacer este requisito?",
    "o": [
      "Configurar y establecer Amazon Polly para escanear patrones de uso en sus datos de Amazon S3",
      "Configurar y establecer Amazon Kendra para monitorear actividades maliciosas en sus datos de Amazon S3",
      "Configurar y establecer Amazon Fraud Detector para enviar alertas cuando se detecten violaciones de seguridad en sus datos de Amazon S3",
      "Configurar y establecer Amazon Macie para monitorear sus datos en Amazon S3"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nConfigurar y establecer Amazon Macie para monitorear sus datos en Amazon S3 - Configurar y establecer Amazon Macie para monitorear sus datos en Amazon S3 es la solución adecuada para este escenario. Amazon Macie utiliza Machine Learning para descubrir, clasificar y proteger datos sensibles almacenados en S3, como la información de identificación personal (PII). Además, Macie evalúa las políticas de acceso de los buckets S3 y alerta sobre posibles violaciones de privacidad o configuración indebida. Esta herramienta ofrece visibilidad sobre dónde se almacenan los datos y cómo se utilizan en la organización, asegurando el cumplimiento de estándares de privacidad y seguridad.\n\nAmazon Macie genera dos tipos de hallazgos:\n\nPolicy Findings: Reportes detallados sobre posibles violaciones de políticas de privacidad.\nSensitive Data Findings: Informes sobre datos sensibles descubiertos en los objetos S3.\nAl configurar Macie, se pueden establecer alertas automáticas para notificar de inmediato cualquier hallazgo relacionado con la privacidad o seguridad de los datos.\n\n\n\nOpciones incorrectas:\n\nConfigurar y establecer Amazon Fraud Detector para enviar alertas cuando se detecten violaciones de seguridad en sus datos de Amazon S3 - Configurar y establecer Amazon Fraud Detector es incorrecto ya que este servicio está diseñado para identificar actividades fraudulentas, como transacciones sospechosas, y no para monitorear datos en S3 ni verificar el cumplimiento de políticas de privacidad.\n\nConfigurar y establecer Amazon Polly para escanear patrones de uso en sus datos de Amazon S3 - Configurar y establecer Amazon Polly es incorrecto porque Amazon Polly es un servicio de conversión de texto a voz y no proporciona funcionalidades de monitoreo ni análisis de datos en S3.\n\nConfigurar y establecer Amazon Kendra para monitorear actividades maliciosas en sus datos de Amazon S3 - Configurar y establecer Amazon Kendra es incorrecto ya que Kendra es un motor de búsqueda inteligente para descubrir información en el contenido de la empresa, pero no puede monitorear actividades maliciosas o analizar datos en S3 para cumplimiento de privacidad.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/macie/latest/userguide/what-is-macie.html\n\nhttps://aws.amazon.com/macie/"
  },
  {
    "q": "Una empresa de logística global necesita una solución para recibir manifiestos de carga enviados por proveedores mediante SFTP. Estos archivos deben almacenarse de forma segura, con alta disponibilidad, y cifrados en reposo. Además, deben eliminarse automáticamente después de 45 días para cumplir con las políticas internas de retención de datos.\n¿Cuál de las siguientes opciones ofrece la mejor solución con el menor esfuerzo operativo?",
    "o": [
      "Implementar AWS Storage Gateway tipo File Gateway y montar un recurso compartido de archivos en la red local. Configurar reglas locales para eliminación manual de archivos antiguos",
      "Utilizar AWS Transfer Family con SFTP para cargar los archivos de manera segura en un bucket de Amazon S3 con cifrado habilitado. Configurar una regla de ciclo de vida en S3 para eliminar automáticamente los archivos después de 45 días",
      "Configurar un bucket de S3 público con cifrado y solicitar a los proveedores que suban sus archivos directamente usando clientes compatibles con HTTP PUT. Eliminar los archivos manualmente después de 45 días",
      "Configurar una instancia de Amazon EC2 con un servidor SFTP. Montar un volumen EBS cifrado en la instancia y usar un script cron para eliminar los archivos después de 45 días"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nUtilizar AWS Transfer Family con SFTP para cargar los archivos de manera segura en un bucket de Amazon S3 con cifrado habilitado. Configurar una regla de ciclo de vida en S3 para eliminar automáticamente los archivos después de 45 días - AWS Transfer Family con SFTP permite transferencias seguras mediante el protocolo estándar, mientras que Amazon S3 proporciona un almacenamiento altamente disponible, cifrado en reposo y con soporte para reglas de ciclo de vida que permiten eliminar automáticamente archivos después de un período determinado. Esta combinación reduce la carga operativa significativamente.\n\n\n\nOpciones incorrectas:\n\nConfigurar una instancia de Amazon EC2 con un servidor SFTP. Montar un volumen EBS cifrado en la instancia y usar un script cron para eliminar los archivos después de 45 días - Usar EC2 como servidor SFTP implica mantenimiento de sistema operativo, configuración de seguridad, administración de discos EBS y scripting manual para borrar archivos, lo que aumenta el esfuerzo operativo y el riesgo de error humano.\n\nImplementar AWS Storage Gateway tipo File Gateway y montar un recurso compartido de archivos en la red local. Configurar reglas locales para eliminación manual de archivos antiguos - AWS Storage Gateway está diseñado para extender almacenamiento en la nube hacia entornos on-premises. Aunque puede almacenar archivos en S3, no permite configuraciones automáticas de eliminación de archivos directamente desde el gateway. Además, agrega complejidad innecesaria.\n\nConfigurar un bucket de S3 público con cifrado y solicitar a los proveedores que suban sus archivos directamente usando clientes compatibles con HTTP PUT. Eliminar los archivos manualmente después de 45 días - Permitir cargas a un bucket S3 público mediante HTTP PUT carece de controles de autenticación robustos y expone riesgos de seguridad. Además, requiere eliminación manual de archivos, lo cual no cumple con el objetivo de automatización ni con las buenas prácticas de seguridad.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/transfer/latest/userguide/what-is.html\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lifecycle-mgmt.html"
  },
  {
    "q": "Una empresa desea consultar datos que residen en múltiples cuentas de AWS desde un lago de datos central. Cada cuenta tiene su propio bucket de Amazon S3 que almacena datos únicos para su función empresarial. Los usuarios de diferentes cuentas deben tener acceso al lago de datos según sus roles.\n¿Qué solución minimizará la sobrecarga y los costos mientras cumple con los patrones de acceso requeridos?",
    "o": [
      "Utilizar AWS Lake Formation para consolidar datos de múltiples cuentas en una sola cuenta",
      "Crear una función Lambda programada para transferir datos de múltiples cuentas a los buckets S3 de una cuenta central",
      "Utilizar AWS Control Tower para gestionar centralmente los buckets de S3 de cada cuenta",
      "Utilizar Amazon Data Firehose para consolidar datos de múltiples cuentas en una sola cuenta"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nUtilizar AWS Lake Formation para consolidar datos de múltiples cuentas en una sola cuenta - AWS Lake Formation es un servicio que facilita la configuración de un lago de datos seguro en cuestión de días. Centraliza y asegura los datos, almacenándolos en su forma original para el análisis. AWS Lake Formation permite compartir datos de manera eficiente entre cuentas sin necesidad de mover físicamente los datos, minimizando la sobrecarga y los costos. Además, se integra con AWS Glue para crear un catálogo de datos y controlar el acceso mediante permisos detallados basados en roles de IAM o usuarios de Active Directory.\n\n\n\nOpciones incorrectas:\n\nUtilizar AWS Control Tower para gestionar centralmente los buckets de S3 de cada cuenta - No ofrece la capacidad de consolidar o compartir datos eficientemente en un lago de datos centralizado.\n\nCrear una función Lambda programada para transferir datos de múltiples cuentas a los buckets S3 de una cuenta central - Aunque es técnicamente posible usar Lambda y el SDK de AWS para mover datos, esta solución sería compleja de implementar y mantener. Requiere manejo de permisos transversales y costos adicionales asociados a las transferencias de datos.\n\nUtilizar Amazon Data Firehose para consolidar datos de múltiples cuentas en una sola cuenta - Amazon Data Firehose está diseñado para la ingesta continua de datos de streaming hacia destinos como S3 o Redshift. Configurar Firehose en múltiples cuentas para consolidar datos sería costoso e innecesariamente complejo en comparación con la solución más directa de Lake Formation.\n\nReferencias:\n\nhttps://aws.amazon.com/lake-formation/\n\nhttps://docs.aws.amazon.com/lake-formation/latest/dg/how-it-works.html"
  },
  {
    "q": "Una plataforma de distribución de contenido multimedia ofrece descargas de software y documentos a través de Amazon S3. Recientemente, detectaron que otros sitios están enlazando directamente a sus archivos, generando un aumento significativo en el uso de ancho de banda sin aportar ingresos ni visibilidad a la empresa.\n¿Cuál es la solución más efectiva para prevenir que otros sitios web accedan a los archivos sin autorización?",
    "o": [
      "Almacenar los archivos en Amazon EFS y compartirlos mediante NFS desde una instancia EC2",
      "Distribuir los archivos mediante Amazon CloudFront para mejorar el rendimiento global",
      "Aplicar reglas con AWS WAF para bloquear peticiones que provengan de dominios externos no autorizados",
      "Configurar el bucket de S3 para deshabilitar el acceso público y utilizar URL pre-firmadas con tiempo de expiración para controlar el acceso"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nConfigurar el bucket de S3 para deshabilitar el acceso público y utilizar URL pre-firmadas con tiempo de expiración para controlar el acceso - Las URL pre-firmadas de S3 son la mejor defensa contra el hotlinking. Solo los usuarios o aplicaciones que posean una URL firmada válida y con tiempo de expiración podrán acceder al archivo. Esto permite que el acceso sea temporal y controlado, y evita que otras páginas reutilicen los enlaces directamente. Además, se pueden generar dinámicamente desde aplicaciones backend, otorgando aún más seguridad.\n\n\n\nOpciones incorrectas:\n\nDistribuir los archivos mediante Amazon CloudFront para mejorar el rendimiento global - Aunque Amazon CloudFront mejora significativamente la velocidad de entrega y la experiencia del usuario final al distribuir contenido mediante su red global de edge locations, por sí solo no evita el hotlinking. Para prevenir que otros sitios enlacen tus archivos, debes usar CloudFront signed URLs o signed cookies, o configurar una política basada en encabezados (como Referer). Sin estas configuraciones adicionales, CloudFront seguiría sirviendo los archivos a cualquier solicitud válida.\n\nAplicar reglas con AWS WAF para bloquear peticiones que provengan de dominios externos no autorizados - AWS WAF está diseñado para proteger aplicaciones web de amenazas como inyecciones SQL, XSS o bots maliciosos. Aunque es posible configurar reglas para bloquear ciertos Referer o patrones de URL, esto no es su propósito principal y no se integra directamente con Amazon S3 para proteger buckets. Además, las reglas basadas en Referer pueden ser fácilmente manipuladas por atacantes, lo que limita su eficacia contra hotlinking.\n\nAlmacenar los archivos en Amazon EFS y compartirlos mediante NFS desde una instancia EC2 - Amazon EFS es un sistema de archivos en red destinado a ser montado en instancias EC2, típicamente en entornos Linux. No está diseñado para servir contenido directamente al público a través de HTTP o HTTPS, lo cual requiere configuración adicional y servidores web sobre EC2. Además, no soluciona el problema del hotlinking, y su uso en este contexto sería innecesariamente complejo y costoso comparado con S3 + URLs pre-firmadas.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/ShareObjectPreSignedURL.html\n\nhttps://aws.amazon.com/cloudfront/"
  },
  {
    "q": "Una empresa planea alojar una aplicación web en un grupo de Auto Scaling de instancias Amazon EC2. La aplicación será utilizada globalmente por usuarios para cargar y almacenar varios tipos de archivos. Basado en las tendencias de uso del usuario, los archivos que tengan más de 2 años deben almacenarse en una clase de almacenamiento diferente. El arquitecto de soluciones de la empresa necesita crear una solución escalable y rentable para almacenar los archivos antiguos, al mismo tiempo que proporciona durabilidad y alta disponibilidad.\n¿Cuál de los siguientes enfoques se puede utilizar para cumplir con este requisito? (Selecciona DOS)",
    "o": [
      "Utilizar Amazon S3 y crear una política de ciclo de vida que moverá los objetos a Amazon S3 Glacier después de 2 años",
      "Utilizar Amazon S3 y crear una política de ciclo de vida que moverá los objetos a Amazon S3 Standard-IA después de 2 años",
      "Utilizar volúmenes Amazon EBS para almacenar los archivos. Configurar Amazon Data Lifecycle Manager (DLM) para programar snapshots de los volúmenes después de 2 años",
      "Utilizar una configuración RAID 0 que distribuya múltiples volúmenes de Amazon EBS para almacenar los archivos. Configurar Amazon Data Lifecycle Manager (DLM) para programar snapshots de los volúmenes después de 2 años",
      "Utilizar Amazon EFS y crear una política de ciclo de vida que moverá los objetos a Amazon EFS-IA después de 2 años"
    ],
    "a": [
      0,
      1
    ],
    "e": "Correcto:\n\nUtilizar Amazon S3 y crear una política de ciclo de vida que moverá los objetos a Amazon S3 Glacier después de 2 años - Amazon S3 Glacier es ideal para el almacenamiento a largo plazo de datos a los que se accede rara vez, y ofrece costos bajos de almacenamiento. La política de ciclo de vida de S3 permite mover automáticamente los objetos a S3 Glacier una vez que cumplen 2 años, optimizando costos y almacenamiento.\n\nUtilizar Amazon S3 y crear una política de ciclo de vida que moverá los objetos a Amazon S3 Standard-IA después de 2 años - Amazon S3 Standard-IA (Infrequent Access) ofrece un costo de almacenamiento más bajo que el S3 Standard y está diseñado para datos a los que se accede con poca frecuencia, pero que requieren acceso rápido cuando se necesitan. La política de ciclo de vida de S3 permite mover automáticamente los objetos a S3 Standard-IA después de 2 años, asegurando una solución escalable y rentable.\n\n\n\n\n\nOpciones incorrectas:\n\nUtilizar volúmenes Amazon EBS para almacenar los archivos. Configurar Amazon Data Lifecycle Manager (DLM) para programar snapshots de los volúmenes después de 2 años - Amazon EBS es más costoso y no es tan escalable como Amazon S3 para el almacenamiento de archivos estáticos. Además, las snapshots de EBS no mueven datos a una clase de almacenamiento más rentable, simplemente crean copias de seguridad.\n\nUtilizar una configuración RAID 0 que distribuya múltiples volúmenes de Amazon EBS para almacenar los archivos. Configurar Amazon Data Lifecycle Manager (DLM) para programar snapshots de los volúmenes después de 2 años - RAID 0 puede ofrecer alto rendimiento, pero no proporciona redundancia o durabilidad. Si falla un volumen, se pierde toda la información almacenada. No es una solución rentable ni escalable en comparación con las opciones de Amazon S3.\n\nUtilizar Amazon EFS y crear una política de ciclo de vida que moverá los objetos a Amazon EFS-IA después de 2 años - Amazon EFS proporciona políticas de ciclo de vida, pero solo permite mover datos al almacenamiento EFS-IA después de 365 días como máximo. No cumple con el requisito de mover datos que tienen más de 2 años.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html\n\nhttps://aws.amazon.com/s3/glacier/\n\nhttps://docs.aws.amazon.com/efs/latest/ug/lifecycle-management-efs.html"
  },
  {
    "q": "Una empresa tiene una arquitectura en la nube compuesta por instancias EC2 de Linux y Windows que procesan altos volúmenes de datos científicos las 24 horas del día, los 7 días de la semana.\nPara garantizar la alta disponibilidad de los sistemas, el arquitecto de soluciones necesita crear una solución que permita monitorear las métricas de utilización de memoria y disco de todas las instancias.\n¿Cuál de las siguientes es la solución de monitoreo más adecuada para implementar?",
    "o": [
      "Usar la configuración predeterminada de CloudWatch en las instancias EC2 donde las métricas de utilización de memoria y disco ya están disponibles. Instalar el agente de AWS Systems Manager (SSM) en todas las instancias EC2",
      "Usar Amazon Inspector e instalar el agente de Inspector en todas las instancias EC2",
      "Instalar el CloudWatch Agent en todas las instancias EC2 para recopilar datos de utilización de memoria y disco. Ver las métricas personalizadas en la consola de Amazon CloudWatch",
      "Habilitar la opción de Enhanced Monitoring en EC2 e instalar CloudWatch Agent en todas las instancias EC2 para poder ver la utilización de memoria y disco en el panel de CloudWatch"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nInstalar el CloudWatch Agent en todas las instancias EC2 para recopilar datos de utilización de memoria y disco. Ver las métricas personalizadas en la consola de Amazon CloudWatch - El CloudWatch Agent permite recopilar métricas personalizadas como la utilización de memoria, intercambio de disco (swap), utilización de espacio en disco y utilización de archivos de página, que no están disponibles de forma predeterminada en CloudWatch. Este agente es compatible con instancias de Windows y Linux y puede instalarse en servidores locales y en instancias EC2. Las métricas recopiladas se envían a CloudWatch como métricas personalizadas, que luego pueden visualizarse en el panel de CloudWatch.\n\nEl CloudWatch Agent permite seleccionar métricas específicas a recopilar, incluidos recursos del sistema operativo y submétricas como la utilización por núcleo de CPU.\nEste agente admite métricas detalladas para sistemas Linux y Windows y es ideal para monitorear la utilización de recursos en tiempo real.\nEs recomendable usar el CloudWatch Agent en lugar de los antiguos Custom Daemon Scripts, ya que proporciona soporte continuo y actualizaciones de AWS.\n\n\nOpciones incorrectas:\n\nUsar la configuración predeterminada de CloudWatch en las instancias EC2 donde las métricas de utilización de memoria y disco ya están disponibles. Instalar el agente de AWS Systems Manager (SSM) en todas las instancias EC2 - La configuración predeterminada de CloudWatch en EC2 no incluye métricas de utilización de memoria ni disco. Se requiere el CloudWatch Agent para recopilar estos datos. Además, el SSM Agent se utiliza principalmente para administración remota, no para recopilación de métricas.\n\nHabilitar la opción de Enhanced Monitoring en EC2 e instalar CloudWatch Agent en todas las instancias EC2 para poder ver la utilización de memoria y disco en el panel de CloudWatch - Enhanced Monitoring solo está disponible para Amazon RDS y no para instancias EC2. Aunque CloudWatch Agent recopila métricas detalladas, Enhanced Monitoring no aplicaría en este caso.\n\nUsar Amazon Inspector e instalar el agente de Inspector en todas las instancias EC2 - Amazon Inspector es una herramienta de evaluación de seguridad para identificar vulnerabilidades y problemas de cumplimiento. No recopila métricas de utilización de memoria o disco en instancias EC2.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring_ec2.html\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/mon-scripts.html#using_put_script"
  },
  {
    "q": "Una empresa de análisis de datos en tiempo real ofrece APIs para transmitir dashboards personalizados a clientes empresariales. Estas APIs están gestionadas mediante Amazon API Gateway en configuración regional. Se está desarrollando una nueva versión de las APIs con mejoras en el rendimiento de respuesta y validación de tokens. El equipo busca una forma de desplegar la nueva versión de forma gradual, monitoreando el comportamiento antes de aplicar el cambio a todos los clientes. También desean minimizar costos y evitar interrupciones.\n¿Cuál es la estrategia de despliegue más adecuada en este caso?",
    "o": [
      "Usar una estrategia de despliegue Canary en API Gateway, dirigiendo inicialmente solo una pequeña fracción del tráfico a la nueva versión. Monitorear errores y métricas antes de aumentar gradualmente la distribución",
      "Actualizar la configuración de integración de la API en producción para apuntar al nuevo backend, manteniendo la misma definición de recursos y métodos",
      "Duplicar el API Gateway existente y crear una nueva etapa para la API actualizada. Una vez validado, redirigir manualmente todo el tráfico a esta nueva etapa",
      "Exportar la definición actual de la API, modificarla localmente e importarla como una API nueva en modo reemplazo (overwrite), reemplazando la anterior"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nUsar una estrategia de despliegue Canary en API Gateway, dirigiendo inicialmente solo una pequeña fracción del tráfico a la nueva versión. Monitorear errores y métricas antes de aumentar gradualmente la distribución - El despliegue Canary en Amazon API Gateway permite realizar lanzamientos graduales sin necesidad de duplicar la infraestructura. Se puede asignar un porcentaje del tráfico a la nueva versión, monitorear errores o métricas personalizadas, y escalar el tráfico de manera controlada. Esto reduce riesgos y evita interrupciones.\n\n\n\n\n\nOpciones incorrectas:\n\nDuplicar el API Gateway existente y crear una nueva etapa para la API actualizada. Una vez validado, redirigir manualmente todo el tráfico a esta nueva etapa - Aunque crear una nueva etapa puede facilitar pruebas, no es un despliegue gradual. Además, redirigir tráfico manualmente implica más gestión y posibles errores humanos.\n\nExportar la definición actual de la API, modificarla localmente e importarla como una API nueva en modo reemplazo (overwrite), reemplazando la anterior - Importar en modo overwrite reemplaza la API existente inmediatamente, lo que puede provocar interrupciones si hay errores en la nueva versión. No permite monitoreo progresivo.\n\nActualizar la configuración de integración de la API en producción para apuntar al nuevo backend, manteniendo la misma definición de recursos y métodos - Cambiar directamente la configuración de backend sin versionado ni transición controlada es riesgoso y no proporciona visibilidad sobre el impacto del cambio.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/canary-release.html\n\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-import-api-update.html"
  },
  {
    "q": "Una aplicación se ejecuta en instancias de Amazon EC2 en una subred privada detrás de un Application Load Balancer en una subred pública. La aplicación es altamente disponible y está distribuida a través de múltiples zonas de disponibilidad (AZs). Las instancias de EC2 deben realizar llamadas API a un servicio basado en internet.\n¿Cómo puede el arquitecto de soluciones habilitar conectividad a internet altamente disponible?",
    "o": [
      "Crear una puerta de enlace NAT y adjuntarla a la VPC. Agregar una ruta a la puerta de enlace a cada tabla de rutas de subred privada",
      "Crear una instancia NAT en la subred privada de cada AZ. Actualizar las tablas de rutas para cada subred privada para dirigir el tráfico con destino a internet a la instancia NAT",
      "Crear una puerta de enlace NAT en la subred pública de cada AZ. Actualizar las tablas de rutas para cada subred privada para dirigir el tráfico con destino a internet a la puerta de enlace NAT",
      "Configurar una puerta de enlace de internet. Agregar una ruta a la puerta de enlace a cada tabla de rutas de subred privada"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nCrear una puerta de enlace NAT en la subred pública de cada AZ. Actualizar las tablas de rutas para cada subred privada para dirigir el tráfico con destino a internet a la puerta de enlace NAT - La puerta de enlace NAT (NAT Gateway) permite a las instancias en subredes privadas acceder a internet sin exponerlas directamente. Debe crearse en una subred pública con una IP pública y conectarse a la puerta de enlace de internet. Para alta disponibilidad, se recomienda crear una puerta de enlace NAT por cada zona de disponibilidad y actualizar las tablas de rutas de las subredes privadas para dirigir el tráfico hacia la puerta de enlace NAT correspondiente.\n\nOpciones incorrectas:\n\nCrear una instancia NAT en la subred privada de cada AZ. Actualizar las tablas de rutas para cada subred privada para dirigir el tráfico con destino a internet a la instancia NAT - Las instancias NAT deben estar en subredes públicas, no privadas. Además, requieren mantenimiento manual, lo que las hace menos recomendables que las NAT Gateway.\n\nCrear una puerta de enlace NAT y adjuntarla a la VPC. Agregar una ruta a la puerta de enlace a cada tabla de rutas de subred privada - No se puede adjuntar una puerta de enlace NAT directamente a una VPC; debe asociarse a una subred pública específica.\n\nConfigurar una puerta de enlace de internet. Agregar una ruta a la puerta de enlace a cada tabla de rutas de subred privada - Las instancias en subredes privadas no pueden usar una puerta de enlace de internet directamente, ya que no tienen direcciones IP públicas.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html\n\nhttps://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-comparison.html"
  },
  {
    "q": "Una empresa tiene una arquitectura de nube híbrida que conecta su centro de datos on-premises e infraestructura en la nube en AWS. Necesitan una solución de almacenamiento duradera para respaldar sus documentos corporativos almacenados on-premises y un caché local que proporcione acceso de baja latencia a sus documentos accedidos recientemente para reducir costos de datos.\nLos documentos deben almacenarse y recuperarse desde AWS a través del protocolo Server Message Block (SMB). Estos archivos deben estar inmediatamente accesibles durante seis meses y archivados por otra década para cumplir con las normativas.\n¿Cuál de las siguientes opciones es el enfoque más rentable y adecuado para implementar este escenario?",
    "o": [
      "Usar AWS Snowmobile para migrar todos los archivos desde la red on-premises. Sube los documentos a un bucket de S3 y configura una política de ciclo de vida para mover los datos a Glacier para su archivado",
      "Lanzar un nuevo tape gateway que conecte tu centro de datos on-premises usando AWS Storage Gateway. Sube los documentos al tape gateway y configura una política de ciclo de vida para mover los datos a Glacier para su archivado",
      "Lanzar un nuevo file gateway que conecte tu centro de datos on-premises usando AWS Storage Gateway. Sube los documentos al file gateway y configura una política de ciclo de vida para mover los datos a Glacier para su archivado",
      "Establecer una conexión Direct Connect para integrar tu red on-premises con tu VPC. Sube los documentos en Amazon EBS Volumes y utiliza una política de ciclo de vida para mover automáticamente las instantáneas de EBS a un bucket de S3, y luego a Glacier para su archivado"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nLanzar un nuevo file gateway que conecte tu centro de datos on-premises usando AWS Storage Gateway. Sube los documentos al file gateway y configura una política de ciclo de vida para mover los datos a Glacier para su archivado - Lanzar un nuevo file gateway que conecte tu centro de datos on-premises usando AWS Storage Gateway. Sube los documentos al file gateway y configura una política de ciclo de vida para mover los datos a Glacier para su archivado. AWS Storage Gateway (file gateway) ofrece una interfaz de archivo en Amazon S3 y combina un servicio en la nube con un dispositivo virtual. Utilizando SMB o NFS, puedes almacenar y recuperar objetos en S3 como archivos o puntos de montaje de archivos. Una vez almacenados en S3, se pueden configurar políticas de ciclo de vida para mover los datos a Glacier, optimizando costos a largo plazo mientras se mantienen accesibles para un acceso rápido en los primeros seis meses.\n\n\n\nOpciones incorrectas:\n\nLanzar un nuevo tape gateway que conecte tu centro de datos on-premises usando AWS Storage Gateway. Sube los documentos al tape gateway y configura una política de ciclo de vida para mover los datos a Glacier para su archivado - Lanzar un nuevo tape gateway que conecte tu centro de datos on-premises usando AWS Storage Gateway. Sube los documentos al tape gateway y configura una política de ciclo de vida para mover los datos a Glacier para su archivado. Aunque tape gateway ofrece almacenamiento duradero y económico en Amazon Glacier, no mantiene un caché local para acceso de baja latencia a datos recientemente utilizados.\n\nEstablecer una conexión Direct Connect para integrar tu red on-premises con tu VPC. Sube los documentos en Amazon EBS Volumes y utiliza una política de ciclo de vida para mover automáticamente las instantáneas de EBS a un bucket de S3, y luego a Glacier para su archivado - Establecer una conexión Direct Connect para integrar tu red on-premises con tu VPC. Sube los documentos en Amazon EBS Volumes y utiliza una política de ciclo de vida para mover automáticamente las instantáneas de EBS a un bucket de S3, y luego a Glacier para su archivado. Aunque esta opción proporciona una conexión de alta velocidad, usar EBS no es tan rentable como S3 para almacenamiento a largo plazo, y no ofrece un acceso eficiente a datos a través de SMB.\n\nUsar AWS Snowmobile para migrar todos los archivos desde la red on-premises. Sube los documentos a un bucket de S3 y configura una política de ciclo de vida para mover los datos a Glacier para su archivado - Usar AWS Snowmobile para migrar todos los archivos desde la red on-premises. Sube los documentos a un bucket de S3 y configura una política de ciclo de vida para mover los datos a Glacier para su archivado. Snowmobile está diseñado para grandes migraciones de datos iniciales y no es adecuado para un entorno híbrido donde se requiere acceso continuo a datos on-premises y en la nube.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html\n\nhttps://docs.aws.amazon.com/storagegateway/latest/userguide/StorageGatewayConcepts.html"
  },
  {
    "q": "Una empresa utiliza un Application Load Balancer (ALB) para sus aplicaciones web de múltiples niveles orientadas al público. El equipo de seguridad ha informado recientemente un aumento de ataques de SQL injection, lo que causa problemas críticos de discrepancia de datos. El mismo problema también afecta a otras aplicaciones web en otras cuentas de AWS que están detrás de un ALB. Se requiere una solución inmediata para prevenir la inyección remota de consultas SQL no autorizadas y proteger sus aplicaciones en múltiples cuentas de AWS.\nComo Solutions Architect, ¿qué solución recomendarías?",
    "o": [
      "Utilizar Amazon Macie para buscar vulnerabilidades y exposición ilimitada de la red. Refactorizar la aplicación web para ser menos susceptible a ataques de SQL injection basándose en la evaluación de seguridad. Utilizar AWS Audit Manager para reutilizar la evaluación de seguridad en todas las cuentas de AWS",
      "Utilizar AWS Network Firewall para filtrar vulnerabilidades web y ataques de fuerza bruta mediante stateful rule groups en todos los Application Load Balancers en todas las cuentas de AWS. Refactorizar la aplicación web para ser menos susceptible a ataques de SQL injection basándose en la evaluación de seguridad",
      "Utilizar AWS WAF y configurar un managed rule group para bloquear patrones de solicitudes asociados con la explotación de bases de datos SQL, como ataques de SQL injection. Asociarlo con el Application Load Balancer. Integrar AWS WAF con AWS Firewall Manager para reutilizar las reglas en todas las cuentas de AWS",
      "Utilizar Amazon GuardDuty y configurar un managed rule group para bloquear patrones de solicitudes asociados con la explotación de bases de datos SQL, como ataques de SQL injection. Asociarlo con el Application Load Balancer y utilizar AWS Security Hub para reutilizar las reglas en todas las cuentas de AWS"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nUtilizar AWS WAF y configurar un managed rule group para bloquear patrones de solicitudes asociados con la explotación de bases de datos SQL, como ataques de SQL injection. Asociarlo con el Application Load Balancer. Integrar AWS WAF con AWS Firewall Manager para reutilizar las reglas en todas las cuentas de AWS - Utilizar AWS WAF y configurar un managed rule group para bloquear patrones de solicitudes asociados con la explotación de bases de datos SQL, como ataques de SQL injection es la opción correcta. AWS WAF permite monitorear y controlar las solicitudes HTTP(S) hacia el ALB. Al usar AWSManagedRulesSQLiRuleSet, se pueden bloquear patrones de inyección de SQL, protegiendo contra consultas SQL no autorizadas. Integrar AWS WAF con AWS Firewall Manager permite centralizar la administración y reutilizar las reglas en múltiples cuentas.\n\n\n\nOpciones incorrectas:\n\nUtilizar AWS Network Firewall para filtrar vulnerabilidades web y ataques de fuerza bruta mediante stateful rule groups en todos los Application Load Balancers en todas las cuentas de AWS. Refactorizar la aplicación web para ser menos susceptible a ataques de SQL injection basándose en la evaluación de seguridad - Utilizar AWS Network Firewall es incorrecto porque este servicio se utiliza para la protección de redes VPC y no se integra directamente con ALB. Requeriría una refactorización significativa de la aplicación web, lo cual no es una solución inmediata. Además, AWS Network Firewall no proporciona reglas gestionadas para ataques de SQL injection como lo hace AWS WAF.\n\nUtilizar Amazon Macie para buscar vulnerabilidades y exposición ilimitada de la red. Refactorizar la aplicación web para ser menos susceptible a ataques de SQL injection basándose en la evaluación de seguridad. Utilizar AWS Audit Manager para reutilizar la evaluación de seguridad en todas las cuentas de AWS - Utilizar Amazon Macie es incorrecto ya que Macie está diseñado para la clasificación y protección de datos confidenciales en S3 y no para la protección de aplicaciones web contra ataques de SQL injection. AWS Audit Manager ayuda en la evaluación de conformidad, pero no previene o mitiga ataques de seguridad en tiempo real.\n\nUtilizar Amazon GuardDuty y configurar un managed rule group para bloquear patrones de solicitudes asociados con la explotación de bases de datos SQL, como ataques de SQL injection. Asociarlo con el Application Load Balancer y utilizar AWS Security Hub para reutilizar las reglas en todas las cuentas de AWS - Utilizar Amazon GuardDuty es incorrecto porque GuardDuty solo proporciona monitoreo de amenazas y alertas, pero no bloquea activamente patrones de inyección de SQL. Además, no se integra con ALB ni reutiliza reglas gestionadas como lo hace AWS WAF.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/waf/latest/developerguide/how-aws-waf-works.html\n\nhttps://docs.aws.amazon.com/waf/latest/developerguide/managed-rule-groups-use-case-sql-db.html"
  },
  {
    "q": "Una empresa farmacéutica tiene recursos alojados tanto en su red local como en la nube de AWS. Quieren que todos sus arquitectos de software accedan a los recursos en ambos entornos utilizando sus credenciales locales, que se almacenan en Active Directory.\nEn este escenario, ¿cuál de las siguientes opciones se puede utilizar para cumplir con este requisito?",
    "o": [
      "Configurar una federación basada en SAML 2.0 utilizando una Web Identity Federation",
      "Usar usuarios de IAM",
      "Usar Amazon VPC",
      "Configurar una federación basada en SAML 2.0 utilizando un Microsoft Active Directory Federation Service (AD FS)"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nConfigurar una federación basada en SAML 2.0 utilizando un Microsoft Active Directory Federation Service (AD FS) - Dado que la empresa utiliza Microsoft Active Directory, que implementa Security Assertion Markup Language (SAML), se puede configurar una federación basada en SAML para el acceso a la API de AWS. Esto permite el inicio de sesión único federado (SSO), lo que permite a los usuarios iniciar sesión en la Consola de administración de AWS o llamar a las APIs de AWS utilizando sus credenciales locales sin necesidad de crear un usuario de IAM para cada uno. Al usar SAML, se simplifica el proceso de federación con AWS, ya que se puede usar el servicio de IdP de AD FS en lugar de escribir código proxy de identidad personalizado.\n\n\n\nOpciones incorrectas:\n\nUsar usuarios de IAM - No es adecuado porque el requisito establece que se utilicen las credenciales locales almacenadas en Active Directory, y crear usuarios de IAM sería una administración adicional e innecesaria.\n\nConfigurar una federación basada en SAML 2.0 utilizando una Web Identity Federation - No es aplicable porque las Web Identity Federation se utilizan principalmente para permitir que los usuarios inicien sesión utilizando un proveedor de identidad (IdP) externo bien conocido como Login con Amazon, Facebook o Google. No utiliza Active Directory.\n\nUsar Amazon VPC - Amazon VPC solo permite aprovisionar una sección aislada de la nube de AWS para lanzar recursos de AWS. No tiene relación con la autenticación de usuarios o Active Directory.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_saml.html\n\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers.html"
  },
  {
    "q": "Una organización de investigación médica quiere construir un sistema que pueda predecir el abuso de prescripción de medicamentos. Recopilarán datos en tiempo real de múltiples fuentes, incluidos datos de Información de Identificación Personal (PII). Es crucial que esta información sensible sea anonimizada antes de almacenarse en una base de datos NoSQL para su posterior procesamiento.\n¿Cuál solución cumpliría con los requisitos?",
    "o": [
      "Ingerir datos en tiempo real utilizando Amazon Kinesis Data Stream. Utilizar una función Lambda para anonimizar la PII y luego almacenarla en Amazon DynamoDB",
      "Crear un data lake en Amazon S3 y usarlo como almacenamiento principal para datos de salud de pacientes. Utilizar un trigger de S3 para ejecutar una función Lambda que realice la anonimización. Enviar los datos anonimizados a Amazon DynamoDB",
      "Desplegar un stream de Amazon Data Firehose para capturar y transformar los datos en tiempo real. Entregar los datos anonimizados a Amazon Redshift para su análisis",
      "Transmitir los datos en una tabla de Amazon DynamoDB. Habilitar DynamoDB Streams y configurar una función que realice la anonimización en los elementos recién escritos"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nIngerir datos en tiempo real utilizando Amazon Kinesis Data Stream. Utilizar una función Lambda para anonimizar la PII y luego almacenarla en Amazon DynamoDB - Ingerir datos en tiempo real utilizando Amazon Kinesis Data Stream permite capturar datos en tiempo real de múltiples fuentes. Luego, una función Lambda procesa estos datos para anonimizar la Información de Identificación Personal (PII) antes de almacenarlos en Amazon DynamoDB. Este enfoque garantiza que los datos sensibles se anonimizan de inmediato durante el tránsito, reduciendo así el riesgo de violaciones de privacidad.\n\nAmazon Kinesis Data Streams permite capturar datos en tiempo real de manera escalable y duradera.\nAWS Lambda se integra fácilmente con Kinesis para procesar y transformar datos antes de que se almacenen.\nEste enfoque asegura que la PII sea anonimizada tan pronto como se recibe, protegiendo la privacidad de los datos antes de su almacenamiento en DynamoDB.\n\n\nOpciones incorrectas:\n\nTransmitir los datos en una tabla de Amazon DynamoDB. Habilitar DynamoDB Streams y configurar una función que realice la anonimización en los elementos recién escritos - Transmitir los datos en una tabla de Amazon DynamoDB es incorrecto porque DynamoDB Streams opera en cambios de datos que ya han sido escritos en la base de datos. Esto significa que la PII ya estaría almacenada sin anonimizar, lo cual representa un riesgo potencial de privacidad.\n\nCrear un data lake en Amazon S3 y usarlo como almacenamiento principal para datos de salud de pacientes. Utilizar un trigger de S3 para ejecutar una función Lambda que realice la anonimización. Enviar los datos anonimizados a Amazon DynamoDB - Crear un data lake en Amazon S3 es incorrecto porque los datos se almacenarían en S3 antes de ser anonimizados. Esto implica que la PII permanecería sin anonimizar en el bucket de S3, lo cual viola el principio de garantizar la anonimización antes del almacenamiento.\n\nDesplegar un stream de Amazon Data Firehose para capturar y transformar los datos en tiempo real. Entregar los datos anonimizados a Amazon Redshift para su análisis - Desplegar un stream de Amazon Data Firehose es incorrecto porque Amazon Redshift es un modelo de base de datos relacional diseñado para análisis y no para almacenamiento NoSQL. El requerimiento especifica que los datos deben almacenarse en una base de datos NoSQL.\n\nReferencias:\n\nhttps://aws.amazon.com/kinesis/data-streams/\n\nhttps://docs.aws.amazon.com/lambda/latest/dg/with-kinesis.html"
  },
  {
    "q": "Una empresa utiliza Amazon S3 para almacenar datos a los que se accede con frecuencia. Cuando se crea o elimina un objeto, el bucket de S3 envía una notificación de evento a una cola de Amazon SQS. Un arquitecto de soluciones necesita crear una solución que notifique al equipo de desarrollo y al equipo de operaciones sobre la creación o eliminación de objetos.\n¿Cuál de las siguientes opciones satisfaría este requisito?",
    "o": [
      "Crear un tema de Amazon SNS y configurar dos colas de SQS para suscribirse al tema. Otorgar permiso a Amazon S3 para enviar notificaciones a Amazon SNS y actualizar el bucket para usar el nuevo tema de SNS",
      "Configurar otra cola de SQS para el otro equipo. Otorgar permiso a Amazon S3 para enviar una notificación a la segunda cola de SQS",
      "Configurar un tema de Amazon SNS y configurar dos colas de SQS para consultar el tema de SNS. Otorgar permiso a Amazon S3 para enviar notificaciones a Amazon SNS y actualizar el bucket para usar el nuevo tema de SNS",
      "Crear un tema FIFO de Amazon SNS para el otro equipo. Otorgar permiso a Amazon S3 para enviar la notificación al segundo tema de SNS"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nCrear un tema de Amazon SNS y configurar dos colas de SQS para suscribirse al tema. Otorgar permiso a Amazon S3 para enviar notificaciones a Amazon SNS y actualizar el bucket para usar el nuevo tema de SNS - Crear un tema de Amazon SNS y configurar dos colas de SQS para suscribirse al tema permite utilizar el patrón de publicación y suscripción para enviar notificaciones a varios destinos. En este caso, el bucket de S3 enviará la notificación al tema de SNS, que a su vez la distribuirá a ambas colas de SQS para que los equipos de desarrollo y operaciones las reciban. Este enfoque utiliza el patrón fanout, que replica y distribuye el mensaje a múltiples suscriptores, permitiendo un procesamiento paralelo y asincrónico.\n\nAmazon SNS permite publicar mensajes a múltiples suscriptores mediante el patrón fanout.\nAmazon SQS maneja las colas de mensajes, lo que permite a los consumidores procesar mensajes de forma asincrónica.\nAl integrar SNS con SQS, se logra una distribución eficiente de notificaciones a múltiples suscriptores.\n\n\nOpciones incorrectas:\n\nConfigurar un tema de Amazon SNS y configurar dos colas de SQS para consultar el tema de SNS. Otorgar permiso a Amazon S3 para enviar notificaciones a Amazon SNS y actualizar el bucket para usar el nuevo tema de SNS - Configurar dos colas de SQS para consultar el tema de SNS es incorrecto porque no se puede configurar SQS para consultar (polling) a SNS. SNS entrega las notificaciones a SQS a través del mecanismo de suscripción push, no por polling.\n\nCrear un tema FIFO de Amazon SNS para el otro equipo. Otorgar permiso a Amazon S3 para enviar la notificación al segundo tema de SNS - Crear un tema FIFO de SNS es incorrecto porque ni SNS FIFO ni SQS FIFO son necesarios en este escenario. La capacidad de deduplicación de FIFO no se requiere, ya que no hay requisitos de procesamiento en tiempo casi real ni de orden estricto de mensajes.\n\nConfigurar otra cola de SQS para el otro equipo. Otorgar permiso a Amazon S3 para enviar una notificación a la segunda cola de SQS - Configurar otra cola de SQS para el otro equipo es incorrecto porque Amazon S3 solo puede enviar notificaciones a una cola de SQS o un tema de SNS a la vez. Para enviar notificaciones a múltiples suscriptores, es necesario usar SNS con SQS en un patrón fanout.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/ways-to-add-notification-config-to-bucket.html\n\nhttps://docs.aws.amazon.com/sns/latest/dg/welcome.html"
  },
  {
    "q": "Una firma de abogados internacional necesita almacenar documentos confidenciales de sus clientes en Amazon S3. Debido a políticas de cumplimiento corporativas y normativas legales internacionales, las claves maestras utilizadas para el cifrado deben ser controladas y almacenadas completamente fuera del entorno de AWS. Además, se requiere que los archivos estén cifrados antes de ser cargados al almacenamiento en la nube.\n¿Qué técnica de cifrado de S3 debe utilizar el Solutions Architect?",
    "o": [
      "Usar Amazon Macie para detectar y cifrar automáticamente los datos sensibles",
      "Configurar SSE con claves proporcionadas por el cliente (SSE-C)",
      "Habilitar cifrado del lado del servidor con S3 y claves almacenadas en CloudHSM",
      "Utilizar cifrado del lado del cliente de S3 con una clave de cifrado administrada localmente"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nUtilizar cifrado del lado del cliente de S3 con una clave de cifrado administrada localmente - El cifrado del lado del cliente con una clave de cifrado administrada localmente garantiza que los archivos estén cifrados antes de salir del entorno de la firma legal. Las claves nunca son almacenadas ni procesadas por AWS, cumpliendo con los requerimientos regulatorios de privacidad y control total de las claves.\n\nOpciones incorrectas:\n\nHabilitar cifrado del lado del servidor con S3 y claves almacenadas en CloudHSM - Aunque AWS CloudHSM ofrece control criptográfico dedicado, sigue siendo un servicio administrado dentro de AWS, por lo tanto, no cumple con el requisito de mantener las claves completamente fuera del entorno de AWS.\n\nUsar Amazon Macie para detectar y cifrar automáticamente los datos sensibles - Amazon Macie es una herramienta de detección y clasificación de datos sensibles, no una solución de cifrado en tránsito ni de gestión de claves.\n\nConfigurar SSE con claves proporcionadas por el cliente (SSE-C) - SSE-C permite que el cliente proporcione una clave para cada solicitud, pero AWS recibe la clave en cada operación, lo que no garantiza que las claves maestras nunca sean vistas o almacenadas temporalmente por AWS.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingClientSideEncryption.html\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/serv-side-encryption.html"
  },
  {
    "q": "Una empresa de tecnología necesita una base de datos relacional altamente disponible para garantizar la continuidad del negocio en caso de una falla en una región completa. La solución debe cumplir con un Recovery Point Objective (RPO) de 1 segundo y un Recovery Time Objective (RTO) de menos de 1 minuto.\nEl equipo de infraestructura busca una estrategia de recuperación ante desastres que permita replicación automática entre regiones con mínima pérdida de datos y una recuperación rápida en caso de una interrupción. ¿Qué servicio de AWS cumple mejor con este requisito?",
    "o": [
      "Amazon RDS for MySQL con réplicas de lectura en otra región",
      "Amazon Redshift con snapshots entre regiones",
      "Amazon DynamoDB Global Table",
      "Amazon Aurora Global Database"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nAmazon Aurora Global Database - Amazon Aurora Global Database es la mejor opción porque permite replicación entre regiones con una latencia inferior a 1 segundo y permite la conmutación por error (failover) en menos de 1 minuto. Esta arquitectura garantiza un RPO de 1 segundo y un RTO de menos de 1 minuto, asegurando continuidad del negocio en caso de un desastre regional.\n\nAurora Global Database permite replicación de datos con una latencia de menos de 1 segundo gracias a su arquitectura basada en almacenamiento distribuido. En caso de una falla en la región principal, una de las regiones secundarias se puede promover a principal en menos de 1 minuto. Esta solución minimiza la pérdida de datos y el tiempo de inactividad sin afectar el rendimiento de la base de datos.\n\n\n\nOpciones incorrectas:\n\nAmazon DynamoDB Global Table - Amazon DynamoDB Global Table es una excelente opción para bases de datos NoSQL distribuidas globalmente, pero en este caso se necesita una base de datos relacional.\n\nAmazon Redshift con snapshots entre regiones - Amazon Redshift con snapshots entre regiones solo permite restauraciones periódicas de los datos, pero no proporciona replicación en tiempo real, lo que no cumple con el RPO de 1 segundo.\n\nAmazon RDS for MySQL con réplicas de lectura en otra región - Amazon RDS for MySQL con réplicas en otra región permite replicación entre regiones, pero el proceso de conmutación por error no es inmediato y puede llevar varios minutos, lo que no cumple con los requisitos de RPO y RTO.\n\nReferencias:\n\nhttps://aws.amazon.com/rds/aurora/global-database/\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-global-database.html"
  },
  {
    "q": "Una plataforma de pagos en línea necesita desplegar al menos 2 instancias EC2 para manejar las transacciones normales y escalar automáticamente hasta 6 instancias EC2 para procesar la carga máxima. La arquitectura debe ser altamente disponible y tolerante a fallos, ya que la aplicación maneja pagos en tiempo real y no puede permitirse interrupciones.\nComo Solutions Architect, ¿qué deberías hacer para cumplir con este requisito?",
    "o": [
      "Crear un Auto Scaling group de instancias EC2 y establecer la capacidad mínima en 2 y la capacidad máxima en 6. Utilizar 2 zonas de disponibilidad y desplegar 1 instancia en cada AZ",
      "Crear un Auto Scaling group de instancias EC2 y establecer la capacidad mínima en 2 y la capacidad máxima en 4. Desplegar 2 instancias en la zona de disponibilidad A y 2 instancias en la zona de disponibilidad B",
      "Crear un Auto Scaling group de instancias EC2 y establecer la capacidad mínima en 4 y la capacidad máxima en 6. Desplegar 2 instancias en la zona de disponibilidad A y otras 2 instancias en la zona de disponibilidad B",
      "Crear un Auto Scaling group de instancias EC2 y establecer la capacidad mínima en 2 y la capacidad máxima en 6. Desplegar 4 instancias en la zona de disponibilidad A"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nCrear un Auto Scaling group de instancias EC2 y establecer la capacidad mínima en 4 y la capacidad máxima en 6. Desplegar 2 instancias en la zona de disponibilidad A y otras 2 instancias en la zona de disponibilidad B - Crear un Auto Scaling group de instancias EC2 y establecer la capacidad mínima en 4 y la capacidad máxima en 6. Desplegar 2 instancias en la zona de disponibilidad A y otras 2 instancias en la zona de disponibilidad B. Este enfoque garantiza alta disponibilidad y tolerancia a fallos al distribuir las instancias en dos zonas de disponibilidad (AZ). Al establecer la capacidad mínima en 4, se asegura que al menos 2 instancias estarán disponibles en cada AZ en todo momento, incluso si una zona falla. La capacidad máxima de 6 permite escalar automáticamente durante los picos de demanda, asegurando un rendimiento óptimo para los pagos en tiempo real.\n\n\n\nOpciones incorrectas:\n\nCrear un Auto Scaling group de instancias EC2 y establecer la capacidad mínima en 2 y la capacidad máxima en 4. Desplegar 2 instancias en la zona de disponibilidad A y 2 instancias en la zona de disponibilidad B - Crear un Auto Scaling group de instancias EC2 y establecer la capacidad mínima en 2 y la capacidad máxima en 4. Desplegar 2 instancias en la zona de disponibilidad A y 2 instancias en la zona de disponibilidad B. Esto limita el escalado máximo a 4 instancias, lo cual no es suficiente para manejar la carga máxima de 6 instancias que se requiere para los momentos de mayor demanda.\n\nCrear un Auto Scaling group de instancias EC2 y establecer la capacidad mínima en 2 y la capacidad máxima en 6. Desplegar 4 instancias en la zona de disponibilidad A - Crear un Auto Scaling group de instancias EC2 y establecer la capacidad mínima en 2 y la capacidad máxima en 6. Desplegar 4 instancias en la zona de disponibilidad A. Este enfoque no proporciona alta disponibilidad ni tolerancia a fallos, ya que todas las instancias están en una sola AZ. Si la zona de disponibilidad A falla, no habrá instancias disponibles para procesar pagos.\n\nCrear un Auto Scaling group de instancias EC2 y establecer la capacidad mínima en 2 y la capacidad máxima en 6. Utilizar 2 zonas de disponibilidad y desplegar 1 instancia en cada AZ - Crear un Auto Scaling group de instancias EC2 y establecer la capacidad mínima en 2 y la capacidad máxima en 6. Utilizar 2 zonas de disponibilidad y desplegar 1 instancia en cada AZ. Este enfoque no cumple con el requisito de alta disponibilidad, ya que si una AZ falla, solo quedaría una instancia activa, lo cual no es suficiente para soportar la carga mínima requerida. Además, no garantiza el manejo adecuado de la carga máxima.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/what-is-amazon-ec2-auto-scaling.html\n\nhttps://docs.aws.amazon.com/documentdb/latest/developerguide/regions-and-azs.html"
  },
  {
    "q": "Una empresa de comercio electrónico opera una aplicación web altamente escalable que depende de una base de datos Amazon Aurora. A medida que aumentan sus usuarios, han notado que las réplicas de lectura luchan por mantenerse al día con el creciente tráfico de lectura, lo que genera cuellos de botella en el rendimiento durante los períodos pico.\nComo arquitecto de soluciones, ¿cuál de las siguientes opciones abordará el problema con la solución más rentable?",
    "o": [
      "Usar escalado automático para la réplica de lectura de Amazon Aurora utilizando Aurora Auto Scaling",
      "Implementar escalado de lectura con Amazon Aurora Global Database",
      "Configurar una réplica de lectura que pueda operar en diferentes regiones",
      "Aumentar el tamaño del clúster de Amazon Aurora"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nUsar escalado automático para la réplica de lectura de Amazon Aurora utilizando Aurora Auto Scaling - Amazon Aurora Auto Scaling ajusta automáticamente el número de instancias de réplicas de lectura en función de la demanda de tráfico de lectura. Esto asegura que el clúster de base de datos escale hacia arriba o hacia abajo según sea necesario sin intervención manual, optimizando costos al evitar el sobreaprovisionamiento o subaprovisionamiento de recursos. En este escenario, Aurora Auto Scaling permite gestionar dinámicamente los recursos, abordando eficazmente el aumento en el tráfico de lectura durante los períodos pico. Esta administración dinámica de recursos garantiza que la empresa pague solo por la capacidad adicional cuando realmente se necesita.\n\nOpciones incorrectas:\n\nAumentar el tamaño del clúster de Amazon Aurora - No es una solución rentable ya que aumentar el tamaño de las instancias de la base de datos conduce a costos constantes, independientemente de si se utilizan todos los recursos durante los períodos de menor demanda.\n\nImplementar escalado de lectura con Amazon Aurora Global Database - Aurora Global Database está diseñado para aplicaciones distribuidas a nivel global y permite que una base de datos Aurora abarque varias regiones de AWS. Si bien esto puede proporcionar alta disponibilidad global, introduce complejidad adicional y puede ser más costoso debido a la infraestructura y los costos de transferencia de datos.\n\nConfigurar una réplica de lectura que pueda operar en diferentes regiones - Configurar una réplica de lectura en diferentes regiones ayuda a la escalabilidad global y a equilibrar las lecturas en varias regiones. Sin embargo, no es la solución más rentable en este escenario ya que se incurriría en costos adicionales de transferencia de datos entre regiones y no se aborda el problema de rendimiento dentro de la misma región.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Integrating.AutoScaling.html\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html"
  },
  {
    "q": "Una empresa de e-Learning aloja su aplicación en .NET en un servidor Windows en su centro de datos on-premises. La aplicación utiliza Oracle Database Standard Edition como base de datos. La compañía quiere migrar esta carga de trabajo a AWS para aprovechar la alta disponibilidad de la nube, minimizando los cambios de desarrollo y simplificando la gestión del entorno.\n¿Cuáles de las siguientes opciones deberían implementarse para cumplir con los requisitos de la empresa? (Selecciona DOS)",
    "o": [
      "Rehostear la aplicación .NET on-premises en un entorno Multi-AZ de AWS Elastic Beanstalk que se ejecuta en múltiples Availability Zones",
      "Refactorizar la aplicación a .NET Core y ejecutarla como un servicio de contenedores serverless utilizando Amazon Elastic Kubernetes Service (Amazon EKS) con AWS Fargate",
      "Provisionar y replatformar la aplicación a Amazon Elastic Container Service (Amazon ECS) con nodos de trabajo EC2. Usar una Amazon Machine Image (AMI) de Windows Server y desplegar la aplicación en el clúster ECS a través de Amazon ECS Anywhere",
      "Migrar la base de datos Oracle a Amazon RDS para Oracle en una implementación Multi-AZ utilizando AWS Database Migration Service (AWS DMS)",
      "Utilizar AWS Application Migration Service (AWS MGN) para migrar el servidor de base de datos Oracle on-premises a una nueva instancia de Amazon EC2"
    ],
    "a": [
      0,
      3
    ],
    "e": "Correcto:\n\nRehostear la aplicación .NET on-premises en un entorno Multi-AZ de AWS Elastic Beanstalk que se ejecuta en múltiples Availability Zones - Rehostear la aplicación .NET on-premises en un entorno Multi-AZ de AWS Elastic Beanstalk es correcto ya que Elastic Beanstalk simplifica la implementación, administración y escalado de aplicaciones .NET sin requerir cambios en el código. Proporciona alta disponibilidad mediante implementaciones Multi-AZ y maneja automáticamente el aprovisionamiento de recursos.\n\nMigrar la base de datos Oracle a Amazon RDS para Oracle en una implementación Multi-AZ utilizando AWS Database Migration Service (AWS DMS) - Migrar la base de datos Oracle a Amazon RDS para Oracle en una implementación Multi-AZ utilizando AWS Database Migration Service (AWS DMS) es correcto porque AWS DMS facilita la migración de bases de datos Oracle on-premises a Amazon RDS sin tiempo de inactividad significativo, proporcionando alta disponibilidad mediante la configuración Multi-AZ.\n\n\n\nOpciones incorrectas:\n\nRefactorizar la aplicación a .NET Core y ejecutarla como un servicio de contenedores serverless utilizando Amazon Elastic Kubernetes Service (Amazon EKS) con AWS Fargate - Refactorizar la aplicación a .NET Core y ejecutarla en Amazon EKS con AWS Fargate es incorrecto porque implica un cambio significativo en el código, lo cual no es adecuado ya que el requisito es minimizar los cambios de desarrollo.\n\nUtilizar AWS Application Migration Service (AWS MGN) para migrar el servidor de base de datos Oracle on-premises a una nueva instancia de Amazon EC2 - Utilizar AWS Application Migration Service (AWS MGN) para migrar el servidor de base de datos Oracle es incorrecto porque AWS MGN no es compatible con Oracle como destino. AWS DMS es la opción más adecuada para migrar bases de datos Oracle a Amazon RDS.\n\nProvisionar y replatformar la aplicación a Amazon Elastic Container Service (Amazon ECS) con nodos de trabajo EC2. Usar una Amazon Machine Image (AMI) de Windows Server y desplegar la aplicación en el clúster ECS a través de Amazon ECS Anywhere - Provisionar y replatformar la aplicación en Amazon ECS con nodos EC2 y usar ECS Anywhere es incorrecto porque implica un cambio en la plataforma de implementación, lo cual puede requerir ajustes significativos en la configuración y administración. Elastic Beanstalk es más adecuado para rehosting sin modificaciones importantes.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/dms/latest/userguide/Welcome.html\n\nhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create_deploy_NET.html"
  },
  {
    "q": "Una empresa requiere que todos los datos almacenados en la nube sean cifrados en reposo. Para integrarse fácilmente con otros servicios de AWS, deben tener control total sobre el cifrado de las claves creadas y la capacidad de eliminar inmediatamente el material de clave de AWS KMS. La solución también debe permitir auditar el uso de la clave independientemente de AWS CloudTrail.\n¿Cuál de las siguientes opciones cumplirá con este requisito?",
    "o": [
      "Usar AWS Key Management Service para crear claves administradas por AWS y almacenar el material de clave no extraíble en AWS CloudHSM",
      "Usar AWS Key Management Service para crear claves administradas por el usuario y almacenar el material de clave no extraíble en AWS CloudHSM",
      "Usar AWS Key Management Service para crear una clave KMS en un almacén de claves personalizado y almacenar el material de clave no extraíble en Amazon S3",
      "Usar AWS Key Management Service para crear una clave KMS en un almacén de claves personalizado y almacenar el material de clave no extraíble en AWS CloudHSM"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nUsar AWS Key Management Service para crear una clave KMS en un almacén de claves personalizado y almacenar el material de clave no extraíble en AWS CloudHSM - Usar AWS Key Management Service para crear una clave KMS en un almacén de claves personalizado y almacenar el material de clave no extraíble en AWS CloudHSM es correcto porque un almacén de claves personalizado en AWS KMS utiliza AWS CloudHSM bajo tu control directo. Esto permite el almacenamiento seguro del material de clave en un HSM dedicado, asegurando que el material de clave nunca salga del HSM. También permite auditar el uso de la clave de manera independiente a AWS CloudTrail y proporciona control total sobre el ciclo de vida de la clave.\n\nOpciones incorrectas:\n\nUsar AWS Key Management Service para crear claves administradas por AWS y almacenar el material de clave no extraíble en AWS CloudHSM - Usar AWS Key Management Service para crear claves administradas por AWS y almacenar el material de clave no extraíble en AWS CloudHSM es incorrecto porque las claves administradas por AWS no otorgan control total al usuario sobre el ciclo de vida y el acceso al material de clave, ya que son gestionadas por AWS.\n\nUsar AWS Key Management Service para crear una clave KMS en un almacén de claves personalizado y almacenar el material de clave no extraíble en Amazon S3 - Usar AWS Key Management Service para crear una clave KMS en un almacén de claves personalizado y almacenar el material de clave no extraíble en Amazon S3 es incorrecto porque Amazon S3 no está diseñado para almacenar material de clave criptográfica de alta seguridad.\n\nUsar AWS Key Management Service para crear claves administradas por el usuario y almacenar el material de clave no extraíble en AWS CloudHSM - Usar AWS Key Management Service para crear claves administradas por el usuario y almacenar el material de clave no extraíble en AWS CloudHSM es incorrecto porque las claves administradas por el usuario en AWS KMS no proporcionan el mismo nivel de control que un almacén de claves personalizado.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/kms/latest/developerguide/custom-key-store-overview.html\n\nhttps://docs.aws.amazon.com/kms/latest/developerguide/keystore-cloudhsm.html"
  },
  {
    "q": "La empresa StellartAmengual está migrando el backend de su aplicación web desde su infraestructura local hacia AWS. En el entorno actual, utilizan una caché en memoria para mejorar el rendimiento de las consultas a la base de datos.\nDurante la migración, el arquitecto de soluciones debe recomendar un servicio en AWS que ofrezca una solución de caché compatible con alta disponibilidad y replicación entre zonas de disponibilidad.\n¿Qué servicio cumple mejor con estos requisitos?",
    "o": [
      "Amazon ElastiCache Memcached",
      "Amazon DynamoDB",
      "Amazon RDS Multi-AZ",
      "Amazon ElastiCache Redis"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nAmazon ElastiCache Redis - Amazon ElastiCache para Redis es una caché en memoria altamente disponible que permite replicación en clústeres multi-AZ. Redis es ideal para casos donde se requiere alta velocidad, durabilidad opcional y replicación síncrona entre nodos para soportar la continuidad del servicio ante fallos.\n\nOpciones incorrectas:\n\nAmazon ElastiCache Memcached - ElastiCache Memcached no admite replicación ni alta disponibilidad. Es una opción sencilla para caché distribuida, pero carece de soporte nativo para failover o sincronización entre zonas.\n\nAmazon RDS Multi-AZ - Amazon RDS Multi-AZ es una base de datos relacional que sí ofrece alta disponibilidad, pero no es una solución en memoria ni adecuada como caché. Se usa para almacenamiento persistente, no para acceso ultra rápido a datos temporales.\n\nAmazon DynamoDB - DynamoDB es una base de datos NoSQL administrada. Aunque es altamente escalable, no es una solución de caché en memoria. En casos donde se requiere una caché sobre DynamoDB, se puede considerar DynamoDB Accelerator (DAX), pero no aplica en este escenario general de migración de caché.\n\nReferencias:\n\nhttps://aws.amazon.com/elasticache/redis-vs-memcached/"
  },
  {
    "q": "Una plataforma de trading de criptomonedas utiliza una API construida en AWS Lambda y API Gateway. Debido a las recientes noticias y rumores sobre el precio de Bitcoin, Ethereum y otras criptomonedas, se espera un aumento significativo de visitantes y nuevos usuarios en los próximos días.\nEn este escenario, ¿cómo puedes proteger los sistemas backend de la plataforma contra picos de tráfico?",
    "o": [
      "Cambiar de AWS Lambda y API Gateway a una arquitectura más escalable y altamente disponible utilizando instancias EC2, ELB y Auto Scaling",
      "Habilitar límites de throttling y caching de resultados en API Gateway",
      "Mover la función Lambda a una VPC",
      "Usar CloudFront frente a API Gateway para actuar como caché"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nHabilitar límites de throttling y caching de resultados en API Gateway - Habilitar límites de throttling y caching de resultados en API Gateway es la solución adecuada para proteger el backend de picos de tráfico. API Gateway permite configurar límites de throttling globales y por método, ayudando a controlar la tasa de solicitudes y evitando la sobrecarga del backend. Además, habilitar el caching reduce la latencia y mejora el rendimiento al responder con datos almacenados en caché para solicitudes repetidas, disminuyendo la carga en las funciones Lambda.\n\n\n\nOpciones incorrectas:\n\nCambiar de AWS Lambda y API Gateway a una arquitectura más escalable y altamente disponible utilizando instancias EC2, ELB y Auto Scaling - Cambiar de AWS Lambda y API Gateway a una arquitectura más escalable con EC2, ELB y Auto Scaling es incorrecto porque AWS Lambda y API Gateway ya son servicios altamente escalables y administrados. No es necesario migrar a EC2 a menos que haya requisitos específicos que Lambda no pueda cumplir.\n\nMover la función Lambda a una VPC - Mover la función Lambda a una VPC no aborda el problema del manejo de picos de tráfico. La ubicación de Lambda en una VPC es relevante para conectividad a recursos privados, no para escalar frente a aumentos de tráfico.\n\nUsar CloudFront frente a API Gateway para actuar como caché - Usar CloudFront frente a API Gateway como caché es incorrecto ya que CloudFront mejora la latencia y la entrega de contenido, pero no gestiona directamente los límites de solicitudes ni protege el backend de sobrecargas. API Gateway ya incluye capacidades de caching y throttling adecuadas para este caso.\n\nReferencias:\n\nhttps://aws.amazon.com/api-gateway/faqs/"
  },
  {
    "q": "Una empresa tiene una aplicación web que utiliza Amazon CloudFront para distribuir imágenes, videos y otros contenidos estáticos almacenados en su bucket S3 a usuarios de todo el mundo. La empresa ha introducido recientemente una función de acceso solo para miembros a algunos de sus archivos multimedia de alta calidad. Se requiere proporcionar acceso a múltiples archivos privados únicamente a sus suscriptores de pago sin tener que cambiar sus URLs actuales.\n¿Cuál de las siguientes opciones es la solución más adecuada para satisfacer este requisito?",
    "o": [
      "Configurar tu distribución de CloudFront para utilizar Field-Level Encryption para proteger tus datos privados y permitir el acceso solo a miembros",
      "Utilizar Signed Cookies para controlar quién puede acceder a los archivos privados en tu distribución de CloudFront modificando tu aplicación para determinar si un usuario debería tener acceso a tu contenido. Para los miembros, enviar los encabezados 'Set-Cookie' al visor, los cuales desbloquearán el contenido solo para ellos",
      "Configurar tu distribución de CloudFront para usar Match Viewer como su Origin Protocol Policy, lo que coincidirá automáticamente con la solicitud del usuario. Esto permitirá el acceso al contenido privado si la solicitud es de un miembro de pago y lo negará si no es miembro",
      "Crear una URL firmada con una política personalizada que solo permita a los miembros ver los archivos privados"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nUtilizar Signed Cookies para controlar quién puede acceder a los archivos privados en tu distribución de CloudFront modificando tu aplicación para determinar si un usuario debería tener acceso a tu contenido. Para los miembros, enviar los encabezados 'Set-Cookie' al visor, los cuales desbloquearán el contenido solo para ellos - Utilizar Signed Cookies para controlar quién puede acceder a los archivos privados en tu distribución de CloudFront modificando tu aplicación para determinar si un usuario debería tener acceso a tu contenido. Para los miembros, enviar los encabezados 'Set-Cookie' al visor, los cuales desbloquearán el contenido solo para ellos. Signed Cookies permiten proporcionar acceso a múltiples archivos privados sin cambiar las URLs actuales, lo que es ideal para este escenario. A diferencia de las URLs firmadas, que son mejores para archivos individuales, los Signed Cookies funcionan bien para controlar el acceso a grupos de archivos, como en un área de suscriptores de pago de un sitio web.\n\nOpciones incorrectas:\n\nConfigurar tu distribución de CloudFront para utilizar Field-Level Encryption para proteger tus datos privados y permitir el acceso solo a miembros - Configurar tu distribución de CloudFront para utilizar Field-Level Encryption para proteger tus datos privados y permitir el acceso solo a miembros. Field-Level Encryption solo protege datos enviados desde el usuario al servidor, como formularios web. No controla el acceso a archivos privados en S3 o CloudFront.\n\nCrear una URL firmada con una política personalizada que solo permita a los miembros ver los archivos privados - Crear una URL firmada con una política personalizada que solo permita a los miembros ver los archivos privados. Las URLs firmadas son ideales para dar acceso a archivos individuales, no a múltiples archivos sin cambiar URLs existentes, como se requiere en este caso.\n\nConfigurar tu distribución de CloudFront para usar Match Viewer como su Origin Protocol Policy, lo que coincidirá automáticamente con la solicitud del usuario. Esto permitirá el acceso al contenido privado si la solicitud es de un miembro de pago y lo negará si no es miembro - Configurar tu distribución de CloudFront para usar Match Viewer como su Origin Protocol Policy, lo que coincidirá automáticamente con la solicitud del usuario. Match Viewer solo coincide con el protocolo (HTTP o HTTPS) utilizado en la solicitud del usuario. No verifica si un usuario es miembro o no.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-choosing-signed-urls-cookies.html\n\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-signed-cookies.html"
  },
  {
    "q": "Una plataforma de intercambio de criptomonedas en línea utiliza AWS con ECS Cluster y RDS en configuración Multi-AZ. La aplicación depende en gran medida de RDS para manejar operaciones complejas de lectura y escritura en la base de datos. Para mantener la confiabilidad, disponibilidad y rendimiento, necesitas monitorear de cerca cómo los diferentes procesos o hilos en una instancia de base de datos usan la CPU, incluyendo el porcentaje de ancho de banda de CPU y la memoria total consumida por cada proceso.\n¿Cuál de las siguientes es la solución más adecuada para monitorear correctamente tu base de datos?",
    "o": [
      "Verificar las métricas CPU% y MEM% que están disponibles en la consola de Amazon RDS y que muestran el porcentaje de ancho de banda de CPU y la memoria total consumida por cada proceso de base de datos de tu instancia de RDS",
      "Crear un script que recopile y publique métricas personalizadas en CloudWatch, las cuales rastreen en tiempo real la utilización de CPU de la instancia RDS, y luego configurar un dashboard personalizado en CloudWatch para ver las métricas",
      "Habilitar Enhanced Monitoring en RDS",
      "Usar Amazon CloudWatch para monitorear la utilización de CPU de tu base de datos"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nHabilitar Enhanced Monitoring en RDS - Habilitar Enhanced Monitoring en RDS proporciona métricas a nivel del sistema operativo (OS) en las instancias de base de datos. Esto incluye detalles sobre la utilización de CPU por proceso o hilo, ancho de banda de CPU y consumo de memoria para cada proceso en la instancia de RDS. Enhanced Monitoring utiliza un agente en la instancia de RDS para recopilar datos con mayor granularidad y precisión que CloudWatch, lo cual es esencial para el análisis detallado del rendimiento.\n\nOpciones incorrectas:\n\nUsar Amazon CloudWatch para monitorear la utilización de CPU de tu base de datos - Usar Amazon CloudWatch para monitorear la utilización de CPU de tu base de datos no proporciona información detallada a nivel de proceso. CloudWatch recopila métricas de utilización de CPU desde el hipervisor de la instancia, lo que no permite ver el uso de CPU desglosado por proceso o hilo en la base de datos.\n\nVerificar las métricas CPU% y MEM% que están disponibles en la consola de Amazon RDS y que muestran el porcentaje de ancho de banda de CPU y la memoria total consumida por cada proceso de base de datos de tu instancia de RDS - Verificar las métricas CPU% y MEM% en la consola de RDS es incorrecto ya que estas métricas no están fácilmente disponibles en la consola de RDS. Para obtener ese nivel de detalle, se requiere habilitar Enhanced Monitoring, que proporciona visibilidad a nivel de proceso.\n\nCrear un script que recopile y publique métricas personalizadas en CloudWatch, las cuales rastreen en tiempo real la utilización de CPU de la instancia RDS, y luego configurar un dashboard personalizado en CloudWatch para ver las métricas - Crear un script personalizado para publicar métricas en CloudWatch agrega una carga operativa innecesaria y complejidad de mantenimiento. Además, CloudWatch no ofrece métricas tan detalladas como Enhanced Monitoring en RDS, por lo que no es la solución más eficiente ni precisa.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Monitoring.OS.html\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/MonitoringOverview.html#monitoring-cloudwatch"
  },
  {
    "q": "Una compañía está diseñando una aplicación bancaria que utiliza Amazon ElastiCache for Redis como su componente de administración de sesiones distribuidas. Para asegurar los datos de sesión y garantizar que los ingenieros en la nube se autentiquen antes de ejecutar comandos Redis, específicamente comandos MULTI EXEC, el sistema debe reforzar una autenticación robusta requiriendo a los usuarios ingresar una contraseña. Además, el acceso debe gestionarse con credenciales de larga duración mientras se mantienen prácticas de seguridad sólidas.\nComo Solutions Architect, ¿cuál de las siguientes opciones debes implementar para cumplir con el requisito anterior?",
    "o": [
      "Habilitar el cifrado en tránsito para los grupos de replicación de Redis",
      "Configurar un grupo de replicación de Redis y habilitar el parámetro AtRestEncryptionEnabled",
      "Generar un token de autenticación de IAM usando credenciales de AWS y proporcionar este token como contraseña",
      "Autenticar a los usuarios utilizando Redis AUTH creando un nuevo clúster de Redis con los parámetros --transit-encryption-enabled y --auth-token habilitados"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nAutenticar a los usuarios utilizando Redis AUTH creando un nuevo clúster de Redis con los parámetros --transit-encryption-enabled y --auth-token habilitados - Autenticar a los usuarios utilizando Redis AUTH creando un nuevo clúster de Redis con --transit-encryption-enabled y --auth-token habilitados es la opción correcta. Esto garantiza que los usuarios deban ingresar una contraseña antes de ejecutar comandos Redis como MULTI EXEC, proporcionando así una capa adicional de seguridad. Además, habilitar el cifrado en tránsito garantiza que los datos estén protegidos mientras se transfieren entre los nodos del clúster. Esta combinación asegura una autenticación robusta y una protección de datos efectiva en movimiento.\n\nRedis AUTH es una característica de seguridad que requiere una contraseña antes de permitir comandos. Se implementa mediante el parámetro --auth-token al crear o actualizar un clúster de Redis en ElastiCache.\n--transit-encryption-enabled cifra los datos en tránsito entre clientes y nodos de Redis, protegiendo la información mientras se transfiere en la red.\nOpciones incorrectas:\n\nHabilitar el cifrado en tránsito para los grupos de replicación de Redis - Habilitar el cifrado en tránsito para los grupos de replicación de Redis es incorrecto, ya que aunque el cifrado en tránsito protege los datos durante su transferencia, no proporciona autenticación de usuarios. Se necesita Redis AUTH para requerir contraseñas antes de ejecutar comandos críticos.\n\nGenerar un token de autenticación de IAM usando credenciales de AWS y proporcionar este token como contraseña - Generar un token de autenticación de IAM usando credenciales de AWS es incorrecto porque IAM no es compatible con la ejecución de comandos Redis como MULTI EXEC. Además, los tokens de IAM expiran cada 12 horas, lo que no cumple con el requisito de credenciales de larga duración.\n\nConfigurar un grupo de replicación de Redis y habilitar el parámetro AtRestEncryptionEnabled - Configurar AtRestEncryptionEnabled es incorrecto porque el cifrado en reposo solo protege los datos en el almacenamiento en memoria. No proporciona autenticación para los usuarios antes de ejecutar comandos Redis. Redis AUTH es necesario para lograr ese control de acceso.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/auth.html\n\nhttps://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/encryption.html"
  },
  {
    "q": "Una empresa recopila datos atmosféricos como temperatura, presión de aire y humedad de diferentes países. Cada ubicación de sitio está equipada con varios instrumentos meteorológicos y una conexión a Internet de alta velocidad. La cantidad promedio de datos recopilados en cada ubicación es de aproximadamente 500 GB y serán analizados por una aplicación de pronóstico meteorológico alojada en Virginia del Norte. Como Solutions Architect, necesitas agregar todos los datos de la manera más rápida posible.\n¿Cuál de las siguientes opciones puede cumplir con este requisito?",
    "o": [
      "Configurar una conexión VPN de sitio a sitio",
      "Habilitar Transfer Acceleration en el bucket de destino y cargar los datos recopilados utilizando Multipart Upload",
      "Usar AWS Snowball Edge para transferir grandes cantidades de datos",
      "Cargar los datos en el bucket S3 más cercano. Configurar una replicación entre regiones y copiar los objetos al bucket de destino"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nHabilitar Transfer Acceleration en el bucket de destino y cargar los datos recopilados utilizando Multipart Upload - Habilitar Transfer Acceleration en el bucket de destino y cargar los datos utilizando Multipart Upload es la mejor opción para transferir grandes cantidades de datos de manera rápida y eficiente a un bucket S3 en una región lejana. S3 Transfer Acceleration utiliza la red global de Amazon CloudFront para optimizar las rutas de carga, lo que resulta en una velocidad de transferencia hasta 500-600% más rápida en comparación con las cargas normales. Además, el uso de Multipart Upload permite dividir el archivo en partes más pequeñas, lo que acelera aún más el proceso de carga y garantiza una mayor confiabilidad.\n\nAmazon S3 Transfer Acceleration utiliza puntos de acceso optimizados en todo el mundo para mejorar la velocidad de carga.\nMultipart Upload permite la carga simultánea de varias partes de un archivo, lo que optimiza el rendimiento.\nEsta combinación es ideal cuando se necesita mover grandes volúmenes de datos a largas distancias con el mínimo tiempo posible.\n\n\nOpciones incorrectas:\n\nCargar los datos en el bucket S3 más cercano. Configurar una replicación entre regiones y copiar los objetos al bucket de destino - Cargar los datos en el bucket S3 más cercano y configurar una replicación entre regiones no es eficiente en términos de velocidad, ya que la replicación entre regiones puede tardar aproximadamente 15 minutos en completar el proceso. La necesidad en este escenario es agregar los datos rápidamente para su análisis en una sola región.\n\nConfigurar una conexión VPN de sitio a sitio - Configurar una conexión VPN de sitio a sitio no es la solución más rápida ya que las VPNs suelen tener limitaciones de ancho de banda y están diseñadas para conexiones seguras a recursos en una VPC, no para transferencias masivas de datos.\n\nUsar AWS Snowball Edge para transferir grandes cantidades de datos - Usar AWS Snowball Edge no es la mejor opción porque el tiempo total de transferencia, incluyendo el envío físico del dispositivo, puede tardar aproximadamente una semana. En este caso, se necesita una transferencia rápida y continua de datos.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration.html\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/replication.html"
  },
  {
    "q": "Una empresa de entretenimiento digital planea implementar un sistema de análisis de eventos de reproducción en tiempo real. Este sistema se ejecutará en una instancia de Amazon EC2 dentro de una subred privada. Por razones de seguridad, esta instancia necesita enviar datos a Amazon Kinesis y almacenar resultados en Amazon S3, pero sin exponer el tráfico a Internet público.\n¿Cuál de las siguientes opciones permite cumplir con este requisito de la forma más segura y eficiente?",
    "o": [
      "Crear un Application Load Balancer en la subred privada y enrutar el tráfico desde la instancia EC2 a los servicios mediante reglas de enrutamiento",
      "Usar endpoints de Amazon VPC para enrutar el tráfico a S3 y Kinesis sin pasar por Internet público",
      "Habilitar el cifrado en tránsito con TLS 1.2 para acceder a S3 y Kinesis desde la instancia EC2",
      "Configurar una Gateway NAT en la subred pública y enrutar el tráfico de la instancia EC2 hacia S3 y Kinesis a través de esta"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nUsar endpoints de Amazon VPC para enrutar el tráfico a S3 y Kinesis sin pasar por Internet público - Utilizar VPC endpoints permite que las instancias EC2 en subredes privadas se comuniquen directamente con servicios de AWS como Amazon S3 y Amazon Kinesis sin necesidad de una IP pública ni de enrutar tráfico a través de Internet. Esto mejora la seguridad y evita la necesidad de usar instancias NAT o gateways adicionales.\n\n\n\nOpciones incorrectas:\n\nConfigurar una Gateway NAT en la subred pública y enrutar el tráfico de la instancia EC2 hacia S3 y Kinesis a través de esta - Una NAT Gateway permite que instancias en subredes privadas accedan a Internet, pero el tráfico sigue pasando por la red pública de AWS. Además, implica costos adicionales por transferencia y uso de IP elástica.\n\nCrear un Application Load Balancer en la subred privada y enrutar el tráfico desde la instancia EC2 a los servicios mediante reglas de enrutamiento - Los Application Load Balancers están diseñados para enrutar tráfico HTTP/HTTPS a instancias EC2 o servicios backend. No permiten acceder directamente a servicios como S3 o Kinesis ni enrutan tráfico saliente desde instancias EC2 a servicios gestionados de AWS.\n\nHabilitar el cifrado en tránsito con TLS 1.2 para acceder a S3 y Kinesis desde la instancia EC2 - El cifrado en tránsito (TLS) asegura la privacidad de los datos, pero no garantiza que el tráfico no esté saliendo por Internet. Para ello, se requieren mecanismos de red como endpoints de VPC o gateways privados.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-endpoints.html\n\nhttps://docs.aws.amazon.com/streams/latest/dev/vpc.html"
  },
  {
    "q": "Una empresa global de manufactura con oficinas en todo el mundo tiene varias cuentas de AWS. Para mejorar la eficiencia y reducir costos, el Director de Información (CIO) desea implementar una solución que administre centralmente sus recursos de AWS. Esto les permitirá aprovisionar recursos de AWS de manera centralizada y compartir recursos, como AWS Transit Gateways, configuraciones de AWS License Manager o reglas de Amazon Route 53 Resolver, en sus diferentes cuentas.\nComo arquitecto de soluciones, ¿qué combinación de opciones deberías implementar en este escenario? (Selecciona DOS)",
    "o": [
      "Consolidar todas las cuentas de la empresa utilizando AWS Organizations",
      "Utilizar AWS Control Tower para compartir fácilmente y de manera segura los recursos con sus cuentas de AWS",
      "Utilizar AWS Resource Access Manager (RAM) para compartir fácilmente y de manera segura los recursos con sus cuentas de AWS",
      "Utilizar AWS Identity and Access Management para configurar el acceso entre cuentas que permita compartir recursos de forma segura con sus cuentas de AWS",
      "Consolidar todas las cuentas de la empresa utilizando AWS ParallelCluster"
    ],
    "a": [
      0,
      2
    ],
    "e": "Correcto:\n\nUtilizar AWS Resource Access Manager (RAM) para compartir fácilmente y de manera segura los recursos con sus cuentas de AWS - AWS Resource Access Manager (RAM) permite compartir de manera fácil y segura recursos de AWS entre cuentas dentro de una Organización de AWS o incluso fuera de ella. Esto incluye recursos como AWS Transit Gateways, configuraciones de License Manager y reglas de Route 53 Resolver. RAM reduce la necesidad de duplicar recursos y minimiza el costo operativo de gestionarlos en múltiples cuentas.\n\nConsolidar todas las cuentas de la empresa utilizando AWS Organizations - AWS Organizations permite consolidar múltiples cuentas de AWS bajo una sola organización para administrarlas de forma centralizada. Con AWS Organizations, puedes crear políticas para controlar el acceso y gestionar permisos en varias cuentas. También facilita la administración de facturación unificada y la implementación de configuraciones globales.\n\n\n\nOpciones incorrectas:\n\nUtilizar AWS Identity and Access Management para configurar el acceso entre cuentas que permita compartir recursos de forma segura con sus cuentas de AWS - Aunque IAM permite delegar acceso entre cuentas, configurar permisos cruzados en múltiples cuentas requiere mucho trabajo manual y mantenimiento constante. RAM es una solución más eficiente para compartir recursos de manera centralizada.\n\nUtilizar AWS Control Tower para compartir fácilmente y de manera segura los recursos con sus cuentas de AWS - AWS Control Tower ayuda a configurar y gobernar un nuevo entorno multi-cuenta en AWS, pero no se utiliza para compartir recursos entre cuentas. Se enfoca en la administración de la conformidad y la seguridad al crear nuevas cuentas.\n\nConsolidar todas las cuentas de la empresa utilizando AWS ParallelCluster - AWS ParallelCluster es una herramienta de administración de clústeres de computación de alto rendimiento (HPC) en AWS, no está diseñado para la consolidación de cuentas.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/ram/\n\nhttps://docs.aws.amazon.com/ram/latest/userguide/shareable.html"
  },
  {
    "q": "Una plataforma de educación en línea está alojada en un grupo de Auto Scaling de instancias EC2. Debido a la variabilidad en la demanda, a veces hay más instancias de las necesarias, lo que genera costos adicionales. El equipo de operaciones ha solicitado a un arquitecto de soluciones que optimice la infraestructura para garantizar una gestión eficiente de los recursos sin afectar el rendimiento de la aplicación.\n¿Qué política de escalado dinámico se debe utilizar para cumplir con este requisito?",
    "o": [
      "Usar escalado de seguimiento de objetivos (Target Tracking Scaling)",
      "Usar escalado simple basado en alarmas de CloudWatch",
      "Usar una combinación de escalado manual y programado",
      "Usar escalado programado (Scheduled Scaling)"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nUsar escalado de seguimiento de objetivos (Target Tracking Scaling) - Target Tracking Scaling ajusta automáticamente el tamaño del grupo de Auto Scaling en función de una métrica clave, como la utilización de CPU o el tráfico de red. Este método evita el aprovisionamiento excesivo y asegura que los recursos se utilicen de manera eficiente, reduciendo costos sin comprometer el rendimiento.\n\nTarget Tracking Scaling ajusta automáticamente la cantidad de instancias EC2 en función de una métrica objetivo, lo que permite optimizar el costo sin comprometer la calidad del servicio.\nEs ideal para cargas de trabajo con tráfico impredecible, ya que responde en tiempo real a las variaciones de la demanda.\nMinimiza el riesgo de sobrecostos y asegura que siempre haya la cantidad justa de instancias para mantener el rendimiento óptimo de la aplicación.\n\n\nOpciones incorrectas:\n\nUsar escalado simple basado en alarmas de CloudWatch - Simple Scaling reacciona a alarmas de CloudWatch, pero debido a los períodos de enfriamiento, puede generar demoras en la respuesta a cambios en la demanda, lo que no es ideal para una aplicación con tráfico variable.\n\nUsar escalado programado (Scheduled Scaling) - Scheduled Scaling solo funciona bien si la carga de trabajo es predecible y sigue patrones horarios o diarios. Sin embargo, en un entorno con demanda fluctuante, como una plataforma de videoconferencias, este enfoque no es suficiente.\n\nUsar una combinación de escalado manual y programado - La combinación de escalado manual y programado no responde dinámicamente a cambios en la carga de trabajo, lo que puede llevar a la sobreutilización o infrautilización de recursos.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-target-tracking.html\n\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/AutoScalingGroup.html"
  },
  {
    "q": "Una empresa de telecomunicaciones gestiona una API que permite a los usuarios modificar planes móviles y servicios contratados. Durante eventos como cierres de facturación o campañas promocionales, el tráfico hacia esta API se incrementa drásticamente.\nLa empresa necesita asegurar tiempos de respuesta consistentes con baja latencia, incluso durante picos de tráfico, y al mismo tiempo minimizar el esfuerzo de administración de infraestructura.\n¿Cuál es la solución más eficiente para satisfacer estos requisitos?",
    "o": [
      "Usar Amazon API Gateway junto con funciones de AWS Lambda con concurrencia provisionada",
      "Usar Amazon API Gateway con tareas de AWS Fargate para manejar las solicitudes de la API",
      "Implementar la API usando AWS Elastic Beanstalk con grupos de auto-scaling",
      "Implementar la API en una instancia de Amazon EC2 detrás de un Application Load Balancer con escalado manual"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nUsar Amazon API Gateway junto con funciones de AWS Lambda con concurrencia provisionada - Integrar Amazon API Gateway con funciones Lambda utilizando concurrencia provisionada es ideal para aplicaciones sensibles a la latencia. Lambda mantiene instancias \"calientes\" siempre disponibles, lo que elimina los tiempos de arranque en frío y mejora significativamente la experiencia del usuario en momentos de alta demanda, sin requerir administración de servidores.\n\nOpciones incorrectas:\n\nImplementar la API usando AWS Elastic Beanstalk con grupos de auto-scaling - Elastic Beanstalk con auto-scaling proporciona escalabilidad automática, pero puede tener un tiempo de reacción mayor ante picos repentinos de tráfico, y no garantiza latencias bajas constantes durante todos los periodos.\n\nImplementar la API en una instancia de Amazon EC2 detrás de un Application Load Balancer con escalado manual - Usar EC2 con escalado manual no es eficiente ni escalable. Requiere intervención humana para ajustar capacidad, lo cual no cumple con el requisito de minimizar esfuerzo operacional**.\n\nUsar Amazon API Gateway con tareas de AWS Fargate para manejar las solicitudes de la API - Aunque Fargate permite ejecutar contenedores sin administrar servidores, la configuración y operación de tareas requiere más mantenimiento, y los tiempos de arranque de tareas pueden introducir demoras perceptibles durante picos.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/lambda/latest/dg/provisioned-concurrency.html"
  },
  {
    "q": "Un Solutions Architect identificó una serie de ataques DDoS mientras monitoreaba la VPC. El arquitecto necesita reforzar la infraestructura actual en la nube para proteger los datos de los clientes.\n¿Cuál de las siguientes es la solución más adecuada para mitigar este tipo de ataques?",
    "o": [
      "Configurar un firewall de aplicaciones web usando AWS WAF para filtrar, monitorear y bloquear tráfico HTTP",
      "Usar AWS Firewall Manager, configurando una capa de seguridad que prevenga ataques SYN floods, ataques de reflexión UDP y otros ataques DDoS",
      "Usar una combinación de Security Groups y Network Access Control Lists para permitir solo el tráfico autorizado a la VPC",
      "Utilizar AWS Shield Advanced para detectar y mitigar ataques DDoS"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nUtilizar AWS Shield Advanced para detectar y mitigar ataques DDoS - Utilizar AWS Shield Advanced para detectar y mitigar ataques DDoS es la opción correcta porque ofrece protección avanzada contra ataques DDoS a nivel de red y transporte. AWS Shield Advanced proporciona detección y mitigación automática contra ataques grandes y sofisticados, acceso al AWS DDoS Response Team (DRT) las 24/7 y reportes detallados. Además, cubre posibles costos asociados con el escalamiento automático durante un ataque.\n\nAWS Shield Advanced proporciona protección mejorada en Elastic Load Balancing (ELB), Amazon CloudFront, Amazon Route 53 y Elastic IPs.\nOfrece alertas en tiempo real y soporte del AWS DDoS Response Team (DRT) para ayudar a mitigar ataques activos.\nAWS Shield Standard está incluido sin costo adicional, pero AWS Shield Advanced ofrece protección más robusta y personalizada.\n\n\nOpciones incorrectas:\n\nUsar AWS Firewall Manager, configurando una capa de seguridad que prevenga ataques SYN floods, ataques de reflexión UDP y otros ataques DDoS - Usar AWS Firewall Manager es incorrecto porque Firewall Manager ayuda a gestionar las políticas de seguridad de AWS WAF y AWS Shield, pero no ofrece protección directa contra ataques DDoS. Se utiliza principalmente para administración centralizada de reglas de seguridad.\n\nConfigurar un firewall de aplicaciones web usando AWS WAF para filtrar, monitorear y bloquear tráfico HTTP - Configurar un firewall de aplicaciones web usando AWS WAF es incorrecto porque AWS WAF está diseñado para proteger aplicaciones web de vulnerabilidades comunes como SQL injection o XSS, pero no puede mitigar grandes volúmenes de tráfico de un ataque DDoS.\n\nUsar una combinación de Security Groups y Network Access Control Lists para permitir solo el tráfico autorizado a la VPC - Usar una combinación de Security Groups y Network ACLs es incorrecto porque estas configuraciones controlan el tráfico autorizado, pero no son suficientes para mitigar un ataque DDoS de gran escala. AWS Shield Advanced es más efectivo para este propósito.\n\nReferencias:\n\nhttps://d1.awsstatic.com/whitepapers/Security/DDoS_White_Paper.pdf\n\nhttps://aws.amazon.com/shield/"
  },
  {
    "q": "Un arquitecto de soluciones ha creado una nueva cuenta de AWS y debe asegurar el acceso del usuario raíz de la cuenta.\n¿Cuál de las siguientes combinaciones de acciones logrará este objetivo? (Selecciona dos).",
    "o": [
      "Habilitar la autenticación multi-factor (MFA) para el usuario raíz",
      "Almacenar las claves de acceso del usuario raíz en un bucket de Amazon S3 encriptado",
      "Agregar el usuario raíz a un grupo con permisos administrativos",
      "Eliminar la cuenta de usuario raíz",
      "Asegurar que el usuario raíz use una contraseña fuerte"
    ],
    "a": [
      0,
      4
    ],
    "e": "Correcto:\n\nAsegurar que el usuario raíz use una contraseña fuerte - Usar una contraseña fuerte para el usuario raíz reduce el riesgo de acceso no autorizado. Es una de las primeras medidas recomendadas al crear una nueva cuenta de AWS.\n\nHabilitar la autenticación multi-factor (MFA) para el usuario raíz - Habilitar la autenticación multi-factor (MFA) añade una capa adicional de seguridad, protegiendo el acceso incluso si la contraseña se ve comprometida.\n\nOpciones incorrectas:\n\nEliminar la cuenta de usuario raíz - No es posible eliminar la cuenta de usuario raíz; esta siempre existe en cada cuenta de AWS.\n\nAgregar el usuario raíz a un grupo con permisos administrativos - El usuario raíz ya tiene todos los permisos de la cuenta, por lo que agregarlo a un grupo administrativo es innecesario y no mejora la seguridad.\n\nAlmacenar las claves de acceso del usuario raíz en un bucket de Amazon S3 encriptado - Las claves de acceso del usuario raíz deben bloquearse o eliminarse; almacenarlas en un bucket S3, aunque esté cifrado, sigue siendo una mala práctica de seguridad.\n\nRecomendaciones adicionales:\n- Bloquear o eliminar las claves de acceso del usuario raíz.\n- No usar la cuenta raíz para tareas diarias; crear usuarios IAM con privilegios mínimos necesarios.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html\n\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_root-user.html"
  },
  {
    "q": "Una empresa de servicios financieros está migrando sus datos sensibles de clientes y aplicaciones a AWS. Quieren asegurar que los datos se almacenen y gestionen de forma segura mientras reducen el mantenimiento general y el esfuerzo operacional asociado con la gestión de bases de datos.\n¿Qué solución cumplirá estos requisitos?",
    "o": [
      "Migrar los datos y aplicaciones a instancias de Amazon RDS. Habilitar encriptación en reposo usando AWS Key Management Service (AWS KMS)",
      "Almacenar los datos en Amazon S3. Utilizar Amazon Macie para seguridad de datos continua y detección de amenazas",
      "Migrar los datos a instancias de Amazon RDS. Habilitar Amazon GuardDuty para protección de datos y detección de amenazas",
      "Migrar las aplicaciones y datos a instancias de Amazon EC2. Utilizar las claves gestionadas por el cliente del AWS Key Management Service (AWS KMS) para encriptación"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nMigrar los datos y aplicaciones a instancias de Amazon RDS. Habilitar encriptación en reposo usando AWS Key Management Service (AWS KMS) - Amazon RDS reduce significativamente el esfuerzo operacional al gestionar automáticamente tareas como respaldos, parches, monitoreo, escalado y replicación. Además, soporta encriptación en reposo integrada con AWS KMS, lo que permite proteger datos sensibles y cumplir con estándares regulatorios sin complejidad adicional.\n\nOpciones incorrectas:\n\nAlmacenar los datos en Amazon S3. Utilizar Amazon Macie para seguridad de datos continua y detección de amenazas - S3 y Macie son excelentes para almacenamiento y análisis de seguridad, pero S3 no es una base de datos transaccional para aplicaciones, un requisito esencial en este caso.\n\nMigrar los datos a instancias de Amazon RDS. Habilitar Amazon GuardDuty para protección de datos y detección de amenazas - GuardDuty detecta amenazas y actividad maliciosa, pero no está diseñado para proteger datos dentro de bases de datos ni reduce el esfuerzo operacional.\n\nMigrar las aplicaciones y datos a instancias de Amazon EC2. Utilizar las claves gestionadas por el cliente del AWS Key Management Service (AWS KMS) para encriptación - Ejecutar bases de datos en EC2 requiere administración manual (respaldos, parches, replicación), lo que va en contra del requisito de minimizar el mantenimiento.\n\nReferencia:\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html"
  },
  {
    "q": "Una aplicación usa una base de datos MySQL ejecutándose en una instancia de Amazon EC2. La aplicación genera alto I/O y escrituras constantes a una sola tabla en la base de datos. ¿Qué tipo de volumen de Amazon EBS proporcionará el rendimiento más consistente y baja latencia?",
    "o": [
      "SSD de IOPS Provisionadas (io1)",
      "SSD de Propósito General (gp2)",
      "HDD Optimizado para Rendimiento (st1)",
      "HDD Frío (sc1)"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nSSD de IOPS Provisionadas (io1) - Los volúmenes SSD de IOPS Provisionadas (io1) están diseñados para cargas de trabajo que requieren I/O intensivo, baja latencia y rendimiento consistente. Permiten provisionar explícitamente el número de IOPS necesarios, lo que los hace ideales para bases de datos con escrituras constantes y alta demanda de rendimiento.\n\nOpciones incorrectas:\n\nHDD Optimizado para Rendimiento (st1) - st1 es un HDD optimizado para rendimiento, pero no ofrece la consistencia ni la baja latencia necesaria para bases de datos relacionales.\n\nSSD de Propósito General (gp2) - gp2 ofrece buen rendimiento general, pero no garantiza el nivel de IOPS necesario para aplicaciones con alto I/O constante.\n\nHDD Frío (sc1) - sc1 es para cargas frías de bajo costo y no es adecuado para acceso frecuente ni cargas intensivas.\n\nReferencia:\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html"
  },
  {
    "q": "Una empresa está creando una solución que debe ofrecer recuperación ante desastres a través de múltiples Regiones de AWS. La solución requiere una base de datos relacional que pueda soportar un Objetivo de Punto de Recuperación (RPO) de 1 segundo y un Objetivo de Tiempo de Recuperación (RTO) de 1 minuto.\n¿Qué solución de AWS puede lograr esto?",
    "o": [
      "Amazon RDS con una réplica entre Regiones",
      "Amazon Aurora Global Database",
      "Amazon DynamoDB global tables",
      "Amazon RDS con Multi-AZ habilitado"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nAmazon Aurora Global Database - Amazon Aurora Global Database ofrece replicación entre Regiones con latencias típicas menores a 1 segundo, lo que permite un RPO de 1 segundo. Además, si la región primaria falla, una región secundaria puede promoverse a primaria en menos de 1 minuto, cumpliendo el RTO requerido. Esta solución está diseñada específicamente para escenarios globales de alta disponibilidad y recuperación ante desastres con bases de datos relacionales.\n\nOpciones incorrectas:\n\nAmazon RDS con una réplica entre Regiones - Las réplicas entre Regiones en Amazon RDS tienen mayor latencia y no pueden garantizar un RPO de 1 segundo ni una promoción tan rápida como Aurora Global Database.\n\nAmazon RDS con Multi-AZ habilitado - RDS Multi-AZ solo ofrece redundancia entre Zonas de Disponibilidad dentro de una misma Región, no entre Regiones. No cumple los requisitos.\n\nAmazon DynamoDB global tables - DynamoDB Global Tables es multi-región, pero no es una base de datos relacional, por lo que no satisface el requisito del escenario.\n\nReferencia:\n\nhttps://aws.amazon.com/rds/aurora/global-database/"
  },
  {
    "q": "Una agencia gubernamental planea almacenar documentos confidenciales sobre salud en AWS. Debido a la naturaleza sensible de la información, el arquitecto de soluciones debe restringir el acceso a los datos para que solo las solicitudes provenientes de una VPC específica puedan acceder al bucket de almacenamiento.\nAdemás, la solución debe evitar que los archivos sean eliminados o sobrescritos para cumplir con el requisito normativo de utilizar un modelo de almacenamiento Write-Once-Read-Many (WORM).\n¿Cuál de las siguientes combinaciones de opciones debería implementar el arquitecto de soluciones? (Selecciona DOS)",
    "o": [
      "Configurar un nuevo bucket de S3 para almacenar los documentos fiscales e integrarlo con AWS Network Firewall. Configurar el Network Firewall para aceptar únicamente solicitudes de acceso de datos de una VPC específica",
      "Crear un nuevo bucket de Amazon S3 con la función S3 Object Lock habilitada. Almacenar los documentos en el bucket y establecer la opción de Legal Hold para la retención de objetos",
      "Habilitar Object Lock pero desactivar Object Versioning en el nuevo bucket de Amazon S3 para cumplir con el requisito de almacenamiento Write-Once-Read-Many (WORM)",
      "Configurar un Amazon S3 Access Point para el bucket de S3 para restringir el acceso a datos únicamente a una VPC específica de Amazon",
      "Almacenar los documentos en la clase de almacenamiento Amazon S3 Glacier Instant Retrieval. Utilizar la API PutBucketPolicy para aplicar una política que restrinja el acceso a una VPC específica de Amazon"
    ],
    "a": [
      1,
      3
    ],
    "e": "Correcto:\n\nConfigurar un Amazon S3 Access Point para el bucket de S3 para restringir el acceso a datos únicamente a una VPC específica de Amazon - Amazon S3 Access Points proporciona un mecanismo eficiente para restringir el acceso a datos de S3 a una VPC específica, asegurando que las solicitudes de datos solo provengan de un entorno privado. Esto facilita la administración de políticas de acceso en entornos con múltiples aplicaciones o equipos que necesitan acceso al bucket de S3 desde diferentes redes privadas.\n\nCrear un nuevo bucket de Amazon S3 con la función S3 Object Lock habilitada. Almacenar los documentos en el bucket y establecer la opción de Legal Hold para la retención de objetos - S3 Object Lock permite el almacenamiento en un modelo Write-Once-Read-Many (WORM), evitando la eliminación o modificación de objetos por un período definido o indefinidamente. Al habilitar el Legal Hold, se asegura que los documentos fiscales permanezcan inmutables hasta que se levante el bloqueo legal, cumpliendo así con los requisitos normativos de retención de datos.\n\n\n\n\n\nAl usar estas dos funcionalidades en conjunto, se asegura un almacenamiento seguro y conforme a normativas para datos confidenciales.\n\nOpciones incorrectas:\n\nAlmacenar los documentos en la clase de almacenamiento Amazon S3 Glacier Instant Retrieval. Utilizar la API PutBucketPolicy para aplicar una política que restrinja el acceso a una VPC específica de Amazon - Amazon S3 Glacier Instant Retrieval es una clase de almacenamiento para datos a los que se accede raramente pero requieren tiempos de recuperación en milisegundos. No proporciona controles de acceso a nivel de VPC, por lo que no cumple con el requisito de restricción de acceso.\n\nConfigurar un nuevo bucket de S3 para almacenar los documentos fiscales e integrarlo con AWS Network Firewall. Configurar el Network Firewall para aceptar únicamente solicitudes de acceso de datos de una VPC específica - AWS Network Firewall protege redes VPC contra amenazas externas y controla el tráfico saliente y entrante, pero no puede restringir directamente el acceso a un bucket de S3. Los Access Points de S3 son la solución correcta para aplicar políticas de acceso específicas de VPC.\n\nHabilitar Object Lock pero desactivar Object Versioning en el nuevo bucket de Amazon S3 para cumplir con el requisito de almacenamiento Write-Once-Read-Many (WORM) - Aunque S3 Object Lock permite el almacenamiento en WORM, Object Versioning debe estar habilitado para que Object Lock funcione correctamente. No es posible desactivar la Versioning si Object Lock está habilitado.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/access-points.html\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lock.html"
  },
  {
    "q": "Una empresa tiene varias cuentas de AWS que son usadas por desarrolladores para entornos de desarrollo, pruebas y preproducción.\nLa empresa ha recibido facturas elevadas por instancias de Amazon EC2 que están subutilizadas. Un arquitecto de soluciones ha sido encargado de restringir la capacidad de lanzar instancias grandes de EC2 en todas las cuentas.\n¿Cómo puede el arquitecto de soluciones cumplir este requisito con el menor esfuerzo operacional?",
    "o": [
      "Crear una organización en AWS Organizations que incluya todas las cuentas y crear una política de control de servicios (SCP) que niegue el lanzamiento de instancias grandes de EC2",
      "Crear un rol IAM en cada cuenta que niegue el lanzamiento de instancias grandes de EC2 y otorgar al grupo IAM de desarrolladores acceso al rol",
      "Crear un rol vinculado al servicio para Amazon EC2 y adjuntar una política que niegue el lanzamiento de instancias grandes de EC2",
      "Crear una política basada en recursos que niegue el lanzamiento de instancias grandes de EC2 y adjuntarla a Amazon EC2 en cada cuenta"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nCrear una organización en AWS Organizations que incluya todas las cuentas y crear una política de control de servicios (SCP) que niegue el lanzamiento de instancias grandes de EC2 - Usar AWS Organizations y aplicar una política de control de servicios (SCP) es la forma más eficiente de restringir el lanzamiento de instancias grandes de EC2 en todas las cuentas. Las SCP establecen los permisos máximos que pueden otorgarse en cada cuenta de la organización, actuando como una barrera de protección centralizada. De esta forma, incluso los administradores de las cuentas no podrán lanzar instancias que excedan los límites definidos.\n\nOpciones incorrectas:\n\nCrear un rol IAM en cada cuenta que niegue el lanzamiento de instancias grandes de EC2 y otorgar al grupo IAM de desarrolladores acceso al rol - Crear un rol IAM en cada cuenta aumenta el esfuerzo operacional y no garantiza consistencia entre cuentas.\n\nCrear una política basada en recursos que niegue el lanzamiento de instancias grandes de EC2 y adjuntarla a Amazon EC2 en cada cuenta - No se pueden adjuntar políticas basadas en recursos directamente a Amazon EC2; este tipo de políticas aplican a recursos como S3 o Lambda.\n\nCrear un rol vinculado al servicio para Amazon EC2 y adjuntar una política que niegue el lanzamiento de instancias grandes de EC2 - Los roles vinculados al servicio son creados automáticamente por AWS y no pueden ser modificados ni personalizados para aplicar restricciones de este tipo.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html\n\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_getting-started_concepts.html"
  },
  {
    "q": "Una empresa planea migrar su carga de trabajo on-premises a AWS. La arquitectura actual se compone de un servidor Microsoft SharePoint que utiliza un almacenamiento de archivos compartido de Windows. El Solutions Architect necesita usar una solución de almacenamiento en la nube que sea altamente disponible y que se pueda integrar con Active Directory para el control de acceso y autenticación.\n¿Cuál de las siguientes opciones puede satisfacer este requisito?",
    "o": [
      "Crear un sistema de archivos Network File System (NFS) utilizando AWS Storage Gateway",
      "Crear un sistema de archivos utilizando Amazon EFS y unirlo a un dominio de Active Directory",
      "Crear un sistema de archivos utilizando Amazon FSx for Windows File Server y unirlo a un dominio de Active Directory en AWS",
      "Lanzar una instancia de Amazon EC2 con Windows Server para montar un bucket de S3 como un volumen de archivos"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nCrear un sistema de archivos utilizando Amazon FSx for Windows File Server y unirlo a un dominio de Active Directory en AWS - Crear un sistema de archivos utilizando Amazon FSx for Windows File Server y unirlo a un dominio de Active Directory en AWS es correcto porque Amazon FSx for Windows File Server proporciona almacenamiento de archivos administrado, altamente confiable y escalable que utiliza el protocolo SMB (Service Message Block) estándar de la industria. Se integra perfectamente con Active Directory, lo que permite administrar permisos de acceso y autenticación de usuarios en entornos de Microsoft Windows.\n\n\n\nOpciones incorrectas:\n\nCrear un sistema de archivos Network File System (NFS) utilizando AWS Storage Gateway - Crear un sistema de archivos Network File System (NFS) utilizando AWS Storage Gateway es incorrecto porque NFS es principalmente para sistemas Linux. No es compatible con la autenticación y el control de acceso de Active Directory en entornos Windows.\n\nCrear un sistema de archivos utilizando Amazon EFS y unirlo a un dominio de Active Directory - Crear un sistema de archivos utilizando Amazon EFS y unirlo a un dominio de Active Directory es incorrecto porque Amazon EFS solo es compatible con sistemas Linux y no puede integrarse con Active Directory para entornos Windows.\n\nLanzar una instancia de Amazon EC2 con Windows Server para montar un bucket de S3 como un volumen de archivos - Lanzar una instancia de Amazon EC2 con Windows Server para montar un bucket de S3 como un volumen de archivos es incorrecto porque Amazon S3 no proporciona la integración nativa con Active Directory ni las capacidades de control de acceso a nivel de archivo necesarias para un almacenamiento compartido de Windows.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/fsx/latest/WindowsGuide/aws-ad-integration-fsx-w.html\n\nhttps://aws.amazon.com/fsx/windows/faqs/"
  },
  {
    "q": "Una empresa de medios digitales procesa videos cada vez que se suben a un bucket de Amazon S3. Utiliza AWS Fargate para ejecutar los trabajos de procesamiento como tareas por lotes. Para minimizar costos, desea mantener solo una tarea en ejecución por defecto y escalar dinámicamente solo cuando se suban nuevos archivos al bucket.\n¿Cuál es la opción más adecuada para implementar esto con el menor esfuerzo operativo?",
    "o": [
      "Configurar una regla de Amazon EventBridge (Amazon CloudWatch Events) para detectar operaciones PUT de objetos en S3 y establecer el destino en el clúster de ECS para ejecutar una nueva tarea de ECS",
      "Configurar una función AWS Lambda activada por eventos de S3 que invoque la API de ECS para ejecutar tareas nuevas",
      "Habilitar el registro de acceso al bucket S3 y usar Amazon Athena para consultar eventos, luego ejecutar tareas manualmente desde ECS",
      "Crear un flujo de Step Functions que utilice CloudTrail para detectar cargas en S3 y luego ejecute la tarea en Fargate"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nConfigurar una regla de Amazon EventBridge (Amazon CloudWatch Events) para detectar operaciones PUT de objetos en S3 y establecer el destino en el clúster de ECS para ejecutar una nueva tarea de ECS - Configurar una regla de Amazon EventBridge para detectar operaciones PUT de objetos en S3 y activar directamente una tarea de ECS es la opción más eficiente y simple. No requiere funciones Lambda, CloudTrail ni componentes adicionales. Es ideal para flujos de trabajo automatizados como procesamiento de archivos multimedia.\n\n\n\nOpciones incorrectas:\n\nCrear un flujo de Step Functions que utilice CloudTrail para detectar cargas en S3 y luego ejecute la tarea en Fargate - Aunque Step Functions puede orquestar procesos, es innecesariamente complejo para este caso simple. Además, depende de CloudTrail, que introduce latencia y configuración adicional.\n\nConfigurar una función AWS Lambda activada por eventos de S3 que invoque la API de ECS para ejecutar tareas nuevas - Lambda puede ser útil, pero EventBridge ya permite activar tareas ECS directamente. Agregar Lambda introduce otro punto de mantenimiento que no es necesario.\n\nHabilitar el registro de acceso al bucket S3 y usar Amazon Athena para consultar eventos, luego ejecutar tareas manualmente desde ECS - Consultar registros con Athena para identificar cargas y luego ejecutar tareas es un enfoque manual y no automatizado, contrario a los requisitos de eficiencia y bajo esfuerzo.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/cloudwatch/latest/events/CloudWatch-Events-tutorial-ECS.html\n\nhttps://docs.aws.amazon.com/cloudwatch/latest/events/Create-CloudWatch-Events-Rule.html"
  },
  {
    "q": "Una empresa de biotecnología ha migrado recientemente su infraestructura de aplicaciones a un clúster de Amazon Elastic Kubernetes Service (Amazon EKS). Como parte de su estrategia de seguridad, necesita garantizar que todos los secretos de configuración y credenciales, como contraseñas de bases de datos y claves API, se almacenen de forma segura y cifrada dentro del almacén de claves de valor etcd de Amazon EKS.\n¿Cuál es la mejor solución para cumplir con estos requisitos de seguridad?",
    "o": [
      "Habilitar el cifrado de secretos en etcd utilizando una clave de AWS KMS en el clúster de Amazon EKS",
      "Utilizar AWS Secrets Manager con una clave de AWS KMS para almacenar de manera segura los datos sensibles dentro del almacén de claves de valor etcd del clúster de Amazon EKS",
      "Habilitar el cifrado predeterminado de Amazon S3 con una clave de AWS KMS para cifrar los secretos almacenados en el clúster de Amazon EKS",
      "Configurar Amazon EBS con encriptación habilitada y montar los volúmenes en los nodos del clúster de Amazon EKS para proteger los datos sensibles"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nHabilitar el cifrado de secretos en etcd utilizando una clave de AWS KMS en el clúster de Amazon EKS - Habilitar el cifrado de secretos en etcd con una clave de AWS KMS protege los datos sensibles almacenados dentro del clúster de EKS. Esto asegura que todas las credenciales y configuraciones estén cifradas en reposo dentro del almacén de claves de etcd, cumpliendo con las mejores prácticas de seguridad.\n\netcd en Amazon EKS almacena datos sensibles del clúster, incluyendo configuraciones y secretos, por lo que es fundamental cifrar esta información.\nAWS KMS permite administrar y controlar las claves criptográficas utilizadas para cifrar los secretos en etcd.\nAl habilitar el cifrado en etcd con KMS, se garantiza la seguridad de los datos en reposo y se cumple con los requisitos de seguridad y cumplimiento normativo.\n\n\nOpciones incorrectas:\n\nUtilizar AWS Secrets Manager con una clave de AWS KMS para almacenar de manera segura los datos sensibles dentro del almacén de claves de valor etcd del clúster de Amazon EKS - AWS Secrets Manager es útil para gestionar secretos y credenciales de manera centralizada, pero no proporciona cifrado directo dentro del almacén de claves de valor etcd de EKS.\n\nHabilitar el cifrado predeterminado de Amazon S3 con una clave de AWS KMS para cifrar los secretos almacenados en el clúster de Amazon EKS - Habilitar el cifrado predeterminado de S3 protege los objetos almacenados en S3, pero no afecta el almacenamiento de secretos dentro del clúster de EKS.\n\nConfigurar Amazon EBS con encriptación habilitada y montar los volúmenes en los nodos del clúster de Amazon EKS para proteger los datos sensibles - Configurar volúmenes EBS cifrados protege el almacenamiento persistente de los nodos del clúster, pero no cifra los datos dentro de etcd, que es donde se almacenan las configuraciones y credenciales críticas del clúster.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/eks/latest/userguide/enable-kms.html\n\nhttps://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/\n\nhttps://docs.aws.amazon.com/eks/latest/userguide/security-considerations.html"
  },
  {
    "q": "Una empresa ha migrado recientemente sus aplicaciones a AWS. El equipo de auditoría debe evaluar si los servicios que utiliza la empresa cumplen con estándares comunes de seguridad y normativas. Un arquitecto de soluciones necesita proporcionar al equipo un informe con todos los documentos relacionados con el cumplimiento de normativas para su cuenta de AWS. ¿Qué acción debería considerar el arquitecto de soluciones?",
    "o": [
      "Utilizar AWS Artifact para ver los informes de seguridad, así como otra información relacionada con el cumplimiento de normativas de AWS",
      "Ver todos los informes de cumplimiento de seguridad de AWS desde AWS Security Hub",
      "Ejecutar un trabajo de evaluación en Amazon Inspector para descargar toda la información relacionada con el cumplimiento de normativas de AWS",
      "Ejecutar un trabajo de Amazon Macie para ver los informes de cumplimiento de Service Organization Control (SOC), Payment Card Industry (PCI) y otros reportes de cumplimiento desde AWS Certificate Manager (ACM)"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nUtilizar AWS Artifact para ver los informes de seguridad, así como otra información relacionada con el cumplimiento de normativas de AWS - AWS Artifact es el recurso central para obtener información relacionada con el cumplimiento de normativas en AWS. Proporciona acceso bajo demanda a informes de seguridad y cumplimiento de normativas de AWS, incluyendo informes de Service Organization Control (SOC), Payment Card Industry (PCI) y certificaciones de organismos de acreditación de acuerdo con normativas y marcos de cumplimiento globales. También incluye acuerdos en línea como el Business Associate Addendum (BAA) y el Non-Disclosure Agreement (NDA).\n\nAWS Artifact incluye informes de cumplimiento globales, como:\n\nSOC 1, SOC 2 y SOC 3\nPCI DSS (Payment Card Industry Data Security Standard)\nCertificaciones ISO (International Organization for Standardization)\nAcuerdos BAA (Business Associate Addendum) para HIPAA (Health Insurance Portability and Accountability Act)\nEste servicio está disponible sin costo adicional para todas las cuentas de AWS y proporciona acceso a los informes en tiempo real.\n\n\n\nOpciones incorrectas:\n\nEjecutar un trabajo de Amazon Macie para ver los informes de cumplimiento de Service Organization Control (SOC), Payment Card Industry (PCI) y otros reportes de cumplimiento desde AWS Certificate Manager (ACM) - Amazon Macie es un servicio para detectar datos confidenciales en S3, mientras que ACM administra certificados SSL/TLS. Ninguno de estos servicios ofrece informes de cumplimiento.\n\nVer todos los informes de cumplimiento de seguridad de AWS desde AWS Security Hub - AWS Security Hub proporciona una visión integral del estado de seguridad y cumplimiento en tiempo real, pero no ofrece acceso a informes de cumplimiento específicos como SOC o PCI.\n\nEjecutar un trabajo de evaluación en Amazon Inspector para descargar toda la información relacionada con el cumplimiento de normativas de AWS - Amazon Inspector evalúa vulnerabilidades en instancias de EC2 y otros recursos, pero no proporciona ni descarga informes de cumplimiento normativo.\n\nReferencias:\n\nhttps://aws.amazon.com/artifact/getting-started/\n\nhttps://docs.aws.amazon.com/artifact/latest/ug/what-is-aws-artifact.html"
  },
  {
    "q": "Una aplicación que registra datos meteorológicos cada minuto está implementada en un grupo de instancias Spot de EC2 y utiliza una instancia de base de datos MySQL en Amazon RDS. Actualmente, solo hay una instancia de RDS en una Zona de Disponibilidad. Planeas mejorar la base de datos para garantizar alta disponibilidad mediante la replicación de datos de manera síncrona a otra instancia de RDS.\n¿Cuál de las siguientes opciones realiza replicación de datos síncrona en RDS?",
    "o": [
      "Instancia de RDS ejecutándose en una implementación Multi-AZ",
      "CloudFront ejecutándose en una implementación Multi-AZ",
      "DynamoDB Read Replica",
      "RDS Read Replica"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nInstancia de RDS ejecutándose en una implementación Multi-AZ - Cuando creas o modificas tu instancia de base de datos para que se ejecute como una implementación Multi-AZ, Amazon RDS aprovisiona y mantiene automáticamente una réplica en espera (standby replica) en una zona de disponibilidad diferente. Las actualizaciones en tu instancia de RDS se replican de manera síncrona a través de las zonas de disponibilidad hacia la instancia en espera para mantenerla sincronizada y proteger los datos contra fallas en la instancia principal. Esto garantiza alta disponibilidad y recuperación ante desastres, ya que en caso de falla de la instancia principal, RDS realiza automáticamente un cambio a la instancia en espera.\n\n\n\nOpciones incorrectas:\n\nCloudFront ejecutándose en una implementación Multi-AZ - CloudFront no tiene una funcionalidad de replicación de datos, ya que es un servicio de distribución de contenido que utiliza una red global de ubicaciones de borde para almacenar en caché y entregar contenido a los usuarios finales.\n\nRDS Read Replica - Una Read Replica de RDS utiliza replicación asíncrona, no síncrona. Esto significa que los datos se copian desde la instancia principal a las réplicas con cierto retraso. Este enfoque es adecuado para escalar operaciones de lectura y descargar tráfico de lectura de la base de datos principal, pero no proporciona alta disponibilidad ni recuperación ante fallas como lo hace Multi-AZ.\n\nDynamoDB Read Replica - DynamoDB utiliza replicación asíncrona para sus tablas globales, no replicación síncrona. Además, no es aplicable a RDS, ya que es un servicio diferente de base de datos NoSQL.\n\nReferencias:\n\nhttps://aws.amazon.com/rds/details/multi-az/"
  },
  {
    "q": "Una empresa de arquitectura con oficinas en varias ciudades está migrando su sistema de colaboración de archivos a AWS. Actualmente utilizan servidores Windows con recursos compartidos SMB para almacenar planos, documentos de proyectos y archivos CAD. La empresa necesita una solución totalmente administrada en la nube que sea compatible con su entorno Windows, permita el acceso concurrente y ofrezca alta disponibilidad.\n¿Cuál de las siguientes opciones se puede utilizar para cumplir con este requisito?",
    "o": [
      "Usar AWS Backup para replicar volúmenes de un servidor de archivos local",
      "Utilizar Amazon FSx for Windows File Server como reemplazo del recurso compartido de archivos",
      "Montar Amazon EBS en múltiples instancias EC2 mediante Amazon FSx Lustre",
      "Crear un bucket de Amazon S3 con acceso mediante Amazon WorkDocs Drive"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nUtilizar Amazon FSx for Windows File Server como reemplazo del recurso compartido de archivos - Amazon FSx for Windows File Server es la opción ideal. Es un sistema de archivos completamente administrado compatible con SMB y Active Directory, diseñado específicamente para cargas de trabajo Windows. Ofrece alta disponibilidad, replicación automática, rendimiento ajustable y se integra fácilmente en redes empresariales distribuidas.\n\n\n\nOpciones incorrectas:\n\nCrear un bucket de Amazon S3 con acceso mediante Amazon WorkDocs Drive - Amazon S3 con WorkDocs Drive permite acceso desde el escritorio, pero no proporciona un recurso SMB compartido tradicional ni está optimizado para aplicaciones que requieren locking de archivos como CAD.\n\nMontar Amazon EBS en múltiples instancias EC2 mediante Amazon FSx Lustre - FSx for Lustre está orientado a cargas HPC y no está diseñado para entornos Windows ni soporta el protocolo SMB. Amazon EBS tampoco se puede montar en múltiples instancias de forma simultánea.\n\nUsar AWS Backup para replicar volúmenes de un servidor de archivos local - AWS Backup permite realizar copias de seguridad y restauración, pero no sustituye a un recurso compartido de archivos ni ofrece una experiencia de colaboración activa.\n\nReferencias:\n\nhttps://aws.amazon.com/fsx/windows/\n\nhttps://docs.aws.amazon.com/fsx/latest/WindowsGuide/what-is-fsx-windows.html"
  },
  {
    "q": "Una institución financiera necesita almacenar reportes sensibles de cumplimiento en un bucket de Amazon S3 con la funcionalidad de versionado habilitada.\nEl arquitecto de soluciones debe asegurarse de que ningún usuario, ni siquiera el usuario root de la cuenta de AWS, pueda eliminar o modificar estos documentos durante un período de siete años, en cumplimiento con normativas estrictas del sector bancario.\n¿Cuál de las siguientes opciones es la forma más segura de almacenar los datos en Amazon S3?",
    "o": [
      "Habilitar S3 Object Lock en modo de gobierno con una retención legal de siete años",
      "Habilitar S3 Object Lock en modo de gobierno con un período de retención de siete años",
      "Habilitar S3 Object Lock en modo de cumplimiento con un período de retención de siete años",
      "Habilitar S3 Object Lock en modo de cumplimiento con una retención legal de siete años"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nHabilitar S3 Object Lock en modo de cumplimiento con un período de retención de siete años - Habilitar S3 Object Lock en modo de cumplimiento con un período de retención de siete años. En el modo de cumplimiento (Compliance Mode), una versión de objeto protegida no puede ser sobrescrita ni eliminada por ningún usuario, ni siquiera por el root user de la cuenta de AWS. Este nivel de seguridad garantiza que los registros críticos de cumplimiento permanezcan intactos durante el período de retención de siete años, cumpliendo con los requisitos de almacenamiento WORM (Write Once Read Many). - S3 Object Lock permite implementar un modelo Write Once Read Many (WORM), protegiendo los datos de modificaciones o eliminaciones no autorizadas. - Existen dos modos de retención: - Governance Mode: Protege los objetos contra eliminación o modificación, pero permite cambios si el usuario tiene permisos administrativos. - Compliance Mode: No permite ninguna modificación o eliminación, incluso por el root user, garantizando el más alto nivel de seguridad. - Además, hay dos tipos de protección: - Período de Retención: Define un tiempo fijo durante el cual los datos no pueden ser eliminados o modificados. - Retención Legal (Legal Hold): Bloquea el objeto indefinidamente hasta que se elimine el bloqueo manualmente, sin una duración predefinida.\n\n\n\nOpciones incorrectas:\n\nHabilitar S3 Object Lock en modo de gobierno con un período de retención de siete años - En el modo de gobierno, los usuarios sin permisos administrativos no pueden modificar ni eliminar objetos bloqueados. Sin embargo, el root user o usuarios con permisos adecuados pueden deshabilitar la retención o eliminar el objeto, lo que no cumple con el requisito de cumplimiento estricto.\n\nHabilitar S3 Object Lock en modo de gobierno con una retención legal de siete años - Una retención legal impide que un objeto sea eliminado, pero no tiene una fecha de vencimiento establecida y puede ser eliminada manualmente en cualquier momento. Además, en el modo de gobierno, el root user podría eliminar los objetos con los permisos adecuados, lo que no garantiza el cumplimiento requerido.\n\nHabilitar S3 Object Lock en modo de cumplimiento con una retención legal de siete años - Aunque el modo de cumplimiento es el adecuado, una retención legal no establece un período de retención específico y puede ser eliminada manualmente. En cambio, un período de retención bloquea la eliminación y modificaciones solo durante el período de tiempo especificado.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lock.html\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lock-overview.html"
  },
  {
    "q": "Una empresa de análisis de datos planea migrar su plataforma de procesamiento de grandes volúmenes de información desde servidores Microsoft Windows locales a Amazon Web Services (AWS). La solución debe garantizar alta disponibilidad en múltiples Availability Zones y ofrecer acceso de baja latencia al almacenamiento en bloque.\n¿Cuál de las siguientes soluciones cumplirá con estos requisitos?",
    "o": [
      "Configurar la plataforma de análisis de datos en instancias de Amazon EC2 Windows en dos Availability Zones. Utilizar Amazon Elastic File System (Amazon EFS) para almacenamiento compartido entre las instancias. Configurar Amazon EFS con replicación entre regiones para sincronizar datos entre Availability Zones",
      "Configurar la plataforma de análisis de datos en instancias de Amazon EC2 Windows en dos Availability Zones. Utilizar Amazon FSx for Windows File Server para almacenamiento compartido",
      "Configurar la plataforma de análisis de datos en instancias de Amazon EC2 Windows en dos Availability Zones. Utilizar Amazon Simple Storage Service (Amazon S3) para almacenamiento y configurar replicación entre regiones para sincronizar datos entre buckets S3 en cada Availability Zone",
      "Configurar la plataforma de análisis de datos en instancias de Amazon EC2 Windows en dos Availability Zones. Utilizar Amazon FSx for NetApp ONTAP para crear un sistema de archivos Multi-AZ y acceder a los datos a través del protocolo iSCSI"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nConfigurar la plataforma de análisis de datos en instancias de Amazon EC2 Windows en dos Availability Zones. Utilizar Amazon FSx for NetApp ONTAP para crear un sistema de archivos Multi-AZ y acceder a los datos a través del protocolo iSCSI - Configurar la plataforma de análisis de datos en instancias de Amazon EC2 Windows en dos Availability Zones y utilizar Amazon FSx for NetApp ONTAP para almacenamiento en bloque con baja latencia es la mejor opción. FSx for NetApp ONTAP proporciona almacenamiento de archivos con alta disponibilidad, basado en el sistema de archivos ONTAP de NetApp, compatible con NFS, SMB e iSCSI. Su integración con el protocolo iSCSI permite ofrecer almacenamiento en bloque de alto rendimiento, ideal para entornos Windows con cargas de trabajo intensivas en datos.\n\n\n\nOpciones incorrectas:\n\nConfigurar la plataforma de análisis de datos en instancias de Amazon EC2 Windows en dos Availability Zones. Utilizar Amazon Simple Storage Service (Amazon S3) para almacenamiento y configurar replicación entre regiones para sincronizar datos entre buckets S3 en cada Availability Zone - Usar Amazon S3 con replicación entre regiones no es adecuado, ya que Amazon S3 es un almacenamiento de objetos y no proporciona la baja latencia necesaria para almacenamiento en bloque en cargas de trabajo de análisis de datos.\n\nConfigurar la plataforma de análisis de datos en instancias de Amazon EC2 Windows en dos Availability Zones. Utilizar Amazon FSx for Windows File Server para almacenamiento compartido - Utilizar Amazon FSx for Windows File Server es incorrecto porque, aunque proporciona almacenamiento compartido con baja latencia para entornos Windows, no cuenta con soporte nativo para almacenamiento en bloque con iSCSI y no ofrece replicación Multi-AZ en modo activo-activo.\n\nConfigurar la plataforma de análisis de datos en instancias de Amazon EC2 Windows en dos Availability Zones. Utilizar Amazon Elastic File System (Amazon EFS) para almacenamiento compartido entre las instancias. Configurar Amazon EFS con replicación entre regiones para sincronizar datos entre Availability Zones - Usar Amazon EFS con replicación entre regiones no es ideal, ya que EFS está optimizado para cargas de trabajo basadas en Linux y sistemas de archivos distribuidos, no para almacenamiento en bloque con baja latencia en entornos Windows.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/fsx/latest/ONTAPGuide/what-is-fsx-ontap.html\n\nhttps://docs.aws.amazon.com/fsx/latest/ONTAPGuide/high-availability-AZ.html"
  },
  {
    "q": "Una empresa de monitoreo de seguridad desea registrar detalles del tráfico que fluye hacia un Elastic Load Balancer (ELB) en su entorno de producción. Necesitan capturar información precisa como dirección IP de origen, puerto de destino y protocolo utilizado, para cumplir con sus políticas de auditoría y análisis de red.\n¿Cuál es la opción más confiable y segura para recopilar esta información?",
    "o": [
      "Habilitar Amazon CloudTrail y configurar reglas de captura de tráfico",
      "Usar Amazon CloudWatch Logs para revisar registros de conexión detallados",
      "Crear un registro de flujo de VPC para cada interfaz de red vinculada al ELB",
      "Crear un registro de flujo de VPC para las subredes donde se encuentra el ELB"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nCrear un registro de flujo de VPC para cada interfaz de red vinculada al ELB - Crear un VPC Flow Log para cada interfaz de red asociada al Elastic Load Balancer permite obtener datos detallados del tráfico entrante y saliente, incluyendo dirección IP de origen, destino, puertos, y protocolos. Es la opción más precisa para capturar tráfico en entornos de red complejos.\n\nOpciones incorrectas:\n\nCrear un registro de flujo de VPC para las subredes donde se encuentra el ELB - Registrar el tráfico a nivel de subred no garantiza una visibilidad completa de cada conexión que pasa por el ELB. Las interfaces de red del ELB ofrecen un nivel de detalle superior.\n\nHabilitar Amazon CloudTrail y configurar reglas de captura de tráfico - Amazon CloudTrail se centra en registrar llamadas a las API de AWS, no el tráfico de red. No puede usarse para análisis de conexiones de red en balanceadores.\n\nUsar Amazon CloudWatch Logs para revisar registros de conexión detallados - CloudWatch Logs solo captura métricas y registros definidos por el usuario o integraciones, pero no registra datos de red sin herramientas como VPC Flow Logs.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html\n\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/network/load-balancer-monitoring.html"
  },
  {
    "q": "Un arquitecto de soluciones a cargo de una aplicación crítica debe asegurar que las instancias de Amazon EC2 puedan ser lanzadas en otra Región de AWS en caso de un desastre.\n¿Qué pasos debe tomar el arquitecto de soluciones? (Selecciona dos).",
    "o": [
      "Lanzar instancias en la segunda Región desde las AMIs",
      "Copiar las instantáneas usando replicación entre regiones de Amazon S3",
      "Habilitar instantáneas entre regiones para las instancias de Amazon EC2",
      "Crear AMIs de las instancias y copiarlas a otra Región",
      "Lanzar instancias en la segunda Región usando la API de S3"
    ],
    "a": [
      0,
      3
    ],
    "e": "Correcto:\n\nLanzar instancias en la segunda Región desde las AMIs - Una vez que las AMIs se han copiado a la segunda Región, se pueden usar para lanzar nuevas instancias EC2 en esa Región, garantizando continuidad operativa en caso de falla regional.\n\nCrear AMIs de las instancias y copiarlas a otra Región - Crear AMIs de las instancias EC2 y copiarlas a otra Región permite tener una copia exacta del sistema, lista para ser usada en escenarios de recuperación ante desastres (DR). Las AMIs copiadas contienen tanto la configuración como el almacenamiento asociado.\n\nOpciones incorrectas:\n\nCopiar las instantáneas usando replicación entre regiones de Amazon S3 - No se pueden copiar instantáneas usando replicación entre regiones de Amazon S3, ya que las instantáneas de EBS no se gestionan directamente mediante S3.\n\nLanzar instancias en la segunda Región usando la API de S3 - No se pueden lanzar instancias usando la API de S3. Las AMIs deben lanzarse mediante la API de EC2.\n\nHabilitar instantáneas entre regiones para las instancias de Amazon EC2 - No existe una opción llamada “instantáneas entre regiones” para EC2. Las copias entre regiones deben hacerse explícitamente mediante el comando de copia de AMI o de snapshot.\n\nReferencias:\n\nhttps://aws.amazon.com/blogs/aws/ebs-snapshot-copy/\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/CopyingAMIs.html"
  },
  {
    "q": "Una empresa tiene 3 ingenieros de DevOps que manejan sus procesos de desarrollo de software y administración de infraestructura. Uno de los ingenieros eliminó accidentalmente un archivo alojado en Amazon S3, lo que causó una interrupción del servicio.\n¿Qué pueden hacer los ingenieros de DevOps para evitar que esto vuelva a ocurrir?",
    "o": [
      "Crear una política de bucket en IAM que deshabilite la operación de borrado",
      "Habilitar el Versionado de S3 y Multi-Factor Authentication (MFA) Delete en el bucket",
      "Configurar una URL firmada para todos los usuarios",
      "Utilizar S3 Infrequently Accessed para almacenar los datos"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nHabilitar el Versionado de S3 y Multi-Factor Authentication (MFA) Delete en el bucket - Habilitar el Versionado de S3 y MFA Delete permite proteger los datos contra eliminaciones accidentales. El versionado guarda múltiples versiones de un objeto, lo que permite recuperarlos en caso de eliminación no intencional. Además, activar MFA Delete añade una capa adicional de seguridad, ya que requiere autenticación multifactor para cambiar el estado del versionado o eliminar versiones de objetos.\n\nVersionado de S3 permite recuperar versiones anteriores de objetos borrados o modificados accidentalmente.\nMFA Delete requiere un código MFA para realizar acciones críticas como eliminar versiones, proporcionando una capa adicional de seguridad.\n\n\nOpciones incorrectas:\n\nUtilizar S3 Infrequently Accessed para almacenar los datos - Utilizar S3 Infrequently Accessed no ayuda a evitar eliminaciones accidentales, ya que solo cambia la clase de almacenamiento para ahorrar costos en datos de acceso poco frecuente.\n\nConfigurar una URL firmada para todos los usuarios - Configurar una URL firmada controla el acceso a los datos, pero no evita la eliminación accidental. Se utiliza para restringir el acceso a contenido privado.\n\nCrear una política de bucket en IAM que deshabilite la operación de borrado - Crear una política de bucket en IAM que deshabilite la operación de borrado evitaría la eliminación por completo, incluso en situaciones donde sí se requiere borrar datos. La necesidad es prevenir eliminaciones accidentales, no deshabilitar la acción de borrar en su totalidad.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html"
  },
  {
    "q": "Una plataforma global de e-learning que transmite clases en vivo y almacena grabaciones bajo demanda está expandiendo su infraestructura. Necesita una base de datos que escale automáticamente durante eventos masivos (como lanzamientos de cursos), sea altamente disponible, tolerante a fallos y permita realizar cambios frecuentes en el modelo de datos sin afectar el rendimiento. También requiere tiempos de respuesta en milisegundos para miles de usuarios accediendo simultáneamente. ¿Cuál es la solución de base de datos más adecuada para cumplir con estos requisitos?",
    "o": [
      "Una base de datos Amazon Aurora en clúster global",
      "Amazon ElastiCache con Redis",
      "Amazon DynamoDB con replicación global",
      "Amazon Keyspaces (for Apache Cassandra)"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nAmazon DynamoDB con replicación global - Amazon DynamoDB con replicación global es la mejor opción para esta plataforma de e-learning.\n\nDynamoDB es una base de datos NoSQL que: - Escala automáticamente para manejar picos de tráfico global (por ejemplo, en el lanzamiento de un curso popular). - Permite replicación multi-región para ofrecer baja latencia en todo el mundo. - No requiere esquema fijo, lo que facilita la evolución de los modelos de datos según se agregan nuevas funcionalidades. - Ofrece tiempos de respuesta en milisegundos, ideal para accesos simultáneos en tiempo real.\n\n\n\nOpciones incorrectas:\n\nUna base de datos Amazon Aurora en clúster global - Amazon Aurora en clúster global es potente y multirregional, pero su naturaleza relacional la hace menos flexible ante cambios frecuentes de modelo de datos. Además, la escalabilidad automática es más limitada frente a DynamoDB.\n\nAmazon Keyspaces (for Apache Cassandra) - Amazon Keyspaces es compatible con Cassandra y escala automáticamente, pero no ofrece aún el mismo nivel de integración y facilidad de uso que DynamoDB, especialmente en cuanto a replicación global y baja latencia garantizada.\n\nAmazon ElastiCache con Redis - Amazon ElastiCache con Redis mejora el rendimiento a través de caching, pero no es una base de datos primaria. No garantiza persistencia ni tolerancia total a fallos, por lo que no cumple con los requisitos del caso.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GlobalTables.html\n\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-general-nosql-design.html\n\nhttps://aws.amazon.com/nosql/"
  },
  {
    "q": "Una empresa de medios digitales gestiona varios petabytes de datos multimedia en un data lake distribuido entre múltiples cuentas de AWS. Usan AWS Lake Formation para controlar el acceso a estos datos.\nEl equipo de marketing necesita acceder de forma segura a conjuntos específicos de datos alojados en distintas cuentas para realizar análisis de campañas segmentadas.\n¿Cuál es la solución más adecuada para otorgar ese acceso con el menor esfuerzo operacional?",
    "o": [
      "Usar el comando Grant de permisos de Lake Formation en cada cuenta donde se almacenan los datos para permitir que los usuarios requeridos del equipo de marketing accedan a los datos",
      "Utilizar el control de acceso basado en etiquetas de Lake Formation para autorizar y otorgar permisos entre cuentas para los datos requeridos a las cuentas del equipo de marketing",
      "Usar AWS DataSync para sincronizar los datos necesarios a las cuentas del equipo de marketing",
      "Replicar los datos requeridos a una cuenta compartida. Crear un rol de acceso IAM en esa cuenta. Otorgar acceso definiendo una política de permisos que incluya usuarios de las cuentas del equipo de marketing como entidades confiables"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nUtilizar el control de acceso basado en etiquetas de Lake Formation para autorizar y otorgar permisos entre cuentas para los datos requeridos a las cuentas del equipo de marketing - El control de acceso basado en etiquetas de Lake Formation permite definir permisos centralizados y consistentes para múltiples cuentas. Esto permite a los administradores aplicar políticas a nivel de etiquetas, reduciendo la complejidad al evitar configuraciones manuales cuenta por cuenta. Es la solución recomendada para entornos multi-cuenta con requisitos de acceso selectivo y seguro.\n\nOpciones incorrectas:\n\nUsar el comando Grant de permisos de Lake Formation en cada cuenta donde se almacenan los datos para permitir que los usuarios requeridos del equipo de marketing accedan a los datos - El comando Grant debe ejecutarse manualmente en cada cuenta y base de datos relevante. Si los datos están distribuidos entre muchas cuentas, esto implica un esfuerzo operativo considerable y difícil de escalar.\n\nReplicar los datos requeridos a una cuenta compartida. Crear un rol de acceso IAM en esa cuenta. Otorgar acceso definiendo una política de permisos que incluya usuarios de las cuentas del equipo de marketing como entidades confiables - Replicar datos en una cuenta compartida aumenta el consumo de almacenamiento, complica la gobernanza y añade pasos operacionales innecesarios. Aunque funcional, no es eficiente ni escalable.\n\nUsar AWS DataSync para sincronizar los datos necesarios a las cuentas del equipo de marketing - AWS DataSync está pensado para mover archivos entre ubicaciones de almacenamiento, como S3 o sistemas on-premises, pero no es una herramienta de control de acceso ni facilita la gobernanza multi-cuenta en Lake Formation.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/lake-formation/latest/dg/tag-based-access-control.html"
  },
  {
    "q": "Un sistema automatizado que exporta contenido multimedia genera archivos de video y los almacena en un bucket S3 llamado media-exports. Un rol de IAM está asociado a esta funcionalidad, y actualmente tiene la siguiente política:\n{ \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"s3:PutObject\", \"s3:GetObject\" ], \"Resource\": \"arn:aws:s3:::media-exports/\" }, { \"Effect\": \"Deny\", \"Action\": [ \"s3:DeleteObject\", \"s3:PutObjectAcl\" ], \"Resource\": \"arn:aws:s3:::media-exports/\" } ] }\n¿Qué efecto tiene esta política sobre el comportamiento del sistema? (Selecciona TRES)",
    "o": [
      "El sistema puede borrar archivos del bucket 'media-exports'",
      "El sistema tiene permisos para listar todos los objetos del bucket 'media-exports'",
      "El sistema no puede eliminar ni modificar los permisos de los objetos debido a la denegación explícita",
      "El sistema puede subir archivos al bucket 'media-exports'",
      "El sistema puede leer archivos almacenados en el bucket 'media-exports'",
      "El sistema puede modificar permisos de objetos en el bucket 'media-exports'"
    ],
    "a": [
      2,
      3,
      4
    ],
    "e": "Correcto:\n\nEl sistema puede subir archivos al bucket 'media-exports' - La acción s3:PutObject está explícitamente permitida, lo cual habilita al sistema a subir archivos al bucket.\n\nEl sistema puede leer archivos almacenados en el bucket 'media-exports' - La acción s3:GetObject también está permitida, por lo tanto, el sistema puede leer objetos ya almacenados.\n\nEl sistema no puede eliminar ni modificar los permisos de los objetos debido a la denegación explícita - Tanto s3:DeleteObject como s3:PutObjectAcl están explícitamente denegadas, lo que impide que el sistema borre objetos o modifique sus permisos.\n\nOpciones incorrectas:\n\nEl sistema puede borrar archivos del bucket 'media-exports' - El sistema no puede eliminar archivos debido a la denegación explícita de s3:DeleteObject.\n\nEl sistema puede modificar permisos de objetos en el bucket 'media-exports' - No puede modificar los permisos ACL de los objetos, ya que la acción s3:PutObjectAcl está explícitamente denegada.\n\nEl sistema tiene permisos para listar todos los objetos del bucket 'media-exports' - La acción s3:ListBucket no está presente en la política, por lo tanto, el sistema no puede listar objetos del bucket.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/API/API_PutObject.html\n\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_action.html"
  },
  {
    "q": "Una empresa de análisis de datos está alojando un data lake que consiste en datos en Amazon S3 y Amazon RDS para PostgreSQL. La empresa necesita una solución de informes que proporcione visualización de datos para el conjunto de datos más reciente e incluya todas las fuentes de datos dentro del data lake. Solo el equipo de gestión de la empresa debe tener acceso completo a todas las visualizaciones. El resto de la empresa debe tener solo acceso limitado.\n¿Qué solución cumplirá estos requisitos?",
    "o": [
      "Crear un análisis en Amazon QuickSight. Conectar todas las fuentes de datos y crear nuevos conjuntos de datos. Publicar paneles para visualizar los datos. Compartir los paneles con los usuarios y grupos apropiados.",
      "Crear una tabla y un crawler de AWS Glue para los datos en Amazon S3. Usar Amazon Athena Federated Query para acceder a datos dentro de Amazon RDS para PostgreSQL. Generar informes usando Amazon Athena. Publicar los informes en Amazon S3. Usar políticas de bucket S3 para limitar el acceso a los informes.",
      "Crear una tabla y un crawler de AWS Glue para los datos en Amazon S3. Crear un trabajo ETL (extract, transform, and load) de AWS Glue para producir informes. Publicar los informes en Amazon S3. Usar políticas de bucket S3 para limitar el acceso a los informes.",
      "Crear un análisis en Amazon QuickSight. Conectar todas las fuentes de datos y crear nuevos conjuntos de datos. Publicar paneles para visualizar los datos. Compartir los paneles con los roles IAM apropiados."
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nCrear un análisis en Amazon QuickSight. Conectar todas las fuentes de datos y crear nuevos conjuntos de datos. Publicar paneles para visualizar los datos. Compartir los paneles con los usuarios y grupos apropiados. - Amazon QuickSight es la mejor opción para visualización de datos e informes, especialmente cuando los datos residen en Amazon S3 y Amazon RDS para PostgreSQL. QuickSight admite conectarse tanto a Amazon S3 (vía Athena) como a RDS para PostgreSQL como fuentes de datos, permitiendo paneles integrados en ambos. QuickSight te permite controlar el acceso a nivel de usuarios y grupos, lo cual es más granular que los roles IAM para compartir paneles. El compartir por usuario/grupo se alinea con la necesidad de dar acceso completo a la gestión y acceso limitado a otros, cumpliendo efectivamente con los requisitos de control de acceso.\n\nOpciones incorrectas:\n\nCrear una tabla y un crawler de AWS Glue para los datos en Amazon S3. Crear un trabajo ETL (extract, transform, and load) de AWS Glue para producir informes. Publicar los informes en Amazon S3. Usar políticas de bucket S3 para limitar el acceso a los informes. - Amazon Athena debe usarse con AWS Glue para proporcionar la funcionalidad requerida como se describe en la explicación anterior.\n\nCrear un análisis en Amazon QuickSight. Conectar todas las fuentes de datos y crear nuevos conjuntos de datos. Publicar paneles para visualizar los datos. Compartir los paneles con los roles IAM apropiados. - Aunque esta opción resuelve el problema de compartir acceso con recursos, no maneja el delta en los datos. Además, conectas usuarios y grupos en tu cuenta de QuickSight pero no roles IAM.\n\nCrear una tabla y un crawler de AWS Glue para los datos en Amazon S3. Usar Amazon Athena Federated Query para acceder a datos dentro de Amazon RDS para PostgreSQL. Generar informes usando Amazon Athena. Publicar los informes en Amazon S3. Usar políticas de bucket S3 para limitar el acceso a los informes. - Aunque las consultas federadas de Athena son útiles para unir datos de S3 y RDS, carece de capacidades de visualización. Además, los informes basados en S3 no son ideales para paneles o compartir restringido por rol de usuario.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/athena/latest/ug/connect-to-a-data-source.html"
  },
  {
    "q": "Una empresa de tecnología tiene una aplicación CRM alojada en un Auto Scaling group de instancias On-Demand EC2 con diferentes tipos y tamaños de instancias. La aplicación se utiliza ampliamente durante el horario laboral de 9 de la mañana a 5 de la tarde. Los usuarios se quejan de que el rendimiento de la aplicación es lento al inicio del día, pero luego funciona normalmente después de un par de horas.\n¿Cuál de las siguientes es la solución operativa más eficiente para garantizar que la aplicación funcione correctamente al inicio del día?",
    "o": [
      "Configurar una política de Predictive scaling para el Auto Scaling group para ajustar automáticamente el número de instancias Amazon EC2",
      "Configurar una política de Dynamic scaling para el Auto Scaling group para lanzar nuevas instancias basadas en la utilización de la memoria",
      "Configurar una política de Scheduled scaling para el Auto Scaling group para lanzar nuevas instancias antes del inicio del día",
      "Configurar una política de Dynamic scaling para el Auto Scaling group para lanzar nuevas instancias basadas en la utilización de la CPU"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nConfigurar una política de Scheduled scaling para el Auto Scaling group para lanzar nuevas instancias antes del inicio del día - Configurar una política de Scheduled scaling para el Auto Scaling group para lanzar nuevas instancias antes del inicio del día es la opción más eficiente operativamente. Esto asegura que las instancias estén ya escaladas y listas antes de que comience el día, evitando problemas de rendimiento durante las primeras horas laborales. Scheduled scaling permite programar actividades de escalado en momentos específicos, ideal para patrones de tráfico predecibles.\n\nScheduled scaling permite planificar acciones de escalado en horarios específicos o de forma recurrente (por ejemplo, todos los días laborales a las 8:00 am).\nEn este escenario, se puede configurar para que las instancias estén listas antes de las 9:00 am cuando los usuarios comienzan a trabajar.\nEsto previene problemas de rendimiento al garantizar que la capacidad esté disponible justo cuando se necesita, en lugar de reaccionar a un aumento en la carga.\nOpciones incorrectas:\n\nConfigurar una política de Predictive scaling para el Auto Scaling group para ajustar automáticamente el número de instancias Amazon EC2 - Configurar una política de Predictive scaling es menos eficiente operativamente en este escenario. Predictive scaling funciona mejor en grupos homogéneos de instancias EC2 con la misma capacidad y tamaño, lo cual no es el caso aquí debido a la variedad de tipos y tamaños de instancias. Esto podría llevar a pronósticos imprecisos y a un escalado ineficiente.\n\nConfigurar una política de Dynamic scaling para el Auto Scaling group para lanzar nuevas instancias basadas en la utilización de la memoria - Configurar una política de Dynamic scaling basada en la utilización de la memoria puede ser útil, pero no es ideal en este caso, ya que la aplicación experimenta picos de uso al inicio del día. Al depender de métricas de utilización, el escalado ocurre después de que ya se ha detectado el problema de rendimiento, en lugar de prevenirlo proactivamente.\n\nConfigurar una política de Dynamic scaling para el Auto Scaling group para lanzar nuevas instancias basadas en la utilización de la CPU - Configurar una política de Dynamic scaling basada en la utilización de la CPU enfrenta el mismo problema que la opción C. Al esperar a que se alcance un umbral de CPU, el escalado ocurre después de que el rendimiento ya ha disminuido, lo que no resuelve eficientemente la necesidad operativa.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/schedule_time.html\n\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-scheduled-scaling.html\n\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-predictive-scaling.html#predictive-scaling-limitations"
  },
  {
    "q": "Una startup está utilizando Amazon RDS para almacenar datos de una aplicación web. La mayor parte del tiempo, la aplicación tiene poca actividad de usuarios, pero recibe picos de tráfico en segundos cuando hay un nuevo anuncio de producto. El Solutions Architect necesita crear una solución que permita a los usuarios de todo el mundo acceder a los datos utilizando una API.\n¿Qué debe hacer el Solutions Architect para cumplir con este requisito?",
    "o": [
      "Crear una API utilizando Amazon API Gateway y usar un grupo de Auto Scaling de instancias EC2 de Amazon para manejar los picos de tráfico en segundos",
      "Crear una API utilizando Amazon API Gateway y usar un clúster de Amazon ECS con Service Auto Scaling para manejar los picos de tráfico en segundos",
      "Crear una API utilizando Amazon API Gateway y usar Amazon Elastic Beanstalk con Auto Scaling para manejar los picos de tráfico en segundos",
      "Crear una API utilizando Amazon API Gateway y usar AWS Lambda para manejar los picos de tráfico en segundos"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nCrear una API utilizando Amazon API Gateway y usar AWS Lambda para manejar los picos de tráfico en segundos - Crear una API utilizando Amazon API Gateway y usar AWS Lambda es la mejor opción para manejar picos de tráfico en segundos debido a la capacidad de Lambda de escalar automáticamente en respuesta a eventos. Lambda puede gestionar miles de solicitudes simultáneas sin necesidad de aprovisionar servidores o gestionar la infraestructura, y puede escalar más rápidamente que otras soluciones basadas en Auto Scaling. Además, Amazon API Gateway permite exponer la función Lambda como una API RESTful, lo cual es ideal para este caso de uso.\n\nAWS Lambda puede manejar ráfagas de tráfico con una alta capacidad de concurrencia.\nAPI Gateway permite gestionar el acceso a la API y proporcionar puntos finales RESTful.\nLambda ofrece un modelo de pago por uso, lo que lo hace rentable para aplicaciones con tráfico esporádico.\nOpciones incorrectas:\n\nCrear una API utilizando Amazon API Gateway y usar un clúster de Amazon ECS con Service Auto Scaling para manejar los picos de tráfico en segundos - Usar Amazon ECS con Service Auto Scaling no es la mejor opción para este escenario, ya que ECS tarda más tiempo en aprovisionar y lanzar nuevas tareas en comparación con Lambda, lo cual podría no ser lo suficientemente rápido para manejar picos instantáneos.\n\nCrear una API utilizando Amazon API Gateway y usar un grupo de Auto Scaling de instancias EC2 de Amazon para manejar los picos de tráfico en segundos - Usar un grupo de Auto Scaling de instancias EC2 tampoco es óptimo porque el escalado de EC2 implica lanzar nuevas instancias, lo cual puede tardar varios minutos, mientras que el requisito es manejar los picos en segundos.\n\nCrear una API utilizando Amazon API Gateway y usar Amazon Elastic Beanstalk con Auto Scaling para manejar los picos de tráfico en segundos - Usar Amazon Elastic Beanstalk con Auto Scaling también tiene una latencia en el escalado, ya que debe lanzar nuevas instancias EC2, lo que no se alinea con la necesidad de manejar picos instantáneos.\n\nReferencias:\n\nhttps://aws.amazon.com/blogs/startups/from-0-to-100k-in-seconds-instant-scale-with-aws-lambda/\n\nhttps://docs.aws.amazon.com/lambda/latest/dg/invocation-scaling.html"
  },
  {
    "q": "Una empresa alojó un sitio web de comercio electrónico en un grupo de Auto Scaling de instancias EC2 detrás de un Application Load Balancer. El Solutions Architect notó que el sitio web está recibiendo una gran cantidad de solicitudes externas ilegítimas desde múltiples sistemas con direcciones IP que cambian constantemente. Para resolver los problemas de rendimiento, el Solutions Architect debe implementar una solución que bloquee las solicitudes ilegítimas con un impacto mínimo en el tráfico legítimo.\n¿Cuál de las siguientes opciones cumple con este requisito?",
    "o": [
      "Crear un network ACL personalizado y asociarlo con la subred del Application Load Balancer para bloquear las solicitudes ofensivas",
      "Crear una regla basada en tasas en AWS WAF y asociar el web ACL a un Application Load Balancer",
      "Crear una regla regular en AWS WAF y asociar el web ACL a un Application Load Balancer",
      "Crear una regla personalizada en el grupo de seguridad del Application Load Balancer para bloquear las solicitudes ofensivas"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nCrear una regla basada en tasas en AWS WAF y asociar el web ACL a un Application Load Balancer - Crear una regla basada en tasas en AWS WAF y asociar el web ACL a un Application Load Balancer. Una regla basada en tasas en AWS WAF rastrea la tasa de solicitudes de cada dirección IP de origen y activa la acción de la regla en direcciones IP con tasas que superan un límite determinado. Puedes establecer un límite en la cantidad de solicitudes permitidas en un lapso de 5 minutos. Esta regla aplica un bloqueo temporal a las direcciones IP que envían solicitudes excesivas, lo que ayuda a mitigar ataques de tipo Denial of Service (DoS) o tráfico ilegítimo sin afectar al tráfico legítimo.\n\n\n\nOpciones incorrectas:\n\nCrear una regla regular en AWS WAF y asociar el web ACL a un Application Load Balancer - Crear una regla regular en AWS WAF y asociar el web ACL a un Application Load Balancer. Una regla regular en AWS WAF no incluye la capacidad de limitar la tasa de solicitudes. Se utiliza principalmente para bloquear o permitir solicitudes en función de patrones de contenido (como IPs específicas o strings en la URL).\n\nCrear una regla personalizada en el grupo de seguridad del Application Load Balancer para bloquear las solicitudes ofensivas - Crear una regla personalizada en el grupo de seguridad del Application Load Balancer para bloquear las solicitudes ofensivas. Los grupos de seguridad solo pueden permitir o denegar el tráfico entrante y saliente en función de direcciones IP o rangos de IP, pero no pueden limitar la tasa de solicitudes ni bloquear direcciones IP que cambian dinámicamente.\n\nCrear un network ACL personalizado y asociarlo con la subred del Application Load Balancer para bloquear las solicitudes ofensivas - Crear un network ACL personalizado y asociarlo con la subred del Application Load Balancer para bloquear las solicitudes ofensivas. Aunque los Network ACLs pueden bloquear tráfico entrante, no pueden limitar la tasa de solicitudes ni lidiar eficientemente con IPs que cambian dinámicamente.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/waf/latest/developerguide/waf-rule-statement-type-rate-based.html\n\nhttps://docs.aws.amazon.com/waf/faqs/"
  },
  {
    "q": "Hay muchas interrupciones en la zona de disponibilidad de tu instancia de base de datos RDS al punto de que pierdes el acceso a la base de datos. ¿Qué podrías hacer para evitar perder el acceso en caso de que este evento vuelva a ocurrir?",
    "o": [
      "Incrementar el tamaño de la instancia de base de datos",
      "Habilitar Multi-AZ failover",
      "Hacer un snapshot de la base de datos",
      "Crear una read replica"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nHabilitar Multi-AZ failover - Habilitar Multi-AZ failover es la solución adecuada, ya que proporciona alta disponibilidad y durabilidad para las instancias de base de datos RDS. Al habilitar Multi-AZ, RDS crea automáticamente una instancia en espera en una zona de disponibilidad diferente y replica sincrónicamente los datos desde la instancia primaria. Si ocurre un fallo en la infraestructura de una AZ, RDS realiza automáticamente un failover a la instancia en espera, garantizando el acceso continuo a la base de datos.\n\n\n\nOpciones incorrectas:\n\nCrear una read replica - Crear una read replica no es una solución adecuada en este caso, ya que está diseñada principalmente para mejorar el rendimiento de lecturas en bases de datos con cargas de trabajo intensivas de lectura. Aunque puedes promover una read replica a una instancia de base de datos primaria en caso de fallo, la replicación asíncrona puede provocar pérdida de datos en escenarios de failover.\n\nHacer un snapshot de la base de datos - Hacer un snapshot de la base de datos permite tener un respaldo, pero no proporciona alta disponibilidad ni recuperación automática en caso de fallo de una AZ. Se requiere restaurar manualmente desde el snapshot, lo que conlleva un tiempo de inactividad.\n\nIncrementar el tamaño de la instancia de base de datos - Incrementar el tamaño de la instancia de base de datos solo aborda problemas de capacidad computacional y rendimiento, pero no proporciona redundancia ni alta disponibilidad en caso de fallos en la Zona de Disponibilidad.\n\nReferencias:\n\nhttps://aws.amazon.com/rds/details/multi-az/"
  },
  {
    "q": "Una empresa de servicios legales quiere proporcionar acceso a la consola de AWS a sus analistas de datos sin necesidad de crear cuentas de usuario en IAM. La política de seguridad de la empresa exige el uso de federación de identidad y control de acceso basado en roles. Actualmente, los permisos de los empleados ya se administran a través de grupos en el Active Directory corporativo.\nEn este escenario, ¿qué combinación de los siguientes servicios puede proporcionar acceso a la consola de AWS a los analistas de datos? (Selecciona DOS)",
    "o": [
      "IAM Groups",
      "AWS Cognito",
      "AWS Directory Service Simple AD",
      "AWS Directory Service AD Connector",
      "IAM Roles"
    ],
    "a": [
      3,
      4
    ],
    "e": "Correcto:\n\nAWS Directory Service AD Connector - AWS Directory Service AD Connector permite a la empresa integrar su Active Directory corporativo con AWS, permitiendo que los analistas de datos utilicen sus credenciales existentes para acceder a la consola de AWS sin necesidad de crear usuarios IAM adicionales.\n\nIAM Roles - IAM Roles permiten otorgar permisos de acceso a usuarios autenticados a través de Active Directory. Mediante la federación de identidad, los analistas de datos pueden iniciar sesión en la consola de AWS y obtener permisos según los grupos a los que pertenecen en Active Directory.\n\n\n\nOpciones incorrectas:\n\nAWS Directory Service Simple AD - AWS Directory Service Simple AD es una alternativa ligera a Active Directory, pero no admite federación de identidad con un Active Directory corporativo existente.\n\nIAM Groups - IAM Groups solo agrupan usuarios de IAM dentro de AWS, pero no se pueden utilizar para administrar permisos de usuarios federados provenientes de Active Directory.\n\nAWS Cognito - AWS Cognito está diseñado para la autenticación y gestión de usuarios en aplicaciones web y móviles, pero no se usa para federar el acceso a la consola de AWS mediante Active Directory.\n\nReferencias:\n\nhttps://aws.amazon.com/directoryservice/ad-connector/\n\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_common-scenarios_federated-users.html"
  },
  {
    "q": "Hubo un incidente en tu entorno de producción donde los datos de usuario almacenados en un bucket de S3 fueron eliminados accidentalmente por uno de los ingenieros DevOps Junior. El problema fue escalado a tu gerente y, después de unos días, se te indicó que mejoraras la seguridad y protección de tus recursos de AWS.\n¿Qué combinación de las siguientes opciones protegerá los objetos de S3 en tu bucket tanto de la eliminación accidental como de la sobrescritura? (Selecciona DOS)",
    "o": [
      "Proporcionar acceso a S3 estrictamente a través de URL firmadas",
      "Habilitar Amazon S3 Intelligent-Tiering",
      "Habilitar Versioning",
      "Habilitar Multi-Factor Authentication (MFA) Delete",
      "Denegar la eliminación en S3 usando una política de bucket de IAM"
    ],
    "a": [
      2,
      3
    ],
    "e": "Correcto:\n\nHabilitar Multi-Factor Authentication (MFA) Delete - Habilitar Multi-Factor Authentication (MFA) Delete añade una capa adicional de seguridad que requiere autenticación multifactor para eliminar versiones de objetos o cambiar el estado de versionado del bucket. Esto ayuda a prevenir eliminaciones accidentales o malintencionadas.\n\nHabilitar Versioning - Habilitar Versioning permite mantener múltiples versiones de un objeto en el mismo bucket, lo que facilita la recuperación de datos eliminados o sobrescritos accidentalmente. Al activar el versionado, puedes restaurar versiones anteriores de un objeto, lo cual protege contra errores humanos y fallos de aplicación.\n\nOpciones incorrectas:\n\nHabilitar Amazon S3 Intelligent-Tiering - Habilitar Amazon S3 Intelligent-Tiering es incorrecto ya que esta funcionalidad está diseñada para optimizar costos de almacenamiento al mover objetos entre diferentes niveles de almacenamiento según la frecuencia de acceso, pero no proporciona protección contra eliminación o sobrescritura accidental.\n\nDenegar la eliminación en S3 usando una política de bucket de IAM - Denegar la eliminación en S3 usando una política de bucket de IAM es incorrecto porque una política de bucket que niegue las eliminaciones restringirá todas las operaciones de borrado, lo cual puede interferir con las operaciones necesarias para la gestión de datos. Además, no ofrece la flexibilidad de recuperación que proporciona el versionado.\n\nProporcionar acceso a S3 estrictamente a través de URL firmadas - Proporcionar acceso a S3 estrictamente a través de URL firmadas es incorrecto ya que las URL firmadas controlan el acceso al contenido, pero no previenen la eliminación accidental ni ofrecen recuperación de datos sobrescritos.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html"
  },
  {
    "q": "Una API GraphQL está alojada en un clúster de Amazon EKS con el tipo de lanzamiento Fargate y desplegada utilizando AWS SAM. La API está conectada a una tabla de Amazon DynamoDB con un Amazon DynamoDB Accelerator (DAX) como su almacén de datos. Ambos recursos están alojados en la región us-east-1.\nEl autenticador de AWS IAM para Kubernetes está integrado en el clúster de EKS para el control de acceso basado en roles (RBAC) y la autenticación del clúster. Un arquitecto de soluciones debe mejorar la seguridad de la red evitando que las llamadas a la base de datos atraviesen la Internet pública. También se requiere un respaldo automatizado entre cuentas para la tabla de DynamoDB con fines de retención a largo plazo.\n¿Cuál de las siguientes opciones debe implementar el arquitecto de soluciones para cumplir con este requisito?",
    "o": [
      "Crear un endpoint de gateway de DynamoDB. Configurar una regla de Network Access Control List (NACL) que permita el tráfico saliente al endpoint dynamodb.us-east-1.amazonaws.com. Usar los respaldos bajo demanda de DynamoDB para la recuperación y respaldo entre cuentas",
      "Crear un endpoint de interfaz de DynamoDB. Asociar el endpoint con la tabla de rutas correspondiente. Habilitar Point-in-Time Recovery (PITR) para restaurar la tabla de DynamoDB a un punto específico en el tiempo en la misma cuenta o en una cuenta de AWS diferente",
      "Crear un endpoint de gateway de DynamoDB. Asociar el endpoint con la tabla de rutas correspondiente. Usar AWS Backup para copiar automáticamente los respaldos bajo demanda de DynamoDB a otra cuenta de AWS para recuperación ante desastres",
      "Crear un endpoint de interfaz de DynamoDB. Configurar una regla sin estado con AWS Network Firewall para controlar todo el tráfico saliente y permitir únicamente el endpoint dynamodb.us-east-1.amazonaws.com. Integrar la tabla de DynamoDB con Amazon Timestream para permitir la recuperación a un punto en el tiempo desde una cuenta de AWS diferente"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nCrear un endpoint de gateway de DynamoDB. Asociar el endpoint con la tabla de rutas correspondiente. Usar AWS Backup para copiar automáticamente los respaldos bajo demanda de DynamoDB a otra cuenta de AWS para recuperación ante desastres - Un endpoint de gateway de DynamoDB permite que los recursos dentro de la VPC accedan a DynamoDB utilizando direcciones IP privadas sin exponer el tráfico a Internet. Esto mejora la seguridad de la red y evita que las llamadas a la base de datos atraviesen la Internet pública. Además, AWS Backup permite copiar automáticamente respaldos bajo demanda de DynamoDB a otra cuenta de AWS, lo que proporciona una solución efectiva para la recuperación ante desastres y la retención de datos a largo plazo.\n\nOpciones incorrectas:\n\nCrear un endpoint de interfaz de DynamoDB. Configurar una regla sin estado con AWS Network Firewall para controlar todo el tráfico saliente y permitir únicamente el endpoint dynamodb.us-east-1.amazonaws.com. Integrar la tabla de DynamoDB con Amazon Timestream para permitir la recuperación a un punto en el tiempo desde una cuenta de AWS diferente - dynamodb.us-east-1.amazonaws.com es un endpoint público para DynamoDB, lo que significa que agregar una regla de AWS Network Firewall no es necesario. Además, Amazon Timestream es una base de datos de series temporales diseñada para aplicaciones de IoT y análisis de datos, no para recuperación a un punto en el tiempo (PITR) en DynamoDB.\n\nCrear un endpoint de gateway de DynamoDB. Configurar una regla de Network Access Control List (NACL) que permita el tráfico saliente al endpoint dynamodb.us-east-1.amazonaws.com. Usar los respaldos bajo demanda de DynamoDB para la recuperación y respaldo entre cuentas - Un Network Access Control List (NACL) no es suficiente para prevenir que el tráfico de DynamoDB pase por la Internet pública. Además, los respaldos bajo demanda de DynamoDB no pueden copiarse a una cuenta o región diferente sin usar AWS Backup.\n\nCrear un endpoint de interfaz de DynamoDB. Asociar el endpoint con la tabla de rutas correspondiente. Habilitar Point-in-Time Recovery (PITR) para restaurar la tabla de DynamoDB a un punto específico en el tiempo en la misma cuenta o en una cuenta de AWS diferente - Point-in-Time Recovery (PITR) solo permite restaurar una tabla de DynamoDB dentro de la misma cuenta y región. No admite copias de seguridad entre cuentas. Para lograr esto, se debe usar AWS Backup.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/vpc-endpoints-dynamodb.html\n\nhttps://docs.aws.amazon.com/backup/latest/devguide/BackupRestore.html\n\nhttps://aws.amazon.com/blogs/database/how-to-configure-a-private-network-environment-for-amazon-dynamodb-using-vpc-endpoints/"
  },
  {
    "q": "Una empresa tiene un requisito de alta prioridad para monitorear ciertas métricas de bases de datos y enviar notificaciones por correo electrónico al equipo de operaciones si ocurre algún problema.\n¿Qué combinación de servicios de AWS puede cumplir con este requisito? (Selecciona DOS)",
    "o": [
      "Amazon CloudWatch",
      "Amazon Simple Email Service (SES)",
      "Amazon Simple Queue Service (SQS)",
      "Instancia de Amazon EC2 con un servidor Berkeley Internet Name Domain (BIND)",
      "Amazon Simple Notification Service (SNS)"
    ],
    "a": [
      0,
      4
    ],
    "e": "Correcto:\n\nAmazon CloudWatch - Amazon CloudWatch permite recopilar, monitorear y analizar métricas operativas y de rendimiento en AWS, incluidas métricas de bases de datos. También permite configurar alarmas para notificar automáticamente si un valor de métrica supera un umbral predefinido.\n\nAmazon Simple Notification Service (SNS) - Amazon Simple Notification Service (SNS) es un servicio de mensajería altamente disponible y escalable que permite enviar notificaciones en tiempo real. Se puede integrar con CloudWatch para alertar al equipo de operaciones en caso de eventos críticos.\n\n\n\nOpciones incorrectas:\n\nInstancia de Amazon EC2 con un servidor Berkeley Internet Name Domain (BIND) - Un servidor BIND en EC2 se utiliza como un sistema de nombres de dominio (DNS) y no está relacionado con el monitoreo de bases de datos ni con el envío de notificaciones.\n\nAmazon Simple Queue Service (SQS) - Amazon Simple Queue Service (SQS) es un servicio de mensajería para la gestión de colas de mensajes, pero no se usa para monitorear aplicaciones ni para enviar notificaciones automáticas.\n\nAmazon Simple Email Service (SES) - Amazon Simple Email Service (SES) está diseñado principalmente para el envío de correos electrónicos masivos, correos transaccionales y marketing, pero no es la mejor opción para enviar notificaciones operativas en un entorno de monitoreo en tiempo real. SNS es una mejor opción en este caso.\n\nReferencias:\n\nhttps://aws.amazon.com/cloudwatch/\n\nhttps://aws.amazon.com/sns/"
  },
  {
    "q": "Una empresa opera una aplicación de comercio electrónico en las regiones us-east-1 y eu-west-1. El arquitecto de soluciones necesita configurar una política de enrutamiento en Route 53 para garantizar que una mayor parte del tráfico proveniente de Estados Unidos y España sea dirigido al recurso en la región us-east-1.\n¿Qué política de enrutamiento debe usar para lograr esto?",
    "o": [
      "Enrutamiento geoproximidad (Geoproximity Routing)",
      "Enrutamiento basado en latencia (Latency Routing)",
      "Enrutamiento geolocalizado (Geolocation Routing)",
      "Enrutamiento ponderado (Weighted Routing)"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nEnrutamiento geoproximidad (Geoproximity Routing) - El enrutamiento geoproximidad (Geoproximity Routing) en Route 53 permite dirigir tráfico en función de la ubicación del usuario y ajustar dinámicamente el alcance geográfico mediante un \"bias\". En este escenario, se puede configurar un bias para que más tráfico de Estados Unidos y España se dirija a la región us-east-1, asegurando que los usuarios de estas áreas prefieran este recurso.\n\nOpciones incorrectas:\n\nEnrutamiento geolocalizado (Geolocation Routing) - El enrutamiento geolocalizado (Geolocation Routing) también enruta tráfico basado en la ubicación del usuario, pero no permite modificar el área de cobertura ni ajustar dinámicamente el tráfico mediante un bias.\n\nEnrutamiento basado en latencia (Latency Routing) - El enrutamiento basado en latencia (Latency Routing) dirige el tráfico a la región de AWS con la menor latencia para cada usuario, pero no garantiza que el tráfico de una ubicación específica sea enviado a un recurso en particular.\n\nEnrutamiento ponderado (Weighted Routing) - El enrutamiento ponderado (Weighted Routing) distribuye el tráfico entre varios recursos según valores de peso asignados manualmente, sin considerar la ubicación geográfica de los usuarios.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html#routing-policy-geoproximity\n\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/rrsets-working-with.html"
  },
  {
    "q": "Una empresa necesita evaluar y auditar todas las configuraciones en su cuenta de AWS. Debe hacer cumplir el cumplimiento estricto rastreando todos los cambios de configuración realizados en cualquiera de sus buckets de Amazon S3. Los buckets de S3 con acceso público también deben identificarse automáticamente para evitar filtraciones de datos.\n¿Cuál de las siguientes opciones cumplirá con este requisito?",
    "o": [
      "Usar AWS Trusted Advisor para analizar su entorno de AWS",
      "Usar AWS CloudTrail y revisar el historial de eventos de su cuenta de AWS",
      "Usar AWS IAM para generar un informe de credenciales",
      "Usar AWS Config para configurar una regla en su cuenta de AWS"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nUsar AWS Config para configurar una regla en su cuenta de AWS - AWS Config permite evaluar, auditar y registrar continuamente la configuración de los recursos en su cuenta de AWS. Config puede rastrear cambios en la configuración de los recursos, registrar el historial de estos cambios y automatizar la evaluación del cumplimiento según reglas definidas por el usuario. Esto ayuda a garantizar que los buckets de Amazon S3 no sean accesibles públicamente si esa es la política de cumplimiento establecida.\n\n\n\nOpciones incorrectas:\n\nUsar AWS CloudTrail y revisar el historial de eventos de su cuenta de AWS - AWS CloudTrail solo rastrea eventos y mantiene un historial de cambios en los recursos de AWS, pero no proporciona una forma automatizada de definir reglas para el cumplimiento ni de evaluar configuraciones.\n\nUsar AWS Trusted Advisor para analizar su entorno de AWS - AWS Trusted Advisor proporciona recomendaciones de mejores prácticas en AWS, pero no permite definir reglas de cumplimiento ni auditar automáticamente la configuración de los recursos.\n\nUsar AWS IAM para generar un informe de credenciales - Un informe de credenciales generado con AWS IAM solo lista los usuarios y sus permisos en la cuenta de AWS, lo que no ayuda a evaluar la configuración de los recursos.\n\nReferencias:\n\nhttps://aws.amazon.com/config/\n\nhttps://docs.aws.amazon.com/config/latest/developerguide/evaluate-config.html"
  },
  {
    "q": "Una empresa ha desarrollado APIs públicas que se ejecutan en un grupo de Auto Scaling de instancias Amazon EC2 detrás de un Elastic Load Balancer. Estas APIs serán consumidas por clientes externos desde redes on-premises que solo pueden acceder a direcciones IP estáticas aprobadas en sus firewalls. El arquitecto de soluciones ha sido asignado para garantizar que los clientes puedan acceder a las APIs sin interrupciones.\n¿Qué solución debe implementar?",
    "o": [
      "Crear un registro CNAME en Route 53 que apunte al nombre DNS del balanceador de carga",
      "Utilizar AWS Global Accelerator para proporcionar direcciones IP estáticas a los clientes y enrutar el tráfico al balanceador de carga",
      "Implementar un Network Load Balancer (NLB) con Elastic IPs y configurarlo como el balanceador de carga de la API",
      "Implementar AWS PrivateLink y crear un endpoint de servicio para exponer las APIs a los clientes"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nImplementar un Network Load Balancer (NLB) con Elastic IPs y configurarlo como el balanceador de carga de la API - Un Network Load Balancer (NLB) permite asociar Elastic IPs, proporcionando direcciones IP estáticas que los clientes pueden agregar a sus listas de permitidos en sus firewalls. Esta es la mejor solución para garantizar que los clientes puedan acceder sin problemas a las APIs. Un Network Load Balancer es ideal para escenarios en los que se requiere estabilidad en las direcciones IP de los servicios. A diferencia de los Application Load Balancers (ALB), los NLB permiten asociar direcciones IP elásticas (EIPs), facilitando la configuración de listas de permitidos en firewalls de clientes.\n\n\n\nOpciones incorrectas:\n\nCrear un registro CNAME en Route 53 que apunte al nombre DNS del balanceador de carga - Un registro CNAME en Route 53 solo resuelve un nombre de dominio a una dirección IP, pero los clientes necesitan direcciones IP estáticas, no un nombre DNS.\n\nImplementar AWS PrivateLink y crear un endpoint de servicio para exponer las APIs a los clientes - AWS PrivateLink es útil para exponer servicios de manera privada dentro de AWS, pero no es una solución viable para clientes externos en redes on-premises que requieren direcciones IP estáticas.\n\nUtilizar AWS Global Accelerator para proporcionar direcciones IP estáticas a los clientes y enrutar el tráfico al balanceador de carga - AWS Global Accelerator proporciona direcciones IP estáticas, pero está diseñado principalmente para optimizar el enrutamiento de tráfico global, no para asignar direcciones IP estáticas a balanceadores de carga dentro de una región.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/network/introduction.html\n\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/using-static-ip-addresses-for-application-load-balancers/\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/elb-attach-elastic-ip-to-public-nlb/"
  },
  {
    "q": "Una empresa está por lanzar una aplicación web dinámica desarrollada con MEAN stack el próximo mes. Es probable que el tráfico sea bastante alto durante las primeras semanas.\nEn caso de una falla de carga, ¿cómo puedes configurar un failover de DNS a un sitio web estático?",
    "o": [
      "Habilitar el failover a una aplicación alojada en un centro de datos on-premises",
      "Duplicar exactamente la arquitectura de la aplicación en otra región y configurar el enrutamiento basado en peso (weighted routing) en DNS",
      "Usar Route 53 con la opción de failover a un bucket S3 con hosting estático o a una distribución de CloudFront",
      "Agregar más servidores en caso de que la aplicación falle"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nUsar Route 53 con la opción de failover a un bucket S3 con hosting estático o a una distribución de CloudFront - Amazon Route 53 Failover Routing permite configurar un mecanismo de respaldo en caso de falla. Puedes configurar Route 53 para realizar failover a un sitio web estático alojado en S3 o CloudFront si la aplicación dinámica falla, asegurando que los usuarios sigan viendo contenido en lugar de un error de conexión.\n\n\n\nOpciones incorrectas:\n\nAgregar más servidores en caso de que la aplicación falle - Agregar más servidores no es una estrategia de failover eficiente, ya que si la aplicación ya falló, habrá un tiempo de inactividad mientras se aprovisionan los nuevos servidores.\n\nDuplicar exactamente la arquitectura de la aplicación en otra región y configurar el enrutamiento basado en peso (weighted routing) en DNS - Duplicar toda la arquitectura en otra región y usar DNS con weighted routing puede ser costoso y complejo. La pregunta se centra en una solución de failover, no en una arquitectura distribuida permanente.\n\nHabilitar el failover a una aplicación alojada en un centro de datos on-premises - Configurar el failover a un centro de datos on-premises es posible, pero no aprovecha al máximo las capacidades de AWS. Route 53 Failover es una mejor solución dentro del entorno en la nube.\n\nReferencias:\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/fail-over-s3-r53/\n\nhttp://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover.html"
  },
  {
    "q": "Una empresa de software tiene recursos alojados en AWS y en servidores on-premises.\nSe te ha solicitado crear una arquitectura desacoplada para aplicaciones que utilicen ambos tipos de recursos.\n¿Cuáles de las siguientes opciones son válidas? (Selecciona DOS)",
    "o": [
      "Usar DynamoDB para utilizar tanto servidores on-premises como instancias EC2 en tu aplicación desacoplada",
      "Usar VPC Peering para conectar servidores on-premises e instancias EC2 en tu aplicación desacoplada",
      "Usar SQS para utilizar tanto servidores on-premises como instancias EC2 en tu aplicación desacoplada",
      "Usar RDS para utilizar tanto servidores on-premises como instancias EC2 en tu aplicación desacoplada",
      "Usar SWF para utilizar tanto servidores on-premises como instancias EC2 en tu aplicación desacoplada"
    ],
    "a": [
      2,
      4
    ],
    "e": "Correcto:\n\nUsar SQS para utilizar tanto servidores on-premises como instancias EC2 en tu aplicación desacoplada - Amazon Simple Queue Service (SQS) permite desacoplar componentes de aplicaciones distribuidas mediante colas de mensajes escalables y confiables. Puede utilizarse para la comunicación entre servidores on-premises e instancias EC2.\n\nUsar SWF para utilizar tanto servidores on-premises como instancias EC2 en tu aplicación desacoplada - Amazon Simple Workflow Service (SWF) facilita la coordinación del trabajo distribuido en múltiples componentes de una aplicación. Se puede utilizar para integrar flujos de trabajo entre servidores on-premises y AWS.\n\nOpciones incorrectas:\n\nUsar VPC Peering para conectar servidores on-premises e instancias EC2 en tu aplicación desacoplada - VPC Peering no es adecuado para conectar servidores on-premises con AWS. Para conectar redes on-premises con AWS, se deben utilizar VPNs o AWS Direct Connect.\n\nUsar RDS para utilizar tanto servidores on-premises como instancias EC2 en tu aplicación desacoplada - Amazon RDS es un servicio de base de datos y no está diseñado para proporcionar una arquitectura desacoplada. Su propósito principal es almacenar datos estructurados, no desacoplar componentes.\n\nUsar DynamoDB para utilizar tanto servidores on-premises como instancias EC2 en tu aplicación desacoplada - Amazon DynamoDB es un servicio de base de datos NoSQL, pero no está diseñado para desacoplar aplicaciones distribuidas entre on-premises y AWS. No es adecuado para este caso de uso.\n\nReferencias:\n\nhttps://aws.amazon.com/sqs/\n\nhttp://docs.aws.amazon.com/amazonswf/latest/developerguide/swf-welcome.html"
  },
  {
    "q": "Una empresa de logística opera una base de datos Oracle on-premises que debe integrarse con su entorno AWS dentro de una VPC. Para establecer una conexión segura entre ambas infraestructuras, han decidido implementar una VPN site-to-site.\n¿Qué requisito debe configurarse fuera de la VPC para que la conexión VPN site-to-site sea exitosa?",
    "o": [
      "Configurar un AWS Transit Gateway y adjuntarlo a la VPC para permitir la conectividad VPN",
      "Habilitar la propagación de rutas en la tabla de rutas de la VPC para redirigir el tráfico a una instancia NAT",
      "Asignar una dirección Elastic IP (EIP) a un Virtual Private Gateway en AWS",
      "Configurar una dirección IP pública y enrutada en Internet (estática) en la interfaz externa del customer gateway on-premises"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nConfigurar una dirección IP pública y enrutada en Internet (estática) en la interfaz externa del customer gateway on-premises - Para establecer una VPN site-to-site, el customer gateway on-premises debe contar con una dirección IP pública y enrutada a Internet. AWS requiere esta IP estática para iniciar y mantener la conexión con el Virtual Private Gateway (VGW) en la VPC. AWS Site-to-Site VPN permite conectar redes on-premises con AWS a través de un túnel IPsec seguro. La dirección IP pública del customer gateway debe ser estática y enrutada en Internet para que AWS pueda establecer la conexión VPN.\n\n\n\nOpciones incorrectas:\n\nAsignar una dirección Elastic IP (EIP) a un Virtual Private Gateway en AWS - No es posible asignar una Elastic IP (EIP) a un Virtual Private Gateway. AWS gestiona la conectividad del VGW sin necesidad de una IP pública fija.\n\nHabilitar la propagación de rutas en la tabla de rutas de la VPC para redirigir el tráfico a una instancia NAT - La propagación de rutas en la tabla de rutas de la VPC ayuda a enrutar tráfico hacia la VPN, pero no es un requisito externo para establecer la conexión VPN.\n\nConfigurar un AWS Transit Gateway y adjuntarlo a la VPC para permitir la conectividad VPN - AWS Transit Gateway puede ser útil para administrar conexiones VPN en múltiples VPCs, pero no es necesario para establecer una VPN site-to-site estándar.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_VPN.html\n\nhttps://docs.aws.amazon.com/vpc/latest/userguide/SetUpVPNConnections.html"
  },
  {
    "q": "Una empresa global ha implementado numerosos servidores AWS Outposts en varias ubicaciones remotas en todo el mundo. Estos servidores deben descargar con frecuencia actualizaciones de software que consisten en múltiples archivos desde un bucket de S3 en la región us-west-2. La empresa está experimentando retrasos significativos en la distribución de estas actualizaciones a todos los servidores.\n¿Qué solución reduciría más efectivamente la latencia de implementación mientras minimiza la sobrecarga operativa?",
    "o": [
      "Configurar una distribución de Amazon CloudFront con el bucket de S3 en us-west-2 como origen principal y crear un origen secundario en otra región, implementando una política de caché CachingDisabled. Usar URLs firmadas para las descargas",
      "Crear una distribución de Amazon CloudFront con el bucket de S3 en us-west-2 como origen. Usar URLs firmadas para las descargas de software",
      "Usar Amazon S3 Transfer Acceleration en el bucket de S3 existente y hacer que los servidores Outposts utilicen el endpoint de Transfer Acceleration para las descargas",
      "Configurar AWS Global Accelerator para enrutar el tráfico desde los servidores Outposts a la ubicación de borde más cercana de AWS y luego usar conexiones VIF privadas para acceder al bucket de S3 en us-west-2"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nCrear una distribución de Amazon CloudFront con el bucket de S3 en us-west-2 como origen. Usar URLs firmadas para las descargas de software - Amazon CloudFront es la mejor opción para reducir la latencia de entrega de archivos en los servidores Outposts. Al crear una distribución de CloudFront con el bucket de S3 en us-west-2 como origen, se aprovechan las ubicaciones de borde globales de CloudFront para almacenar en caché y distribuir los archivos con baja latencia. Además, el uso de URLs firmadas agrega una capa de seguridad adicional, permitiendo que solo usuarios autorizados accedan a las actualizaciones de software.\n\n\n\nOpciones incorrectas:\n\nConfigurar una distribución de Amazon CloudFront con el bucket de S3 en us-west-2 como origen principal y crear un origen secundario en otra región, implementando una política de caché CachingDisabled. Usar URLs firmadas para las descargas - Agregar un origen secundario en otra región no agrega valor significativo en este caso, ya que la fuente principal de los archivos sigue siendo el bucket de S3 en us-west-2. Además, la política CachingDisabled anularía los beneficios del almacenamiento en caché de CloudFront, lo que aumentaría la latencia.\n\nConfigurar AWS Global Accelerator para enrutar el tráfico desde los servidores Outposts a la ubicación de borde más cercana de AWS y luego usar conexiones VIF privadas para acceder al bucket de S3 en us-west-2 - AWS Global Accelerator está diseñado para mejorar la disponibilidad y el rendimiento de aplicaciones en múltiples regiones, pero no está optimizado para distribuir archivos desde S3. Además, las conexiones VIF (Virtual Interface) suelen usarse con AWS Direct Connect y no con S3.\n\nUsar Amazon S3 Transfer Acceleration en el bucket de S3 existente y hacer que los servidores Outposts utilicen el endpoint de Transfer Acceleration para las descargas - Amazon S3 Transfer Acceleration es útil para transferencias de datos de larga distancia, pero no proporciona almacenamiento en caché, lo que podría generar mayores costos y latencias innecesarias en comparación con CloudFront.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/GettingStarted.SimpleDistribution.html\n\nhttps://docs.aws.amazon.com/outposts/latest/userguide/region-connectivity.html\n\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-signed-urls.html"
  },
  {
    "q": "Una empresa ha desarrollado una aplicación que se ejecuta en AWS Fargate y utiliza Amazon RDS con Multi-AZ para su base de datos.\nEl equipo de seguridad ha solicitado que todas las credenciales de la base de datos, claves API y otros secretos estén cifrados y se roten periódicamente para minimizar riesgos de seguridad.\nLa aplicación debe poder recuperar automáticamente las credenciales actualizadas sin necesidad de redeploys manuales.\n¿Cuál de las siguientes opciones es la más adecuada para cumplir con estos requisitos?",
    "o": [
      "Usar AWS Secrets Manager para almacenar y cifrar las credenciales de la base de datos y claves API. Habilitar la rotación automática de credenciales y configurar la aplicación para obtenerlas en tiempo real",
      "Almacenar las credenciales en AWS Systems Manager Parameter Store como SecureString. Configurar una función Lambda que actualice las credenciales en la aplicación cada vez que sean rotadas",
      "Generar credenciales en la aplicación en cada inicio y almacenarlas temporalmente en una tabla de Amazon DynamoDB con cifrado habilitado",
      "Almacenar las credenciales en AWS Key Management Service (KMS) y permitir que las tareas Fargate las descifren cada vez que inicien"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nUsar AWS Secrets Manager para almacenar y cifrar las credenciales de la base de datos y claves API. Habilitar la rotación automática de credenciales y configurar la aplicación para obtenerlas en tiempo real - AWS Secrets Manager es la mejor opción para almacenar, cifrar y gestionar secretos de forma segura. Proporciona rotación automática de credenciales y permite que la aplicación acceda a la última versión en tiempo real sin intervención manual. AWS Secrets Manager permite la recuperación automática de credenciales en aplicaciones, eliminando la necesidad de reinicios cuando se actualizan. La integración con RDS permite que AWS Secrets Manager administre y rote credenciales sin interrupciones en la aplicación.\n\n\n\nOpciones incorrectas:\n\nAlmacenar las credenciales en AWS Systems Manager Parameter Store como SecureString. Configurar una función Lambda que actualice las credenciales en la aplicación cada vez que sean rotadas - Aunque AWS Systems Manager Parameter Store admite SecureString, no permite la rotación automática nativa de credenciales sin intervención adicional mediante una función Lambda o scripts personalizados.\n\nAlmacenar las credenciales en AWS Key Management Service (KMS) y permitir que las tareas Fargate las descifren cada vez que inicien - AWS KMS es un servicio para gestionar claves de cifrado, pero no para almacenar y rotar secretos como credenciales de bases de datos o claves API.\n\nGenerar credenciales en la aplicación en cada inicio y almacenarlas temporalmente en una tabla de Amazon DynamoDB con cifrado habilitado - Almacenar credenciales en DynamoDB no es una práctica recomendada, ya que no está diseñado para la gestión segura de secretos ni ofrece rotación automática integrada.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/secretsmanager/latest/userguide/intro.html\n\nhttps://aws.amazon.com/secrets-manager/"
  },
  {
    "q": "Una empresa de software internacional proporciona a sus clientes soluciones y herramientas personalizadas diseñadas para recolección y análisis eficiente de datos en AWS. La empresa pretende gestionar centralmente y distribuir un conjunto estándar de soluciones y herramientas para las necesidades de autoservicio de sus clientes.\n¿Qué solución satisfaría mejor estos requisitos?",
    "o": [
      "Crear reglas de AWS Config para los clientes",
      "Crear portafolios de AWS Service Catalog para los clientes",
      "Crear stacks de AWS CloudFormation para los clientes",
      "Crear documentos de AWS Systems Manager para los clientes"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nCrear portafolios de AWS Service Catalog para los clientes - AWS Service Catalog permite crear y gestionar portafolios centralizados de soluciones aprobadas, que los clientes pueden usar en modo autoservicio. Proporciona control de acceso, gobernanza, versiones y distribución centralizada, cumpliendo perfectamente con los requisitos de esta empresa.\n\nOpciones incorrectas:\n\nCrear stacks de AWS CloudFormation para los clientes - CloudFormation despliega infraestructura, pero no ofrece un catálogo autoservicio ni gestión centralizada de productos para múltiples clientes.\n\nCrear documentos de AWS Systems Manager para los clientes - Systems Manager Documents automatiza tareas en instancias, pero no sirve para distribuir soluciones completas como productos reutilizables para autoservicio.\n\nCrear reglas de AWS Config para los clientes - AWS Config es para auditoría y cumplimiento, no para distribuir herramientas ni gestionar soluciones estándar.\n\nReferencia:\n\nhttps://aws.amazon.com/servicecatalog/"
  },
  {
    "q": "Una empresa lanzó un sitio web que acepta fotos de alta calidad y las convierte en un montaje de video descargable. El sitio web ofrece una cuenta gratuita y una cuenta premium que garantiza un procesamiento más rápido. Todas las solicitudes, tanto de miembros gratuitos como premium, se procesan a través de una única cola SQS y luego son manejadas por un grupo de instancias EC2 que generan los videos. La empresa necesita garantizar que los usuarios premium que pagaron por el servicio tengan mayor prioridad que los usuarios gratuitos.\n¿Cómo debería la empresa rediseñar su arquitectura para abordar este requisito?",
    "o": [
      "Usar Amazon S3 para almacenar y procesar las fotos y luego generar el montaje de video posteriormente",
      "Usar Amazon Kinesis para procesar las fotos y generar el montaje de video en tiempo real",
      "Para las solicitudes realizadas por miembros premium, establecer una prioridad más alta en la cola SQS para que sean procesadas antes que las solicitudes realizadas por miembros gratuitos",
      "Crear una cola de SQS para los miembros gratuitos y otra para los miembros premium. Configurar las instancias EC2 para consumir mensajes de la cola premium primero y, si está vacía, obtener mensajes de la cola de SQS de los miembros gratuitos"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nCrear una cola de SQS para los miembros gratuitos y otra para los miembros premium. Configurar las instancias EC2 para consumir mensajes de la cola premium primero y, si está vacía, obtener mensajes de la cola de SQS de los miembros gratuitos - La mejor solución es crear dos colas de SQS separadas para cada tipo de miembro. Las instancias EC2 pueden consultar primero la cola de SQS de los miembros premium y, una vez que se procesan esos mensajes, pueden comenzar a procesar los mensajes de los miembros gratuitos. Esto garantiza que los usuarios premium reciban prioridad sin afectar el flujo de procesamiento.\n\nOpciones incorrectas:\n\nUsar Amazon S3 para almacenar y procesar las fotos y luego generar el montaje de video posteriormente - Amazon S3 es un servicio de almacenamiento duradero y no un servicio de procesamiento de datos. No es adecuado para la gestión de colas ni para la priorización de solicitudes en este escenario.\n\nUsar Amazon Kinesis para procesar las fotos y generar el montaje de video en tiempo real - Amazon Kinesis se utiliza para el procesamiento de datos en tiempo real y no para la gestión de colas de mensajes. Este servicio no es aplicable en este caso, ya que el problema no se basa en el streaming de datos, sino en la priorización del procesamiento.\n\nPara las solicitudes realizadas por miembros premium, establecer una prioridad más alta en la cola SQS para que sean procesadas antes que las solicitudes realizadas por miembros gratuitos - No es posible establecer prioridades dentro de una sola cola SQS. Amazon SQS funciona en un modelo de procesamiento FIFO (First-In, First-Out) o en un enfoque estándar donde los mensajes se entregan al menos una vez sin prioridad específica. Para manejar prioridades, se deben usar múltiples colas.\n\nReferencia:\n\nhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-best-practices.html"
  },
  {
    "q": "Una compañía de seguros planea implementar una funcionalidad de filtrado de mensajes en su aplicación web. Para ello, necesitan crear colas de Amazon SQS separadas para cada tipo de solicitud de cotización. Todo el procesamiento del mensaje no debe exceder las 24 horas.\nComo arquitecto de soluciones de la empresa, ¿cuál de las siguientes opciones deberías elegir para cumplir con este requisito?",
    "o": [
      "Crear un único tema de Amazon SNS y configurar las colas de Amazon SQS para suscribirse al tema de SNS. Establecer políticas de filtrado en las suscripciones de SNS para publicar el mensaje en la cola de SQS designada según el tipo de solicitud de cotización",
      "Crear un único tema de Amazon SNS y configurar las colas de Amazon SQS para suscribirse al tema de SNS. Publicar los mismos mensajes en todas las colas de SQS. Filtrar los mensajes en cada cola en función del tipo de solicitud de cotización",
      "Crear múltiples temas de Amazon SNS y configurar las colas de Amazon SQS para suscribirse a los temas de SNS. Publicar el mensaje en la cola de SQS designada según el tipo de solicitud de cotización",
      "Crear un flujo de datos en Amazon Kinesis Data Streams. Usar la Amazon Kinesis Client Library para entregar todos los registros a las colas de SQS designadas según el tipo de solicitud de cotización"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nCrear un único tema de Amazon SNS y configurar las colas de Amazon SQS para suscribirse al tema de SNS. Establecer políticas de filtrado en las suscripciones de SNS para publicar el mensaje en la cola de SQS designada según el tipo de solicitud de cotización - Amazon SNS es un servicio de mensajería de publicación/suscripción completamente administrado. Permite distribuir mensajes a múltiples puntos de suscripción, como colas de Amazon SQS, funciones AWS Lambda y endpoints HTTP/S. Para cumplir con el escenario planteado, se debe usar un solo tema de SNS y configurar políticas de filtrado en las suscripciones de SNS para asegurarse de que cada mensaje se publique solo en la cola de SQS correspondiente según el tipo de solicitud de cotización. Esto evita la distribución innecesaria de mensajes y permite una entrega eficiente.\n\n\n\nOpciones incorrectas:\n\nCrear múltiples temas de Amazon SNS y configurar las colas de Amazon SQS para suscribirse a los temas de SNS. Publicar el mensaje en la cola de SQS designada según el tipo de solicitud de cotización - No es necesario crear múltiples temas de SNS para este escenario. Un solo tema de SNS con políticas de filtrado configuradas en las suscripciones de SQS es suficiente para distribuir los mensajes a las colas correctas.\n\nCrear un único tema de Amazon SNS y configurar las colas de Amazon SQS para suscribirse al tema de SNS. Publicar los mismos mensajes en todas las colas de SQS. Filtrar los mensajes en cada cola en función del tipo de solicitud de cotización - En este caso, todas las colas de SQS recibirían los mismos mensajes, lo que requeriría filtrado adicional en cada cola. Esto genera procesamiento innecesario y puede superar el límite de tiempo de 24 horas. La solución óptima es utilizar el filtrado en la suscripción de SNS en lugar de hacerlo en las colas de SQS.\n\nCrear un flujo de datos en Amazon Kinesis Data Streams. Usar la Amazon Kinesis Client Library para entregar todos los registros a las colas de SQS designadas según el tipo de solicitud de cotización - Amazon Kinesis Data Streams no es un servicio de filtrado de mensajes. Se usa para el procesamiento de datos en tiempo real y no es adecuado para distribuir mensajes a colas de SQS según el tipo de solicitud de cotización.\n\nReferencias:\n\nhttps://aws.amazon.com/getting-started/hands-on/filter-messages-published-to-topics/\n\nhttps://docs.aws.amazon.com/sns/latest/dg/sns-message-filtering.html\n\nhttps://docs.aws.amazon.com/sns/latest/dg/sns-sqs-as-subscriber.html"
  },
  {
    "q": "Un arquitecto de soluciones está diseñando un sitio web de tres niveles que se alojará en un grupo de Auto Scaling de Amazon EC2 detrás de un Application Load Balancer (ALB) con acceso público a Internet. El sitio web almacenará datos en un clúster de bases de datos sin servidor de Amazon Aurora, que también se utilizará para generar informes mensuales.\nLa empresa requiere una topología de red que siga un enfoque por capas para reducir el impacto de configuraciones incorrectas en los grupos de seguridad o listas de control de acceso a la red. El filtrado web también debe estar habilitado para detener automáticamente el tráfico a URL maliciosas y para rechazar inmediatamente solicitudes provenientes de nombres de dominio completamente cualificados (FQDNs) en listas negras.\n¿Qué topología de red proporciona los recursos mínimos necesarios para que el sitio web funcione?",
    "o": [
      "Configurar un grupo de Auto Scaling de instancias EC2 detrás de un Application Load Balancer con un clúster de bases de datos sin servidor de Aurora para almacenar datos. Desplegar todos los recursos en una subred pública. Configurar reglas de enrutamiento en el Application Load Balancer para detener el tráfico hacia URL maliciosas y rechazar solicitudes de FQDNs en listas negras",
      "Configurar un Application Load Balancer en una subred pública y alojar el grupo de Auto Scaling de instancias EC2 y el clúster de bases de datos sin servidor de Aurora en subredes privadas. Lanzar un AWS Network Firewall con la política de firewall adecuada para detener automáticamente el tráfico a URL maliciosas y rechazar solicitudes provenientes de FQDNs en listas negras. Redirigir el tráfico de red de la VPC a través de los endpoints del firewall",
      "Configurar un Application Load Balancer al frente de un grupo de Auto Scaling de instancias EC2 con un clúster de Aurora Serverless DB para almacenar datos. Lanzar un NAT Gateway en una subred pública para restringir que servicios externos inicien conexiones a las instancias EC2 y rechazar inmediatamente las solicitudes de FQDNs no autorizados. Desplegar todos los demás recursos en subredes privadas",
      "Configurar un Application Load Balancer y un NAT Gateway desplegados en subredes públicas. Lanzar el grupo de Auto Scaling de instancias EC2 y el clúster de bases de datos sin servidor de Aurora en subredes privadas. Integrar directamente AWS Network Firewall con el Application Load Balancer para detener automáticamente el tráfico hacia URL maliciosas y rechazar solicitudes de FQDNs en listas negras"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nConfigurar un Application Load Balancer en una subred pública y alojar el grupo de Auto Scaling de instancias EC2 y el clúster de bases de datos sin servidor de Aurora en subredes privadas. Lanzar un AWS Network Firewall con la política de firewall adecuada para detener automáticamente el tráfico a URL maliciosas y rechazar solicitudes provenientes de FQDNs en listas negras. Redirigir el tráfico de red de la VPC a través de los endpoints del firewall - Esta opción sigue un enfoque de seguridad por capas recomendado en AWS. Al colocar el Application Load Balancer en una subred pública y el grupo de Auto Scaling de EC2 junto con la base de datos en subredes privadas, se reduce la exposición a amenazas externas. Además, AWS Network Firewall proporciona un filtrado avanzado de tráfico que permite bloquear automáticamente solicitudes a URL maliciosas y rechazar tráfico desde dominios en listas negras. Redirigir el tráfico de la VPC a través de los endpoints del firewall ayuda a mantener un control centralizado de la seguridad de la red.\n\n\n\nOpciones incorrectas:\n\nConfigurar un Application Load Balancer al frente de un grupo de Auto Scaling de instancias EC2 con un clúster de Aurora Serverless DB para almacenar datos. Lanzar un NAT Gateway en una subred pública para restringir que servicios externos inicien conexiones a las instancias EC2 y rechazar inmediatamente las solicitudes de FQDNs no autorizados. Desplegar todos los demás recursos en subredes privadas - Aunque un NAT Gateway ayuda a restringir conexiones externas a instancias EC2 en subredes privadas, no tiene la capacidad de bloquear tráfico malicioso basado en URL o FQDNs en listas negras. Network Firewall es la solución recomendada para este propósito.\n\nConfigurar un grupo de Auto Scaling de instancias EC2 detrás de un Application Load Balancer con un clúster de bases de datos sin servidor de Aurora para almacenar datos. Desplegar todos los recursos en una subred pública. Configurar reglas de enrutamiento en el Application Load Balancer para detener el tráfico hacia URL maliciosas y rechazar solicitudes de FQDNs en listas negras - Alojar todos los recursos en una subred pública expone la infraestructura a riesgos de seguridad. Además, el balanceador de carga por sí solo no puede bloquear tráfico basado en URL maliciosas y FQDNs en listas negras.\n\nConfigurar un Application Load Balancer y un NAT Gateway desplegados en subredes públicas. Lanzar el grupo de Auto Scaling de instancias EC2 y el clúster de bases de datos sin servidor de Aurora en subredes privadas. Integrar directamente AWS Network Firewall con el Application Load Balancer para detener automáticamente el tráfico hacia URL maliciosas y rechazar solicitudes de FQDNs en listas negras - AWS Network Firewall no se puede integrar directamente con un Application Load Balancer. La integración debe hacerse a nivel de enrutamiento dentro de la VPC para controlar y filtrar el tráfico de manera efectiva.\n\nReferencias:\n\nhttps://aws.amazon.com/wellarchitected/2020-07-02T19-33-23/waf,ailp,security.en.html\n\nhttps://docs.aws.amazon.com/wellarchitected/latest/security-pillar/protecting-networks.html\n\nhttps://docs.aws.amazon.com/network-firewall/latest/developerguide/stateful-rule-groups-domain-names.html"
  },
  {
    "q": "Una nueva aplicación será lanzada en una instancia de Amazon EC2 con un volumen de Elastic Block Store (EBS). Un arquitecto de soluciones necesita determinar la opción de almacenamiento más rentable. La aplicación tendrá uso infrecuente, con picos de tráfico por un par de horas en la mañana y tarde. El I/O de disco es variable con picos de hasta 3,000 IOPS.\n¿Qué solución debe recomendar el arquitecto de soluciones?",
    "o": [
      "Amazon EBS HDD Frío (sc1)",
      "Amazon EBS HDD Optimizado para Rendimiento (st1)",
      "Amazon EBS SSD de IOPS Provisionadas (io1)",
      "Amazon EBS SSD de Propósito General (gp2)"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nAmazon EBS SSD de Propósito General (gp2) - Los volúmenes SSD de Propósito General (gp2) ofrecen una combinación óptima entre costo y rendimiento, con capacidad de hacer burst hasta 3,000 IOPS, lo cual satisface perfectamente los picos de demanda de la aplicación sin incurrir en costos innecesarios.\n\nOpciones incorrectas:\n\nAmazon EBS HDD Optimizado para Rendimiento (st1) - st1 no tiene garantías de IOPS y no es adecuado para picos de rendimiento consistentes.\n\nAmazon EBS SSD de IOPS Provisionadas (io1) - io1 podría manejar los picos, pero sería una opción mucho más costosa y no necesaria para esta carga.\n\nAmazon EBS HDD Frío (sc1) - sc1 es para cargas frías y no ofrece rendimiento suficiente ni burst para esta aplicación.\n\nReferencia:\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html"
  },
  {
    "q": "Una empresa ejecuta una aplicación web en contenedores Docker utilizando Amazon ECS, con almacenamiento en Amazon FSx for Lustre para cargas de trabajo de alto rendimiento. Para garantizar la continuidad del negocio, han implementado un entorno de recuperación ante desastres (DR) en otra región de AWS. El arquitecto de soluciones debe diseñar un mecanismo automático para redirigir el tráfico al entorno DR en caso de que la aplicación principal falle, asegurando una conmutación rápida y sin intervención manual.\n¿Cuál es la solución más efectiva para cumplir con este requisito?",
    "o": [
      "Configurar en Route 53 una política de enrutamiento de failover con health checks en el endpoint principal. Habilitar la opción Evaluate Target Health para que Route 53 redirija automáticamente el tráfico al entorno DR cuando el primario deje de estar disponible",
      "Configurar una alarma en Amazon CloudWatch para monitorear la disponibilidad del servicio y activar una función Lambda. La función actualizará el registro DNS en Route 53 para redirigir el tráfico al entorno DR",
      "Configurar en Route 53 una política de enrutamiento ponderado (Weighted Routing) con health checks en ambos entornos. Ajustar los pesos para favorecer el entorno primario y permitir la conmutación al DR en caso de fallo",
      "Configurar una regla de Amazon EventBridge para detectar fallos en el servicio principal y activar una función Lambda. La función ejecutará la API ChangeResourceRecordSets en Route 53 para actualizar el registro DNS al entorno DR"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nConfigurar en Route 53 una política de enrutamiento de failover con health checks en el endpoint principal. Habilitar la opción Evaluate Target Health para que Route 53 redirija automáticamente el tráfico al entorno DR cuando el primario deje de estar disponible - La política de enrutamiento de failover en Route 53 permite establecer una configuración activa-pasiva. Al agregar un health check al endpoint primario y habilitar Evaluate Target Health, Route 53 redirigirá automáticamente el tráfico al entorno DR si el servicio principal deja de estar disponible.\n\nOpciones incorrectas:\n\nConfigurar una regla de Amazon EventBridge para detectar fallos en el servicio principal y activar una función Lambda. La función ejecutará la API ChangeResourceRecordSets en Route 53 para actualizar el registro DNS al entorno DR - EventBridge no es la mejor opción para gestionar el failover de DNS, ya que no puede detectar directamente fallos en un endpoint. Route 53 Failover Routing es una solución más adecuada.\n\nConfigurar una alarma en Amazon CloudWatch para monitorear la disponibilidad del servicio y activar una función Lambda. La función actualizará el registro DNS en Route 53 para redirigir el tráfico al entorno DR - Aunque CloudWatch puede detectar métricas de disponibilidad, no es una solución óptima para cambiar registros DNS automáticamente. Route 53 tiene mecanismos nativos para esto.\n\nConfigurar en Route 53 una política de enrutamiento ponderado (Weighted Routing) con health checks en ambos entornos. Ajustar los pesos para favorecer el entorno primario y permitir la conmutación al DR en caso de fallo - El enrutamiento ponderado (Weighted Routing) distribuye tráfico con base en pesos predefinidos, pero no está diseñado para conmutación automática ante fallos de un entorno.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-types.html\n\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/health-checks-types.html"
  },
  {
    "q": "Una empresa quiere optimizar el proceso de creación de múltiples cuentas de AWS dentro de una AWS Organization. Cada unidad organizativa (OU) debe poder lanzar nuevas cuentas con configuraciones preaprobadas del equipo de seguridad, lo que permitirá estandarizar las configuraciones base y de red para todas las cuentas dentro de la organización.\n¿Qué solución requiere el menor esfuerzo para implementar?",
    "o": [
      "Centralizar la creación de cuentas de AWS utilizando AWS Systems Manager OpsCenter. Aplicar políticas y detectar violaciones en todas las cuentas de AWS usando AWS Security Hub",
      "Configurar AWS Resource Access Manager (AWS RAM) para lanzar nuevas cuentas de AWS y estandarizar las configuraciones base y de red para cada unidad organizativa",
      "Configurar un agregador de AWS Config en la cuenta raíz de la organización para habilitar la agregación de datos multi-cuenta y multi-región. Implementar paquetes de conformidad para estandarizar las configuraciones base y de red en todas las cuentas",
      "Configurar un AWS Control Tower Landing Zone. Habilitar reglas de seguridad preconfiguradas para aplicar políticas o detectar violaciones"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nConfigurar un AWS Control Tower Landing Zone. Habilitar reglas de seguridad preconfiguradas para aplicar políticas o detectar violaciones - AWS Control Tower proporciona una solución centralizada y automatizada para crear cuentas dentro de una organización en AWS. Establece reglas de seguridad preconfiguradas (guardrails) y permite definir configuraciones base para todas las cuentas nuevas, asegurando conformidad y reduciendo la sobrecarga operativa.\n\n\n\nOpciones incorrectas:\n\nCentralizar la creación de cuentas de AWS utilizando AWS Systems Manager OpsCenter. Aplicar políticas y detectar violaciones en todas las cuentas de AWS usando AWS Security Hub - AWS Systems Manager OpsCenter es un servicio diseñado para administrar incidentes y eventos operativos en recursos de AWS, pero no para la creación y gobernanza de cuentas dentro de una organización.\n\nConfigurar AWS Resource Access Manager (AWS RAM) para lanzar nuevas cuentas de AWS y estandarizar las configuraciones base y de red para cada unidad organizativa - AWS Resource Access Manager (RAM) permite compartir recursos entre cuentas de AWS, pero no es capaz de lanzar nuevas cuentas ni aplicar configuraciones predefinidas para gobernanza.\n\nConfigurar un agregador de AWS Config en la cuenta raíz de la organización para habilitar la agregación de datos multi-cuenta y multi-región. Implementar paquetes de conformidad para estandarizar las configuraciones base y de red en todas las cuentas - AWS Config permite monitorear y verificar la conformidad de los recursos dentro de una cuenta o varias cuentas en la organización, pero no facilita la creación de cuentas ni la aplicación automática de configuraciones de gobernanza.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/controltower/latest/userguide/account-factory.html\n\nhttps://aws.amazon.com/blogs/mt/how-to-automate-the-creation-of-multiple-accounts-in-aws-control-tower/\n\nhttps://aws.amazon.com/blogs/aws-control-tower-set-up-govern-a-multi-account-aws-environment/"
  },
  {
    "q": "Una empresa tiene dos instancias EC2 dentro de una Virtual Private Cloud (VPC), pero están desplegadas en diferentes subredes dentro de la misma zona de disponibilidad.\nUna instancia EC2 aloja un servidor de base de datos.\nLa otra instancia EC2 aloja un backend de aplicación que necesita conectarse con la base de datos.\nDebes asegurarte de que estas dos instancias puedan comunicarse correctamente dentro de la VPC.\n¿Qué aspectos debes verificar para garantizar la comunicación? (Selecciona DOS)",
    "o": [
      "Habilitar un NAT Gateway en la VPC para permitir la comunicación interna entre las instancias EC2",
      "Configurar una ruta por defecto en la tabla de enrutamiento que envíe tráfico interno a un Internet Gateway (IGW)",
      "Revisar las Network ACLs de ambas subredes para asegurarse de que no bloquean el tráfico entre las dos instancias",
      "Verificar si los grupos de seguridad permiten la comunicación entre la aplicación y la base de datos en los puertos y protocolos correctos",
      "Verificar si ambas instancias están en la misma zona de disponibilidad"
    ],
    "a": [
      2,
      3
    ],
    "e": "Correcto:\n\nVerificar si los grupos de seguridad permiten la comunicación entre la aplicación y la base de datos en los puertos y protocolos correctos - Los grupos de seguridad de AWS funcionan como firewalls a nivel de instancia y deben configurarse para permitir que la aplicación backend acceda a la base de datos en el puerto y protocolo adecuados.\n\nRevisar las Network ACLs de ambas subredes para asegurarse de que no bloquean el tráfico entre las dos instancias - Las Network ACLs (NACLs) operan a nivel de subred y pueden bloquear o permitir tráfico entre instancias en diferentes subredes dentro de la misma VPC. Deben configurarse para permitir el tráfico entre la subred de la aplicación y la subred de la base de datos.\n\n\n\nPara asegurar la comunicación entre instancias en diferentes subredes dentro de la misma VPC, es fundamental verificar tanto los grupos de seguridad como las Network ACLs.\n\nLa tabla de enrutamiento solo afecta el tráfico entre redes externas o VPCs separadas, pero no afecta la conectividad dentro de una misma VPC.\n\nOpciones incorrectas:\n\nVerificar si ambas instancias están en la misma zona de disponibilidad - Las instancias EC2 pueden comunicarse sin problemas a través de la VPC incluso si están en diferentes zonas de disponibilidad, siempre que los grupos de seguridad y las Network ACLs lo permitan.\n\nHabilitar un NAT Gateway en la VPC para permitir la comunicación interna entre las instancias EC2 - Un NAT Gateway solo se usa para permitir que instancias en subredes privadas accedan a Internet, pero no es necesario para la comunicación interna dentro de la VPC.\n\nConfigurar una ruta por defecto en la tabla de enrutamiento que envíe tráfico interno a un Internet Gateway (IGW) - Un Internet Gateway (IGW) solo es necesario para permitir el tráfico saliente a Internet. No es necesario para la comunicación interna entre instancias dentro de la VPC.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/vpc/latest/userguide/VPC_Security.html\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/security-groups.html"
  },
  {
    "q": "Una empresa opera un sistema de procesamiento de datos en tiempo real en un grupo de Auto Scaling de instancias Amazon EC2. Los ingenieros han notado que algunas instancias experimentan fallos esporádicos debido al uso excesivo de memoria, lo que provoca que el sistema de intercambio (swap) se llene completamente. El arquitecto de soluciones debe encontrar una forma efectiva de monitorear el uso del swap y alertar cuando el consumo supere un umbral crítico.\n¿Cuál de las siguientes opciones es la más adecuada para cumplir con este requisito?",
    "o": [
      "Configurar AWS CloudTrail para registrar eventos de bajo rendimiento y enviarlos a CloudWatch Logs",
      "Instalar el agente de CloudWatch en cada instancia y habilitar la métrica SwapUtilization para su monitoreo",
      "Habilitar el monitoreo detallado en CloudWatch y configurar una alarma para la métrica SwapUsage",
      "Crear una alarma en CloudWatch basada en la métrica MemoryUtilization y asociarla a un evento de fallo de la instancia"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nInstalar el agente de CloudWatch en cada instancia y habilitar la métrica SwapUtilization para su monitoreo - De forma predeterminada, CloudWatch no recopila métricas del sistema operativo como el uso de swap. Para monitorear el uso del swap en las instancias EC2, se debe instalar el agente de CloudWatch y habilitar la métrica SwapUtilization. Esto permite recopilar y visualizar en CloudWatch los datos de consumo de swap, facilitando la configuración de alarmas para detectar condiciones críticas.\n\n\n\nOpciones incorrectas:\n\nHabilitar el monitoreo detallado en CloudWatch y configurar una alarma para la métrica SwapUsage - CloudWatch no recopila SwapUsage de manera predeterminada. El monitoreo detallado solo incluye métricas como CPU, red y almacenamiento, pero no métricas del sistema operativo como swap.\n\nConfigurar AWS CloudTrail para registrar eventos de bajo rendimiento y enviarlos a CloudWatch Logs - AWS CloudTrail solo rastrea eventos administrativos y cambios en la infraestructura, pero no proporciona métricas de rendimiento del sistema operativo.\n\nCrear una alarma en CloudWatch basada en la métrica MemoryUtilization y asociarla a un evento de fallo de la instancia - MemoryUtilization mide el uso de memoria de la instancia, pero no proporciona información sobre el consumo de swap. Para monitorear el swap, es obligatorio instalar y configurar el agente de CloudWatch.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Install-CloudWatch-Agent.html\n\nhttps://aws.amazon.com/cloudwatch/"
  },
  {
    "q": "Una organización multinacional tiene una aplicación distribuida que se ejecuta en instancias de Amazon EC2, que están detrás de un Application Load Balancer en un grupo de Auto Scaling. La aplicación utiliza una base de datos MySQL alojada en Amazon Aurora. El clúster de base de datos se extiende a través de múltiples Zonas de Disponibilidad en una sola región.\nLa organización planea lanzar sus servicios en una nueva área geográfica y quiere asegurar máxima disponibilidad con interrupción mínima del servicio.\n¿Qué estrategia debe adoptar la organización?",
    "o": [
      "Crear un nivel de aplicación similar en la nueva región. Establecer una nueva base de datos Aurora MySQL en esta región. Usar AWS Database Migration Service (AWS DMS) para replicación continua desde la base de datos primaria a la nueva región. Implementar verificaciones de salud de Amazon Route 53 con una política de enrutamiento de conmutación por error a la nueva región",
      "Establecer el nivel de aplicación en la nueva región. Usar Amazon Aurora Global Database para desplegar la base de datos en las regiones primaria y nueva. Aplicar verificaciones de salud de Amazon Route 53 con una política de enrutamiento de conmutación por error a la nueva región. Promover la secundaria a primaria según sea necesario",
      "Replicar el nivel de aplicación en la nueva región. Implementar una Réplica de Lectura de Aurora MySQL en la nueva región usando verificaciones de salud de Route 53 y una política de enrutamiento de conmutación por error. En caso de falla primaria, promover la Réplica de Lectura a primaria",
      "Expandir el grupo de Auto Scaling existente a la nueva Región. Utilizar Amazon Aurora Global Database para extender la base de datos a través de las regiones primaria y nueva. Implementar verificaciones de salud de Amazon Route 53 con una política de enrutamiento de conmutación por error dirigida hacia la nueva región"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nEstablecer el nivel de aplicación en la nueva región. Usar Amazon Aurora Global Database para desplegar la base de datos en las regiones primaria y nueva. Aplicar verificaciones de salud de Amazon Route 53 con una política de enrutamiento de conmutación por error a la nueva región. Promover la secundaria a primaria según sea necesario - La estrategia óptima para lograr alta disponibilidad global y mínima interrupción es implementar el nivel de aplicación en la nueva región y utilizar Amazon Aurora Global Database, que ofrece replicación entre regiones con latencia inferior a 1 segundo y permite conmutación por error rápida y controlada. Combinado con Amazon Route 53 Failover Routing, el tráfico se redirige automáticamente a la región secundaria en caso de una falla.\n\nOpciones incorrectas:\n\nReplicar el nivel de aplicación en la nueva región. Implementar una Réplica de Lectura de Aurora MySQL en la nueva región usando verificaciones de salud de Route 53 y una política de enrutamiento de conmutación por error. En caso de falla primaria, promover la Réplica de Lectura a primaria - Una réplica de lectura entre regiones no garantiza tiempos de recuperación bajos. La promoción no es inmediata y puede causar interrupciones.\n\nExpandir el grupo de Auto Scaling existente a la nueva Región. Utilizar Amazon Aurora Global Database para extender la base de datos a través de las regiones primaria y nueva. Implementar verificaciones de salud de Amazon Route 53 con una política de enrutamiento de conmutación por error dirigida hacia la nueva región - No es posible expandir un Auto Scaling Group entre regiones. Cada ASG es regional.\n\nCrear un nivel de aplicación similar en la nueva región. Establecer una nueva base de datos Aurora MySQL en esta región. Usar AWS Database Migration Service (AWS DMS) para replicación continua desde la base de datos primaria a la nueva región. Implementar verificaciones de salud de Amazon Route 53 con una política de enrutamiento de conmutación por error a la nueva región - AWS DMS sirve para migraciones o cargas analíticas, pero no proporciona la alta disponibilidad ni baja latencia entre regiones que ofrece Aurora Global Database.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-global-database.html\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-global-database-disaster-recovery.html#aurora-global-database-failover"
  },
  {
    "q": "Un equipo de desarrollo está diseñando una arquitectura escalable para una plataforma de mensajería en la nube.\nLa aplicación debe permitir comunicación bidireccional en tiempo real entre los clientes y servidores, utilizando el protocolo WebSocket.\nAdemás, la solución debe admitir enrutamiento basado en rutas y enrutamiento basado en hosts.\n¿Qué configuración satisface mejor este requisito?",
    "o": [
      "Configurar un Network Load Balancer y asociarlo a AWS Global Accelerator para mejorar la disponibilidad y el rendimiento de la aplicación",
      "Configurar un Network Load Balancer con listeners TCP y UDP para manejar el tráfico en tiempo real",
      "Configurar un Gateway Load Balancer frente al grupo de Auto Scaling. Definir una política de balanceo de carga basada en sesiones TCP persistentes",
      "Configurar un Application Load Balancer frente al grupo de Auto Scaling. Habilitar WebSockets en el listener"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nConfigurar un Application Load Balancer frente al grupo de Auto Scaling. Habilitar WebSockets en el listener - El Application Load Balancer (ALB) opera en la capa 7 del modelo OSI y admite WebSockets, lo que permite mantener conexiones persistentes y bidireccionales en tiempo real. También proporciona enrutamiento basado en rutas y enrutamiento basado en hosts, lo que lo convierte en la mejor opción para esta arquitectura.\n\nWebSockets requiere un balanceador de carga en la capa 7 para gestionar correctamente las conexiones persistentes y bidireccionales.\nApplication Load Balancer es la mejor opción porque permite manejar WebSockets y ofrece enrutamiento avanzado para distribuir el tráfico adecuadamente.\nPara garantizar alta disponibilidad, el ALB debe estar configurado frente a un grupo de Auto Scaling distribuido en múltiples zonas de disponibilidad.\nOpciones incorrectas:\n\nConfigurar un Network Load Balancer y asociarlo a AWS Global Accelerator para mejorar la disponibilidad y el rendimiento de la aplicación - AWS Global Accelerator mejora el rendimiento y la disponibilidad del tráfico global, pero no proporciona soporte directo para WebSockets ni permite el enrutamiento basado en rutas o hosts.\n\nConfigurar un Gateway Load Balancer frente al grupo de Auto Scaling. Definir una política de balanceo de carga basada en sesiones TCP persistentes - Gateway Load Balancer está diseñado para enrutar tráfico hacia dispositivos de seguridad virtualizados y no es adecuado para gestionar conexiones WebSocket ni enrutamiento en la capa de aplicación.\n\nConfigurar un Network Load Balancer con listeners TCP y UDP para manejar el tráfico en tiempo real - Network Load Balancer (NLB) opera en la capa 4 y no admite WebSockets. Además, no proporciona capacidades de enrutamiento avanzado como las que requiere la aplicación.\n\nReferencias:\n\nhttps://aws.amazon.com/elasticloadbalancing/features/\n\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-listeners.html"
  },
  {
    "q": "Una empresa tiene una arquitectura sin servidor compuesta por AWS Amplify, Amazon API Gateway y una función Lambda.\nLa aplicación está conectada a una instancia de base de datos Amazon RDS MySQL en una subred privada. Además, una URL de función Lambda (Lambda Function URL) se implementa como el endpoint HTTPS dedicado para la función, con el siguiente valor:\nhttps://joanstellart.lambda-url.us-west-2.on.aws/\nDurante los picos de tráfico, la base de datos genera un error de 'too many connections', impidiendo que los usuarios accedan a la aplicación.\n¿Qué solución podría implementar la empresa para resolver este problema?",
    "o": [
      "Aumentar el límite de concurrencia de la función Lambda",
      "Aumentar el límite de tasa de API Gateway",
      "Provisionar un RDS Proxy entre la función Lambda y la instancia de base de datos RDS",
      "Incrementar la memoria asignada a la función Lambda"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nProvisionar un RDS Proxy entre la función Lambda y la instancia de base de datos RDS - Provisionar un RDS Proxy entre la función Lambda y la base de datos RDS ayuda a administrar un gran número de conexiones mediante el establecimiento de un pool de conexiones. Esto evita que la base de datos se sobrecargue con demasiadas conexiones simultáneas generadas por instancias Lambda en paralelo.\n\n\n\nOpciones incorrectas:\n\nAumentar el límite de tasa de API Gateway - Aumentar el límite de tasa de API Gateway solo permite que se realicen más solicitudes por cliente, pero no soluciona el problema de sobrecarga en la base de datos.\n\nIncrementar la memoria asignada a la función Lambda - Incrementar la memoria de la función Lambda solo haría que se ejecute más rápido, pero no resolvería el error de 'too many connections', ya que el problema está en la base de datos.\n\nAumentar el límite de concurrencia de la función Lambda - Aumentar el límite de concurrencia de la función Lambda permitiría que más solicitudes simultáneas se ejecuten en paralelo, lo que podría empeorar el problema al abrir más conexiones a la base de datos.\n\nReferencias:\n\nhttps://aws.amazon.com/rds/proxy/\n\nhttps://aws.amazon.com/blogs/compute/using-amazon-rds-proxy-with-aws-lambda/"
  },
  {
    "q": "Una startup que ofrece un servicio intuitivo de análisis de datos financieros ha consultado sobre su arquitectura en AWS. Tienen una flota de instancias de trabajo en Amazon EC2 que procesan datos financieros y generan reportes que son utilizados por sus clientes. Debes almacenar los archivos de reporte generados en un almacenamiento duradero. La cantidad de archivos a almacenar puede crecer con el tiempo, ya que la empresa está expandiéndose rápidamente a nivel internacional. Por lo tanto, también necesitan distribuir los reportes más rápido a clientes ubicados en todo el mundo.\n¿Cuál de las siguientes opciones de almacenamiento es rentable y escalable para este escenario?",
    "o": [
      "Usar Amazon Redshift como almacenamiento de datos y CloudFront como la CDN",
      "Usar múltiples almacenes de instancias EC2 para almacenamiento de datos y ElastiCache como la CDN",
      "Usar Amazon S3 Glacier como almacenamiento de datos y ElastiCache como la CDN",
      "Usar Amazon S3 como almacenamiento de datos y CloudFront como la CDN"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nUsar Amazon S3 como almacenamiento de datos y CloudFront como la CDN - Amazon S3 ofrece una solución altamente duradera, escalable y segura para almacenar archivos de respaldo y datos críticos, lo que lo convierte en la mejor opción para la startup que busca almacenar reportes de texto y audio de manera confiable. Además, Amazon CloudFront proporciona una red de entrega de contenido (CDN) eficiente que distribuye rápidamente los reportes a los clientes a nivel global con baja latencia y alto rendimiento.\n\n\n\nOpciones incorrectas:\n\nUsar Amazon S3 Glacier como almacenamiento de datos y ElastiCache como la CDN - Amazon S3 Glacier está diseñado principalmente para almacenamiento de archivos a largo plazo y no para acceso frecuente. En este escenario, los reportes deben estar disponibles rápidamente, lo que hace que S3 Glacier no sea la mejor opción. Además, ElastiCache es un servicio de almacenamiento en caché en memoria y no un servicio de distribución de contenido (CDN) como CloudFront.\n\nUsar Amazon Redshift como almacenamiento de datos y CloudFront como la CDN - Amazon Redshift es un almacén de datos diseñado para cargas de trabajo analíticas y no para el almacenamiento de archivos de reportes. Utilizar Redshift para este caso sería ineficiente y costoso. CloudFront sigue siendo una opción adecuada para la entrega de contenido, pero la combinación con Redshift no es óptima.\n\nUsar múltiples almacenes de instancias EC2 para almacenamiento de datos y ElastiCache como la CDN - El almacenamiento en instancias EC2 no es duradero, lo que significa que los datos podrían perderse si la instancia falla. Además, ElastiCache es un sistema de almacenamiento en caché en memoria y no un servicio de distribución de contenido global, lo que lo hace inadecuado para este escenario.\n\nReferencias:\n\nhttps://aws.amazon.com/s3/\n\nhttps://aws.amazon.com/caching/cdn/"
  },
  {
    "q": "Una startup ha desarrollado un sitio web informativo que solo contiene contenido estático y lo ha alojado en un bucket de Amazon S3.\nPara que el sitio web esté accesible a través de su dominio personalizado recientemente adquirido en Route 53, el equipo necesita configurar correctamente el enrutamiento de tráfico.\n¿Cuáles son los requisitos previos para permitir que Amazon Route 53 dirija tráfico al sitio web alojado en un bucket de Amazon S3? (Selecciona DOS)",
    "o": [
      "Configurar un conjunto de registros de tipo 'SRV'",
      "Habilitar la replicación de objetos de S3 en múltiples regiones",
      "Configurar políticas de acceso público en Amazon S3 con reglas de control de versiones habilitadas",
      "Registrar un nombre de dominio en Route 53 o un proveedor externo",
      "Nombrar el bucket de S3 con el mismo nombre que el dominio registrado"
    ],
    "a": [
      3,
      4
    ],
    "e": "Correcto:\n\nRegistrar un nombre de dominio en Route 53 o un proveedor externo - Para enrutar tráfico a un sitio web estático en S3, la empresa debe contar con un nombre de dominio registrado. Puede ser gestionado a través de Route 53 o de un registrador externo.\n\nNombrar el bucket de S3 con el mismo nombre que el dominio registrado - Amazon S3 requiere que el bucket de alojamiento estático tenga el mismo nombre que el dominio registrado. Por ejemplo, si el dominio es miexample.com, el bucket de S3 debe llamarse miexample.com.\n\n\n\nPara que el sitio web sea accesible a través del dominio, Route 53 debe tener un registro tipo Alias apuntando al bucket de S3.\n\nLa configuración del bucket debe habilitar el alojamiento de sitios web estáticos y definir una página de índice (index.html).\n\nOpciones incorrectas:\n\nConfigurar un conjunto de registros de tipo 'SRV' - Los registros SRV se utilizan para servicios específicos como VoIP y no son necesarios para enrutar tráfico web a un bucket de S3.\n\nHabilitar la replicación de objetos de S3 en múltiples regiones - La replicación de objetos de S3 se usa para sincronizar datos entre regiones, pero no afecta el enrutamiento de tráfico a un sitio web alojado en S3.\n\nConfigurar políticas de acceso público en Amazon S3 con reglas de control de versiones habilitadas - Si bien los permisos de acceso público son necesarios para permitir la visualización de contenido en S3, las reglas de control de versiones no son un requisito para enrutar tráfico desde Route 53.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/RoutingToS3Bucket.html"
  },
  {
    "q": "El equipo de IT de una empresa ha solicitado una estrategia automatizada para realizar copias de seguridad de todos los volúmenes EBS de las instancias EC2 como parte del Plan de Continuidad del Negocio. El Director de TI ha enfatizado la importancia de una solución rápida, rentable y sin intervención manual para la gestión de estos respaldos.\n¿Cuál es la mejor opción para cumplir con estos requisitos?",
    "o": [
      "Configurar una política de ciclo de vida en S3 para almacenar copias de seguridad automáticas de los volúmenes EBS",
      "Crear un script en AWS CLI que ejecute 'create-snapshot' en intervalos programados mediante un cron job",
      "Usar Amazon Data Lifecycle Manager (DLM) para automatizar la creación y administración de snapshots de EBS",
      "Implementar Amazon Storage Gateway y usarlo para almacenar los respaldos de volúmenes EBS en servidores locales"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nUsar Amazon Data Lifecycle Manager (DLM) para automatizar la creación y administración de snapshots de EBS - Amazon Data Lifecycle Manager (DLM) permite automatizar la creación y administración de snapshots de volúmenes EBS sin necesidad de programación manual.\n\nDLM simplifica la gestión de copias de seguridad al permitir la configuración de políticas de retención, eliminación y programación de snapshots, optimizando costos y cumplimiento.\n\nOpciones incorrectas:\n\nConfigurar una política de ciclo de vida en S3 para almacenar copias de seguridad automáticas de los volúmenes EBS - Amazon S3 no tiene una política de ciclo de vida para administrar snapshots de volúmenes EBS. Las reglas de ciclo de vida de S3 solo aplican a objetos almacenados en S3, pero no a volúmenes EBS.\n\nCrear un script en AWS CLI que ejecute 'create-snapshot' en intervalos programados mediante un cron job - Crear un script con AWS CLI y programar tareas para ejecutar 'create-snapshot' puede ser una alternativa funcional, pero requiere administración y mantenimiento manual. DLM ofrece una solución más eficiente y sin intervención manual.\n\nImplementar Amazon Storage Gateway y usarlo para almacenar los respaldos de volúmenes EBS en servidores locales - Amazon Storage Gateway está diseñado para la integración de almacenamiento híbrido con centros de datos locales, pero no es la mejor opción para gestionar snapshots de volúmenes EBS en AWS.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snapshot-lifecycle.html\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-creating-snapshot.html"
  },
  {
    "q": "Tanto los registros históricos como los datos de acceso frecuente se almacenan en un sistema de almacenamiento local en las instalaciones de la empresa. La cantidad de datos actuales está creciendo a un ritmo exponencial. Dado que la capacidad de almacenamiento está llegando a su límite, el Solutions Architect ha decidido mover los registros históricos a AWS para liberar espacio para los datos activos.\n¿Cuáles de las siguientes arquitecturas proporcionan la mejor solución en términos de costos y gestión operativa?",
    "o": [
      "Usar AWS DataSync para mover los registros históricos de las instalaciones a AWS. Seleccionar Amazon S3 Standard como destino de los datos. Modificar la configuración de ciclo de vida de S3 para mover los datos de Standard a Amazon S3 Glacier Deep Archive después de 30 días",
      "Usar AWS Storage Gateway para mover los registros históricos de las instalaciones a AWS. Seleccionar Amazon S3 Glacier como destino de los datos",
      "Usar AWS Storage Gateway para mover los registros históricos de las instalaciones a AWS. Seleccionar Amazon S3 Glacier Deep Archive como destino de los datos",
      "Usar AWS DataSync para mover los registros históricos de las instalaciones a AWS. Seleccionar Amazon S3 Glacier Deep Archive como destino de los datos"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nUsar AWS DataSync para mover los registros históricos de las instalaciones a AWS. Seleccionar Amazon S3 Glacier Deep Archive como destino de los datos - AWS DataSync es la solución más adecuada para transferir grandes volúmenes de datos históricos desde sistemas de almacenamiento en las instalaciones a AWS. Permite mover datos de manera rápida y eficiente a almacenamiento seguro y de bajo costo, como Amazon S3 Glacier Deep Archive, sin necesidad de modificar las aplicaciones existentes. Glacier Deep Archive es la opción más rentable para almacenar datos a largo plazo que rara vez se acceden.\n\n\n\nOpciones incorrectas:\n\nUsar AWS Storage Gateway para mover los registros históricos de las instalaciones a AWS. Seleccionar Amazon S3 Glacier como destino de los datos - AWS Storage Gateway no es la mejor opción para la migración de grandes volúmenes de datos, ya que está diseñado principalmente para almacenamiento híbrido, proporcionando acceso de baja latencia a los datos almacenados en AWS. No está optimizado para transferencias masivas de datos históricos.\n\nUsar AWS DataSync para mover los registros históricos de las instalaciones a AWS. Seleccionar Amazon S3 Standard como destino de los datos. Modificar la configuración de ciclo de vida de S3 para mover los datos de Standard a Amazon S3 Glacier Deep Archive después de 30 días - AWS DataSync permite transferir datos directamente a Amazon S3 Glacier Deep Archive sin necesidad de configurar reglas de ciclo de vida en S3. La opción mencionada implica un paso innecesario al primero mover los datos a S3 Standard y luego aplicar una política de ciclo de vida para trasladarlos a Glacier Deep Archive después de 30 días, lo que resulta en costos adicionales.\n\nUsar AWS Storage Gateway para mover los registros históricos de las instalaciones a AWS. Seleccionar Amazon S3 Glacier Deep Archive como destino de los datos - AWS Storage Gateway no es la mejor solución para la migración de registros históricos a AWS, ya que su propósito principal es proporcionar almacenamiento en caché y transferencia de datos optimizada para entornos híbridos.\n\nReferencias:\n\nhttps://aws.amazon.com/datasync/faqs/\n\nhttps://aws.amazon.com/storagegateway/faqs/"
  },
  {
    "q": "Una empresa necesita mejorar la visibilidad de sus costos en AWS y asegurarse de que cada equipo de desarrollo pueda rastrear sus gastos de manera eficiente.\nEl equipo financiero ha solicitado un informe mensual que muestre los costos de cada equipo dentro de la organización.\n¿Cuál de las siguientes soluciones permitirá generar estos informes de manera eficiente?",
    "o": [
      "Configurar un Informe de Costos y Uso en AWS y exportarlo manualmente a una hoja de cálculo para clasificar los costos",
      "Usar AWS Cost Explorer para filtrar y visualizar el gasto total según los recursos consumidos por cada equipo",
      "Etiquetar todos los recursos con el nombre del equipo de desarrollo y habilitar etiquetas de asignación de costos",
      "Crear presupuestos en AWS Budgets y configurar alertas para cada equipo cuando su gasto supere un umbral predefinido"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nEtiquetar todos los recursos con el nombre del equipo de desarrollo y habilitar etiquetas de asignación de costos - AWS permite agregar etiquetas personalizadas a los recursos, como el nombre del equipo de desarrollo. Activar las etiquetas de asignación de costos permite que AWS genere informes de facturación segmentados por equipo, proporcionando visibilidad sobre el gasto. Las etiquetas de asignación de costos permiten categorizar los recursos por equipos, proyectos o cualquier otra unidad organizativa. Una vez habilitadas, AWS Billing consolida la información en los informes de facturación para un análisis detallado de costos.\n\n\n\nOpciones incorrectas:\n\nCrear presupuestos en AWS Budgets y configurar alertas para cada equipo cuando su gasto supere un umbral predefinido - AWS Budgets es útil para monitorear costos y establecer alertas, pero no proporciona un desglose detallado de los costos por equipo. Su función principal es la gestión de presupuestos y alertas de gastos.\n\nUsar AWS Cost Explorer para filtrar y visualizar el gasto total según los recursos consumidos por cada equipo - AWS Cost Explorer permite visualizar costos y filtrar por recurso, pero no genera automáticamente informes organizados por equipo. Para una gestión eficiente, se requieren etiquetas de asignación de costos.\n\nConfigurar un Informe de Costos y Uso en AWS y exportarlo manualmente a una hoja de cálculo para clasificar los costos - El Informe de Costos y Uso de AWS proporciona datos detallados, pero no clasifica automáticamente los costos por equipo. Se necesitaría procesamiento manual adicional, lo cual es menos eficiente que usar etiquetas de costos.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html\n\nhttps://aws.amazon.com/aws-cost-management/aws-cost-explorer/"
  },
  {
    "q": "Una aplicación se ejecuta en instancias de Amazon EC2 a través de múltiples Zonas de Disponibilidad. Las instancias se ejecutan en un grupo de Auto Scaling de Amazon EC2 detrás de un Application Load Balancer. La aplicación rinde mejor cuando la utilización de CPU de las instancias de EC2 está en o cerca del 40%.\n¿Qué debe hacer un arquitecto de soluciones para mantener el rendimiento deseado a través de todas las instancias en el grupo?",
    "o": [
      "Usar acciones de escalado programadas para escalar hacia arriba y hacia abajo el grupo de Auto Scaling",
      "Usar una política de seguimiento de objetivos para escalar dinámicamente el grupo de Auto Scaling",
      "Usar una función de AWS Lambda para actualizar la capacidad deseada del grupo de Auto Scaling",
      "Usar una política de escalado simple para escalar dinámicamente el grupo de Auto Scaling"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nUsar una política de seguimiento de objetivos para escalar dinámicamente el grupo de Auto Scaling - Una política de seguimiento de objetivos permite definir una métrica (como la utilización de CPU) y un valor objetivo (40%). El Auto Scaling ajusta automáticamente la capacidad para mantener la métrica alrededor del objetivo, respondiendo de forma dinámica a los cambios en la carga.\n\nOpciones incorrectas:\n\nUsar una función de AWS Lambda para actualizar la capacidad deseada del grupo de Auto Scaling - Lambda no es necesario para modificar capacidad; Auto Scaling ya puede hacerlo automáticamente.\n\nUsar una política de escalado simple para escalar dinámicamente el grupo de Auto Scaling - Las políticas simples dependen de umbrales estáticos y no mantienen la métrica en un valor objetivo.\n\nUsar acciones de escalado programadas para escalar hacia arriba y hacia abajo el grupo de Auto Scaling - El escalado programado no responde a cambios dinámicos en la carga.\n\nReferencia:\n\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-target-tracking.html"
  },
  {
    "q": "Una empresa de comercio electrónico quiere optimizar la entrega de imágenes en su sitio web utilizando Amazon CloudFront.\nPara mejorar la experiencia del usuario, la empresa planea servir imágenes en formato AVIF a los navegadores que lo admitan y en formato PNG para aquellos que no lo soporten.\nAdicionalmente, desean agregar un encabezado personalizado en la respuesta para realizar un mejor seguimiento del tráfico de imágenes.\nComo arquitecto de soluciones, ¿qué estrategia recomendarías para cumplir con estos requisitos minimizando la sobrecarga operativa?",
    "o": [
      "Implementar un servicio de conversión de imágenes en contenedores ECS con AWS Fargate e integrarlo con CloudFront. Usar funciones Lambda para modificar los encabezados de respuesta y servir el formato adecuado según el User-Agent",
      "Crear múltiples distribuciones de CloudFront, cada una sirviendo un formato de imagen diferente (AVIF o PNG). Usar Route 53 para enrutar las solicitudes entrantes a la distribución adecuada según el User-Agent",
      "Configurar una política de encabezados en CloudFront y definir reglas para que el formato de imagen se determine con base en el User-Agent en la solicitud",
      "Configurar comportamientos en CloudFront basados en el encabezado User-Agent. Utilizar funciones Lambda@Edge para modificar los encabezados de respuesta y servir el formato correcto"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nConfigurar comportamientos en CloudFront basados en el encabezado User-Agent. Utilizar funciones Lambda@Edge para modificar los encabezados de respuesta y servir el formato correcto - Lambda@Edge permite interceptar las solicitudes y modificar las respuestas en el borde de la red de CloudFront, lo que significa que se pueden detectar los encabezados User-Agent y modificar la respuesta para servir el formato de imagen adecuado antes de que la solicitud llegue al origen. También permite agregar encabezados personalizados sin necesidad de infraestructura adicional. CloudFront puede almacenar en caché múltiples versiones de un mismo recurso en función de los encabezados configurados. Lambda@Edge proporciona flexibilidad para modificar solicitudes y respuestas en el borde de la red, reduciendo la latencia y mejorando la eficiencia de entrega de contenido.\n\n\n\nOpciones incorrectas:\n\nImplementar un servicio de conversión de imágenes en contenedores ECS con AWS Fargate e integrarlo con CloudFront. Usar funciones Lambda para modificar los encabezados de respuesta y servir el formato adecuado según el User-Agent - Configurar un servicio de conversión de imágenes en ECS con AWS Fargate introduce una sobrecarga operativa innecesaria. Lambda@Edge puede manejar esta lógica de conversión sin necesidad de mantener una infraestructura adicional.\n\nConfigurar una política de encabezados en CloudFront y definir reglas para que el formato de imagen se determine con base en el User-Agent en la solicitud - Las políticas de encabezados en CloudFront solo permiten controlar qué encabezados incluir o excluir en las respuestas, pero no pueden modificar dinámicamente los formatos de imagen basados en User-Agent.\n\nCrear múltiples distribuciones de CloudFront, cada una sirviendo un formato de imagen diferente (AVIF o PNG). Usar Route 53 para enrutar las solicitudes entrantes a la distribución adecuada según el User-Agent - Crear múltiples distribuciones de CloudFront para cada formato de imagen genera complejidad operativa innecesaria y no es una solución escalable. Lambda@Edge permite lograr el mismo resultado en una sola distribución de CloudFront.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/lambda-at-the-edge.html\n\nhttps://docs.aws.amazon.com/lambda/latest/dg/lambda-edge.html"
  },
  {
    "q": "Una empresa de medios necesita migrar 400 TB de datos archivados desde sus servidores locales a Amazon S3 para mejorar la durabilidad y disponibilidad de la información. Actualmente, cuentan con una conexión a Internet de 100 Mbps, lo que podría representar un desafío en términos de tiempo y costos para completar la transferencia.\n¿Cuál es la opción más rápida y rentable para realizar esta migración?",
    "o": [
      "Utilizar AWS Snowmobile para mover los datos a Amazon S3",
      "Cargar los datos directamente a S3 utilizando la conexión de 100 Mbps",
      "Configurar una conexión AWS Direct Connect antes de iniciar la transferencia",
      "Solicitar múltiples dispositivos AWS Snowball para transferir los datos a Amazon S3"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nSolicitar múltiples dispositivos AWS Snowball para transferir los datos a Amazon S3 - AWS Snowball es la mejor alternativa para mover grandes volúmenes de datos (terabytes a petabytes) de manera rápida y rentable. Dado que una conexión de 100 Mbps tardaría más de 300 días en transferir 400 TB, Snowball permite completar la migración en cuestión de días, reduciendo significativamente el tiempo y los costos asociados.\n\n\n\nOpciones incorrectas:\n\nUtilizar AWS Snowmobile para mover los datos a Amazon S3 - AWS Snowmobile está diseñado para mover volúmenes masivos de datos (hasta 100 PB) en camiones físicos, lo que lo hace innecesario y costoso para una transferencia de solo 400 TB.\n\nConfigurar una conexión AWS Direct Connect antes de iniciar la transferencia - AWS Direct Connect es útil para transferencias continuas de datos, pero establecer una conexión puede tomar semanas o meses, además de incurrir en costos adicionales. Para una migración única, Snowball es más eficiente.\n\nCargar los datos directamente a S3 utilizando la conexión de 100 Mbps - Transferir 400 TB a través de una conexión de 100 Mbps tomaría más de 300 días, lo que no es viable. Snowball es la opción óptima para acelerar el proceso sin depender de la conexión de Internet de la empresa.\n\nReferencias:\n\nhttps://aws.amazon.com/snowball/\n\nhttps://aws.amazon.com/snowball/faqs/"
  },
  {
    "q": "Una empresa de logística tiene dos VPCs: VPC-A y VPC-B conectadas mediante un enlace de peering. VPC-A contiene solo subredes privadas, mientras que VPC-B tiene solo subredes públicas.\nActualmente, la empresa utiliza una única conexión AWS Direct Connect con una interfaz virtual privada para conectar su red on-premises con VPC-A.\nPara mejorar la disponibilidad y redundancia de la conexión, ¿cuáles de las siguientes opciones son recomendadas? (Selecciona DOS)",
    "o": [
      "Crear una nueva conexión AWS Direct Connect e interfaz virtual privada en la misma región, pero asociarla a VPC-B",
      "Habilitar AWS Global Accelerator para mejorar la latencia de la conexión entre la red on-premises y VPC-A",
      "Implementar una segunda conexión AWS Direct Connect e interfaz virtual privada en la misma región de AWS para VPC-A",
      "Establecer una VPN de hardware entre VPC-B y la red on-premises para proporcionar redundancia a VPC-A",
      "Configurar una VPN de hardware a través de Internet entre VPC-A y la red on-premises como respaldo"
    ],
    "a": [
      2,
      4
    ],
    "e": "Correcto:\n\nImplementar una segunda conexión AWS Direct Connect e interfaz virtual privada en la misma región de AWS para VPC-A - Agregar una segunda conexión AWS Direct Connect en la misma región y asociarla a VPC-A mejora la tolerancia a fallos. Si la conexión primaria falla, la nueva conexión puede asumir el tráfico, garantizando la continuidad operativa.\n\nConfigurar una VPN de hardware a través de Internet entre VPC-A y la red on-premises como respaldo - Configurar una VPN de hardware a través de Internet entre VPC-A y la red on-premises proporciona una ruta de respaldo en caso de que falle Direct Connect. Este es un enfoque recomendado por AWS para la alta disponibilidad en arquitecturas híbridas.\n\n\n\nOpciones incorrectas:\n\nCrear una nueva conexión AWS Direct Connect e interfaz virtual privada en la misma región, pero asociarla a VPC-B - Asociar una conexión Direct Connect a VPC-B no beneficia a VPC-A porque AWS VPC Peering no permite el enrutamiento transitorio. VPC-A no podría usar la conexión de VPC-B para comunicarse con la red on-premises.\n\nHabilitar AWS Global Accelerator para mejorar la latencia de la conexión entre la red on-premises y VPC-A - AWS Global Accelerator optimiza el enrutamiento a nivel global, pero no proporciona redundancia ni tolerancia a fallos en conexiones Direct Connect.\n\nEstablecer una VPN de hardware entre VPC-B y la red on-premises para proporcionar redundancia a VPC-A - Una VPN entre VPC-B y la red on-premises no solucionaría el problema de redundancia de VPC-A debido a que el peering de VPC no soporta el enrutamiento transitorio.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/directconnect/latest/UserGuide/Resiliency.html\n\nhttps://docs.aws.amazon.com/vpc/latest/peering/invalid-peering-configurations.html#edge-to-edge-vgw"
  },
  {
    "q": "Una empresa de desarrollo de software está desplegando una aplicación basada en microservicios en Amazon Elastic Kubernetes Service (Amazon EKS). El tráfico de la aplicación fluctúa significativamente a lo largo del día y la empresa quiere asegurar que el clúster de EKS escale hacia arriba y hacia abajo según estos patrones de tráfico.\n¿Qué combinación de pasos satisfaría estos requisitos con esfuerzo operacional mínimo (Selecciona DOS.)",
    "o": [
      "Integrar Amazon SQS y conectarlo a Amazon EKS para gestión de cargas de trabajo",
      "Emplear el Kubernetes Cluster Autoscaler para gestionar dinámicamente la cantidad de nodos en el clúster de EKS",
      "Utilizar el Kubernetes Metrics Server para habilitar autoescalado horizontal de pods basado en utilización de recursos",
      "Aprovechar AWS X-Ray para rastrear y analizar la actividad de red de la aplicación",
      "Implementar el Kubernetes Vertical Pod Autoscaler para ajustar la asignación de CPU y memoria para los pods"
    ],
    "a": [
      1,
      2
    ],
    "e": "Correcto:\n\nUtilizar el Kubernetes Metrics Server para habilitar autoescalado horizontal de pods basado en utilización de recursos - El Kubernetes Metrics Server recopila métricas de CPU y memoria de los pods y nodos, lo que habilita al Horizontal Pod Autoscaler a aumentar o reducir el número de pods en función de la carga real. Es el método estándar en Kubernetes para autoescalado basado en utilización.\n\nEmplear el Kubernetes Cluster Autoscaler para gestionar dinámicamente la cantidad de nodos en el clúster de EKS - El Kubernetes Cluster Autoscaler ajusta automáticamente la cantidad de nodos en el clúster cuando los pods no pueden programarse por falta de recursos o cuando hay nodos subutilizados. Esto permite escalar la infraestructura de forma dinámica según demanda.\n\nOpciones incorrectas:\n\nAprovechar AWS X-Ray para rastrear y analizar la actividad de red de la aplicación - AWS X-Ray rastrea solicitudes y diagnostica problemas en la aplicación, pero no realiza autoescalado.\n\nImplementar el Kubernetes Vertical Pod Autoscaler para ajustar la asignación de CPU y memoria para los pods - El Vertical Pod Autoscaler ajusta CPU/memoria de pods individuales, pero no escala el número de pods ni los nodos del clúster.\n\nIntegrar Amazon SQS y conectarlo a Amazon EKS para gestión de cargas de trabajo - Amazon SQS puede ayudar a desacoplar microservicios, pero no interviene en el proceso de autoescalado del clúster ni de los pods.\n\nReferencias:\nhttps://kubernetes.io/docs/tasks/debug/debug-cluster/resource-metrics-pipeline/#metrics-server\n\nhttps://docs.aws.amazon.com/eks/latest/userguide/autoscaling.html"
  },
  {
    "q": "Una empresa de medios digitales comparte contenido estático con sus usuarios premium en todo el mundo y también con sus socios que distribuyen sus archivos multimedia. La empresa busca formas de reducir los costos de sus servidores y entregar de manera segura sus datos a sus clientes globalmente con baja latencia.\n¿Qué combinación de servicios debe utilizarse para proporcionar la arquitectura más adecuada y rentable? (Selecciona DOS)",
    "o": [
      "Amazon CloudFront",
      "AWS Fargate",
      "Amazon S3",
      "AWS Global Accelerator",
      "AWS Lambda"
    ],
    "a": [
      0,
      2
    ],
    "e": "Correcto:\n\nAmazon S3 - Amazon S3 es un servicio de almacenamiento de objetos altamente escalable, duradero y rentable. Es ideal para almacenar contenido estático como imágenes, videos y archivos multimedia, lo que lo convierte en la mejor opción para servir datos a los clientes.\n\nAmazon CloudFront - Amazon CloudFront es una red de distribución de contenido (CDN) que acelera la entrega de contenido estático y dinámico a nivel mundial. Se integra perfectamente con Amazon S3 y reduce los costos de transferencia de datos, al tiempo que mejora la seguridad y la latencia mediante el uso de ubicaciones de borde globales.\n\n\n\nOpciones incorrectas:\n\nAWS Global Accelerator - AWS Global Accelerator está diseñado para mejorar la disponibilidad y el rendimiento de aplicaciones no HTTP, como juegos en línea (UDP), IoT (MQTT) o voz sobre IP. No es la mejor opción para distribuir contenido estático, ya que CloudFront es el servicio adecuado para este caso de uso.\n\nAWS Lambda - AWS Lambda es un servicio sin servidor que ejecuta código en respuesta a eventos. Aunque es rentable, no está diseñado para almacenar ni distribuir contenido estático. La combinación óptima en este escenario es S3 y CloudFront.\n\nAWS Fargate - AWS Fargate es un servicio de cómputo sin servidor para contenedores, útil para ejecutar aplicaciones en ECS y EKS. No es rentable ni adecuado para almacenar y servir contenido estático en comparación con Amazon S3 y CloudFront.\n\nReferencias:\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/cloudfront-serve-static-website/\n\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/amazon-s3-amazon-cloudfront-a-match-made-in-the-cloud/\n\nhttps://aws.amazon.com/global-accelerator/faqs/"
  },
  {
    "q": "Todos los objetos subidos a un bucket de Amazon S3 deben estar cifrados para cumplir con las normativas de seguridad. El bucket utilizará cifrado del lado del servidor con claves de cifrado administradas por Amazon S3 (SSE-S3) para cifrar los datos utilizando el cifrado de bloques Advanced Encryption Standard (AES-256).\n¿Cuál de los siguientes encabezados de solicitud debe usarse?",
    "o": [
      "x-amz-server-side-encryption-customer-key",
      "x-amz-server-side-encryption-customer-key-MD5",
      "x-amz-server-side-encryption",
      "x-amz-server-side-encryption-customer-algorithm"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nx-amz-server-side-encryption - El encabezado x-amz-server-side-encryption es el que se usa para indicar que Amazon S3 debe cifrar el objeto en el servidor utilizando claves administradas por Amazon S3 (SSE-S3). Con SSE-S3, S3 cifra cada objeto con una clave única y, como medida adicional de seguridad, cifra la clave misma con una clave maestra que se rota regularmente.\n\n\n\nOpciones incorrectas:\n\nx-amz-server-side-encryption-customer-key-MD5 - El encabezado x-amz-server-side-encryption-customer-key-MD5 se usa en el cifrado del lado del servidor con claves proporcionadas por el cliente (SSE-C). Este encabezado se emplea para enviar el hash MD5 de la clave de cifrado del cliente y verificar su integridad, pero no es aplicable a SSE-S3, donde las claves son administradas por Amazon S3.\n\nx-amz-server-side-encryption-customer-algorithm - El encabezado x-amz-server-side-encryption-customer-algorithm también se usa con SSE-C y especifica el algoritmo de cifrado que se debe utilizar con la clave proporcionada por el cliente. No es necesario cuando se usa SSE-S3, ya que en este caso Amazon S3 administra el cifrado y utiliza AES-256 por defecto.\n\nx-amz-server-side-encryption-customer-key - El encabezado x-amz-server-side-encryption-customer-key se usa en SSE-C para proporcionar la clave de cifrado que se utilizará para proteger el objeto. Sin embargo, en SSE-S3, las claves son gestionadas automáticamente por Amazon S3, por lo que este encabezado no es necesario.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/UsingServerSideEncryption.html\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/ServerSideEncryptionCustomerKeys.html"
  },
  {
    "q": "Una empresa tiene una red de cámaras de vigilancia instaladas dentro de las instalaciones de su centro de datos. La gerencia quiere aprovechar la Inteligencia Artificial para monitorear y detectar el acceso no autorizado de personas a áreas restringidas. Si se detecta una persona no autorizada, el equipo de seguridad debe recibir una alerta por SMS.\n¿Qué solución satisface este requisito?",
    "o": [
      "Configurar Amazon Managed Service for Prometheus para transmitir en vivo las grabaciones de las cámaras. Usar Amazon Fraud Detector para detectar personas no autorizadas. Configurar los números de teléfono del equipo de seguridad como suscriptores de un tema de SNS",
      "Reemplazar las cámaras existentes con dispositivos AWS IoT. Cargar un modelo de detección facial en los dispositivos IoT y enviarlos a AWS Control Tower para verificación y notificación",
      "Usar Amazon Kinesis Video para transmitir en vivo las grabaciones de las cámaras. Usar Amazon Rekognition para detectar a las personas autorizadas. Configurar los números de teléfono del equipo de seguridad como suscriptores de un tema de SNS",
      "Configurar Amazon Elastic Transcoder para transmitir en vivo las grabaciones de las cámaras. Usar Amazon Kendra para detectar personas autorizadas. Configurar los números de teléfono del equipo de seguridad como suscriptores de un tema de SNS"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nUsar Amazon Kinesis Video para transmitir en vivo las grabaciones de las cámaras. Usar Amazon Rekognition para detectar a las personas autorizadas. Configurar los números de teléfono del equipo de seguridad como suscriptores de un tema de SNS - Amazon Kinesis Video Streams permite transmitir de manera segura video en vivo desde dispositivos conectados a AWS, donde puede ser analizado con Machine Learning (ML) o almacenado para reproducción y procesamiento. Amazon Rekognition Video puede detectar objetos, escenas y rostros en videos en tiempo real, lo que permite identificar a personas autorizadas y alertar al equipo de seguridad a través de Amazon SNS en caso de detección de personas no autorizadas.\n\n\n\nOpciones incorrectas:\n\nConfigurar Amazon Elastic Transcoder para transmitir en vivo las grabaciones de las cámaras. Usar Amazon Kendra para detectar personas autorizadas. Configurar los números de teléfono del equipo de seguridad como suscriptores de un tema de SNS - Amazon Elastic Transcoder no es una herramienta para transmisión en vivo ni para detección de personas; su propósito es convertir archivos multimedia de un formato a otro. Además, Amazon Kendra es un servicio de búsqueda inteligente y no se puede utilizar para la detección facial.\n\nReemplazar las cámaras existentes con dispositivos AWS IoT. Cargar un modelo de detección facial en los dispositivos IoT y enviarlos a AWS Control Tower para verificación y notificación - AWS IoT no es un servicio de videovigilancia ni está diseñado para reemplazar cámaras de seguridad. Además, AWS Control Tower es un servicio para la gobernanza y administración de múltiples cuentas en AWS, no para la verificación de videos en vivo.\n\nConfigurar Amazon Managed Service for Prometheus para transmitir en vivo las grabaciones de las cámaras. Usar Amazon Fraud Detector para detectar personas no autorizadas. Configurar los números de teléfono del equipo de seguridad como suscriptores de un tema de SNS - Amazon Managed Service for Prometheus es un servicio de monitoreo para entornos en contenedores, pero no es capaz de transmitir video en vivo. Amazon Fraud Detector es una herramienta diseñada para identificar actividades fraudulentas, como fraudes en pagos y creación de cuentas falsas, y no está diseñado para analizar transmisiones en vivo para detectar accesos no autorizados.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/kinesisvideostreams/latest/dg/what-is-kinesis-video.html\n\nhttps://aws.amazon.com/blogs/aws/launch-welcoming-amazon-rekognition-video-service/"
  },
  {
    "q": "Un arquitecto de soluciones está construyendo una infraestructura en la nube donde las instancias EC2 requieren acceso a varios servicios de AWS como S3 y Redshift. El arquitecto también debe proporcionar acceso a los administradores del sistema para que puedan implementar y probar sus cambios.\n¿Qué configuración se debe utilizar para garantizar que el acceso a los recursos sea seguro y no se vea comprometido? (Selecciona DOS)",
    "o": [
      "Asignar un rol de IAM a la instancia Amazon EC2",
      "Asignar un usuario de IAM para cada instancia Amazon EC2",
      "Habilitar la autenticación multifactor (MFA)",
      "Almacenar las claves de acceso de AWS en la instancia EC2",
      "Almacenar las claves de acceso de AWS en ACM"
    ],
    "a": [
      0,
      2
    ],
    "e": "Correcto:\n\nAsignar un rol de IAM a la instancia Amazon EC2 - Asignar un rol de IAM a la instancia EC2 es la mejor práctica recomendada por AWS para permitir que las instancias accedan de manera segura a otros servicios de AWS. En lugar de almacenar claves de acceso en la instancia, el uso de roles de IAM permite la autenticación segura sin necesidad de gestionar credenciales manualmente.\n\nHabilitar la autenticación multifactor (MFA) - Habilitar la autenticación multifactor (MFA) agrega una capa adicional de seguridad para los administradores del sistema que requieren acceso a la infraestructura. MFA requiere un segundo factor de autenticación además de la contraseña, lo que reduce el riesgo de accesos no autorizados.\n\n\n\nOpciones incorrectas:\n\nAlmacenar las claves de acceso de AWS en la instancia EC2 - Almacenar claves de acceso en una instancia EC2 es una mala práctica, ya que puede comprometer la seguridad si la instancia es comprometida o si las credenciales se exponen accidentalmente.\n\nAsignar un usuario de IAM para cada instancia Amazon EC2 - No es necesario crear un usuario de IAM para cada instancia EC2. Los roles de IAM ya proporcionan flexibilidad y una mejor gestión de permisos sin necesidad de usuarios individuales.\n\nAlmacenar las claves de acceso de AWS en ACM - ACM (AWS Certificate Manager) se usa para gestionar certificados SSL/TLS, no para almacenar claves de acceso de AWS.\n\nReferencias:\n\nhttps://aws.amazon.com/iam/details/mfa\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html"
  },
  {
    "q": "Una empresa tiene una base de datos MySQL on-premises que necesita ser replicada en Amazon S3 en formato CSV. La base de datos eventualmente será migrada a un clúster de Amazon Aurora Serverless e integrada con un RDS Proxy para permitir que las aplicaciones web compartan conexiones a la base de datos. Dado que los datos no han sido completamente migrados, los cambios recientes en la base de datos on-premises deben transmitirse continuamente al bucket de S3. La empresa quiere una solución que requiera el menor esfuerzo de administración y sea altamente segura.\n¿Qué patrón de ingesta debe seleccionar un arquitecto de soluciones?",
    "o": [
      "Usar AWS Schema Conversion Tool (AWS SCT) para convertir los datos de MySQL a CSV. Configurar AWS Application Migration Service (AWS MGN) para capturar cambios en la base de datos MySQL on-premises y enviarlos a Amazon S3",
      "Usar un clúster de AWS Snowball Edge para migrar datos a Amazon S3 y AWS DataSync para capturar cambios en los datos. Crear una clave de cifrado KMS personalizada para el trabajo de AWS Snowball Edge",
      "Configurar una tarea de replicación completa y captura de cambios en datos (CDC) con AWS Database Migration Service (AWS DMS). Agregar un nuevo certificado de Autoridad Certificadora (CA) y crear un endpoint de AWS DMS con SSL",
      "Configurar una tarea de replicación completa con AWS Database Migration Service (AWS DMS). Crear un endpoint de AWS DMS con SSL utilizando AWS Network Firewall"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nConfigurar una tarea de replicación completa y captura de cambios en datos (CDC) con AWS Database Migration Service (AWS DMS). Agregar un nuevo certificado de Autoridad Certificadora (CA) y crear un endpoint de AWS DMS con SSL - AWS Database Migration Service (DMS) permite replicar datos de MySQL en Amazon S3 con una estrategia de replicación completa y captura de cambios en datos (CDC). Utilizar CDC garantiza que los cambios recientes en la base de datos on-premises se repliquen continuamente en Amazon S3. Además, habilitar SSL y agregar un certificado de Autoridad Certificadora (CA) mejora la seguridad de la conexión con el endpoint de AWS DMS.\n\nOpciones incorrectas:\n\nConfigurar una tarea de replicación completa con AWS Database Migration Service (AWS DMS). Crear un endpoint de AWS DMS con SSL utilizando AWS Network Firewall - Un trabajo de replicación completa por sí solo no capturará cambios en la base de datos después de la migración inicial. AWS Network Firewall tampoco es necesario para la configuración SSL de AWS DMS.\n\nUsar AWS Schema Conversion Tool (AWS SCT) para convertir los datos de MySQL a CSV. Configurar AWS Application Migration Service (AWS MGN) para capturar cambios en la base de datos MySQL on-premises y enviarlos a Amazon S3 - AWS Schema Conversion Tool (SCT) solo se usa para convertir bases de datos a formatos compatibles con AWS y no para la replicación de cambios en datos. AWS Application Migration Service (AWS MGN) está diseñado para migraciones lift-and-shift de servidores, no para bases de datos.\n\nUsar un clúster de AWS Snowball Edge para migrar datos a Amazon S3 y AWS DataSync para capturar cambios en los datos. Crear una clave de cifrado KMS personalizada para el trabajo de AWS Snowball Edge - AWS Snowball Edge es más adecuado para migraciones de grandes volúmenes de datos, pero no para replicación continua de datos. AWS DataSync requiere pasos adicionales que AWS DMS puede simplificar.\n\nReferencias:\n\nhttps://aws.amazon.com/blogs/big-data/loading-ongoing-data-lake-changes-with-aws-dms-and-aws-glue/\n\nhttps://docs.aws.amazon.com/dms/latest/userguide/Welcome.html\n\nhttps://docs.aws.amazon.com/dms/latest/userguide/CHAP_Security.html#CHAP_Security.SSL.Limitations"
  },
  {
    "q": "Un banco comercial tiene una aplicación de trading de divisas. Crearon un grupo de Auto Scaling de instancias EC2 que permite al banco gestionar el tráfico actual y lograr eficiencia en costos. Quieren que el grupo de Auto Scaling se comporte de tal manera que siga un conjunto predefinido de parámetros antes de reducir el número de instancias EC2. Esto protege el sistema de desaceleraciones no deseadas o indisponibilidad.\n¿Cuáles de las siguientes afirmaciones son verdaderas con respecto al período de cooldown? (Selecciona DOS)",
    "o": [
      "Su valor predeterminado es de 300 segundos",
      "Garantiza que el grupo de Auto Scaling no lance ni termine instancias EC2 adicionales antes de que la actividad de escalado anterior surta efecto",
      "Garantiza que el grupo de Auto Scaling lance o termine instancias EC2 adicionales sin ningún tiempo de inactividad",
      "Su valor predeterminado es de 600 segundos",
      "Garantiza que antes de que el grupo de Auto Scaling escale hacia afuera, las instancias EC2 tengan tiempo suficiente para enfriarse"
    ],
    "a": [
      0,
      1
    ],
    "e": "Correcto:\n\nSu valor predeterminado es de 300 segundos - El valor predeterminado del período de cooldown en Auto Scaling es de 300 segundos. Este tiempo puede configurarse para adaptarse a los requisitos de la aplicación.\n\nGarantiza que el grupo de Auto Scaling no lance ni termine instancias EC2 adicionales antes de que la actividad de escalado anterior surta efecto - El período de cooldown en Auto Scaling garantiza que el grupo no lance ni termine instancias adicionales antes de que la actividad de escalado previa surta efecto. Esto previene un comportamiento de escalado ineficiente y ayuda a evitar la sobreasignación o terminación prematura de instancias.\n\n\n\nOpciones incorrectas:\n\nGarantiza que antes de que el grupo de Auto Scaling escale hacia afuera, las instancias EC2 tengan tiempo suficiente para enfriarse - El período de cooldown no está diseñado para permitir que las instancias 'se enfríen' antes de escalar hacia afuera. Su propósito principal es evitar que múltiples eventos de escalado ocurran demasiado rápido y desestabilicen el sistema.\n\nGarantiza que el grupo de Auto Scaling lance o termine instancias EC2 adicionales sin ningún tiempo de inactividad - El grupo de Auto Scaling no garantiza que las instancias sean lanzadas o terminadas sin tiempo de inactividad. De hecho, el período de cooldown evita que las instancias sean lanzadas o terminadas de manera inmediata después de una actividad de escalado.\n\nSu valor predeterminado es de 600 segundos - El valor predeterminado del período de cooldown no es 600 segundos; el valor correcto es 300 segundos.\n\nReferencias:\n\nhttp://docs.aws.amazon.com/autoscaling/latest/userguide/as-instance-termination.html"
  },
  {
    "q": "Una empresa ejecuta una aplicación de dashboard en una instancia Spot de Amazon EC2 dentro de una subred privada. El dashboard es accesible a través de un nombre de dominio que apunta a la dirección IPv4 privada de la interfaz de red principal de la instancia. Un arquitecto de soluciones debe aumentar la disponibilidad de la red permitiendo que el flujo de tráfico se reanude en otra instancia si la instancia principal se termina.\n¿Qué solución cumple con estos requisitos?",
    "o": [
      "Usar AWS Network Firewall para desacoplar la interfaz de red elástica principal de la instancia y moverla a una nueva instancia en caso de falla",
      "Configurar AWS Transfer para FTPS en modo Implicit FTPS para deshabilitar automáticamente las verificaciones de source/destination en la interfaz de red elástica primaria de la instancia y reasignarla a otra instancia",
      "Crear una interfaz de red elástica secundaria y apuntar su dirección IPv4 privada al nombre de dominio de la aplicación. Adjuntar la nueva interfaz de red a la instancia primaria. Si la instancia falla, mover la interfaz de red secundaria a otra instancia",
      "Adjuntar una Elastic IP a la interfaz de red principal de la instancia y apuntar su dirección IP al nombre de dominio de la aplicación. Mover automáticamente la Elastic IP a una instancia secundaria si la instancia principal deja de estar disponible utilizando AWS Transit Gateway"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nCrear una interfaz de red elástica secundaria y apuntar su dirección IPv4 privada al nombre de dominio de la aplicación. Adjuntar la nueva interfaz de red a la instancia primaria. Si la instancia falla, mover la interfaz de red secundaria a otra instancia - Una interfaz de red elástica (ENI) secundaria permite redirigir automáticamente el tráfico a una instancia secundaria en caso de falla. La interfaz de red mantiene la dirección IPv4 privada, las direcciones Elastic IP y la dirección MAC, lo que permite una rápida conmutación por error sin necesidad de cambiar la tabla de enrutamiento ni modificar los registros DNS.\n\n\n\nOpciones incorrectas:\n\nAdjuntar una Elastic IP a la interfaz de red principal de la instancia y apuntar su dirección IP al nombre de dominio de la aplicación. Mover automáticamente la Elastic IP a una instancia secundaria si la instancia principal deja de estar disponible utilizando AWS Transit Gateway - Las Elastic IPs no son necesarias en este caso, ya que la aplicación está en una subred privada y usa direcciones IPv4 privadas. Además, AWS Transit Gateway no puede mover automáticamente una Elastic IP entre instancias EC2, ya que su propósito es conectar VPCs y redes on-premises.\n\nUsar AWS Network Firewall para desacoplar la interfaz de red elástica principal de la instancia y moverla a una nueva instancia en caso de falla - AWS Network Firewall no es una herramienta para administrar interfaces de red elásticas ni para moverlas entre instancias. Se utiliza principalmente para filtrar tráfico perimetral en una VPC, pero no puede desacoplar ni reasignar una ENI.\n\nConfigurar AWS Transfer para FTPS en modo Implicit FTPS para deshabilitar automáticamente las verificaciones de source/destination en la interfaz de red elástica primaria de la instancia y reasignarla a otra instancia - AWS Transfer for FTPS es un servicio para la transferencia de archivos segura, y no tiene relación con la reasignación de interfaces de red elásticas. Además, la desactivación de source/destination checks solo se aplica a configuraciones de gateway en EC2, pero no permite mover una interfaz de red a otra instancia.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/scenarios-eni.html\n\nhttps://aws.amazon.com/aws-transfer-family/faqs/"
  },
  {
    "q": "Una aplicación se ejecuta en instancias de Amazon EC2 en una subred privada. Las instancias de EC2 procesan datos que se almacenan en un bucket de Amazon S3. Los datos son altamente confidenciales y se requiere una conexión privada y segura entre las instancias de EC2 y el bucket de S3.\n¿Qué solución cumple estos requisitos?",
    "o": [
      "Configurar encriptación para el bucket de S3 usando una clave de AWS KMS",
      "Configurar un certificado SSL/TLS personalizado en el bucket de S3",
      "Configurar una política IAM para otorgar acceso de lectura-escritura al bucket de S3",
      "Configurar políticas de bucket de S3 para permitir acceso desde un endpoint de VPC"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nConfigurar políticas de bucket de S3 para permitir acceso desde un endpoint de VPC - Para garantizar acceso privado y seguro desde instancias en subredes privadas hacia Amazon S3, se debe utilizar un Endpoint de VPC de tipo Gateway para S3. Mediante una política de bucket se puede restringir el accesocúnicamente al endpoint, asegurando que ninguna conexión pública pueda acceder al bucket.\n\nComunicación privada sin pasar por Internet\nRestricción estricta mediante políticas de bucket vinculadas al VPC Endpoint\nCumple requisitos de seguridad para datos altamente confidenciales\nOpciones incorrectas:\n\nConfigurar un certificado SSL/TLS personalizado en el bucket de S3 - No es posible cargar un certificado SSL/TLS personalizado en Amazon S3.\n\nConfigurar encriptación para el bucket de S3 usando una clave de AWS KMS - La encriptación KMS protege los datos en reposo, pero no controla cómo se accede ni garantiza conexiones privadas.\n\nConfigurar una política IAM para otorgar acceso de lectura-escritura al bucket de S3 - Las políticas IAM definen permisos, pero no fuerzan rutas de red privadas. Se necesita un VPC Endpoint para lograrlo.\n\nReferencia:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/example-bucket-policies-vpc-endpoint.html"
  },
  {
    "q": "Una empresa tiene una aplicación que envía continuamente documentos cifrados a Amazon S3. La empresa requiere que la configuración de acceso a los datos cumpla con estrictos estándares de cumplimiento. También deben recibir alertas si existe algún riesgo de acceso no autorizado o patrones de acceso sospechosos.\n¿Qué paso se necesita para cumplir con estos requisitos?",
    "o": [
      "Usar Amazon Rekognition para monitorear y reconocer patrones en S3",
      "Usar AWS CloudTrail para monitorear y detectar patrones de acceso en S3",
      "Usar Amazon Inspector para alertar cuando se detecte una violación de seguridad en S3",
      "Usar Amazon GuardDuty para monitorear actividad maliciosa en S3"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nUsar Amazon GuardDuty para monitorear actividad maliciosa en S3 - Amazon GuardDuty puede generar hallazgos basados en actividades sospechosas, como solicitudes provenientes de direcciones IP maliciosas, cambios en políticas de buckets/ACLs para exponer un bucket de S3 al público, o patrones de llamadas a la API sospechosos que intentan descubrir permisos incorrectamente configurados en un bucket. GuardDuty utiliza una combinación de detección de anomalías, aprendizaje automático e inteligencia de amenazas actualizada continuamente para identificar actividades maliciosas en S3.\n\nOpciones incorrectas:\n\nUsar Amazon Rekognition para monitorear y reconocer patrones en S3 - Amazon Rekognition no es una herramienta de seguridad para S3. Su función principal es identificar objetos, personas, texto, escenas y actividades en imágenes o videos, así como detectar contenido inapropiado.\n\nUsar AWS CloudTrail para monitorear y detectar patrones de acceso en S3 - AWS CloudTrail puede rastrear llamadas a la API dentro de AWS, incluidas aquellas realizadas mediante la Consola de Administración de AWS, AWS SDKs, herramientas de línea de comandos y otros servicios de AWS. Sin embargo, su propósito principal no es monitorear ni detectar patrones de acceso sospechosos en S3, sino proporcionar auditoría operativa, gobernanza y análisis de riesgos.\n\nUsar Amazon Inspector para alertar cuando se detecte una violación de seguridad en S3 - Amazon Inspector es una herramienta automatizada de evaluación de seguridad que ayuda a mejorar la seguridad y el cumplimiento de aplicaciones desplegadas en AWS, pero no se usa para monitorear actividad maliciosa en S3.\n\nReferencias:\n\nhttps://aws.amazon.com/guardduty/\n\nhttps://aws.amazon.com/blogs/aws/new-using-amazon-guardduty-to-protect-your-s3-buckets/"
  },
  {
    "q": "Una empresa planea migrar su conjunto de aplicaciones en contenedores que actualmente se ejecutan on-premises a un servicio de contenedores en AWS. La solución debe ser agnóstica de la nube y utilizar una plataforma de código abierto que pueda administrar automáticamente las cargas de trabajo y los servicios en contenedores. También debe permitir el uso de la misma configuración y herramientas en distintos entornos de producción.\n¿Qué debe hacer el arquitecto de soluciones para realizar una migración adecuada y cumplir con este requisito?",
    "o": [
      "Migrar la aplicación a Amazon Container Registry (ECR) con instancias EC2 como nodos de trabajo",
      "Migrar la aplicación a Amazon Elastic Container Service con tareas de ECS que usen el tipo de lanzamiento Amazon EC2",
      "Migrar la aplicación a Amazon Elastic Container Service con tareas de ECS que usen el tipo de lanzamiento AWS Fargate",
      "Migrar la aplicación a Amazon Elastic Kubernetes Service con nodos de trabajo EKS"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nMigrar la aplicación a Amazon Elastic Kubernetes Service con nodos de trabajo EKS - Amazon Elastic Kubernetes Service (EKS) es la mejor opción en este escenario porque Kubernetes es una plataforma de código abierto y agnóstica de la nube. Esto permite que la empresa utilice la misma configuración y herramientas en diferentes entornos de producción, incluyendo on-premises, otras nubes o AWS. Amazon EKS proporciona un plano de control completamente administrado y escalable para Kubernetes, lo que facilita la administración de cargas de trabajo en contenedores.\n\n\n\nOpciones incorrectas:\n\nMigrar la aplicación a Amazon Container Registry (ECR) con instancias EC2 como nodos de trabajo - Amazon Elastic Container Registry (ECR) es solo un servicio de almacenamiento y administración de imágenes de contenedores, pero no proporciona un entorno de ejecución para la aplicación. No es una solución de orquestación de contenedores.\n\nMigrar la aplicación a Amazon Elastic Container Service con tareas de ECS que usen el tipo de lanzamiento Amazon EC2 - Amazon Elastic Container Service (ECS) con instancias EC2 no es una opción adecuada porque ECS es un servicio propietario de AWS. No es una plataforma de código abierto ni agnóstica de la nube, lo que limitaría la portabilidad de la aplicación si en el futuro la empresa decide migrar a otra nube o entorno on-premises.\n\nMigrar la aplicación a Amazon Elastic Container Service con tareas de ECS que usen el tipo de lanzamiento AWS Fargate - AWS Fargate es una opción sin servidor para la ejecución de contenedores dentro de ECS, pero ECS sigue siendo un servicio propietario de AWS. Como la empresa busca una solución basada en código abierto y agnóstica de la nube, Fargate no es la mejor elección.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/eks/latest/userguide/what-is-eks.html\n\nhttps://aws.amazon.com/eks/faqs/"
  },
  {
    "q": "Una empresa ha desarrollado una aplicación de planificación de comidas que proporciona recomendaciones de menús semanales y rastrea el consumo de alimentos de los usuarios. La aplicación se ejecuta en una instancia EC2 que requiere acceso a varios servicios de AWS para su operación diaria.\n¿Cuál de las siguientes opciones es la mejor manera de permitir que la instancia EC2 acceda al bucket S3 y a otros servicios de AWS?",
    "o": [
      "Almacenar las credenciales de la API en un host bastión",
      "Agregar las credenciales de la API en el Grupo de Seguridad y asignarlo a la instancia EC2",
      "Almacenar las credenciales de la API en la instancia EC2",
      "Crear un rol en IAM y asignarlo a la instancia EC2"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nCrear un rol en IAM y asignarlo a la instancia EC2 - La mejor práctica para manejar credenciales de API es crear un nuevo rol en AWS Identity and Access Management (IAM) y asignarlo a la instancia EC2. Esto permite que la instancia asuma el rol y obtenga credenciales temporales para acceder a los servicios de AWS de manera segura, evitando la necesidad de almacenar credenciales estáticas en la instancia.\n\n\n\nOpciones incorrectas:\n\nAlmacenar las credenciales de la API en un host bastión - Almacenar credenciales de API en un host bastión no es seguro ni recomendable. Un host bastión está diseñado para gestionar accesos administrativos a la infraestructura, no para actuar como un gestor de credenciales.\n\nAgregar las credenciales de la API en el Grupo de Seguridad y asignarlo a la instancia EC2 - Un Grupo de Seguridad se usa para definir reglas de tráfico de red, pero no puede contener ni administrar credenciales de API. Esta opción no es válida para otorgar acceso seguro a los servicios de AWS desde la instancia EC2.\n\nAlmacenar las credenciales de la API en la instancia EC2 - Almacenar credenciales directamente en la instancia EC2 es una mala práctica de seguridad, ya que expone las credenciales a riesgos innecesarios. Las credenciales podrían ser comprometidas si alguien obtiene acceso a la instancia.\n\nReferencias:\n\nhttp://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html"
  },
  {
    "q": "Un arquitecto de soluciones está diseñando una solución de almacenamiento segura, rentable y altamente disponible para los datos de una empresa. Uno de los requisitos es garantizar que la versión anterior de un archivo se preserve y pueda recuperarse si se carga una versión modificada. Además, la empresa debe cumplir con estrictos requisitos normativos que exigen que los datos se mantengan en un estado inmutable durante al menos 3 años antes de ser archivados. Una vez archivados, los datos solo se accederán una vez al año.\n¿Cómo debe el arquitecto de soluciones construir la solución?",
    "o": [
      "Crear un bucket S3 Standard y habilitar S3 Object Lock en modo governance",
      "Crear un bucket S3 Standard con versionado a nivel de objeto habilitado y configurar una regla de ciclo de vida que transfiera los archivos a Amazon S3 Glacier Deep Archive después de 3 años",
      "Crear un bucket S3 One-Zone-IA con versionado a nivel de objeto habilitado y configurar una regla de ciclo de vida que transfiera los archivos a Amazon S3 Glacier Deep Archive después de 3 años",
      "Crear un bucket S3 Standard con S3 Object Lock en modo compliance habilitado y luego configurar una regla de ciclo de vida que transfiera los archivos a Amazon S3 Glacier Deep Archive después de 3 años"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nCrear un bucket S3 Standard con S3 Object Lock en modo compliance habilitado y luego configurar una regla de ciclo de vida que transfiera los archivos a Amazon S3 Glacier Deep Archive después de 3 años - S3 Object Lock en modo compliance impide que los datos sean sobrescritos o eliminados por cualquier usuario, incluyendo el administrador de la cuenta de AWS, durante el período de retención requerido. Esto es esencial para cumplir con normativas estrictas de almacenamiento inmutable.\n\nDespués de 3 años, los datos pueden moverse automáticamente a Amazon S3 Glacier Deep Archive utilizando reglas de ciclo de vida, lo que reduce costos sin comprometer la durabilidad de los datos.\n\n\n\n\n\nOpciones incorrectas:\n\nCrear un bucket S3 Standard con versionado a nivel de objeto habilitado y configurar una regla de ciclo de vida que transfiera los archivos a Amazon S3 Glacier Deep Archive después de 3 años - Habilitar el versionado en un bucket de S3 Standard ayuda a preservar versiones anteriores, pero no impide la modificación o eliminación de datos, lo que lo hace inadecuado para cumplir con requisitos regulatorios estrictos.\n\nCrear un bucket S3 One-Zone-IA con versionado a nivel de objeto habilitado y configurar una regla de ciclo de vida que transfiera los archivos a Amazon S3 Glacier Deep Archive después de 3 años - S3 One-Zone-IA no ofrece la misma durabilidad y disponibilidad que S3 Standard, lo que lo hace inapropiado para almacenar datos críticos que requieren cumplimiento normativo. Además, no incluye S3 Object Lock en modo compliance.\n\nCrear un bucket S3 Standard y habilitar S3 Object Lock en modo governance - S3 Object Lock en modo governance permite que ciertos usuarios con permisos adecuados eliminen el bloqueo, lo que podría no cumplir con requisitos regulatorios estrictos. El modo compliance es necesario para garantizar la inmutabilidad total.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/Versioning.html\n\nhttps://aws.amazon.com/blogs/aws/new-amazon-s3-storage-class-glacier-deep-archive/\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lock.html#object-lock-overview"
  },
  {
    "q": "Una empresa posee una plataforma de videos donde los usuarios suben contenido a Amazon S3. Recientemente, ha habido un incremento en la cantidad de videos con contenido inapropiado. Actualmente, la empresa depende de la moderación manual, pero quiere optimizar el proceso mediante Inteligencia Artificial para identificar y marcar videos para su revisión. Además, por razones de seguridad, cualquier comunicación con los recursos dentro de la VPC de AWS no debe pasar por Internet pública.\n¿Cómo se puede lograr esta tarea con el menor esfuerzo posible?",
    "o": [
      "Entrenar un modelo de clasificación de videos en Amazon SageMaker. Configurar AWS Shield para garantizar que todas las comunicaciones sean seguras dentro de la VPC",
      "Usar Amazon Rekognition Video para detectar contenido inapropiado en los videos almacenados en Amazon S3. Configurar un endpoint de VPC para Amazon Rekognition con las políticas necesarias para evitar que el tráfico pase por Internet pública",
      "Usar Amazon Lookout for Vision para analizar cada video cargado en S3. Implementar AWS Network Firewall para evitar que las solicitudes salientes pasen por Internet pública",
      "Usar Amazon Macie para detectar videos con contenido inadecuado en Amazon S3. Implementar AWS Direct Connect para asegurar que los datos de la aplicación no pasen por Internet pública"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nUsar Amazon Rekognition Video para detectar contenido inapropiado en los videos almacenados en Amazon S3. Configurar un endpoint de VPC para Amazon Rekognition con las políticas necesarias para evitar que el tráfico pase por Internet pública - Amazon Rekognition Video proporciona una API lista para detectar contenido explícito en videos almacenados en S3. Es una solución preentrenada que permite moderar contenido sin necesidad de desarrollar modelos personalizados de Machine Learning. Para evitar que las solicitudes pasen por Internet pública, se debe configurar un endpoint de interfaz VPC para Amazon Rekognition. Esto permite que los recursos dentro de la VPC se comuniquen de manera privada con Rekognition.\n\n\n\nOpciones incorrectas:\n\nUsar Amazon Lookout for Vision para analizar cada video cargado en S3. Implementar AWS Network Firewall para evitar que las solicitudes salientes pasen por Internet pública - Amazon Lookout for Vision se usa para detectar anomalías en imágenes industriales y no está diseñado para analizar videos en busca de contenido inapropiado. Además, AWS Network Firewall protege redes contra amenazas, pero no evita que el tráfico pase por Internet pública de forma automática.\n\nEntrenar un modelo de clasificación de videos en Amazon SageMaker. Configurar AWS Shield para garantizar que todas las comunicaciones sean seguras dentro de la VPC - Amazon SageMaker requiere entrenar un modelo personalizado para la clasificación de videos, lo cual es un proceso costoso y complejo. En cambio, Amazon Rekognition ya ofrece detección de contenido explícito lista para usar. AWS Shield protege contra ataques DDoS, pero no restringe el tráfico dentro de la VPC.\n\nUsar Amazon Macie para detectar videos con contenido inadecuado en Amazon S3. Implementar AWS Direct Connect para asegurar que los datos de la aplicación no pasen por Internet pública - Amazon Macie es una herramienta de detección de datos sensibles en S3, como información personal o confidencial, pero no está diseñada para analizar videos. Además, AWS Direct Connect proporciona conectividad privada a AWS, pero no es necesario para evitar que el tráfico dentro de la VPC pase por Internet pública.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/rekognition/latest/dg/video-content-moderation.html\n\nhttps://docs.aws.amazon.com/rekognition/latest/dg/vpc.html"
  },
  {
    "q": "Una organización utiliza actualmente una solución de respaldo en cinta para almacenar los datos de sus aplicaciones on-premises. Planean utilizar un servicio de almacenamiento en la nube para preservar los datos de respaldo durante hasta 10 años, con acceso ocasional de una o dos veces al año.\n¿Cuál de las siguientes es la opción más rentable para implementar esta solución?",
    "o": [
      "Usar AWS Storage Gateway para respaldar los datos y hacer la transición a Amazon S3 Glacier Deep Archive",
      "Usar Amazon S3 para almacenar los datos de respaldo y agregar una regla de ciclo de vida para hacer la transición de la versión actual a Amazon S3 Glacier",
      "Usar AWS Storage Gateway para respaldar los datos directamente en Amazon S3 Glacier",
      "Solicitar un dispositivo AWS Snowball Edge para importar el respaldo directamente a Amazon S3 Glacier"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nUsar AWS Storage Gateway para respaldar los datos y hacer la transición a Amazon S3 Glacier Deep Archive - AWS Storage Gateway (Tape Gateway) es la mejor opción para reemplazar soluciones de respaldo en cinta físicas con cintas virtuales en AWS sin necesidad de cambiar los flujos de trabajo existentes. Tape Gateway permite la transición automática de los respaldos a Amazon S3 Glacier o Amazon S3 Glacier Deep Archive, lo que reduce significativamente los costos de almacenamiento a largo plazo.\n\n\n\nOpciones incorrectas:\n\nUsar Amazon S3 para almacenar los datos de respaldo y agregar una regla de ciclo de vida para hacer la transición de la versión actual a Amazon S3 Glacier - Aunque almacenar los datos en Amazon S3 y configurar una regla de ciclo de vida para moverlos a Glacier es una opción viable, integrar un sistema de respaldo basado en cintas directamente con S3 es difícil sin usar Storage Gateway.\n\nSolicitar un dispositivo AWS Snowball Edge para importar el respaldo directamente a Amazon S3 Glacier - AWS Snowball Edge no permite la integración directa con S3 Glacier. Además, para optimizar costos, los datos deben almacenarse en S3 Glacier Deep Archive, lo cual Snowball Edge no puede hacer directamente.\n\nUsar AWS Storage Gateway para respaldar los datos directamente en Amazon S3 Glacier - Respaldar los datos directamente en Amazon S3 Glacier es más costoso que utilizar Amazon S3 Glacier Deep Archive. La mejor opción es permitir que AWS Storage Gateway gestione la transición automática de los datos a la clase de almacenamiento más económica.\n\nReferencias:\n\nhttps://aws.amazon.com/storagegateway/faqs/\n\nhttps://aws.amazon.com/s3/storage-classes/"
  },
  {
    "q": "Una empresa de comercio electrónico opera una aplicación web sin servidor que debe interactuar con numerosas tablas de Amazon DynamoDB para cumplir con las solicitudes de usuarios. Es crítico que el rendimiento de la aplicación permanezca consistente y sin afectación mientras interactúa con estas tablas.\n¿Qué método proporciona la manera más eficiente operacionalmente de cumplir estos requisitos?",
    "o": [
      "Amazon S3 con activadores de Lambda",
      "AWS AppSync con múltiples fuentes de datos y resolvers",
      "AWS Glue con un conector de DynamoDB",
      "AWS Lambda con Step Functions"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nAWS AppSync con múltiples fuentes de datos y resolvers - AWS AppSync permite crear APIs GraphQL totalmente gestionadas que pueden acceder simultáneamente a múltiples tablas de DynamoDB mediante resolvers. Es altamente eficiente operacionalmente, escalable y diseñado para acceso en tiempo real, ofreciendo exactamente los datos que la aplicación necesita sin afectar rendimiento.\n\nOpciones incorrectas:\n\nAWS Glue con un conector de DynamoDB - AWS Glue es para ETL y análisis, no para acceso en tiempo real desde una aplicación.\n\nAWS Lambda con Step Functions - Step Functions añade orquestación y complejidad innecesaria, aumentando latencia en consultas simples.\n\nAmazon S3 con activadores de Lambda - S3 + Lambda no tiene relación con consultas en DynamoDB y añadiría pasos innecesarios.\n\nReferencia:\n\nhttps://aws.amazon.com/es/appsync/"
  },
  {
    "q": "Una empresa ejecuta un servicio de medios de transmisión y el contenido se almacena en Amazon S3. El servidor de catálogo de medios extrae contenido actualizado de S3 y puede emitir más de 1 millón de operaciones de lectura por segundo por períodos cortos. La latencia debe mantenerse por debajo de 5ms para estas actualizaciones.\n¿Qué solución proporcionará el mejor rendimiento para las actualizaciones del catálogo de medios?",
    "o": [
      "Actualizar el código de la aplicación para usar un clúster de Amazon DynamoDB Accelerator",
      "Actualizar el código de la aplicación para usar un clúster de Amazon ElastiCache para Redis",
      "Implementar un volumen de Instance store en el servidor de catálogo de medios",
      "Implementar Amazon CloudFront y cachear el contenido en Edge Locations"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nActualizar el código de la aplicación para usar un clúster de Amazon ElastiCache para Redis - Amazon ElastiCache para Redis proporciona almacenamiento en memoria con latencia sub-milisegundo y soporte para altísimas tasas de solicitudes por segundo. Es ideal para reducir la dependencia directa de S3 en escenarios donde se necesitan lecturas extremadamente rápidas y frecuentes, como un catálogo de medios que se actualiza constantemente.\n\nOpciones incorrectas:\n\nImplementar un volumen de Instance store en el servidor de catálogo de medios - El instance store mejora I/O local, pero no mejora el rendimiento al leer datos desde S3.\n\nActualizar el código de la aplicación para usar un clúster de Amazon DynamoDB Accelerator - DAX acelera DynamoDB, no S3; no aplica para este caso.\n\nImplementar Amazon CloudFront y cachear el contenido en Edge Locations - CloudFront acelera distribución hacia usuarios finales, no la comunicación interna entre S3 y un servidor de catálogo.\n\nReferencia:\n\nhttps://aws.amazon.com/blogs/storage/turbocharge-amazon-s3-with-amazon-elasticache-for-redis/"
  },
  {
    "q": "Una empresa de streaming de música está desarrollando una aplicación web que necesita un almacenamiento de clave-valor para guardar la información de los artistas y sus álbumes.\nCada registro debe incluir el ID del artista, nombre del álbum, año de lanzamiento, géneros musicales y un listado de canciones.\nEl frontend de la aplicación se ejecutará en un clúster de Amazon ECS con el tipo de lanzamiento AWS Fargate.\n¿Cuál de las siguientes opciones es la mejor configuración para la capa de base de datos?",
    "o": [
      "Lanzar una tabla en Amazon DynamoDB",
      "Utilizar Amazon DocumentDB con MongoDB para almacenar los datos",
      "Configurar Amazon Aurora Serverless con replicación multi-región",
      "Implementar Amazon RDS con PostgreSQL y habilitar particionamiento en las tablas"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nLanzar una tabla en Amazon DynamoDB - Amazon DynamoDB es una base de datos NoSQL administrada que admite almacenamiento de clave-valor y documentos. Es altamente escalable y ofrece baja latencia de milisegundos, lo que la hace ideal para almacenar y consultar modelos de datos con claves compuestas, como los registros de artistas y álbumes descritos en este caso. DynamoDB permite consultas rápidas con claves compuestas (partition key + sort key). Proporciona escalabilidad automática y soporte para almacenamiento distribuido sin preocuparse por la administración de infraestructura. Es ideal para cargas de trabajo de alta demanda con accesos rápidos y patrones de datos no estructurados.\n\n\n\nOpciones incorrectas:\n\nImplementar Amazon RDS con PostgreSQL y habilitar particionamiento en las tablas - Amazon RDS con PostgreSQL es una base de datos relacional, que no es ideal para un modelo de datos de clave-valor. El esquema flexible y la escalabilidad de DynamoDB lo hacen una mejor opción.\n\nUtilizar Amazon DocumentDB con MongoDB para almacenar los datos - Amazon DocumentDB está diseñado para almacenar documentos en formato JSON y ejecutar consultas compatibles con MongoDB, pero no es la mejor opción para consultas eficientes con claves compuestas ni para almacenamiento de clave-valor a gran escala.\n\nConfigurar Amazon Aurora Serverless con replicación multi-región - Aurora Serverless es una base de datos relacional optimizada para cargas de trabajo transaccionales. No es adecuada para una aplicación que requiere una estructura flexible de almacenamiento de clave-valor.\n\nReferencias:\n\nhttps://aws.amazon.com/dynamodb/\n\nhttps://aws.amazon.com/nosql/key-value/"
  },
  {
    "q": "Una empresa tiene múltiples VPCs con IPv6 habilitado para su conjunto de aplicaciones web. El arquitecto de soluciones intentó desplegar una nueva instancia EC2, pero encontró un error que indicaba que no había direcciones IPv4 disponibles en la subred. La VPC tiene una combinación de bloques CIDR IPv4 e IPv6, pero los bloques CIDR de IPv4 están cerca de agotarse. El arquitecto necesita una solución que resuelva este problema y permita escalabilidad futura.\n¿Cómo debería el arquitecto de soluciones resolver este problema?",
    "o": [
      "Deshabilitar el soporte IPv4 en la VPC y usar únicamente las direcciones IPv6 disponibles",
      "Configurar una nueva subred IPv4 con un rango CIDR más grande. Asociar la nueva subred con la VPC y luego lanzar la instancia",
      "Asegurar que la VPC tenga bloques CIDR de IPv6. Eliminar cualquier bloque CIDR de IPv4 asociado con la VPC",
      "Configurar una nueva subred solo con IPv6 con un rango CIDR grande. Asociar la nueva subred con la VPC y luego lanzar la instancia"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nConfigurar una nueva subred IPv4 con un rango CIDR más grande. Asociar la nueva subred con la VPC y luego lanzar la instancia - La mejor solución es crear una nueva subred con un rango CIDR IPv4 más grande y asociarla con la VPC. Esto permitirá el despliegue de nuevas instancias EC2 sin problemas de agotamiento de direcciones IPv4 y asegurará la escalabilidad futura de la infraestructura.\n\n\n\nOpciones incorrectas:\n\nAsegurar que la VPC tenga bloques CIDR de IPv6. Eliminar cualquier bloque CIDR de IPv4 asociado con la VPC - No se puede eliminar el soporte de IPv4 en una VPC, ya que IPv4 es el sistema de direccionamiento predeterminado en AWS. La VPC solo puede operar en modo de doble pila (dual-stack), lo que permite la comunicación con IPv4, IPv6 o ambos, pero no exclusivamente con IPv6.\n\nConfigurar una nueva subred solo con IPv6 con un rango CIDR grande. Asociar la nueva subred con la VPC y luego lanzar la instancia - Aunque se puede crear una subred exclusivamente con IPv6, esta función solo es compatible con instancias EC2 de tipo Nitro. Además, el escenario no menciona que se esté utilizando un tipo de instancia Nitro, por lo que esta opción no es aplicable en general.\n\nDeshabilitar el soporte IPv4 en la VPC y usar únicamente las direcciones IPv6 disponibles - No es posible deshabilitar el soporte de IPv4 en una VPC, ya que IPv4 es el esquema de direccionamiento predeterminado en AWS. Aunque las direcciones IPv6 pueden estar habilitadas, las instancias EC2 por defecto usan IPv4 para su direccionamiento IP principal.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/vpc/latest/userguide/vpc-migrate-ipv6.html\n\nhttps://docs.aws.amazon.com/vpc/latest/userguide/vpc-ip-addressing.html\n\nhttps://aws.amazon.com/vpc/faqs/"
  },
  {
    "q": "Una aplicación web de comercio electrónico necesita una base de datos clave-valor altamente escalable. ¿Qué servicio de base de datos de AWS debe ser usado?",
    "o": [
      "Amazon DynamoDB",
      "Amazon RDS",
      "Amazon RedShift",
      "Amazon ElastiCache"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nAmazon DynamoDB - Amazon DynamoDB es una base de datos NoSQL completamente gestionada que ofrece un modelo clave-valor altamente escalable, con rendimiento rápido y predecible. Es la opción óptima para aplicaciones que requieren escalabilidad masiva y baja latencia.\n\nOpciones incorrectas:\n\nAmazon ElastiCache - ElastiCache es un servicio de caché en memoria, no una base de datos clave-valor persistente.\n\nAmazon RedShift - RedShift es un data warehouse para cargas analíticas (OLAP), no para operaciones transaccionales clave-valor.\n\nAmazon RDS - RDS es un motor relacional (SQL), no un sistema NoSQL clave-valor.\n\nReferencia:\n\nhttps://aws.amazon.com/nosql/key-value/"
  },
  {
    "q": "Una startup tiene una instancia EC2 que aloja una aplicación web. Se espera que el volumen de usuarios crezca en los próximos meses, por lo que es necesario agregar más elasticidad y escalabilidad a la arquitectura de AWS para manejar la demanda.\n¿Cuáles de las siguientes opciones pueden satisfacer este requisito en el escenario dado? (Selecciona DOS)",
    "o": [
      "Configurar dos instancias EC2 y usar Route 53 para enrutar el tráfico con una política de enrutamiento ponderado (Weighted Routing Policy)",
      "Configurar dos instancias EC2 y colocarlas detrás de un Elastic Load Balancer (ELB)",
      "Configurar AWS WAF detrás de la instancia EC2",
      "Configurar una caché S3 frente a la instancia EC2",
      "Configurar dos instancias EC2 utilizando Launch Templates e integradas con AWS Glue"
    ],
    "a": [
      0,
      1
    ],
    "e": "Correcto:\n\nConfigurar dos instancias EC2 y colocarlas detrás de un Elastic Load Balancer (ELB) - Un Elastic Load Balancer (ELB) distribuye automáticamente el tráfico entre múltiples instancias EC2, lo que mejora la disponibilidad, escalabilidad y tolerancia a fallos de la aplicación web.\n\nConfigurar dos instancias EC2 y usar Route 53 para enrutar el tráfico con una política de enrutamiento ponderado (Weighted Routing Policy) - Amazon Route 53 con Weighted Routing Policy permite distribuir el tráfico entre dos o más instancias EC2 en diferentes regiones o zonas de disponibilidad, proporcionando una solución escalable y de alta disponibilidad.\n\n\n\nOpciones incorrectas:\n\nConfigurar una caché S3 frente a la instancia EC2 - Amazon S3 no es una solución de caching para instancias EC2. Aunque S3 se puede utilizar para servir contenido estático con CloudFront, no ayuda a escalar una instancia EC2 que ejecuta una aplicación web dinámica.\n\nConfigurar AWS WAF detrás de la instancia EC2 - AWS WAF es un firewall para proteger aplicaciones web contra amenazas comunes como inyecciones SQL o ataques XSS, pero no proporciona elasticidad ni escalabilidad a la arquitectura.\n\nConfigurar dos instancias EC2 utilizando Launch Templates e integradas con AWS Glue - AWS Glue es un servicio de procesamiento ETL (Extract, Transform, Load) para análisis de datos, no está relacionado con la escalabilidad de instancias EC2 ni con la administración del tráfico.\n\nReferencias:\n\nhttps://aws.amazon.com/elasticloadbalancing\n\nhttp://docs.aws.amazon.com/Route53/latest/DeveloperGuide/Welcome.html"
  },
  {
    "q": "Una aplicación heredada está siendo migrada a AWS. La aplicación tiene una gran cantidad de datos que rara vez se acceden. Cuando se accede a los archivos, se recuperan secuencialmente. La aplicación será migrada a una instancia de Amazon EC2.\n¿Cuál es el tipo de volumen EBS MENOS costoso para este caso de uso?",
    "o": [
      "HDD Optimizado para Rendimiento (st1)",
      "HDD Frío (sc1)",
      "SSD de IOPS Provisionadas (io1)",
      "SSD de Propósito General (gp2)"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nHDD Frío (sc1) - Los volúmenes EBS HDD Frío (sc1) son la opción más económica de todos los tipos de EBS y están diseñados específicamente para datos accedidos infrecuentemente y patrones de acceso secuencial. Son ideales para casos de uso de archivo de bajo costo.\n\nOpciones incorrectas:\n\nSSD de IOPS Provisionadas (io1) - io1 es la opción más costosa y está diseñada para cargas de trabajo con altos requisitos de IOPS.\n\nHDD Optimizado para Rendimiento (st1) - st1 es HDD optimizado para rendimiento, pero más costoso que sc1 y usado para datos accedidos con más frecuencia.\n\nSSD de Propósito General (gp2) - gp2 es SSD de uso general, más costoso que sc1 y no necesario para este patrón de acceso.\n\nReferencia:\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html"
  },
  {
    "q": "Una empresa necesita mover un almacén de datos de 80 TB a la nube. Con el ancho de banda actual, la transferencia tardaría 2 meses en completarse.\n¿Cuál es el servicio más rentable que permitiría cargar los datos en AWS de manera rápida?",
    "o": [
      "Amazon S3 Multipart Upload",
      "AWS Snowball Edge",
      "AWS Direct Connect",
      "AWS Snowmobile"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nAWS Snowball Edge - AWS Snowball Edge es un dispositivo de transferencia de datos que permite mover grandes volúmenes de datos a AWS más rápido que utilizando Internet. Es una opción rentable para cargas de trabajo que requieren mover terabytes de datos, ya que el dispositivo es enviado físicamente a la empresa, donde los datos pueden ser cargados y luego enviados de vuelta a AWS para su almacenamiento en la nube.\n\nOpciones incorrectas:\n\nAWS Direct Connect - AWS Direct Connect es una conexión de red dedicada entre las instalaciones locales y AWS. No es una solución adecuada para la transferencia única de grandes volúmenes de datos, ya que su implementación y uso están más orientados a conexiones de red de baja latencia y uso continuo en el tiempo.\n\nAmazon S3 Multipart Upload - Amazon S3 Multipart Upload permite dividir archivos grandes en varias partes para facilitar su carga en Amazon S3. Sin embargo, aún se dependería del ancho de banda disponible en la empresa, lo que haría que la transferencia siga tardando demasiado.\n\nAWS Snowmobile - AWS Snowmobile es un servicio diseñado para mover exabytes de datos utilizando un contenedor de 45 pies transportado por camión. Es una solución excesiva para la necesidad de transferir 80 TB, ya que Snowmobile está pensado para volúmenes de datos mucho mayores.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/snowball/latest/ug/whatisnowball.html\n\nhttps://docs.aws.amazon.com/snowball/latest/ug/device-differences.html"
  },
  {
    "q": "Una organización almacena y gestiona registros financieros de varias empresas en su centro de datos on-premises, el cual está casi sin espacio disponible. La administración ha decidido migrar todos los registros existentes a un servicio de almacenamiento en la nube. Todos los registros financieros futuros también se almacenarán en la nube. Para mayor seguridad, los registros deben estar protegidos contra eliminaciones o sobrescrituras.\n¿Cuál de las siguientes opciones debes implementar para cumplir con este requisito?",
    "o": [
      "Usar AWS Storage Gateway para establecer un almacenamiento híbrido en la nube. Almacenar todos los datos en Amazon EBS y habilitar object lock",
      "Usar AWS DataSync para mover los datos. Almacenar todos los datos en Amazon S3 y habilitar object lock",
      "Usar AWS Storage Gateway para establecer un almacenamiento híbrido en la nube. Almacenar todos los datos en Amazon S3 y habilitar object lock",
      "Usar AWS DataSync para mover los datos. Almacenar todos los datos en Amazon EFS y habilitar object lock"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nUsar AWS DataSync para mover los datos. Almacenar todos los datos en Amazon S3 y habilitar object lock - AWS DataSync permite migrar grandes volúmenes de datos desde un entorno on-premises a AWS sin necesidad de desarrollar soluciones personalizadas. Amazon S3 es la mejor opción de almacenamiento en la nube, ya que admite S3 Object Lock, una funcionalidad que previene que los datos sean eliminados o sobrescritos, garantizando la seguridad y conformidad de los registros financieros.\n\n\n\nOpciones incorrectas:\n\nUsar AWS Storage Gateway para establecer un almacenamiento híbrido en la nube. Almacenar todos los datos en Amazon S3 y habilitar object lock - AWS Storage Gateway es útil cuando se necesita mantener una integración con almacenamiento on-premises. Sin embargo, en este caso, se requiere una migración completa a la nube, por lo que AWS DataSync es la mejor opción.\n\nUsar AWS DataSync para mover los datos. Almacenar todos los datos en Amazon EFS y habilitar object lock - Amazon EFS no admite Object Lock. Object Lock es una característica específica de Amazon S3.\n\nUsar AWS Storage Gateway para establecer un almacenamiento híbrido en la nube. Almacenar todos los datos en Amazon EBS y habilitar object lock - Amazon EBS tampoco admite Object Lock. Además, Amazon EBS es un almacenamiento de bloque, que no es ideal para almacenar grandes volúmenes de registros financieros a largo plazo.\n\nReferencias:\n\nhttps://aws.amazon.com/datasync/faqs/\n\nhttps://docs.aws.amazon.com/datasync/latest/userguide/what-is-datasync.html\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/object-lock.html"
  },
  {
    "q": "Una empresa de comercio electrónico tiene su plataforma alojada en AWS en múltiples regiones, con un grupo de Auto Scaling de instancias EC2 detrás de un Application Load Balancer en cada región.\nLos usuarios acceden a la plataforma desde distintas partes del mundo, pero debido a regulaciones de cumplimiento:\nLos usuarios de Canadá deben conectarse a los servidores en la región ca-central-1.\nLos usuarios de Brasil deben conectarse a los servidores en la región sa-east-1.\n¿Cuál es la mejor solución para cumplir con este requisito?",
    "o": [
      "Configurar Route 53 con una política de enrutamiento basado en latencia (Latency-Based Routing)",
      "Configurar una distribución de CloudFront con restricciones geográficas (geo-restrictions)",
      "Configurar Route 53 con una política de enrutamiento geolocalizado (Geolocation Routing)",
      "Usar Application Load Balancers en cada región para dirigir el tráfico de los usuarios según su ubicación"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nConfigurar Route 53 con una política de enrutamiento geolocalizado (Geolocation Routing) - Route 53 con enrutamiento geolocalizado permite dirigir el tráfico a la región correcta en función de la ubicación geográfica del usuario. Esto se basa en la dirección IP de la consulta DNS, asegurando que los usuarios de Canadá se dirijan a ca-central-1 y los usuarios de Brasil a sa-east-1.\n\n\n\nEnrutamiento geolocalizado (Geolocation Routing) en Route 53 es útil cuando se necesita cumplir con requisitos regulatorios o restricciones de datos específicas para diferentes regiones.\nSe pueden definir reglas adicionales para manejar usuarios en ubicaciones no específicas, asignándolos a una región predeterminada.\nEsta configuración permite un control preciso sobre la distribución del tráfico global.\nOpciones incorrectas:\n\nUsar Application Load Balancers en cada región para dirigir el tráfico de los usuarios según su ubicación - Un Application Load Balancer solo equilibra la carga dentro de una misma región y no tiene la capacidad de enrutar tráfico entre múltiples regiones de AWS.\n\nConfigurar una distribución de CloudFront con restricciones geográficas (geo-restrictions) - La restricción geográfica en CloudFront está diseñada para bloquear el acceso de usuarios en ciertas ubicaciones, pero no para dirigir tráfico a regiones específicas.\n\nConfigurar Route 53 con una política de enrutamiento basado en latencia (Latency-Based Routing) - El enrutamiento basado en latencia en Route 53 dirige a los usuarios a la región con menor latencia en ese momento, lo que no garantiza que los usuarios de Canadá y Brasil sean dirigidos exclusivamente a las regiones requeridas.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/geolocation-routing-policy"
  },
  {
    "q": "Una empresa ejecuta una aplicación web multi-tier en una nube privada virtual (VPC) que no está conectada a su red corporativa. Se están conectando a la VPC a través de Internet para administrar la flota de instancias Amazon EC2 que se ejecutan en subredes públicas y privadas. El arquitecto de soluciones ha agregado un bastion host con acceso Microsoft Remote Desktop Protocol (RDP) a los grupos de seguridad de las instancias de la aplicación, pero la empresa quiere restringir aún más el acceso administrativo a todas las instancias en la VPC.\n¿Cuál de las siguientes opciones de implementación de bastion host cumplirá con este requisito?",
    "o": [
      "Implementar un bastion host con Windows en la subred pública con una dirección Elastic IP y permitir el acceso SSH al bastion desde cualquier lugar",
      "Implementar un bastion host con Windows en la subred privada con una dirección Elastic IP y restringir el acceso RDP al bastion solo desde las direcciones IP corporativas",
      "Implementar un bastion host con Windows en la red corporativa con acceso RDP a todas las instancias EC2 en la VPC",
      "Implementar un bastion host con Windows en la subred pública con una dirección Elastic IP y permitir el acceso RDP solo desde las direcciones IP corporativas"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nImplementar un bastion host con Windows en la subred pública con una dirección Elastic IP y permitir el acceso RDP solo desde las direcciones IP corporativas - Un bastion host debe implementarse en una subred pública con una dirección Elastic IP para permitir la conexión desde la red corporativa a través de Internet. Para mejorar la seguridad, el acceso RDP debe estar restringido únicamente a las direcciones IP corporativas mediante reglas en el grupo de seguridad del bastion host.\n\n\n\nOpciones incorrectas:\n\nImplementar un bastion host con Windows en la subred pública con una dirección Elastic IP y permitir el acceso SSH al bastion desde cualquier lugar - Permitir acceso SSH desde cualquier lugar no es una buena práctica de seguridad. Además, como el bastion host es un sistema Windows, el acceso adecuado es mediante RDP, no SSH (que es más común en sistemas Linux).\n\nImplementar un bastion host con Windows en la subred privada con una dirección Elastic IP y restringir el acceso RDP al bastion solo desde las direcciones IP corporativas - Un bastion host debe ubicarse en una subred pública, no en una privada, ya que necesita un Elastic IP para permitir la conexión desde redes externas.\n\nImplementar un bastion host con Windows en la red corporativa con acceso RDP a todas las instancias EC2 en la VPC - No se implementa un bastion host en la red corporativa. Debe estar en la subred pública dentro de la VPC para proporcionar acceso seguro a las instancias EC2.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/quickstart/latest/linux-bastion/architecture.html"
  },
  {
    "q": "Por razones de privacidad de datos, una empresa del sector salud ha sido requerida para cumplir con la Ley de Portabilidad y Responsabilidad de Seguros de Salud (HIPAA). La empresa almacena todas sus copias de seguridad en un bucket de Amazon S3. Se requiere que los datos almacenados en el bucket de S3 estén cifrados.\n¿Cuáles son las dos mejores opciones para lograr esto? (Selecciona DOS)",
    "o": [
      "Habilitar el cifrado del lado del servidor (Server-Side Encryption) en un bucket de S3 para usar cifrado AES-256",
      "Habilitar el cifrado del lado del servidor en un bucket de S3 para usar cifrado AES-128",
      "Almacenar los datos en snapshots de EBS cifrados",
      "Almacenar los datos en volúmenes EBS con cifrado habilitado en lugar de usar Amazon S3",
      "Antes de enviar los datos a Amazon S3 a través de HTTPS, cifrar los datos localmente primero utilizando tus propias claves de cifrado"
    ],
    "a": [
      0,
      4
    ],
    "e": "Correcto:\n\nAntes de enviar los datos a Amazon S3 a través de HTTPS, cifrar los datos localmente primero utilizando tus propias claves de cifrado - El cifrado del lado del cliente (Client-Side Encryption) consiste en cifrar los datos antes de enviarlos a Amazon S3. Esto permite a la empresa controlar completamente las claves de cifrado y asegurarse de que los datos estén protegidos antes de ser almacenados en la nube.\n\nHabilitar el cifrado del lado del servidor (Server-Side Encryption) en un bucket de S3 para usar cifrado AES-256 - Amazon S3 admite el cifrado del lado del servidor (SSE), que cifra los datos cuando se almacenan en S3 y los descifra cuando se accede a ellos. SSE-S3 utiliza el cifrado AES-256, que es el estándar de cifrado recomendado para cumplir con requisitos de seguridad como HIPAA.\n\n\n\nOpciones incorrectas:\n\nHabilitar el cifrado del lado del servidor en un bucket de S3 para usar cifrado AES-128 - Amazon S3 no proporciona cifrado AES-128. Solo admite AES-256, por lo que esta opción no es válida.\n\nAlmacenar los datos en volúmenes EBS con cifrado habilitado en lugar de usar Amazon S3 - Aunque Amazon EBS permite cifrado en volúmenes, este escenario requiere almacenamiento en Amazon S3. El uso de EBS no cumple con el requisito de almacenamiento en S3.\n\nAlmacenar los datos en snapshots de EBS cifrados - Las snapshots de EBS cifradas son útiles para copias de seguridad de volúmenes de EBS, pero la pregunta especifica que los datos deben almacenarse en un bucket de S3. Por lo tanto, esta opción no es aplicable.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/UsingEncryption.html\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/UsingClientSideEncryption.html"
  },
  {
    "q": "Una empresa de comercio electrónico recibe diariamente grandes volúmenes de archivos de datos de ventas en formato .csv de sus socios externos.\nEstos archivos de datos se almacenan en un bucket de S3 para su procesamiento y generación de informes. La empresa quiere implementar una solución automatizada para convertir estos archivos .csv al formato Apache Parquet y almacenar el resultado en un nuevo bucket de S3 llamado blockstellart-data-transformed. El objetivo de esta nueva solución es mejorar el procesamiento de datos y las cargas de trabajo analíticas de la empresa, manteniendo bajos costos operativos.\n¿Cuál de las siguientes opciones debe implementarse para cumplir con estos requisitos con el MENOR esfuerzo operativo?",
    "o": [
      "Usar notificaciones de eventos de Amazon S3 para activar una función AWS Lambda que convierta archivos .csv a Apache Parquet utilizando Apache Spark en un clúster de Amazon EMR. Almacenar los archivos procesados en el bucket blockstellart-data-transformed",
      "Utilizar una definición de trabajo en AWS Batch con sintaxis Bash para convertir los archivos .csv al formato Apache Parquet. Configurar la ejecución automática del trabajo cuando un nuevo archivo .csv sea cargado en el bucket de origen",
      "Usar AWS Glue Crawler para descubrir automáticamente los archivos de datos sin procesar en S3 y analizar su esquema. Crear un trabajo ETL programado en AWS Glue que convierta los archivos .csv al formato Apache Parquet y almacene los archivos procesados en el bucket blockstellart-data-transformed",
      "Integrar Amazon EMR File System (EMRFS) con el bucket de origen en S3 para detectar automáticamente los nuevos archivos de datos. Usar Amazon EMR Serverless con Apache Spark para convertir los archivos .csv al formato Apache Parquet y almacenar el resultado en el bucket blockstellart-data-transformed"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nUsar AWS Glue Crawler para descubrir automáticamente los archivos de datos sin procesar en S3 y analizar su esquema. Crear un trabajo ETL programado en AWS Glue que convierta los archivos .csv al formato Apache Parquet y almacene los archivos procesados en el bucket blockstellart-data-transformed - AWS Glue es un servicio ETL completamente administrado que facilita la clasificación, limpieza y movimiento de datos entre distintas fuentes y formatos. AWS Glue Crawler analiza automáticamente los archivos .csv en S3, detecta su esquema y genera un catálogo de datos. Luego, un trabajo ETL programado en AWS Glue puede convertir los archivos a Apache Parquet y almacenarlos en un nuevo bucket de S3 con un esfuerzo operativo mínimo.\n\n\n\nOpciones incorrectas:\n\nIntegrar Amazon EMR File System (EMRFS) con el bucket de origen en S3 para detectar automáticamente los nuevos archivos de datos. Usar Amazon EMR Serverless con Apache Spark para convertir los archivos .csv al formato Apache Parquet y almacenar el resultado en el bucket blockstellart-data-transformed - Amazon EMR Serverless puede ser una opción viable, pero configurar EMRFS para detectar nuevos archivos en S3 no es la solución óptima. AWS Glue es una opción más eficiente para esta tarea.\n\nUtilizar una definición de trabajo en AWS Batch con sintaxis Bash para convertir los archivos .csv al formato Apache Parquet. Configurar la ejecución automática del trabajo cuando un nuevo archivo .csv sea cargado en el bucket de origen - AWS Batch es más adecuado para administrar cargas de trabajo de procesamiento en contenedores. Su uso en este escenario introduciría una mayor complejidad operativa y requeriría una gestión manual de los trabajos.\n\nUsar notificaciones de eventos de Amazon S3 para activar una función AWS Lambda que convierta archivos .csv a Apache Parquet utilizando Apache Spark en un clúster de Amazon EMR. Almacenar los archivos procesados en el bucket blockstellart-data-transformed - Usar Amazon S3 con notificaciones de eventos para activar AWS Lambda y procesar los datos en un clúster EMR introduce costos adicionales y esfuerzos de configuración. EMR requiere administración y monitoreo, lo que no es ideal para una solución de bajo mantenimiento.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/patterns/three-aws-glue-etl-job-types-for-converting-data-to-apache-parquet.html\n\nhttps://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-format-parquet-home.html\n\nhttps://docs.aws.amazon.com/glue/latest/dg/crawler-running.html"
  },
  {
    "q": "Una agencia gubernamental ha desarrollado un sistema de análisis de inteligencia, con entornos separados para desarrollo y producción en AWS. Un analista de datos tiene permisos en la cuenta de desarrollo, pero ha recibido autorización temporal para acceder a la cuenta de producción con privilegios limitados a los servicios de Amazon EC2 y Amazon S3. El acceso debe ser restringido a un período específico y no debe requerir la creación de credenciales permanentes.\n¿Qué servicio de AWS proporciona credenciales temporales seguras para cumplir con este requisito?",
    "o": [
      "Configurar AWS IAM Identity Center para administrar el acceso temporal entre cuentas",
      "Usar AWS Security Token Service (STS) para emitir credenciales temporales con AssumeRole",
      "Usar AWS Cognito para generar tokens JWT de autenticación temporal",
      "Crear un usuario IAM con permisos restringidos y eliminarlo manualmente después del período de acceso"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nUsar AWS Security Token Service (STS) para emitir credenciales temporales con AssumeRole - AWS Security Token Service (STS) permite generar credenciales temporales para acceder a AWS, sin necesidad de crear usuarios IAM permanentes. Mediante AssumeRole, el usuario en la cuenta de desarrollo puede obtener acceso temporal a la cuenta de producción con permisos específicos para EC2 y S3, asegurando un control granular y un acceso restringido por tiempo.\n\n\n\nOpciones incorrectas:\n\nUsar AWS Cognito para generar tokens JWT de autenticación temporal - AWS Cognito emite JSON Web Tokens (JWT) para autenticación en aplicaciones web y móviles, pero no proporciona credenciales temporales para acceder a los servicios de AWS.\n\nConfigurar AWS IAM Identity Center para administrar el acceso temporal entre cuentas - AWS IAM Identity Center facilita la autenticación centralizada para múltiples cuentas, pero no genera credenciales temporales como STS.\n\nCrear un usuario IAM con permisos restringidos y eliminarlo manualmente después del período de acceso - Crear un usuario IAM temporalmente y luego eliminarlo manualmente es una mala práctica, ya que introduce riesgos de seguridad y requiere gestión manual. STS es la solución recomendada para accesos temporales controlados.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp.html\n\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp_request.html"
  },
  {
    "q": "Un arquitecto de soluciones ha recibido la tarea de alojar un sitio web que consta de HTML, CSS y algunos archivos JavaScript. Las páginas web mostrarán varias imágenes de alta resolución. El sitio web debe tener tiempos de carga óptimos y ser capaz de responder a altas tasas de solicitudes.\n¿Cuál de las siguientes arquitecturas puede proporcionar la experiencia de carga más rápida y rentable?",
    "o": [
      "Alojar el sitio web en un entorno AWS Elastic Beanstalk. Cargar las imágenes en un bucket de S3. Usar CloudFront como CDN para entregar las imágenes más cerca de los usuarios finales",
      "Cargar los archivos HTML, CSS, JavaScript e imágenes en un único bucket de S3. Habilitar el hosting de sitios web. Crear una distribución de CloudFront y apuntar el dominio al endpoint del sitio web en S3",
      "Alojar el sitio web en un servidor Nginx en una instancia EC2. Cargar las imágenes en un bucket de S3. Usar CloudFront como CDN para entregar las imágenes más cerca de los usuarios finales",
      "Lanzar un Auto Scaling Group utilizando una AMI con un servidor web Apache preconfigurado. Luego, configurar la política de escalado en consecuencia. Almacenar las imágenes en un Elastic Block Store. Finalmente, apuntar el endpoint de la instancia a AWS Global Accelerator"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nCargar los archivos HTML, CSS, JavaScript e imágenes en un único bucket de S3. Habilitar el hosting de sitios web. Crear una distribución de CloudFront y apuntar el dominio al endpoint del sitio web en S3 - Usar Amazon S3 para alojar un sitio web estático es una solución altamente escalable, económica y de alto rendimiento. Para mejorar aún más el rendimiento, integrar Amazon CloudFront permite una entrega rápida y segura de los archivos del sitio web a los usuarios finales, reduciendo la latencia y mejorando la experiencia del usuario.\n\n\n\nOpciones incorrectas:\n\nLanzar un Auto Scaling Group utilizando una AMI con un servidor web Apache preconfigurado. Luego, configurar la política de escalado en consecuencia. Almacenar las imágenes en un Elastic Block Store. Finalmente, apuntar el endpoint de la instancia a AWS Global Accelerator - Ejecutar un sitio web estático en una instancia EC2 con Auto Scaling y Global Accelerator introduce costos innecesarios y una complejidad operativa mayor. AWS S3 es la mejor solución para este caso.\n\nAlojar el sitio web en un entorno AWS Elastic Beanstalk. Cargar las imágenes en un bucket de S3. Usar CloudFront como CDN para entregar las imágenes más cerca de los usuarios finales - Elastic Beanstalk es útil para desplegar aplicaciones web dinámicas con backend, pero es excesivo para alojar un sitio web estático. Amazon S3 y CloudFront son opciones más eficientes.\n\nAlojar el sitio web en un servidor Nginx en una instancia EC2. Cargar las imágenes en un bucket de S3. Usar CloudFront como CDN para entregar las imágenes más cerca de los usuarios finales - Configurar manualmente un servidor Nginx en EC2 para alojar contenido estático es innecesario y costoso en comparación con S3 y CloudFront, que ofrecen escalabilidad automática y menor esfuerzo de administración.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteHosting.html\n\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/amazon-s3-amazon-cloudfront-a-match-made-in-the-cloud/"
  },
  {
    "q": "Un arquitecto de soluciones de una compañía multinacional de videojuegos desarrolla juegos para PS4, Xbox One y Nintendo Switch, así como una serie de juegos móviles para Android e iOS. Debido a la variedad de productos y servicios que manejan, el arquitecto propuso utilizar API Gateway.\n¿Cuáles son las características clave de API Gateway que el arquitecto puede mencionar al cliente? (Selecciona DOS)",
    "o": [
      "Solo pagas por las llamadas a la API que recibes y la cantidad de datos transferidos",
      "Permite ejecutar aplicaciones que requieren altos niveles de comunicación entre nodos a escala en AWS a través de su sistema operativo (OS) personalizado que evita la sobrecarga del hardware",
      "Proporciona automáticamente un lenguaje de consulta para tus APIs similar a GraphQL",
      "Permite construir APIs RESTful y APIs WebSocket optimizadas para cargas de trabajo sin servidor",
      "Proporciona direcciones IP estáticas de anycast que sirven como un punto de entrada fijo para tus aplicaciones alojadas en una o más regiones de AWS"
    ],
    "a": [
      0,
      3
    ],
    "e": "Correcto:\n\nSolo pagas por las llamadas a la API que recibes y la cantidad de datos transferidos - API Gateway tiene un modelo de precios basado en el consumo, lo que significa que solo pagas por las llamadas a la API que procesas y la cantidad de datos transferidos, sin costos mínimos ni tarifas iniciales.\n\nPermite construir APIs RESTful y APIs WebSocket optimizadas para cargas de trabajo sin servidor - API Gateway facilita la construcción de APIs RESTful y WebSocket, lo que lo hace ideal para cargas de trabajo sin servidor (serverless). Puede integrarse con AWS Lambda para ejecutar código sin necesidad de administrar servidores.\n\n\n\nOpciones incorrectas:\n\nPermite ejecutar aplicaciones que requieren altos niveles de comunicación entre nodos a escala en AWS a través de su sistema operativo (OS) personalizado que evita la sobrecarga del hardware - La capacidad de ejecutar aplicaciones con altos niveles de comunicación entre nodos y evitar la sobrecarga del hardware pertenece a Elastic Fabric Adapter, no a API Gateway.\n\nProporciona direcciones IP estáticas de anycast que sirven como un punto de entrada fijo para tus aplicaciones alojadas en una o más regiones de AWS - API Gateway no proporciona direcciones IP estáticas de anycast. Esta funcionalidad es una característica de AWS Global Accelerator.\n\nProporciona automáticamente un lenguaje de consulta para tus APIs similar a GraphQL - API Gateway no proporciona automáticamente un lenguaje de consulta para APIs similar a GraphQL. Sin embargo, puedes usar API Gateway para exponer GraphQL si lo implementas con AWS AppSync.\n\nReferencias:\n\nhttps://aws.amazon.com/api-gateway/\n\nhttps://aws.amazon.com/api-gateway/features/"
  },
  {
    "q": "Una empresa planea realizar una auditoría de seguridad de su red. La aplicación web está alojada en un grupo de Auto Scaling de instancias EC2 con un Application Load Balancer al frente para distribuir uniformemente el tráfico entrante.\nUn arquitecto de soluciones ha sido asignado para mejorar la postura de seguridad de la infraestructura en la nube de la empresa y minimizar el impacto de ataques DDoS en sus recursos.\n¿Cuál de las siguientes opciones es la solución más efectiva que debe implementarse?",
    "o": [
      "Configurar una distribución de Amazon CloudFront y establecer un Network Load Balancer como el origen. Usar Amazon GuardDuty para bloquear hosts sospechosos según sus hallazgos de seguridad. Configurar una función AWS Lambda personalizada que procese los registros de seguridad e invoque Amazon SNS para notificaciones",
      "Configurar una distribución de Amazon CloudFront y establecer un Application Load Balancer como el origen. Crear una regla ACL basada en tasa utilizando AWS WAF y asociarla con Amazon CloudFront",
      "Configurar una distribución de Amazon CloudFront y establecer un Network Load Balancer como el origen. Usar VPC Flow Logs para monitorear patrones de tráfico anormales. Configurar una función AWS Lambda personalizada que procese los registros de flujo e invoque Amazon SNS para notificaciones",
      "Configurar una distribución de Amazon CloudFront y establecer un Application Load Balancer como el origen. Crear una regla de grupo de seguridad y denegar todas las direcciones sospechosas. Usar Amazon SNS para notificaciones"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nConfigurar una distribución de Amazon CloudFront y establecer un Application Load Balancer como el origen. Crear una regla ACL basada en tasa utilizando AWS WAF y asociarla con Amazon CloudFront - AWS WAF (Web Application Firewall) protege contra ataques de aplicaciones web, incluyendo DDoS a nivel de aplicación. Utilizar reglas ACL basadas en tasa permite bloquear automáticamente direcciones IP sospechosas cuando exceden un umbral definido. Integrar AWS WAF con Amazon CloudFront proporciona protección avanzada contra ataques DDoS, minimizando el impacto en la infraestructura.\n\n\n\nOpciones incorrectas:\n\nConfigurar una distribución de Amazon CloudFront y establecer un Application Load Balancer como el origen. Crear una regla de grupo de seguridad y denegar todas las direcciones sospechosas. Usar Amazon SNS para notificaciones - Bloquear direcciones manualmente a través de un grupo de seguridad no es una solución sostenible para mitigar ataques DDoS, ya que estos pueden generar una gran cantidad de paquetes con direcciones IP dinámicas.\n\nConfigurar una distribución de Amazon CloudFront y establecer un Network Load Balancer como el origen. Usar Amazon GuardDuty para bloquear hosts sospechosos según sus hallazgos de seguridad. Configurar una función AWS Lambda personalizada que procese los registros de seguridad e invoque Amazon SNS para notificaciones - Amazon GuardDuty es un servicio de detección de amenazas, pero no bloquea automáticamente tráfico sospechoso. En este escenario, AWS WAF sería la mejor solución para mitigar ataques HTTP flood.\n\nConfigurar una distribución de Amazon CloudFront y establecer un Network Load Balancer como el origen. Usar VPC Flow Logs para monitorear patrones de tráfico anormales. Configurar una función AWS Lambda personalizada que procese los registros de flujo e invoque Amazon SNS para notificaciones - VPC Flow Logs permite monitorear tráfico de red, pero no puede bloquear automáticamente tráfico malicioso. No es la mejor opción para mitigar ataques DDoS en comparación con AWS WAF.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/waf/latest/developerguide/ddos-overview.html\n\nhttps://docs.aws.amazon.com/waf/latest/developerguide/ddos-get-started-rate-based-rules.html\n\nhttps://d0.awsstatic.com/whitepapers/Security/DDoS_White_Paper.pdf"
  },
  {
    "q": "Una aplicación contable utiliza una base de datos RDS configurada con despliegue Multi-AZ para mejorar la disponibilidad.\n¿Qué sucede con RDS si la instancia de base de datos primaria falla?",
    "o": [
      "El registro de nombre canónico (CNAME) se cambia de la instancia primaria a la instancia en espera",
      "La dirección IP de la instancia de base de datos primaria se cambia a la instancia de base de datos en espera",
      "Se crea una nueva instancia de base de datos en la zona de disponibilidad en espera",
      "La instancia de base de datos primaria se reiniciará"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nEl registro de nombre canónico (CNAME) se cambia de la instancia primaria a la instancia en espera - En Amazon RDS con despliegue Multi-AZ, el failover ocurre automáticamente sin intervención administrativa. Cuando la instancia primaria falla, Amazon RDS cambia el registro CNAME para apuntar a la instancia en espera, que se promueve automáticamente como la nueva primaria. Esto permite que las aplicaciones reanuden la operación sin cambios manuales en la configuración.\n\n\n\nOpciones incorrectas:\n\nSe crea una nueva instancia de base de datos en la zona de disponibilidad en espera - No se crea una nueva instancia de base de datos, ya que la instancia en espera ya está preconfigurada en otra zona de disponibilidad y lista para asumir el rol de primaria.\n\nLa instancia de base de datos primaria se reiniciará - La instancia de base de datos no se reinicia, ya que en caso de fallo, la base de datos simplemente cambia a la instancia en espera sin necesidad de reiniciar la instancia defectuosa.\n\nLa dirección IP de la instancia de base de datos primaria se cambia a la instancia de base de datos en espera - La dirección IP de la base de datos no cambia, porque las direcciones IP en AWS son específicas por subred y las subredes no pueden abarcar múltiples zonas de disponibilidad. En cambio, el failover se maneja mediante un cambio en el CNAME.\n\nReferencias:\n\nhttps://aws.amazon.com/rds/details/multi-az/\n\nhttps://aws.amazon.com/rds/faqs/"
  },
  {
    "q": "Una empresa necesita almacenar registros financieros históricos que deben estar disponibles de inmediato cuando se soliciten, pero que rara vez son accedidos. Para reducir costos sin comprometer la disponibilidad, el arquitecto de soluciones decidió migrar estos registros de la clase de almacenamiento S3 Standard a S3 Standard - Infrequent Access (IA).\n¿Cuáles de las siguientes afirmaciones sobre S3 Standard - Infrequent Access (IA) son correctas? (Selecciona DOS)",
    "o": [
      "Es ideal para datos que requieren acceso inmediato, pero que no se consultan con frecuencia",
      "Tiene mayor latencia y menor rendimiento en comparación con S3 Standard",
      "Está diseñado específicamente para almacenamiento a largo plazo y archivado",
      "Ofrece almacenamiento a menor costo que S3 Standard, pero aplica tarifas adicionales por recuperación de datos",
      "Automáticamente transfiere datos a una clase de almacenamiento de menor costo cuando no se acceden con frecuencia"
    ],
    "a": [
      0,
      3
    ],
    "e": "Correcto:\n\nEs ideal para datos que requieren acceso inmediato, pero que no se consultan con frecuencia - S3 Standard - IA es óptimo para datos que necesitan estar disponibles de inmediato, pero que rara vez se consultan, ofreciendo el mismo rendimiento que S3 Standard a un costo menor.\n\nOfrece almacenamiento a menor costo que S3 Standard, pero aplica tarifas adicionales por recuperación de datos - S3 Standard - IA tiene un menor costo de almacenamiento en comparación con S3 Standard, aunque aplica un cargo adicional por la recuperación de datos.\n\n\n\nOpciones incorrectas:\n\nTiene mayor latencia y menor rendimiento en comparación con S3 Standard - S3 Standard - IA mantiene la misma baja latencia y alto rendimiento que S3 Standard.\n\nAutomáticamente transfiere datos a una clase de almacenamiento de menor costo cuando no se acceden con frecuencia - No transfiere datos automáticamente entre clases de almacenamiento. Para esto, se debe utilizar S3 Intelligent-Tiering.\n\nEstá diseñado específicamente para almacenamiento a largo plazo y archivado - No está diseñado para archivado a largo plazo. Amazon S3 Glacier es una mejor opción para este caso debido a su costo mucho más bajo.\n\nReferencias:\n\nhttps://aws.amazon.com/s3/storage-classes/\n\nhttps://aws.amazon.com/s3/faqs"
  },
  {
    "q": "Una empresa de e-commerce necesita realizar análisis en tiempo real sobre los datos de navegación y comportamiento de los clientes en su sitio web. El objetivo es obtener insights sobre patrones de compra y tendencias sin necesidad de administrar infraestructura de bases de datos.\n¿Qué servicios de AWS deberían usarse en conjunto para recopilar, almacenar y analizar estos datos de manera eficiente?",
    "o": [
      "Amazon Kinesis Data Firehose para ingerir los datos en Amazon S3 y Amazon Athena para analizarlos",
      "Amazon S3 para almacenar los datos y una instancia EC2 con Apache Spark para analizarlos",
      "Amazon EC2 con volúmenes EBS para almacenar y analizar los datos en tiempo real",
      "Amazon DynamoDB para almacenar los datos y Amazon QuickSight para visualizarlos"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nAmazon Kinesis Data Firehose para ingerir los datos en Amazon S3 y Amazon Athena para analizarlos - Amazon Kinesis Data Firehose + Amazon S3 + Amazon Athena es la mejor combinación para recopilar, almacenar y analizar datos de navegación en tiempo real sin administrar infraestructura.\n\n\n\nAmazon Kinesis Data Firehose permite ingerir flujos de datos en tiempo real y almacenarlos directamente en S3 sin necesidad de administrar servidores.\nAmazon S3 proporciona almacenamiento escalable, duradero y económico para grandes volúmenes de datos. Amazon Athena permite ejecutar consultas SQL directamente sobre los datos en S3 sin necesidad de configurar bases de datos o servidores.\nOpciones incorrectas:\n\nAmazon S3 para almacenar los datos y una instancia EC2 con Apache Spark para analizarlos - Usar una instancia EC2 con Apache Spark es una opción más compleja que requiere mantenimiento de infraestructura, aumentando la carga operativa.\n\nAmazon DynamoDB para almacenar los datos y Amazon QuickSight para visualizarlos - DynamoDB es una base de datos NoSQL diseñada para acceso rápido a datos estructurados, pero no es la mejor opción para almacenamiento masivo de datos de eventos en tiempo real. Además, Amazon QuickSight es una herramienta de visualización, pero no un servicio de análisis de datos.\n\nAmazon EC2 con volúmenes EBS para almacenar y analizar los datos en tiempo real - Almacenar y analizar datos en EC2 con volúmenes EBS es ineficiente y costoso. EBS no es ideal para almacenamiento masivo de datos, y EC2 requiere administración constante.\n\nReferencias:\n\nhttps://aws.amazon.com/kinesis/data-firehose/\n\nhttps://aws.amazon.com/athena/\n\nhttps://docs.aws.amazon.com/kinesis/latest/dev/introduction.html"
  },
  {
    "q": "Una empresa necesita recopilar gigabytes de datos por segundo desde sitios web y feeds de redes sociales para obtener información sobre sus productos y mejorar la experiencia del usuario.\nPara cumplir con este requisito, se ha desarrollado una aplicación alojada en un Auto Scaling Group de instancias Spot EC2, que procesa los datos y almacena los resultados en DynamoDB y Redshift. La solución debe incluir una función de fan-out mejorada.\n¿Qué servicio administrado de AWS puedes usar para recopilar y procesar grandes volúmenes de datos en tiempo real con el menor esfuerzo?",
    "o": [
      "Amazon Managed Streaming for Apache Kafka (Amazon MSK)",
      "Amazon Kinesis Data Streams",
      "AWS Data Exchange",
      "Amazon S3 Access Points"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nAmazon Kinesis Data Streams - Amazon Kinesis Data Streams permite recopilar y procesar grandes volúmenes de datos en tiempo real con una arquitectura altamente escalable y administrada.\n\nSe usa comúnmente para datos de infraestructura de TI, registros de aplicaciones, eventos de mercado y clics de usuario.\nIncluye fan-out mejorado, lo que permite que múltiples consumidores procesen datos simultáneamente sin afectar el rendimiento.\nIntegra con DynamoDB, Redshift y S3, lo que lo hace ideal para el escenario planteado.\n\n\nOpciones incorrectas:\n\nAWS Data Exchange - AWS Data Exchange es un servicio de mercado de datos, no una solución para procesamiento de datos en tiempo real.\n\nAmazon S3 Access Points - Amazon S3 Access Points solo gestiona el acceso a objetos en S3 y no está diseñado para procesamiento de streaming en tiempo real.\n\nAmazon Managed Streaming for Apache Kafka (Amazon MSK) - Amazon MSK (Kafka) permite procesar datos en streaming, pero requiere más esfuerzo administrativo que Kinesis. No tiene fan-out mejorado nativo, por lo que no cumple totalmente con los requisitos del escenario.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/streams/latest/dev/introduction.html\n\nhttps://aws.amazon.com/kinesis/"
  },
  {
    "q": "Una empresa está utilizando 10 cuentas de AWS consolidadas mediante AWS Organizations. Desean copiar más de 500 objetos de un bucket de S3 a otro bucket de S3 que pertenece a una cuenta diferente dentro de la misma organización.\nEl arquitecto de soluciones recibió instrucciones para configurar los permisos necesarios para esta tarea y garantizar que la cuenta de destino sea la propietaria de los objetos copiados, en lugar de la cuenta de origen.\n¿Cómo puede el arquitecto lograr este requisito?",
    "o": [
      "Configurar permisos de acceso entre cuentas en S3 creando una política de IAM administrada por el cliente que permita a un usuario o rol de IAM copiar objetos del bucket de origen en una cuenta al bucket de destino en la otra cuenta. Luego, adjuntar la política al usuario o rol de IAM que se usará para copiar objetos entre cuentas",
      "Habilitar la función El solicitante paga (Requester Pay) en el bucket de S3 de origen. Las tarifas se eximirían mediante la facturación consolidada ya que ambas cuentas de AWS forman parte de AWS Organizations",
      "Configurar Cross-Origin Resource Sharing (CORS) en S3 creando una política de bucket que permita a un usuario o rol de IAM copiar objetos del bucket de origen en una cuenta al bucket de destino en la otra cuenta",
      "Conectar los dos buckets de S3 de las diferentes cuentas de AWS a Amazon WorkDocs. Configurar acceso entre cuentas para integrar los dos buckets de S3. Usar la consola de Amazon WorkDocs para copiar los objetos de una cuenta a la otra con la propiedad de los objetos modificada a la cuenta de destino"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nConfigurar permisos de acceso entre cuentas en S3 creando una política de IAM administrada por el cliente que permita a un usuario o rol de IAM copiar objetos del bucket de origen en una cuenta al bucket de destino en la otra cuenta. Luego, adjuntar la política al usuario o rol de IAM que se usará para copiar objetos entre cuentas - La mejor solución es configurar permisos de acceso entre cuentas en S3 mediante una política de IAM. Esto garantiza que el usuario o rol de IAM tenga los permisos necesarios para realizar la copia de objetos entre cuentas. Además, al ejecutar la copia desde la cuenta de destino, esta se convertirá en la propietaria de los objetos copiados.\n\n\n\nOpciones incorrectas:\n\nConectar los dos buckets de S3 de las diferentes cuentas de AWS a Amazon WorkDocs. Configurar acceso entre cuentas para integrar los dos buckets de S3. Usar la consola de Amazon WorkDocs para copiar los objetos de una cuenta a la otra con la propiedad de los objetos modificada a la cuenta de destino - Amazon WorkDocs no es una herramienta adecuada para transferir objetos entre buckets de S3 en diferentes cuentas. WorkDocs está diseñado para la colaboración en documentos, no para la gestión de almacenamiento en S3.\n\nHabilitar la función El solicitante paga (Requester Pay) en el bucket de S3 de origen. Las tarifas se eximirían mediante la facturación consolidada ya que ambas cuentas de AWS forman parte de AWS Organizations - La función El solicitante paga (Requester Pays) se usa para transferir el costo del acceso y descarga de los objetos al solicitante en lugar del propietario del bucket. No otorga los permisos necesarios para copiar objetos entre cuentas ni garantiza que la cuenta de destino se convierta en propietaria de los objetos copiados.\n\nConfigurar Cross-Origin Resource Sharing (CORS) en S3 creando una política de bucket que permita a un usuario o rol de IAM copiar objetos del bucket de origen en una cuenta al bucket de destino en la otra cuenta - Configurar CORS en S3 no es relevante en este caso, ya que CORS solo permite que aplicaciones web cargadas en un dominio accedan a recursos en un dominio diferente. No gestiona permisos de acceso entre diferentes cuentas de AWS.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/example-walkthroughs-managing-access-example2.html\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/copy-s3-objects-account/\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/cross-account-access-s3/"
  },
  {
    "q": "Una fintech está desarrollando una plataforma de pagos digitales que almacena información financiera de los clientes en volúmenes EBS adjuntos a instancias EC2. Además, la plataforma almacena registros de transacciones y comprobantes en un bucket de Amazon S3.\nDado que la empresa debe cumplir con regulaciones estrictas de seguridad y protección de datos, el equipo de TI está evaluando opciones para asegurar la información almacenada tanto en EBS como en S3.\n¿Qué medidas de seguridad deberían implementarse para proteger estos datos sensibles? (Selecciona DOS)",
    "o": [
      "Crear instantáneas de EBS regularmente para respaldo y recuperación de datos",
      "Configurar reglas en AWS WAF para proteger las API utilizadas por la aplicación de pagos",
      "Habilitar el cifrado de volúmenes EBS con AWS Key Management Service (AWS KMS)",
      "Mover las instancias EC2 de una subred pública a una subred privada para mayor seguridad",
      "Habilitar el cifrado del lado del servidor en Amazon S3 o usar cifrado del lado del cliente"
    ],
    "a": [
      2,
      4
    ],
    "e": "Correcto:\n\nHabilitar el cifrado de volúmenes EBS con AWS Key Management Service (AWS KMS) - Habilitar el cifrado de EBS con AWS KMS proporciona una capa adicional de seguridad para los datos almacenados en los volúmenes de la aplicación. Este cifrado protege los datos en reposo y se gestiona de forma transparente sin afectar el rendimiento de la aplicación.\n\nHabilitar el cifrado del lado del servidor en Amazon S3 o usar cifrado del lado del cliente - Amazon S3 permite el cifrado del lado del servidor (SSE) y el cifrado del lado del cliente (CSE) para proteger los datos almacenados en sus buckets. SSE cifra automáticamente los datos al ser almacenados en S3, mientras que CSE permite a los clientes cifrar los datos antes de subirlos, asegurando un control total sobre las claves de cifrado.\n\n\n\nOpciones incorrectas:\n\nCrear instantáneas de EBS regularmente para respaldo y recuperación de datos - Crear instantáneas de EBS es útil para respaldos y recuperación ante desastres, pero no cifra los datos almacenados en los volúmenes. Para garantizar la seguridad, las instantáneas deben crearse a partir de volúmenes cifrados.\n\nMover las instancias EC2 de una subred pública a una subred privada para mayor seguridad - Migrar las instancias EC2 a una subred privada mejora la seguridad de la red, pero no protege los datos almacenados en EBS o S3. El cifrado sigue siendo necesario para cumplir con regulaciones de protección de datos.\n\nConfigurar reglas en AWS WAF para proteger las API utilizadas por la aplicación de pagos - AWS WAF protege las aplicaciones web contra amenazas como ataques de inyección SQL o XSS, pero no es una solución para proteger datos en almacenamiento. En este caso, el foco es la seguridad de los datos en reposo, lo que requiere cifrado.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/UsingEncryption.html"
  },
  {
    "q": "Una empresa de transmisión de contenido tiene una aplicación web que se ejecuta en diez instancias Amazon T3 EC2, detrás de un Application Load Balancer.\nEl tráfico de la aplicación es estable y no presenta variaciones significativas en la carga. Un arquitecto de soluciones debe configurar un Auto Scaling Group para garantizar la disponibilidad continua de la aplicación con la mínima interrupción posible en caso de fallos.\n¿Cuál de las siguientes opciones satisface mejor estos requisitos?",
    "o": [
      "Ejecutar diez instancias EC2 con Auto Scaling en una sola Availability Zone detrás de un Application Load Balancer",
      "Distribuir cinco instancias EC2 en una Availability Zone y cinco en otra dentro de la misma región, utilizando un Application Load Balancer",
      "Implementar dos instancias EC2 en cinco regiones distintas, detrás de un Amazon Elastic Load Balancer",
      "Implementar cinco instancias EC2 en una región y cinco en otra, utilizando Amazon Route 53 para distribuir el tráfico entre ambas regiones"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nDistribuir cinco instancias EC2 en una Availability Zone y cinco en otra dentro de la misma región, utilizando un Application Load Balancer - La mejor estrategia es distribuir las instancias EC2 en dos Availability Zones dentro de la misma región. Esto mejora la alta disponibilidad y la tolerancia a fallos:\n\n\n\nSi una Availability Zone falla, las instancias en la otra zona seguirán operando.\nAuto Scaling puede lanzar nuevas instancias automáticamente en la zona activa para mantener la capacidad requerida.\nEl Application Load Balancer (ALB) distribuye el tráfico entre ambas Availability Zones, minimizando el impacto de fallos en la infraestructura.\nOpciones incorrectas:\n\nImplementar cinco instancias EC2 en una región y cinco en otra, utilizando Amazon Route 53 para distribuir el tráfico entre ambas regiones - Route 53 permite distribuir tráfico entre múltiples regiones, pero la pregunta no menciona la necesidad de resiliencia multi-región. Además, esta configuración introduce una mayor complejidad operativa sin aportar beneficios adicionales en este caso.\n\nEjecutar diez instancias EC2 con Auto Scaling en una sola Availability Zone detrás de un Application Load Balancer - Alojar todas las instancias en una única Availability Zone no proporciona tolerancia a fallos. Si la zona falla, la aplicación quedará completamente inoperativa.\n\nImplementar dos instancias EC2 en cinco regiones distintas, detrás de un Amazon Elastic Load Balancer - Un Elastic Load Balancer no puede distribuir tráfico entre diferentes regiones. Para lograrlo, sería necesario un servicio adicional como AWS Global Accelerator o Amazon Route 53, lo que introduce mayor complejidad sin necesidad.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/as-multi-az.html\n\nhttps://aws.amazon.com/elasticloadbalancing/"
  },
  {
    "q": "Un arquitecto de soluciones está gestionando la cuenta de AWS de una empresa con aproximadamente 500 usuarios de IAM. La empresa ha implementado una nueva política que requiere cambiar los permisos asociados a 200 usuarios de IAM que controlan el acceso a los buckets de Amazon S3.\n¿Qué debe hacer el arquitecto de soluciones para evitar la tarea tediosa de aplicar la política a cada usuario individualmente?",
    "o": [
      "Crear una nueva política y aplicarla a múltiples usuarios de IAM utilizando un script de shell",
      "Crear un nuevo grupo de IAM y luego agregar a los usuarios que requieren acceso al bucket de S3. Después, aplicar la política al grupo de IAM",
      "Crear una nueva política de acceso a un bucket de S3 con acceso ilimitado para cada usuario de IAM",
      "Crear un nuevo rol de IAM y agregar a cada usuario al rol de IAM"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nCrear un nuevo grupo de IAM y luego agregar a los usuarios que requieren acceso al bucket de S3. Después, aplicar la política al grupo de IAM - La mejor opción es crear un grupo de IAM y agregar a los usuarios que necesitan acceso a S3, aplicando la política al grupo en lugar de a cada usuario individualmente.\n\n\n\nEsto facilita la administración, ya que los permisos se pueden gestionar de manera centralizada en el grupo de IAM.\nAdemás, si en el futuro se necesitan cambios en los permisos, solo será necesario modificar la política del grupo, sin afectar cada usuario individualmente.\nOpciones incorrectas:\n\nCrear una nueva política y aplicarla a múltiples usuarios de IAM utilizando un script de shell - Aplicar una política individualmente a cada usuario mediante un script de shell podría ahorrar tiempo inicialmente, pero no es una solución escalable ni fácil de administrar. Es mejor utilizar grupos de IAM para gestionar los permisos de forma centralizada.\n\nCrear un nuevo rol de IAM y agregar a cada usuario al rol de IAM - Un rol de IAM está diseñado para proporcionar permisos a recursos de AWS o a usuarios/servicios externos, no para administrar usuarios dentro de la misma cuenta de AWS. En este caso, la solución correcta es utilizar un grupo de IAM, no un rol.\n\nCrear una nueva política de acceso a un bucket de S3 con acceso ilimitado para cada usuario de IAM - Crear una política de acceso ilimitado para cada usuario no es recomendable porque viola los principios de seguridad y escalabilidad. Los grupos de IAM permiten gestionar los permisos de forma más eficiente y segura.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_groups.html"
  },
  {
    "q": "Una empresa está desplegando una aplicación de análisis en AWS Fargate. La aplicación requiere almacenamiento conectado que ofrezca acceso concurrente a archivos y alto rendimiento.\n¿Qué opción de almacenamiento debe recomendar el arquitecto de soluciones?",
    "o": [
      "Crear un recurso compartido de archivos de Amazon FSx for Lustre y establecer un rol IAM que permita a Fargate comunicarse con FSx for Lustre.",
      "Crear un volumen de Amazon EBS para la aplicación y establecer un rol IAM que permita a Fargate comunicarse con Amazon EBS.",
      "Crear un recurso compartido de archivos de Amazon EFS y establecer un rol IAM que permita a Fargate comunicarse con Amazon EFS.",
      "Crear un bucket de Amazon S3 para la aplicación y establecer un rol IAM para que Fargate se comunique con Amazon S3."
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nCrear un recurso compartido de archivos de Amazon EFS y establecer un rol IAM que permita a Fargate comunicarse con Amazon EFS. - Amazon Elastic File System ofrece acceso concurrente a un sistema de archivos compartido y proporciona alto rendimiento. Puede crear políticas del sistema de archivos para controlar el acceso y luego usar un rol IAM que se especifica en la política para el acceso.\n\nOpciones incorrectas:\n\nCrear un recurso compartido de archivos de Amazon FSx for Lustre y establecer un rol IAM que permita a Fargate comunicarse con FSx for Lustre. - No se admite conectar Fargate a FSx for Lustre.\n\nCrear un volumen de Amazon EBS para la aplicación y establecer un rol IAM que permita a Fargate comunicarse con Amazon EBS. - Los volúmenes EBS no se pueden compartir entre tareas de Fargate, se usan con instancias EC2.\n\nCrear un bucket de Amazon S3 para la aplicación y establecer un rol IAM para que Fargate se comunique con Amazon S3. - S3 usa una API REST, no una API del sistema de archivos, por lo que el acceso puede ser compartido pero no concurrente.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/efs/latest/ug/iam-access-control-nfs-efs.html"
  },
  {
    "q": "Un arquitecto de soluciones está diseñando una infraestructura de alta disponibilidad para una aplicación web alojada en instancias EC2 dentro de un Auto Scaling Group.\nUno de los requisitos clave es garantizar que los datos almacenados en los volúmenes raíz de EBS no se eliminen si una instancia se termina.\n¿Qué configuración debe aplicarse para cumplir con este requisito?",
    "o": [
      "Configurar el Auto Scaling Group (ASG) para suspender la verificación de estado de cada instancia EC2",
      "Establecer el atributo DeleteOnTermination de los volúmenes EBS en False",
      "Utilizar AWS Backup para realizar copias de seguridad periódicas de los volúmenes raíz de EBS",
      "Habilitar la opción de Protección contra Terminación en todas las instancias EC2"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nEstablecer el atributo DeleteOnTermination de los volúmenes EBS en False - Por defecto, los volúmenes raíz de Amazon EBS se eliminan automáticamente cuando una instancia EC2 se termina.\n\nPara evitar que esto ocurra, se debe configurar el atributo DeleteOnTermination en False al momento de lanzar la instancia o modificarlo en volúmenes ya existentes.\nEsto garantiza que el volumen raíz persista después de la terminación de la instancia, permitiendo su reutilización en otra instancia.\nOpciones incorrectas:\n\nConfigurar el Auto Scaling Group (ASG) para suspender la verificación de estado de cada instancia EC2 - Suspender la verificación de estado en el Auto Scaling Group (ASG) puede impedir que las instancias defectuosas sean reemplazadas, lo que afectaría la disponibilidad de la aplicación.\n\nHabilitar la opción de Protección contra Terminación en todas las instancias EC2 - La Protección contra Terminación impide que una instancia EC2 sea eliminada manualmente, pero no evita su terminación automática en un Auto Scaling Group.\n\nUtilizar AWS Backup para realizar copias de seguridad periódicas de los volúmenes raíz de EBS - Aunque AWS Backup puede ser útil para realizar copias de seguridad periódicas, no evita la eliminación del volumen raíz al terminar una instancia. La mejor solución es modificar el atributo DeleteOnTermination.\n\nReferencias:\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/deleteontermination-ebs/\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/terminating-instances.html"
  },
  {
    "q": "Una empresa está planeando migrar una gran cantidad de datos importantes a Amazon S3. Los datos se cargarán en un bucket con versionado habilitado en la Región us-west-1. La solución necesita incluir la replicación de los datos a otra Región para fines de recuperación ante desastres.\n¿Cómo debe configurar un arquitecto de soluciones la replicación?",
    "o": [
      "Crear un bucket de S3 adicional con versionado en otra región y configurar el uso compartido de recursos de origen cruzado (CORS)",
      "Crear un bucket de S3 adicional en otra región y configurar el uso compartido de recursos de origen cruzado (CORS)",
      "Crear un bucket de S3 adicional en otra región y configurar la replicación entre regiones",
      "Crear un bucket de S3 adicional con versionado en otra región y configurar la replicación entre regiones"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nCrear un bucket de S3 adicional con versionado en otra región y configurar la replicación entre regiones - La replicación permite la copia automática y asíncrona de objetos entre buckets de Amazon S3. Los buckets que están configurados para la replicación de objetos pueden ser propiedad de la misma cuenta de AWS o de diferentes cuentas. Puede copiar objetos entre diferentes Regiones de AWS o dentro de la misma Región. Tanto el bucket de origen como el de destino deben tener el versionado habilitado.\n\nOpciones incorrectas:\n\nCrear un bucket de S3 adicional en otra región y configurar el uso compartido de recursos de origen cruzado (CORS) - CORS no está relacionado con la replicación.\n\nCrear un bucket de S3 adicional con versionado en otra región y configurar el uso compartido de recursos de origen cruzado (CORS) - CORS no está relacionado con la replicación.\n\nCrear un bucket de S3 adicional en otra región y configurar la replicación entre regiones - El bucket de destino también debe tener el versionado habilitado.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/replication.html"
  },
  {
    "q": "Una gran empresa de ciberseguridad necesita configurar un bastion host en Linux para permitir el acceso a las instancias de Amazon EC2 que se ejecutan en su VPC. Por razones de seguridad, solo los clientes que se conecten desde la dirección IP pública externa de la empresa (192.168.45.200) deben tener acceso SSH al host.\n¿Cuál es la mejor opción para cumplir con este requisito?",
    "o": [
      "Regla de entrada de ACL de red: Protocolo - UDP, Rango de puertos - 22, Origen 192.168.45.200/32",
      "Regla de entrada de Grupo de Seguridad: Protocolo - TCP, Rango de puertos - 22, Origen 192.168.45.200/32",
      "Regla de entrada de ACL de red: Protocolo - TCP, Rango de puertos - 22, Origen 192.168.45.200/0",
      "Regla de entrada de Grupo de Seguridad: Protocolo - UDP, Rango de puertos - 22, Origen 192.168.45.200/32"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nRegla de entrada de Grupo de Seguridad: Protocolo - TCP, Rango de puertos - 22, Origen 192.168.45.200/32 - La opción correcta es configurar una regla de entrada en un grupo de seguridad para permitir el tráfico SSH (TCP, puerto 22) desde una dirección IP específica (192.168.45.200/32).\n\n\n\nLos grupos de seguridad operan a nivel de instancia y son la mejor práctica para restringir el acceso a instancias individuales dentro de la VPC.\nLa notación /32 indica que solo esa IP específica tendrá acceso.\nOpciones incorrectas:\n\nRegla de entrada de ACL de red: Protocolo - TCP, Rango de puertos - 22, Origen 192.168.45.200/0 - Esta regla de ACL de red permite el acceso desde toda la red (192.168.45.200/0) en lugar de solo una dirección IP específica. Esto introduce un riesgo de seguridad, ya que cualquier IP dentro de ese rango podría intentar acceder al bastion host.\n\nRegla de entrada de ACL de red: Protocolo - UDP, Rango de puertos - 22, Origen 192.168.45.200/32 - SSH utiliza el protocolo TCP en el puerto 22, no UDP. Definir una regla de ACL de red en UDP para este puerto no permitiría la conectividad SSH esperada.\n\nRegla de entrada de Grupo de Seguridad: Protocolo - UDP, Rango de puertos - 22, Origen 192.168.45.200/32 - SSH no utiliza UDP. Además, las reglas de grupo de seguridad deben configurarse con el protocolo correcto para que la conectividad funcione correctamente.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html"
  },
  {
    "q": "Un equipo de ciencia de datos necesita una gran cantidad de capacidad computacional en AWS para entrenar modelos de aprendizaje automático.\nLos modelos pueden tardar varias horas en procesarse, pero si la capacidad de cómputo se interrumpe, el entrenamiento puede reanudarse sin problemas desde donde se detuvo.\n¿Cuál es la opción de compra de instancias EC2 más rentable para este caso?",
    "o": [
      "Instancias On-Demand",
      "Reservas de Capacidad On-Demand",
      "Instancias Reservadas",
      "Instancias Spot"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nInstancias Spot - Las Instancias Spot son la mejor opción para cargas de trabajo tolerantes a fallos, como el entrenamiento de modelos de machine learning.\n\n\n\nOfrecen hasta un 90% de descuento en comparación con las Instancias On-Demand.\nSon ideales para cargas de trabajo interrumpibles, como big data, rendering, procesamiento por lotes y entrenamientos de IA.\nSi una instancia Spot es interrumpida, se puede reanudar la tarea utilizando estrategias como checkpointing o distribución de carga.\nOpciones incorrectas:\n\nReservas de Capacidad On-Demand - Las Reservas de Capacidad On-Demand garantizan disponibilidad de instancias, pero son costosas y no aportan beneficios en entornos donde la interrupción no es un problema.\n\nInstancias On-Demand - Las Instancias On-Demand permiten pagar solo por el uso sin compromisos a largo plazo, pero son significativamente más costosas que las Instancias Spot.\n\nInstancias Reservadas - Las Instancias Reservadas requieren un compromiso de 1 o 3 años para obtener descuentos, pero son más adecuadas para cargas de trabajo predecibles y siempre activas.\n\nReferencias:\n\nhttp://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-instances.html\n\nhttps://aws.amazon.com/ec2/spot/"
  },
  {
    "q": "Una empresa de e-learning almacena sus materiales educativos en Amazon S3 y utiliza CloudFront para distribuir los archivos a estudiantes en diferentes regiones.\nActualmente, los estudiantes pueden acceder a los archivos directamente desde las URL de S3 o mediante CloudFront. El arquitecto de soluciones debe garantizar que solo los estudiantes autorizados accedan a los archivos y que el contenido solo se sirva a través de CloudFront para mejorar la seguridad y la distribución de los materiales.\n¿Qué combinación de acciones debe implementar el arquitecto para cumplir con estos requisitos? (Selecciona DOS)",
    "o": [
      "Configurar CloudFront para requerir URLs firmadas o cookies firmadas, asegurando que solo los usuarios autorizados puedan acceder al contenido",
      "Implementar una función Lambda@Edge en CloudFront para validar que solo los usuarios autenticados accedan a los archivos",
      "Utilizar URLs pre-firmadas de S3 para restringir el acceso a los archivos y eliminar el permiso de acceso público en el bucket de S3",
      "Habilitar Origin Shield en Amazon CloudFront para garantizar que solo los estudiantes autenticados accedan al contenido",
      "Configurar una Identidad de Acceso de Origen (OAI) en CloudFront y otorgarle permisos para leer los archivos en el bucket de S3"
    ],
    "a": [
      0,
      4
    ],
    "e": "Correcto:\n\nConfigurar una Identidad de Acceso de Origen (OAI) en CloudFront y otorgarle permisos para leer los archivos en el bucket de S3 - Una Identidad de Acceso de Origen (OAI) en CloudFront permite restringir el acceso directo a los archivos en S3, asegurando que solo las solicitudes provenientes de CloudFront puedan acceder a ellos. Esto evita que los estudiantes descarguen los archivos directamente desde S3 y refuerza la seguridad.\n\nConfigurar CloudFront para requerir URLs firmadas o cookies firmadas, asegurando que solo los usuarios autorizados puedan acceder al contenido - Usar URLs firmadas o cookies firmadas en CloudFront permite restringir el acceso a los materiales educativos a usuarios autenticados. Esta técnica garantiza que solo los estudiantes autorizados puedan acceder a los archivos.\n\n\n\nOpciones incorrectas:\n\nUtilizar URLs pre-firmadas de S3 para restringir el acceso a los archivos y eliminar el permiso de acceso público en el bucket de S3 - Las URLs pre-firmadas de S3 permiten restringir el acceso, pero no cumplen con el requisito de servir el contenido exclusivamente a través de CloudFront. Esta opción no es óptima para este caso.\n\nHabilitar Origin Shield en Amazon CloudFront para garantizar que solo los estudiantes autenticados accedan al contenido - Origin Shield optimiza la entrega de contenido y reduce la carga en el origen, pero no tiene relación con la autenticación o restricción de acceso a los archivos.\n\nImplementar una función Lambda@Edge en CloudFront para validar que solo los usuarios autenticados accedan a los archivos - Aunque Lambda@Edge permite modificar las respuestas de CloudFront, no es la solución ideal para restringir el acceso a los archivos en S3. La mejor manera de hacerlo es mediante OAI y URLs o cookies firmadas.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/PrivateContent.html\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/PresignedUrlUploadObject.html"
  },
  {
    "q": "Una empresa de atención médica está migrando su sistema de registros de pacientes a AWS. La empresa recibe miles de archivos de datos de pacientes cifrados todos los días a través de FTP. Un servidor on-premises procesa los archivos de datos dos veces al día. Sin embargo, el trabajo de procesamiento tarda horas en finalizar.\nLa empresa quiere que la solución de AWS procese los archivos de datos entrantes tan pronto como lleguen con cambios mínimos en los clientes FTP que envían los archivos. La solución debe eliminar los archivos de datos entrantes después de que los archivos hayan sido procesados exitosamente. El procesamiento de cada archivo necesita tomar alrededor de 10 minutos.\n¿Qué solución cumplirá estos requisitos de la manera más eficiente operacionalmente?",
    "o": [
      "Usar AWS Transfer Family para crear un servidor SFTP para almacenar archivos entrantes en Amazon S3 Glacier. Configurar una instancia de Amazon EC2 para procesar los archivos. Usar reglas de Amazon EventBridge para invocar la instancia EC2 para procesar los archivos dos veces al día desde S3 Glacier. Eliminar los objetos después de que el trabajo haya procesado los objetos.",
      "Usar una instancia de Amazon EC2 que ejecute un servidor SFTP para almacenar archivos entrantes en Amazon S3 Standard. Configurar una cola de trabajos en AWS Batch. Usar reglas de Amazon EventBridge para invocar el trabajo para procesar los archivos dos veces al día. Eliminar los archivos después de que el trabajo haya procesado los archivos.",
      "Usar AWS Transfer Family para crear un servidor SFTP para almacenar archivos entrantes en Amazon S3 Standard. Crear una función de AWS Lambda para procesar los archivos y eliminar los archivos después de que sean procesados. Usar una notificación de eventos de S3 para invocar la función Lambda cuando lleguen los archivos.",
      "Usar AWS Transfer Family para crear un servidor SFTP para almacenar archivos entrantes en Amazon S3 Standard. Usar instancias de Amazon EC2 administradas por un grupo de Auto Scaling para procesar los archivos. Configurar una notificación de eventos de S3 para activar una función de AWS Lambda que lance las instancias EC2 cuando lleguen los archivos. Eliminar los archivos después de que sean procesados."
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nUsar AWS Transfer Family para crear un servidor SFTP para almacenar archivos entrantes en Amazon S3 Standard. Crear una función de AWS Lambda para procesar los archivos y eliminar los archivos después de que sean procesados. Usar una notificación de eventos de S3 para invocar la función Lambda cuando lleguen los archivos. - AWS Transfer Family proporciona soporte completamente administrado para transferencias de archivos directamente hacia y desde Amazon S3 usando SFTP. Almacenar archivos entrantes en S3 Standard ofrece almacenamiento de objetos de alta durabilidad, disponibilidad y rendimiento para datos accedidos frecuentemente.\n\nAWS Lambda puede responder inmediatamente a eventos de S3, lo que permite procesar archivos tan pronto como lleguen. Lambda también puede eliminar los archivos después del procesamiento. Esto cumple con todos los requisitos y es eficiente operacionalmente, ya que requiere una gestión mínima y tiene costos bajos.\n\nOpciones incorrectas:\n\nUsar AWS Transfer Family para crear un servidor SFTP para almacenar archivos entrantes en Amazon S3 Standard. Usar instancias de Amazon EC2 administradas por un grupo de Auto Scaling para procesar los archivos. Configurar una notificación de eventos de S3 para activar una función de AWS Lambda que lance las instancias EC2 cuando lleguen los archivos. Eliminar los archivos después de que sean procesados. - Aunque esta solución funcionará, es menos eficiente operacionalmente porque administrar instancias EC2 y un grupo de Auto Scaling es más complejo y probablemente más costoso que simplemente usar AWS Lambda para el procesamiento.\n\nUsar AWS Transfer Family para crear un servidor SFTP para almacenar archivos entrantes en Amazon S3 Glacier. Configurar una instancia de Amazon EC2 para procesar los archivos. Usar reglas de Amazon EventBridge para invocar la instancia EC2 para procesar los archivos dos veces al día desde S3 Glacier. Eliminar los objetos después de que el trabajo haya procesado los objetos. - Esta opción implica usar Amazon S3 Glacier, que se usa principalmente para almacenamiento de archivo a largo plazo. Acceder a datos para procesamiento podría tomar más tiempo y ser más costoso que usar S3 Standard. Además, las instancias EC2 necesitan ser administradas y son menos eficientes para este escenario en comparación con AWS Lambda.\n\nUsar una instancia de Amazon EC2 que ejecute un servidor SFTP para almacenar archivos entrantes en Amazon S3 Standard. Configurar una cola de trabajos en AWS Batch. Usar reglas de Amazon EventBridge para invocar el trabajo para procesar los archivos dos veces al día. Eliminar los archivos después de que el trabajo haya procesado los archivos. - Esta opción no cumple con el requisito de procesar archivos de datos entrantes tan pronto como lleguen, ya que las reglas de EventBridge invocarían el trabajo solo dos veces al día. También implica administrar una instancia EC2, lo que es menos eficiente operacionalmente que la opción de AWS Transfer Family y AWS Lambda.\n\nReferencias:\n\nhttps://aws.amazon.com/aws-transfer-family/"
  },
  {
    "q": "Una empresa está implementando un entorno de Microsoft Dynamics CRM en AWS utilizando CloudFormation. El arquitecto de soluciones necesita instalar y configurar la arquitectura, que incluye controladores de dominio de Microsoft Active Directory (AD), Microsoft SQL Server 2016 y múltiples instancias de Amazon EC2 para alojar Microsoft Dynamics CRM y otras dependencias.\nEl arquitecto debe asegurarse de que los componentes requeridos se estén ejecutando correctamente antes de que CloudFormation continúe con la creación de la pila. ¿Cuál de las siguientes opciones debe configurar el arquitecto para cumplir con este requisito?",
    "o": [
      "Configurar el atributo DependsOn en la plantilla de CloudFormation. Enviar una señal de éxito después de que las aplicaciones estén instaladas y configuradas utilizando el script auxiliar cfn-init",
      "Configurar un atributo UpdatePolicy en la instancia dentro de la plantilla de CloudFormation. Enviar una señal de éxito después de que las aplicaciones estén instaladas y configuradas utilizando el script auxiliar cfn-signal",
      "Configurar un atributo CreationPolicy en la instancia dentro de la plantilla de CloudFormation. Enviar una señal de éxito después de que las aplicaciones estén instaladas y configuradas utilizando el script auxiliar cfn-signal",
      "Configurar el atributo UpdateReplacePolicy en la instancia dentro de la plantilla de CloudFormation. Enviar una señal de éxito después de que las aplicaciones estén instaladas y configuradas utilizando el script auxiliar cfn-signal"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nConfigurar un atributo CreationPolicy en la instancia dentro de la plantilla de CloudFormation. Enviar una señal de éxito después de que las aplicaciones estén instaladas y configuradas utilizando el script auxiliar cfn-signal - La mejor opción es configurar un atributo CreationPolicy en la instancia dentro de la plantilla de CloudFormation y utilizar cfn-signal para indicar que las aplicaciones se han instalado y configurado correctamente. Esto evita que CloudFormation complete la creación de la pila hasta que los componentes necesarios estén en funcionamiento.\n\n\n\nOpciones incorrectas:\n\nConfigurar el atributo DependsOn en la plantilla de CloudFormation. Enviar una señal de éxito después de que las aplicaciones estén instaladas y configuradas utilizando el script auxiliar cfn-init - Aunque el atributo DependsOn puede garantizar que un recurso específico se cree antes que otro, no es adecuado para gestionar la instalación y configuración de aplicaciones. Además, el script cfn-init no está diseñado para enviar señales de éxito a CloudFormation.\n\nConfigurar un atributo UpdatePolicy en la instancia dentro de la plantilla de CloudFormation. Enviar una señal de éxito después de que las aplicaciones estén instaladas y configuradas utilizando el script auxiliar cfn-signal - El atributo UpdatePolicy se utiliza principalmente para actualizar recursos, como en Auto Scaling Groups, y para operaciones de reversión de pilas. No es el mecanismo adecuado para esperar la configuración de aplicaciones en instancias de EC2.\n\nConfigurar el atributo UpdateReplacePolicy en la instancia dentro de la plantilla de CloudFormation. Enviar una señal de éxito después de que las aplicaciones estén instaladas y configuradas utilizando el script auxiliar cfn-signal - UpdateReplacePolicy se utiliza para conservar o hacer una copia de seguridad de una instancia cuando se reemplaza durante una actualización de la pila. No es la opción correcta para garantizar que las aplicaciones estén configuradas antes de continuar con la creación de la pila.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-creationpolicy.html\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/deploying.applications.html#deployment-walkthrough-cfn-signal\n\nhttps://aws.amazon.com/blogs/devops/use-a-creationpolicy-to-wait-for-on-instance-configurations/"
  },
  {
    "q": "Una empresa de servicios financieros necesita un servicio de almacenamiento duradero en la nube de AWS para almacenar respaldos de registros contables y documentos críticos. El servicio debe permitir la transferencia de datos desde sus servidores locales y proporcionar acceso a los archivos mediante protocolos estándar de almacenamiento como SMB o NFS, para facilitar su recuperación cuando sea necesario.\n¿Cuál de las siguientes opciones cumplirá con este requisito?",
    "o": [
      "Usar AWS Storage Gateway file gateway para almacenar todos los datos de respaldo en Amazon S3",
      "Usar AWS Snowball Edge para realizar directamente la copia de seguridad de los datos en Amazon S3 Glacier",
      "Usar AWS Storage Gateway volume gateway para almacenar los datos de respaldo y acceder a ellos directamente mediante acciones de la API de Amazon S3",
      "Usar Amazon EBS volumes para almacenar todos los datos de respaldo y adjuntarlo a una instancia de Amazon EC2"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nUsar AWS Storage Gateway file gateway para almacenar todos los datos de respaldo en Amazon S3 - AWS Storage Gateway (File Gateway) es la mejor opción, ya que proporciona una interfaz de archivos basada en la nube para almacenar y recuperar datos en Amazon S3 utilizando protocolos de almacenamiento estándar como SMB o NFS. Esto permite a las aplicaciones locales acceder a los datos sin modificaciones y garantiza almacenamiento duradero en S3.\n\n\n\nOpciones incorrectas:\n\nUsar AWS Storage Gateway volume gateway para almacenar los datos de respaldo y acceder a ellos directamente mediante acciones de la API de Amazon S3 - Volume Gateway no permite acceso directo a los datos mediante la API de Amazon S3. Volume Gateway se usa para respaldos en volúmenes EBS y snapshots en S3, pero no proporciona acceso a archivos a través de protocolos estándar.\n\nUsar Amazon EBS volumes para almacenar todos los datos de respaldo y adjuntarlo a una instancia de Amazon EC2 - Amazon EBS no es una opción de almacenamiento duradero para respaldos. EBS está diseñado para almacenamiento de instancias EC2 y no admite acceso mediante NFS o SMB.\n\nUsar AWS Snowball Edge para realizar directamente la copia de seguridad de los datos en Amazon S3 Glacier - AWS Snowball Edge no puede almacenar ni recuperar datos directamente desde Amazon S3 Glacier. Snowball se usa para transferir grandes volúmenes de datos a AWS, pero no para proporcionar acceso en línea mediante protocolos estándar.\n\nReferencias:\n\nhttps://aws.amazon.com/storagegateway/faqs/\n\nhttps://aws.amazon.com/s3/storage-classes/"
  },
  {
    "q": "Un arquitecto de soluciones está diseñando una aplicación que se ejecutará en instancias de Amazon EC2. La aplicación usará Amazon S3 para almacenar archivos de imagen y una tabla de Amazon DynamoDB para almacenar información de clientes. El equipo de seguridad requiere que el tráfico entre las instancias EC2 y los servicios de AWS no atraviese la internet pública.\n¿Cómo puede el arquitecto de soluciones cumplir con los requisitos del equipo de seguridad?",
    "o": [
      "Crear un gateway privado virtual y configurar las tablas de enrutamiento de VPC.",
      "Crear endpoints de VPC de interfaz para Amazon S3 y DynamoDB.",
      "Crear endpoints de VPC de gateway para Amazon S3 y DynamoDB.",
      "Crear un NAT gateway en una subred pública y configurar las tablas de enrutamiento."
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nCrear endpoints de VPC de gateway para Amazon S3 y DynamoDB. - Un endpoint de VPC permite conexiones privadas entre su VPC y los servicios de AWS compatibles y los servicios de endpoint de VPC impulsados por AWS PrivateLink. Un endpoint de gateway se usa para Amazon S3 y Amazon DynamoDB. Especifica un endpoint de gateway como objetivo de la tabla de enrutamiento para el tráfico que está destinado a los servicios de AWS compatibles.\n\nOpciones incorrectas:\n\nCrear endpoints de VPC de interfaz para Amazon S3 y DynamoDB. - Debe usar un endpoint de VPC de gateway para S3 y DynamoDB.\n\nCrear un gateway privado virtual y configurar las tablas de enrutamiento de VPC. - Los VGW se usan para conexiones VPN, no permiten el acceso a servicios de AWS desde una VPC.\n\nCrear un NAT gateway en una subred pública y configurar las tablas de enrutamiento. - Un NAT gateway se usa para habilitar la conectividad a internet para instancias en subredes privadas. Las conexiones atravesarán la internet.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints.html"
  },
  {
    "q": "Una empresa fintech ha desplegado una aplicación en una instancia de Amazon EC2 con volúmenes de Instance Store adjuntos y una dirección IP elástica (Elastic IP).\nPara reducir costos, un script de Lambda detiene automáticamente la instancia fuera del horario laboral (de 6 PM a 8 AM) y la inicia nuevamente al inicio del día laboral.\n¿Qué sucede cuando la instancia EC2 es detenida y luego iniciada nuevamente? (Selecciona DOS)",
    "o": [
      "La Elastic Network Interface (ENI) se desasocia",
      "La dirección Elastic IP se desasocia automáticamente",
      "No habrá cambios en la instancia ni en sus volúmenes",
      "Todos los datos en los volúmenes de Instance Store adjuntos se perderán",
      "El host físico donde se ejecuta la instancia puede cambiar"
    ],
    "a": [
      3,
      4
    ],
    "e": "Correcto:\n\nEl host físico donde se ejecuta la instancia puede cambiar - Cuando una instancia EC2 respaldada por EBS se detiene y luego se inicia, AWS puede moverla a un host físico diferente en su infraestructura. Esto ocurre porque la instancia ya no está vinculada a un hardware específico y puede ser reasignada dinámicamente.\n\nTodos los datos en los volúmenes de Instance Store adjuntos se perderán - Los volúmenes de Instance Store son almacenamiento efímero, lo que significa que todos los datos almacenados en ellos se eliminan al detener la instancia. Solo los volúmenes EBS persisten después de detener y reiniciar una instancia.\n\n\n\nOpciones incorrectas:\n\nLa Elastic Network Interface (ENI) se desasocia - La Elastic Network Interface (ENI) permanece asociada a la instancia EC2 aunque esta se detenga y reinicie.\n\nLa dirección Elastic IP se desasocia automáticamente - La Elastic IP no se desasocia automáticamente al detener la instancia si esta está dentro de una VPC. Solo se desasociaría si la instancia estuviera en la plataforma EC2-Classic (en desuso).\n\nNo habrá cambios en la instancia ni en sus volúmenes - Detener e iniciar la instancia puede provocar cambios como la reasignación a un nuevo host físico y la pérdida de datos en Instance Store.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-lifecycle.html\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ComponentsAMIs.html#storage-for-the-root-device"
  },
  {
    "q": "Un arquitecto de soluciones no puede conectarse a una instancia EC2 recién implementada a través de SSH utilizando una computadora personal. Sin embargo, el arquitecto pudo acceder con éxito a otras instancias dentro de la VPC sin problemas.\n¿Cuál de las siguientes opciones debería verificar y posiblemente corregir para restaurar la conectividad?",
    "o": [
      "Configurar el Security Group de la instancia EC2 para permitir tráfico de entrada en el puerto 22 desde tu dirección IP",
      "Configurar el Security Group de la instancia EC2 para permitir tráfico de entrada en el puerto 3389 desde tu dirección IP",
      "Usar Amazon Data Lifecycle Manager",
      "Configurar la Network Access Control List (NACL) de tu VPC para permitir tráfico de entrada en el puerto 22 desde tu dirección IP"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nConfigurar el Security Group de la instancia EC2 para permitir tráfico de entrada en el puerto 22 desde tu dirección IP - Para conectarse a una instancia EC2 mediante SSH, es necesario asegurarse de que el puerto 22 esté permitido en el Security Group de la instancia. Los Security Groups actúan como firewalls virtuales que controlan el tráfico entrante y saliente de las instancias asociadas. Si la regla de ingreso para el puerto 22 no está configurada correctamente, la conexión SSH será rechazada.\n\n\n\nOpciones incorrectas:\n\nConfigurar el Security Group de la instancia EC2 para permitir tráfico de entrada en el puerto 3389 desde tu dirección IP - El puerto 3389 se utiliza para conexiones RDP (Remote Desktop Protocol) en instancias Windows, y no es relevante para SSH en instancias Linux.\n\nConfigurar la Network Access Control List (NACL) de tu VPC para permitir tráfico de entrada en el puerto 22 desde tu dirección IP - Configurar la Network Access Control List (NACL) de la VPC para permitir tráfico en el puerto 22 no es necesario en este caso, ya que el arquitecto ya puede conectarse a otras instancias EC2 dentro de la misma VPC. Además, las NACLs controlan el tráfico a nivel de la subred, mientras que los Security Groups operan a nivel de instancia.\n\nUsar Amazon Data Lifecycle Manager - Amazon Data Lifecycle Manager se usa para gestionar el ciclo de vida de snapshots de volúmenes EBS y no para configurar reglas de acceso o conectividad de red.\n\nReferencia:\n\nhttp://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-network-security.html"
  },
  {
    "q": "Una aplicación se ejecuta en instancias de Amazon EC2 respaldadas por volúmenes de Amazon EBS y una base de datos de Amazon RDS. La aplicación es altamente sensible y los requisitos de cumplimiento de seguridad exigen que toda la información de identificación personal (PII) esté cifrada en reposo.\n¿Qué solución debe elegir un arquitecto de soluciones para cumplir con este requisito?",
    "o": [
      "Habilitar el cifrado en Amazon RDS durante la creación. Usar Amazon Macie para identificar datos sensibles.",
      "Configurar cifrado SSL/TLS usando claves maestras de cliente (CMK) de AWS KMS para cifrar los volúmenes de la base de datos.",
      "Configurar el cifrado de Amazon EBS y el cifrado de Amazon RDS con claves de AWS KMS para cifrar los volúmenes de instancia y base de datos.",
      "Desplegar AWS CloudHSM, generar claves de cifrado y usar la clave maestra de cliente (CMK) para cifrar los volúmenes de la base de datos."
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nConfigurar el cifrado de Amazon EBS y el cifrado de Amazon RDS con claves de AWS KMS para cifrar los volúmenes de instancia y base de datos. - Los datos deben estar cifrados en reposo tanto en los volúmenes EBS adjuntos a la instancia EC2 como en la base de datos RDS. Ambas ubicaciones de almacenamiento pueden cifrarse usando claves de AWS KMS. Con RDS, KMS usa una clave maestra de cliente (CMK) para cifrar la instancia de base de datos, todos los registros, respaldos e instantáneas.\n\nOpciones incorrectas:\n\nHabilitar el cifrado en Amazon RDS durante la creación. Usar Amazon Macie para identificar datos sensibles. - Esta opción no cifra los volúmenes EBS adjuntos a la instancia EC2 y Macie no se puede usar con RDS.\n\nConfigurar cifrado SSL/TLS usando claves maestras de cliente (CMK) de AWS KMS para cifrar los volúmenes de la base de datos. - El cifrado SSL cifra los datos en tránsito pero no en reposo.\n\nDesplegar AWS CloudHSM, generar claves de cifrado y usar la clave maestra de cliente (CMK) para cifrar los volúmenes de la base de datos. - CloudHSM no es necesario para esta solución, y necesitamos cifrar tanto los volúmenes de la base de datos como los volúmenes EBS.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html"
  },
  {
    "q": "Una aplicación de producción se ejecuta en una instancia de base de datos MySQL de Amazon RDS. Un arquitecto de soluciones está construyendo una nueva herramienta de informes que accederá a los mismos datos. La herramienta de informes debe ser altamente disponible y no afectar el rendimiento de la aplicación de producción.\n¿Cómo se puede lograr esto?",
    "o": [
      "Crear una réplica de lectura Multi-AZ de RDS de la instancia de base de datos RDS de producción",
      "Usar Amazon Data Lifecycle Manager para crear y administrar instantáneas automáticamente",
      "Crear un despliegue Multi-AZ entre regiones y crear una réplica de lectura en la segunda región",
      "Crear una réplica de lectura Single-AZ de RDS de la instancia de base de datos RDS de producción. Crear una segunda réplica de lectura Single-AZ de RDS desde la réplica"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nCrear una réplica de lectura Multi-AZ de RDS de la instancia de base de datos RDS de producción - Puede crear una réplica de lectura como una instancia de base de datos Multi-AZ. Amazon RDS crea un standby de su réplica en otra Zona de Disponibilidad para soporte de conmutación por error para la réplica. Crear su réplica de lectura como una instancia de base de datos Multi-AZ es independiente de si la base de datos de origen es una instancia de base de datos Multi-AZ.\n\nOpciones incorrectas:\n\nCrear una réplica de lectura Single-AZ de RDS de la instancia de base de datos RDS de producción. Crear una segunda réplica de lectura Single-AZ de RDS desde la réplica - Las réplicas de lectura se usan principalmente para escalado horizontal. La mejor solución para alta disponibilidad es usar una réplica de lectura Multi-AZ.\n\nUsar Amazon Data Lifecycle Manager para crear y administrar instantáneas automáticamente - Usar instantáneas no es la mejor solución para alta disponibilidad.\n\nCrear un despliegue Multi-AZ entre regiones y crear una réplica de lectura en la segunda región - No se puede crear un despliegue Multi-AZ entre regiones con RDS.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_MySQL.Replication.ReadReplicas.html#USER_MySQL.Replication.ReadReplicas.MultiAZ"
  },
  {
    "q": "Una empresa aeroespacial ha adoptado recientemente una infraestructura híbrida en la nube con AWS. Una de las tareas del arquitecto de soluciones es lanzar una VPC con subnets públicas y privadas para sus instancias EC2, así como para sus instancias de base de datos.\n¿Cuáles de las siguientes afirmaciones son verdaderas con respecto a las subnets en una VPC de Amazon? (Selecciona DOS)",
    "o": [
      "Cada subnet se asigna a una única Availability Zone",
      "El tamaño de bloque permitido en una VPC está entre una máscara de red /16 (65,536 direcciones IP) y /29 (8 direcciones IP)",
      "Las instancias EC2 en una subnet privada pueden comunicarse con Internet solo si tienen una Elastic IP",
      "Cada subnet abarca 3 Availability Zones",
      "Cada subnet que creas está automáticamente asociada con la tabla de rutas principal de la VPC"
    ],
    "a": [
      0,
      4
    ],
    "e": "Correcto:\n\nCada subnet se asigna a una única Availability Zone - Cada subnet dentro de una VPC se asigna a una única Availability Zone. Las Availability Zones son ubicaciones físicas separadas dentro de una región de AWS diseñadas para aislar fallas. Una subnet no puede abarcar múltiples Availability Zones.\n\nCada subnet que creas está automáticamente asociada con la tabla de rutas principal de la VPC - Cada subnet que creas en una VPC se asocia automáticamente con la tabla de rutas principal de la VPC. Esto significa que, a menos que asignes manualmente una subnet a una tabla de rutas diferente, usará la tabla principal.\n\n\n\nOpciones incorrectas:\n\nLas instancias EC2 en una subnet privada pueden comunicarse con Internet solo si tienen una Elastic IP - Las instancias en una subnet privada pueden comunicarse con Internet no solo mediante una Elastic IP, sino también con una IP pública a través de una NAT Gateway o una NAT Instance. Una Elastic IP solo es relevante para instancias en una subnet pública.\n\nCada subnet abarca 3 Availability Zones - Cada subnet se encuentra dentro de una única Availability Zone y no puede abarcar múltiples zonas de disponibilidad. Las subnets están diseñadas para estar contenidas dentro de una zona para garantizar aislamiento y resiliencia.\n\nEl tamaño de bloque permitido en una VPC está entre una máscara de red /16 (65,536 direcciones IP) y /29 (8 direcciones IP) - El rango permitido para los bloques de direcciones IP dentro de una VPC está entre una máscara de red /16 (65,536 direcciones IP) y /28 (16 direcciones IP), no /29.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Subnets.html\n\nhttps://docs.aws.amazon.com/vpc/latest/userguide/vpc-ip-addressing.html"
  },
  {
    "q": "Una empresa planea asignar a cada desarrollador una cuenta personal de AWS mediante AWS Organizations. Para cumplir con normativas, se configurarán reglas de AWS Config en las nuevas cuentas. El arquitecto de soluciones debe asegurarse de que los desarrolladores no puedan eliminar ni modificar ninguna regla de AWS Config.\n¿Cuál es la solución con el menor esfuerzo operativo?",
    "o": [
      "Configurar una regla de AWS Config en la cuenta raíz para detectar si se realizan cambios en las reglas de AWS Config de la nueva cuenta",
      "Agregar la cuenta de AWS de los desarrolladores a una unidad organizativa (OU). Adjuntar una Service Control Policy (SCP) a la OU para restringir el acceso a AWS Config",
      "Usar un rol de IAM en las nuevas cuentas con una relación de confianza adjunta para deshabilitar el acceso del usuario root a AWS Config",
      "Configurar AWS Control Tower en la cuenta raíz para detectar cambios en las reglas de AWS Config de las nuevas cuentas. Adjuntar una relación de confianza IAM al usuario IAM de cada desarrollador para evitar cambios en AWS Config"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nAgregar la cuenta de AWS de los desarrolladores a una unidad organizativa (OU). Adjuntar una Service Control Policy (SCP) a la OU para restringir el acceso a AWS Config - Service Control Policies (SCPs) permiten establecer restricciones a nivel organizacional dentro de AWS Organizations.\n\nAl asociar las cuentas de los desarrolladores a una Organizational Unit (OU) con una SCP que restrinja el acceso a AWS Config, se evita que cualquier usuario modifique sus reglas.\nIncluso si un usuario obtiene permisos administrativos, no podrá modificar las reglas de AWS Config debido a la restricción impuesta por la SCP.\nTambién se puede usar SCP para bloquear el acceso del usuario root, evitando que se eludan las restricciones.\n\n\nOpciones incorrectas:\n\nConfigurar AWS Control Tower en la cuenta raíz para detectar cambios en las reglas de AWS Config de las nuevas cuentas. Adjuntar una relación de confianza IAM al usuario IAM de cada desarrollador para evitar cambios en AWS Config - AWS Control Tower está diseñado para gestionar entornos multi-cuenta de manera segura, pero no restringe accesos a recursos específicos como AWS Config. No es la herramienta adecuada para evitar modificaciones en AWS Config.\n\nConfigurar una regla de AWS Config en la cuenta raíz para detectar si se realizan cambios en las reglas de AWS Config de la nueva cuenta - Configurar una regla de AWS Config en la cuenta raíz solo permite detectar cambios, pero no restringe accesos ni impide modificaciones, por lo que no cumple el objetivo.\n\nUsar un rol de IAM en las nuevas cuentas con una relación de confianza adjunta para deshabilitar el acceso del usuario root a AWS Config - Los roles IAM no pueden restringir el acceso del usuario root. IAM Trust Policies solo definen qué entidades pueden asumir un rol, pero no limitan acciones dentro de una cuenta.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/controltower/latest/userguide/organizations.html\n\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html"
  },
  {
    "q": "Una empresa ha implementado sensores en un centro comercial para monitorear la afluencia de visitantes. Cada sensor transmite datos en tiempo real a un flujo de Amazon Kinesis con la configuración predeterminada.\nUn proceso de consumo está configurado para extraer y analizar los datos cada dos días, pero el equipo ha notado que algunos registros no están siendo almacenados en Amazon S3. Se ha verificado que los sensores están enviando correctamente los datos a Kinesis diariamente.\n¿Cuál podría ser la causa de este problema?",
    "o": [
      "Es posible que tu cuenta de AWS haya sido comprometida y alguien haya eliminado registros en el flujo de Kinesis",
      "Amazon S3 tiene una configuración predeterminada que mueve automáticamente los datos a Amazon Glacier después de un día",
      "Los sensores tienen fallas intermitentes de conexión, lo que impide que algunos datos sean enviados a Kinesis",
      "Por defecto, Amazon Kinesis solo retiene los datos durante 24 horas a menos que se configure una retención extendida"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nPor defecto, Amazon Kinesis solo retiene los datos durante 24 horas a menos que se configure una retención extendida - Por defecto, los registros en Amazon Kinesis están disponibles solo durante 24 horas. Si el consumidor procesa los datos cada dos días, los registros más antiguos se eliminan antes de ser consumidos, lo que resulta en la pérdida de algunos datos antes de que sean almacenados en S3. Para evitar este problema, se puede aumentar el período de retención hasta un máximo de 365 días.\n\n\n\nOpciones incorrectas:\n\nLos sensores tienen fallas intermitentes de conexión, lo que impide que algunos datos sean enviados a Kinesis - Ya se verificó que los sensores están enviando los datos correctamente, por lo que un problema de conexión intermitente no es la causa principal.\n\nAmazon S3 tiene una configuración predeterminada que mueve automáticamente los datos a Amazon Glacier después de un día - Amazon S3 no mueve automáticamente los datos a Amazon Glacier. La administración del ciclo de vida en S3 debe ser configurada explícitamente por el usuario para trasladar objetos a Glacier después de un período determinado.\n\nEs posible que tu cuenta de AWS haya sido comprometida y alguien haya eliminado registros en el flujo de Kinesis - Aunque una brecha de seguridad podría ser una posibilidad, es poco probable sin evidencia de accesos sospechosos o eliminación de datos manual. El problema radica en la configuración predeterminada de retención de datos en Kinesis.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/streams/latest/dev/kinesis-extended-retention.html"
  },
  {
    "q": "Un servidor on-premises utiliza un compartido de archivos SMB para almacenar datos de la aplicación.\nLa aplicación genera 50 MB de datos por día, pero solo necesita acceder a algunos de ellos para procesos diarios.\nPara reducir costos, la empresa planea migrar todos los datos a AWS, pero quiere mantener acceso de baja latencia, similar al compartido de archivos local.\nLa empresa no tiene la capacidad de desarrollar una solución personalizada para esta integración.\n¿Qué servicio de AWS debería usar la empresa?",
    "o": [
      "AWS Virtual Private Network (VPN)",
      "AWS Storage Gateway",
      "AWS Snowball Edge",
      "Amazon FSx for Windows File Server"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nAWS Storage Gateway - AWS Storage Gateway permite crear un File Gateway que soporta SMB y proporciona acceso híbrido entre almacenamiento local y en la nube.\n\n\n\nCaché local: Permite acceso de baja latencia a los datos más utilizados sin necesidad de descargarlos continuamente de AWS.\nAutomatización: Sin necesidad de desarrollo adicional, gestiona la migración de archivos a Amazon S3 mientras mantiene el acceso desde el sistema on-premises.\nOpciones incorrectas:\n\nAWS Snowball Edge - AWS Snowball Edge es una solución de migración masiva de datos, pero no proporciona acceso en tiempo real ni almacenamiento híbrido.\n\nAWS Virtual Private Network (VPN) - AWS VPN establece conexiones seguras entre on-premises y AWS, pero no ofrece integración con sistemas de archivos SMB ni almacenamiento optimizado.\n\nAmazon FSx for Windows File Server - Amazon FSx for Windows File Server es una solución de almacenamiento totalmente en AWS, lo que significa que los datos deben ser accedidos a través de internet. No ofrece almacenamiento en caché local, lo que afectaría la latencia en comparación con Storage Gateway.\n\nReferencias:\n\nhttps://aws.amazon.com/storagegateway/\n\nhttps://docs.aws.amazon.com/storagegateway/latest/userguide/CreatingAnSMBFileShare.html"
  },
  {
    "q": "Una nueva plataforma de banca en línea ha sido rediseñada para tener una arquitectura de microservicios en la que las aplicaciones complejas se descomponen en servicios más pequeños e independientes. La nueva plataforma utiliza Kubernetes y los contenedores de la aplicación están optimizados para ejecutar servicios pequeños y desacoplados.\nLa nueva solución debe eliminar la necesidad de aprovisionar y administrar servidores, permitir especificar y pagar solo por los recursos utilizados por la aplicación y mejorar la seguridad mediante aislamiento a nivel de aplicación.\n¿Cuál de las siguientes es la solución más adecuada para implementar esta nueva plataforma en AWS?",
    "o": [
      "Implementar un clúster de Amazon EKS en AWS Outposts con Kubernetes Cluster Autoscaler y sincronizar los pods huérfanos con Amazon AppFlow",
      "Utilizar AWS Fargate en Amazon EKS con Service Auto Scaling para ejecutar la plataforma bancaria basada en contenedores",
      "Alojar la aplicación en Amazon EMR Serverless y un almacenamiento EBS con la función de restauración rápida de snapshots habilitada",
      "Usar Amazon ECS para ejecutar el clúster de Kubernetes en AWS Fargate"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nUtilizar AWS Fargate en Amazon EKS con Service Auto Scaling para ejecutar la plataforma bancaria basada en contenedores - AWS Fargate en Amazon EKS con Service Auto Scaling es la mejor opción porque elimina la necesidad de aprovisionar y administrar servidores, permite pagar solo por los recursos utilizados y mejora la seguridad mediante el aislamiento de aplicaciones. Fargate asigna automáticamente la cantidad correcta de recursos de cómputo y escala la capacidad del clúster de manera eficiente, cumpliendo con los requisitos de la arquitectura de microservicios basada en Kubernetes.\n\n\n\nOpciones incorrectas:\n\nImplementar un clúster de Amazon EKS en AWS Outposts con Kubernetes Cluster Autoscaler y sincronizar los pods huérfanos con Amazon AppFlow - Implementar un clúster de Amazon EKS en AWS Outposts con Kubernetes Cluster Autoscaler no es adecuado, ya que AWS Outposts requiere mantener un servidor físico en las instalaciones, lo que contradice el requisito de eliminar la necesidad de administrar servidores. Además, Amazon AppFlow se usa para integrar soluciones SaaS con servicios de AWS, no para manejar pods huérfanos en Kubernetes.\n\nAlojar la aplicación en Amazon EMR Serverless y un almacenamiento EBS con la función de restauración rápida de snapshots habilitada - Amazon EMR Serverless está diseñado para cargas de trabajo de big data y procesamiento distribuido, no para ejecutar aplicaciones basadas en Kubernetes. Además, la función de restauración rápida de snapshots en EBS es irrelevante en este escenario, ya que no hay un requisito de replicación de datos ni de alta recuperación ante desastres (RTO/RPO).\n\nUsar Amazon ECS para ejecutar el clúster de Kubernetes en AWS Fargate - Amazon ECS está diseñado principalmente para ejecutar contenedores Docker sin Kubernetes. La opción correcta para Kubernetes es Amazon EKS con Fargate.\n\nReferencias:\n\nhttps://aws.amazon.com/fargate/\n\nhttps://docs.aws.amazon.com/AmazonECS/latest/developerguide/ECS_GetStarted_Fargate.html"
  },
  {
    "q": "Una base de datos MySQL en producción alojada en Amazon RDS se está quedando sin espacio en disco. La gerencia ha consultado al arquitecto de soluciones para aumentar la capacidad de almacenamiento sin afectar el rendimiento de la base de datos.\n¿Cómo puede el arquitecto de soluciones satisfacer este requisito con el menor esfuerzo operativo?",
    "o": [
      "Modificar la configuración de la instancia de base de datos y habilitar el autoscaling de almacenamiento",
      "Modificar el tipo de almacenamiento de la instancia de base de datos a Provisioned IOPS",
      "Cambiar el default_storage_engine del grupo de parámetros de la instancia de base de datos a MyISAM",
      "Aumentar el almacenamiento asignado para la instancia de base de datos"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nModificar la configuración de la instancia de base de datos y habilitar el autoscaling de almacenamiento - La mejor opción con el menor esfuerzo operativo es habilitar RDS Storage Auto Scaling. Este servicio supervisa automáticamente el consumo de almacenamiento y ajusta la capacidad sin tiempos de inactividad cuando la utilización se acerca al límite provisionado. Se puede activar con unos pocos clics en la consola de administración de AWS y no tiene costos adicionales más allá del almacenamiento utilizado.\n\nOpciones incorrectas:\n\nCambiar el default_storage_engine del grupo de parámetros de la instancia de base de datos a MyISAM - Cambiar el default_storage_engine a MyISAM no aumenta el espacio en disco. Este parámetro solo cambia el motor de almacenamiento predeterminado de MySQL, lo que no resuelve el problema de capacidad.\n\nAumentar el almacenamiento asignado para la instancia de base de datos - Aumentar el almacenamiento asignado para la instancia resolvería el problema de espacio en disco, pero podría causar degradación del rendimiento temporalmente mientras la instancia se ajusta al nuevo almacenamiento.\n\nModificar el tipo de almacenamiento de la instancia de base de datos a Provisioned IOPS - Cambiar el tipo de almacenamiento a Provisioned IOPS puede mejorar el rendimiento de la base de datos, pero no resuelve directamente el problema de falta de almacenamiento. Provisioned IOPS está diseñado para aplicaciones con requisitos de alta velocidad de entrada/salida, no para escalabilidad automática del almacenamiento.\n\nReferencias:\n\nhttps://aws.amazon.com/about-aws/whats-new/2019/06/rds-storage-auto-scaling/\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PIOPS.StorageTypes.html#USER_PIOPS_Autoscaling"
  },
  {
    "q": "En Amazon EC2, puedes administrar tus instancias desde el momento en que las inicias hasta su terminación. Para optimizar costos, es importante conocer cómo se facturan los distintos estados de una instancia EC2.\n¿Cuáles de las siguientes afirmaciones son correctas con respecto a la facturación de EC2? (Selecciona DOS)",
    "o": [
      "No se te cobrará si la instancia EC2 no está en estado 'running', independientemente de si está en 'stopping' o 'stopped'",
      "Las instancias reservadas continúan generando costos incluso si están en estado 'terminated', hasta que finalice el período de reserva contratado",
      "Se te cobrará cuando una instancia Spot esté en estado 'stopping', esperando ser terminada por AWS",
      "Si una instancia On-Demand entra en estado 'stopping' debido a que está hibernando, seguirá generando costos",
      "Se te cobrará cuando tu instancia On-Demand esté en estado 'pending' antes de entrar en 'running'"
    ],
    "a": [
      1,
      3
    ],
    "e": "Correcto:\n\nLas instancias reservadas continúan generando costos incluso si están en estado 'terminated', hasta que finalice el período de reserva contratado - Las instancias reservadas generan costos durante todo el período contratado, independientemente de si están activas o terminadas. AWS cobra por estas instancias en función del compromiso adquirido al momento de la compra, por lo que, incluso si la instancia está en estado \"terminated\", el costo se mantiene hasta que termine el contrato.\n\nSi una instancia On-Demand entra en estado 'stopping' debido a que está hibernando, seguirá generando costos - Si una instancia On-Demand entra en estado \"stopping\" debido a que está en proceso de hibernación, seguirá generando costos. Esto se debe a que la RAM se conserva en almacenamiento EBS y AWS sigue cobrando por esta reserva de recursos.\n\n\n\nOpciones incorrectas:\n\nSe te cobrará cuando tu instancia On-Demand esté en estado 'pending' antes de entrar en 'running' - AWS no cobra cuando una instancia está en estado \"pending\", ya que el cobro solo comienza cuando la instancia entra en estado \"running\".\n\nNo se te cobrará si la instancia EC2 no está en estado 'running', independientemente de si está en 'stopping' o 'stopped' - No siempre es cierto que una instancia en \"stopping\" o \"stopped\" no genera costos. Si la instancia está hibernando, seguirá generando costos por la RAM reservada.\n\nSe te cobrará cuando una instancia Spot esté en estado 'stopping', esperando ser terminada por AWS - Cuando una instancia Spot está en estado \"stopping\" debido a una interrupción por parte de AWS, el cobro finaliza, ya que AWS no factura por tiempo no utilizado en instancias Spot.\n\nReferencias:\n\nhttps://github.com/awsdocs/amazon-ec2-user-guide/pull/45\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-lifecycle.html"
  },
  {
    "q": "Una corporación tiene un servicio de juegos multijugador basado en web que opera usando protocolos TCP y UDP. Amazon Route 53 se emplea actualmente para dirigir el tráfico de la aplicación a un conjunto de Network Load Balancers (NLBs) en varias Regiones de AWS. Para prepararse para un aumento en la actividad de usuarios, la empresa debe mejorar el rendimiento de la aplicación y reducir la latencia.\n¿Qué enfoque cumplirá mejor estos requisitos?",
    "o": [
      "Implementar AWS Global Accelerator delante de los NLBs y alinear el endpoint de Global Accelerator para usar los puertos de listener apropiados.",
      "Incorporar Amazon CloudFront delante de los NLBs y extender la duración de la directiva Cache-Control max-age.",
      "Sustituir los NLBs con Application Load Balancers (ALBs) y configurar Route 53 para utilizar enrutamiento basado en latencia.",
      "Insertar un endpoint de Amazon API Gateway detrás de los NLBs, habilitar el almacenamiento en caché de API y personalizar el almacenamiento en caché de métodos en diferentes etapas."
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nImplementar AWS Global Accelerator delante de los NLBs y alinear el endpoint de Global Accelerator para usar los puertos de listener apropiados. - AWS Global Accelerator está diseñado para mejorar la disponibilidad y el rendimiento de sus aplicaciones para usuarios locales y globales. Dirige el tráfico a endpoints óptimos a través de la red global de AWS, mejorando así el rendimiento de su tráfico TCP y UDP al enrutar paquetes a través de la infraestructura de red global de AWS, reduciendo el jitter y mejorando el rendimiento general del juego.\n\nOpciones incorrectas:\n\nSustituir los NLBs con Application Load Balancers (ALBs) y configurar Route 53 para utilizar enrutamiento basado en latencia. - Los Application Load Balancers (ALBs) son balanceadores de carga de capa 7 y no admiten el manejo de tráfico TCP y UDP sin procesar, que es un requisito para la aplicación de juegos en la pregunta. Los NLBs, por otro lado, son adecuados para necesidades de rendimiento extremo y para tráfico TCP/UDP.\n\nInsertar un endpoint de Amazon API Gateway detrás de los NLBs, habilitar el almacenamiento en caché de API y personalizar el almacenamiento en caché de métodos en diferentes etapas. - Aunque API Gateway agregaría más control y seguridad a la aplicación, la característica de almacenamiento en caché no es necesariamente beneficiosa para este escenario de juegos en tiempo real donde el contenido probablemente cambie con frecuencia e impredeciblemente.\n\nIncorporar Amazon CloudFront delante de los NLBs y extender la duración de la directiva Cache-Control max-age. - Amazon CloudFront es una red de entrega de contenido (CDN) que acelera la entrega de su contenido web estático y dinámico. Aunque podría ayudar potencialmente con el rendimiento de la aplicación, no mejora directamente el rendimiento TCP/UDP, que es el requisito específico en este caso.\n\nReferencias:\n\nhttps://aws.amazon.com/global-accelerator/"
  },
  {
    "q": "Una empresa tiene algunos datos estadísticos almacenados en una base de datos de Amazon RDS. La empresa quiere permitir que los usuarios accedan a esta información usando una API. Un arquitecto de soluciones debe crear una solución que permita acceso esporádico a los datos, que va desde ninguna solicitud hasta grandes ráfagas de tráfico.\n¿Qué solución debe sugerir el arquitecto de soluciones?",
    "o": [
      "Configurar un Amazon API Gateway y usar Amazon ECS",
      "Configurar un Amazon API Gateway y usar Amazon EC2 con Auto Scaling",
      "Configurar un Amazon API Gateway y usar funciones de AWS Lambda",
      "Configurar un Amazon API Gateway y usar AWS Elastic Beanstalk"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nConfigurar un Amazon API Gateway y usar funciones de AWS Lambda - Esta pregunta simplemente está pidiendo que se determine el mejor servicio de cómputo para los requisitos establecidos. Los requisitos clave son que el servicio de cómputo debe ser adecuado para una carga de trabajo que puede variar bastante ampliamente en demanda, desde ninguna solicitud hasta grandes ráfagas de tráfico.\n\nAWS Lambda es una solución ideal ya que solo paga cuando se realizan solicitudes y puede escalar fácilmente para acomodar las grandes ráfagas de tráfico. Lambda funciona bien tanto con API Gateway como con Amazon RDS.\n\nOpciones incorrectas:\n\nConfigurar un Amazon API Gateway y usar AWS Elastic Beanstalk - AWS Elastic Beanstalk requiere administración de servidores y no es tan eficiente para cargas de trabajo esporádicas como Lambda.\n\nConfigurar un Amazon API Gateway y usar Amazon EC2 con Auto Scaling - Amazon EC2 con Auto Scaling requiere administración de instancias y no es tan eficiente para cargas de trabajo esporádicas como Lambda.\n\nConfigurar un Amazon API Gateway y usar Amazon ECS - Amazon ECS requiere administración de contenedores y no escala tan eficientemente como Lambda para cargas de trabajo esporádicas.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/lambda/latest/dg/invocation-scaling.html"
  },
  {
    "q": "Una empresa de tecnología ha estado ejecutando varias instancias EC2 reservadas para alojar una plataforma de análisis de datos. Debido a un cambio en los objetivos de negocio, la plataforma fue descontinuada la semana pasada. La empresa ahora busca minimizar costos y deshacerse de estas instancias reservadas lo antes posible.\n¿Qué acciones rentables debe tomar el equipo de AWS para optimizar los costos en esta situación? (Selecciona DOS)",
    "o": [
      "Terminar las instancias reservadas para evitar que, una vez vencida la reserva, sean facturadas como instancias On-Demand",
      "Intentar vender las instancias reservadas en una plataforma de terceros fuera de AWS",
      "Detener las instancias reservadas lo antes posible para reducir costos",
      "Publicar las instancias reservadas en el AWS Reserved Instance Marketplace para revenderlas",
      "Solicitar a AWS la cancelación anticipada de la reserva"
    ],
    "a": [
      0,
      3
    ],
    "e": "Correcto:\n\nPublicar las instancias reservadas en el AWS Reserved Instance Marketplace para revenderlas - AWS Reserved Instance Marketplace permite a los clientes vender instancias reservadas que ya no necesitan. Esto es una manera efectiva de recuperar parte de la inversión si la instancia ya no es requerida antes de que termine el plazo del contrato.\n\nTerminar las instancias reservadas para evitar que, una vez vencida la reserva, sean facturadas como instancias On-Demand - **Finalizar las instancias reservadas ayuda a evitar que, cuando expire la reserva, las instancias sean facturadas como On-Demand, lo que es más costoso. Como la plataforma ya fue descontinuada, mantener estas instancias activas solo genera costos innecesarios.\n\nOpciones incorrectas:\n\nIntentar vender las instancias reservadas en una plataforma de terceros fuera de AWS - AWS no permite vender instancias reservadas en plataformas externas. El único canal autorizado para revenderlas es el AWS Reserved Instance Marketplace.\n\nDetener las instancias reservadas lo antes posible para reducir costos - Detener las instancias reservadas no elimina sus costos. Aunque estén detenidas, la empresa seguirá pagando por la reserva. Además, si la instancia tiene direcciones IP elásticas o volúmenes EBS adjuntos, estos seguirán generando costos.\n\nSolicitar a AWS la cancelación anticipada de la reserva - AWS no ofrece la opción de cancelar una reserva de instancias EC2 antes de que termine su período contratado. La única opción viable es revenderlas en el Marketplace.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ri-market-general.html\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-lifecycle.html"
  },
  {
    "q": "Una empresa de comercio electrónico utiliza Auto Scaling para gestionar la capacidad de su infraestructura en AWS. Recientemente, el equipo de operaciones ha creado una nueva Amazon Machine Image (AMI) con mejoras de seguridad y rendimiento.\nEl equipo ahora necesita asegurarse de que todas las nuevas instancias EC2 lanzadas a través del Auto Scaling Group utilicen esta nueva AMI.\n¿Qué cambio debe realizarse?",
    "o": [
      "No hacer nada. El Auto Scaling Group actualizará automáticamente las instancias con la nueva AMI",
      "Crear un nuevo target group y una nueva launch template",
      "Crear una nueva launch template con la nueva AMI y asociarla al Auto Scaling Group",
      "Crear un nuevo target group para que las instancias EC2 usen la nueva AMI"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nCrear una nueva launch template con la nueva AMI y asociarla al Auto Scaling Group - En un Auto Scaling Group, las instancias EC2 se lanzan utilizando una launch template. Dado que una launch template no se puede modificar después de ser creada, es necesario generar una nueva que incluya la nueva AMI y luego actualizar el Auto Scaling Group para utilizar esta nueva configuración.\n\n\n\nOpciones incorrectas:\n\nCrear un nuevo target group para que las instancias EC2 usen la nueva AMI - Los target groups se utilizan para la integración con Elastic Load Balancers (ELB) y no afectan la configuración de lanzamiento de instancias en Auto Scaling. No es necesario crear un nuevo target group solo para actualizar la AMI.\n\nNo hacer nada. El Auto Scaling Group actualizará automáticamente las instancias con la nueva AMI - Auto Scaling no actualiza automáticamente las instancias existentes con una nueva AMI. Es necesario crear una nueva launch template y actualizar el Auto Scaling Group para que las nuevas instancias utilicen la AMI actualizada.\n\nCrear un nuevo target group y una nueva launch template - No es necesario crear un nuevo target group. Solo es necesario actualizar la launch template para que las nuevas instancias EC2 usen la nueva AMI.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/launch-templates.html\n\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/AutoScalingGroup.html"
  },
  {
    "q": "Una empresa necesita asegurar que pueda realizar una conmutación por error entre Regiones de AWS en caso de un desastre de manera fluida con tiempo de inactividad y pérdida de datos mínimos. Las aplicaciones se ejecutarán en una configuración activa-activa.\n¿Qué estrategia de recuperación ante desastres (DR) debe recomendar un arquitecto de soluciones?",
    "o": [
      "Pilot light (Luz piloto)",
      "Multi-site (Multi-sitio)",
      "Warm standby (Reserva en caliente)",
      "Backup and restore (Respaldo y restauración)"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nMulti-site (Multi-sitio) - Una solución multi-site se ejecuta en AWS así como en su infraestructura on-site existente en una configuración activa-activa. El método de replicación de datos que emplee estará determinado por el punto de recuperación que elija. Esto es el Objetivo de Tiempo de Recuperación (RTO - el tiempo máximo de inactividad permitido antes de que se restauren las operaciones degradadas) o el Objetivo de Punto de Recuperación (RPO - la ventana de tiempo máxima permitida en la que aceptará la pérdida de transacciones durante el proceso de DR).\n\nOpciones incorrectas:\n\nPilot light (Luz piloto) - Con una estrategia de luz piloto, un mínimo esencial de servicios están en ejecución y el resto solo se pone en línea durante una situación de recuperación ante desastres.\n\nWarm standby (Reserva en caliente) - El término reserva en caliente se usa para describir un escenario de DR en el que una versión reducida de un entorno completamente funcional siempre está en ejecución en la nube.\n\nBackup and restore (Respaldo y restauración) - Este es el enfoque de DR de menor costo que simplemente implica crear respaldos en línea de todos los datos y aplicaciones.\n\nReferencias:\n\nhttps://aws.amazon.com/blogs/publicsector/rapidly-recover-mission-critical-systems-in-a-disaster/"
  },
  {
    "q": "Una empresa ha lanzado un juego móvil multijugador basado en Realidad Virtual (VR), con un backend serverless en AWS. El backend utiliza una tabla de Amazon DynamoDB para almacenar los perfiles y puntuaciones de los jugadores, y una función Lambda para procesar las solicitudes de los usuarios. Dado que el juego ha alcanzado millones de usuarios activos diarios, el arquitecto de soluciones necesita optimizar la escalabilidad y el rendimiento del sistema mientras mantiene los costos bajo control.\n¿Cuáles son las mejores estrategias para lograr esto? (Selecciona DOS)",
    "o": [
      "Configurar CloudFront con DynamoDB como origen y almacenar en caché los datos de acceso frecuente en ElastiCache en el dispositivo del usuario",
      "Usar API Gateway con AWS Lambda y habilitar caching en los datos de acceso frecuente, además de activar la replicación global de DynamoDB",
      "Permitir a los jugadores acceder directamente a DynamoDB mediante IAM Identity Center (SSO) y ajustar manualmente la capacidad de lectura y escritura aprovisionada",
      "Confiar en la capacidad de Auto Scaling predeterminada de DynamoDB y habilitar DynamoDB Accelerator (DAX) para mejorar la latencia",
      "Habilitar DynamoDB Accelerator (DAX) y asegurarse de que Auto Scaling esté activado para gestionar la capacidad de lectura y escritura de forma dinámica"
    ],
    "a": [
      1,
      4
    ],
    "e": "Correcto:\n\nHabilitar DynamoDB Accelerator (DAX) y asegurarse de que Auto Scaling esté activado para gestionar la capacidad de lectura y escritura de forma dinámica - Habilitar DynamoDB Accelerator (DAX) mejora significativamente el rendimiento de lectura al almacenar en caché las consultas más frecuentes, reduciendo la latencia de milisegundos a microsegundos. Activar Auto Scaling permite ajustar la capacidad de DynamoDB de manera automática según la carga del tráfico del juego, evitando problemas de rendimiento y sobrecostos.\n\nUsar API Gateway con AWS Lambda y habilitar caching en los datos de acceso frecuente, además de activar la replicación global de DynamoDB - API Gateway junto con AWS Lambda permite manejar altas cargas de solicitudes sin administrar servidores. Además, habilitar el caching en API Gateway reduce la cantidad de llamadas directas a DynamoDB, mejorando la velocidad y reduciendo costos. Activar DynamoDB Global Tables replica los datos en múltiples regiones, optimizando el rendimiento para jugadores distribuidos globalmente.\n\nOpciones incorrectas:\n\nConfigurar CloudFront con DynamoDB como origen y almacenar en caché los datos de acceso frecuente en ElastiCache en el dispositivo del usuario - CloudFront no puede utilizar DynamoDB como origen, ya que es una CDN diseñada para contenido web estático y dinámico, mientras que DynamoDB es una base de datos NoSQL.\n\nPermitir a los jugadores acceder directamente a DynamoDB mediante IAM Identity Center (SSO) y ajustar manualmente la capacidad de lectura y escritura aprovisionada - Permitir a los jugadores acceder directamente a DynamoDB mediante IAM Identity Center (SSO) no es una estrategia viable, ya que introduce riesgos de seguridad y no optimiza el rendimiento del backend. Además, administrar manualmente la capacidad de lectura y escritura no es una solución escalable.\n\nConfiar en la capacidad de Auto Scaling predeterminada de DynamoDB y habilitar DynamoDB Accelerator (DAX) para mejorar la latencia - Auto Scaling no está activado por defecto en DynamoDB; debe configurarse explícitamente. Aunque DAX mejora la latencia, no elimina la necesidad de gestionar adecuadamente la escalabilidad de la base de datos.\n\nReferencias:\n\nhttps://aws.amazon.com/lambda/faqs/\n\nhttps://aws.amazon.com/api-gateway/faqs/\n\nhttps://aws.amazon.com/dynamodb/dax/"
  },
  {
    "q": "Una empresa de comercio electrónico está experimentando un crecimiento acelerado en su plataforma de ventas en línea, la cual utiliza un clúster de Amazon ECS con AWS Fargate y Amazon Aurora. Se espera que la cantidad de consultas de lectura a la base de datos aumente significativamente debido a la temporada de descuentos. Para escalar la carga de trabajo, un arquitecto de soluciones ha lanzado recientemente dos Read Replicas en el clúster de base de datos.\n¿Cuál de las siguientes configuraciones es la más adecuada para balancear automáticamente las solicitudes de lectura entrantes de manera equitativa entre las Read Replicas?",
    "o": [
      "Habilitar Amazon Aurora Parallel Query",
      "Utilizar el endpoint de lectura (Reader Endpoint) integrado de Amazon Aurora",
      "Utilizar el endpoint del clúster (Cluster Endpoint) integrado de Amazon Aurora",
      "Crear un nuevo Network Load Balancer para distribuir equitativamente las consultas de lectura a las Read Replicas de Amazon Aurora"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nUtilizar el endpoint de lectura (Reader Endpoint) integrado de Amazon Aurora - El endpoint de lectura (Reader Endpoint) de Amazon Aurora permite balancear automáticamente la carga de trabajo de lectura en todas las Read Replicas disponibles. Este endpoint dirige las consultas SELECT de manera equitativa entre las réplicas, asegurando una mejor distribución de carga y reduciendo la presión sobre la instancia primaria.\n\nOpciones incorrectas:\n\nHabilitar Amazon Aurora Parallel Query - Aurora Parallel Query mejora la ejecución de una sola consulta compleja al distribuir su carga en múltiples nodos de almacenamiento, pero no balancea la carga entre múltiples Read Replicas, por lo que no cumple con el objetivo del escenario.\n\nCrear un nuevo Network Load Balancer para distribuir equitativamente las consultas de lectura a las Read Replicas de Amazon Aurora - Network Load Balancer (NLB) está diseñado para distribuir tráfico de red, no consultas de bases de datos. Aurora ya tiene un mecanismo nativo para balanceo de carga mediante el Reader Endpoint.\n\nUtilizar el endpoint del clúster (Cluster Endpoint) integrado de Amazon Aurora - El Cluster Endpoint solo apunta a la instancia primaria del clúster, lo que es ideal para operaciones de escritura pero no para distribuir consultas de lectura entre Read Replicas.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Overview.Endpoints.html\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Overview.html\n\nhttps://aws.amazon.com/rds/aurora/parallel-query/"
  },
  {
    "q": "Una empresa de viajes tiene un conjunto de aplicaciones web alojadas en un grupo de Auto Scaling de instancias EC2 bajo un Application Load Balancer (ALB) que maneja tráfico de varios dominios web como explore-paris.com, discover-tokyo.com, visit-barcelona.com y muchos otros. Para mejorar la seguridad y reducir costos operativos, se te ha pedido que asegures el tráfico SSL permitiendo múltiples dominios sin necesidad de volver a autenticar y reprovisionar el certificado cada vez que se agregue un nuevo dominio. Esta migración de HTTP a HTTPS también ayudará a mejorar su SEO y el ranking en Google.\n¿Cuál de las siguientes es la solución más rentable para cumplir con este requisito?",
    "o": [
      "Agregar un Subject Alternative Name (SAN) para cada dominio adicional en tu certificado",
      "Usar un certificado wildcard para manejar múltiples subdominios y diferentes dominios",
      "Cargar todos los certificados SSL de los dominios en el ALB utilizando la consola y vincular múltiples certificados al mismo listener seguro en el load balancer. ALB seleccionará automáticamente el certificado TLS óptimo para cada cliente utilizando Server Name Indication (SNI)",
      "Crear una nueva distribución de CloudFront y configurarla para atender solicitudes HTTPS utilizando direcciones IP dedicadas para asociar los nombres de dominio alternativos con una dirección IP dedicada en cada ubicación perimetral de CloudFront"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nCargar todos los certificados SSL de los dominios en el ALB utilizando la consola y vincular múltiples certificados al mismo listener seguro en el load balancer. ALB seleccionará automáticamente el certificado TLS óptimo para cada cliente utilizando Server Name Indication (SNI) - La mejor opción es cargar los certificados SSL en el ALB y vincular múltiples certificados al mismo listener seguro utilizando Server Name Indication (SNI). SNI permite que un solo ALB maneje múltiples dominios con diferentes certificados sin necesidad de direcciones IP dedicadas ni reprovisionamiento constante. ALB elegirá automáticamente el certificado adecuado para cada cliente.\n\nOpciones incorrectas:\n\nUsar un certificado wildcard para manejar múltiples subdominios y diferentes dominios - Un certificado wildcard solo puede manejar múltiples subdominios dentro de un mismo dominio (ejemplo.explore-paris.com), pero no dominios completamente diferentes (explore-paris.com y discover-tokyo.com). No cumple con el requisito del escenario.\n\nCrear una nueva distribución de CloudFront y configurarla para atender solicitudes HTTPS utilizando direcciones IP dedicadas para asociar los nombres de dominio alternativos con una dirección IP dedicada en cada ubicación perimetral de CloudFront - Configurar CloudFront para atender solicitudes HTTPS con direcciones IP dedicadas es una opción válida, pero no es rentable. CloudFront cobra tarifas adicionales por el uso de direcciones IP dedicadas y asociar certificados SSL/TLS con una distribución de CloudFront. Utilizar SNI con ALB es una alternativa más eficiente y sin costo adicional.\n\nAgregar un Subject Alternative Name (SAN) para cada dominio adicional en tu certificado - Agregar Subject Alternative Names (SAN) en un certificado es correcto técnicamente, pero cada vez que se agregue un nuevo dominio se requerirá reprovisionar y volver a autenticar el certificado. Dado que uno de los requisitos es evitar este proceso, esta opción no es la más adecuada.\n\nReferencias:\n\nhttps://aws.amazon.com/blogs/aws/new-application-load-balancer-sni/\n\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/cnames-https-dedicated-ip-or-sni.html\n\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/application/create-https-listener.html"
  },
  {
    "q": "La empresa de medios para la que trabajas tiene una aplicación de transcodificación de video que se ejecuta en Amazon EC2. Cada instancia de EC2 consulta una cola para determinar qué video debe ser transcodificado y luego ejecuta el proceso de transcodificación. Si este proceso se interrumpe, el video será transcodificado por otra instancia según el sistema de colas.\nEsta aplicación tiene una gran acumulación de videos que necesitan ser transcodificados. Tu gerente quiere reducir esta acumulación agregando más instancias de EC2, sin embargo, estas instancias solo se necesitan hasta que se reduzca la acumulación.\nEn este escenario, ¿qué tipo de instancia de Amazon EC2 es la opción más rentable?",
    "o": [
      "Instancias dedicadas",
      "Instancias reservadas",
      "Instancias Spot",
      "Instancias bajo demanda"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nInstancias Spot - Las instancias Spot de Amazon EC2 son la opción más rentable para este caso, ya que ofrecen capacidad computacional a precios con grandes descuentos en comparación con las instancias bajo demanda. Dado que la aplicación puede manejar la terminación inesperada de instancias (debido a que los trabajos interrumpidos pueden ser retomados por otra instancia en la cola), las instancias Spot son ideales para reducir costos y escalar temporalmente la capacidad de procesamiento hasta que la acumulación de videos disminuya.\n\n\n\nOpciones incorrectas:\n\nInstancias reservadas - Las instancias reservadas están diseñadas para cargas de trabajo constantes y de largo plazo, donde se requiere capacidad computacional garantizada. No son adecuadas para un escenario en el que las instancias solo se necesitan temporalmente y no se requiere disponibilidad continua.\n\nInstancias dedicadas - Las instancias dedicadas están reservadas para casos en los que se requiere aislamiento físico de hardware, lo cual no es necesario en este escenario. Además, son más costosas que otras opciones y no ofrecen ventajas en términos de escalabilidad temporal para la transcodificación de videos.\n\nInstancias bajo demanda - Las instancias bajo demanda son una opción válida, pero tienen un costo significativamente más alto en comparación con las instancias Spot. Dado que la aplicación puede manejar interrupciones, no hay necesidad de pagar por instancias bajo demanda cuando las instancias Spot pueden realizar el mismo trabajo a un costo mucho menor.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-interruptions.html\n\nhttp://docs.aws.amazon.com/AWSEC2/latest/UserGuide/how-spot-instances-work.html\n\nhttps://aws.amazon.com/blogs/compute/new-amazon-ec2-spot-pricing"
  },
  {
    "q": "Una plataforma global de streaming de contenido ha desplegado su infraestructura en AWS y espera un tráfico masivo de usuarios conectándose desde diversas regiones del mundo. El servicio debe estar disponible las 24 horas del día, los 7 días de la semana, sin interrupciones. Además, la arquitectura debe ser lo suficientemente resiliente para soportar la caída de una región completa de AWS sin afectar la experiencia del usuario. Para cumplir con este requisito, el arquitecto de soluciones ha distribuido los recursos en múltiples regiones de AWS y necesita configurar Route 53 para garantizar la máxima disponibilidad. Cuando un recurso se vuelva no saludable, Route 53 debe detectarlo y dejar de incluirlo en las respuestas a las consultas DNS.\n¿Cuál de las siguientes configuraciones de enrutamiento es la más tolerante a fallos que debería utilizar el arquitecto de soluciones en este escenario?",
    "o": [
      "Configurar un Active-Passive Failover con registros ponderados",
      "Configurar un Active-Passive Failover con múltiples recursos primarios y secundarios",
      "Configurar un Active-Active Failover con una política de enrutamiento ponderado",
      "Configurar un Active-Active Failover con un recurso primario y un recurso secundario"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nConfigurar un Active-Active Failover con una política de enrutamiento ponderado - La configuración de Active-Active Failover con una política de enrutamiento ponderado es la opción correcta, ya que permite que todos los recursos estén activos al mismo tiempo. Route 53 supervisará la salud de cada recurso y excluirá los que se vuelvan no saludables. Esto proporciona una alta disponibilidad y resistencia ante fallos, ya que no hay dependencia de un recurso primario o secundario, sino que todos los recursos se utilizan en paralelo.\n\nOpciones incorrectas:\n\nConfigurar un Active-Passive Failover con múltiples recursos primarios y secundarios - Un Active-Passive Failover con múltiples recursos primarios y secundarios no es ideal en este caso, ya que la solución requiere que todos los recursos estén activos simultáneamente. Active-Passive está diseñado para situaciones donde solo los recursos primarios están activos y los secundarios permanecen en espera.\n\nConfigurar un Active-Active Failover con un recurso primario y un recurso secundario - No se puede configurar un Active-Active Failover con un solo recurso primario y un solo recurso secundario, ya que en un Active-Active todos los recursos deben estar disponibles simultáneamente sin una jerarquía de primarios y secundarios.\n\nConfigurar un Active-Passive Failover con registros ponderados - Un Active-Passive Failover con registros ponderados no cumple con el requisito del escenario porque Active-Passive implica que solo los recursos primarios estarán activos mientras los secundarios permanecen en espera. En este caso, se requiere que todos los recursos estén activos todo el tiempo, lo que solo es posible con Active-Active Failover.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-types.html\n\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html\n\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-configuring.html"
  },
  {
    "q": "Una empresa almacena reportes financieros y documentos legales en un bucket de Amazon S3. Para cumplir con una auditoría de seguridad, se ha asignado al arquitecto de soluciones la tarea de rastrear todos los objetos nuevos agregados al bucket y aquellos eliminados. También debe detectar cuando un objeto versionado es eliminado permanentemente.\nEl arquitecto debe configurar Amazon S3 para enviar notificaciones de estos eventos a una cola para procesamiento automático y a un tema de SNS para notificar al equipo de cumplimiento.\n¿Cuál de las siguientes opciones es la más adecuada para que el arquitecto implemente?",
    "o": [
      "Crear un nuevo Amazon SNS topic y una Amazon SQS queue. Agregar una configuración de notificación de eventos en el bucket de S3 para publicar los eventos s3:ObjectCreated: y s3:ObjectRemoved:Delete en SQS y SNS",
      "Crear un nuevo Amazon SNS topic y Amazon MQ. Agregar una configuración de notificación de eventos en el bucket de S3 para publicar los eventos s3:ObjectCreated: y s3:ObjectRemoved:DeleteMarkerCreated en SQS y SNS",
      "Crear un nuevo Amazon SNS topic y Amazon MQ. Agregar una configuración de notificación de eventos en el bucket de S3 para publicar los eventos s3:ObjectAdded: y s3:ObjectRemoved: en SQS y SNS",
      "Crear un nuevo Amazon SNS topic y una Amazon SQS queue. Agregar una configuración de notificación de eventos en el bucket de S3 para publicar los eventos s3:ObjectCreated: y s3:ObjectRemoved:DeleteMarkerCreated"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nCrear un nuevo Amazon SNS topic y una Amazon SQS queue. Agregar una configuración de notificación de eventos en el bucket de S3 para publicar los eventos s3:ObjectCreated: y s3:ObjectRemoved:Delete en SQS y SNS - La mejor solución es configurar Amazon SNS y Amazon SQS para recibir notificaciones de eventos generados en S3. El bucket de S3 debe publicar eventos cuando se crea un objeto (s3:ObjectCreated:*) y cuando se elimina un objeto (s3:ObjectRemoved:Delete).\n\n\n\n\n\nOpciones incorrectas:\n\nCrear un nuevo Amazon SNS topic y Amazon MQ. Agregar una configuración de notificación de eventos en el bucket de S3 para publicar los eventos s3:ObjectAdded: y s3:ObjectRemoved: en SQS y SNS - El evento \"s3:ObjectAdded:*\" no existe en S3. Además, Amazon MQ no es un destino compatible para notificaciones de eventos en S3; en su lugar, se debe usar Amazon SQS.\n\nCrear un nuevo Amazon SNS topic y una Amazon SQS queue. Agregar una configuración de notificación de eventos en el bucket de S3 para publicar los eventos s3:ObjectCreated: y s3:ObjectRemoved:DeleteMarkerCreated - \"s3:ObjectRemoved:DeleteMarkerCreated\" solo se activa cuando se crea un \"delete marker\" en un objeto versionado. Esto no cubre la eliminación de objetos no versionados ni garantiza la detección de eliminaciones permanentes.\n\nCrear un nuevo Amazon SNS topic y Amazon MQ. Agregar una configuración de notificación de eventos en el bucket de S3 para publicar los eventos s3:ObjectCreated: y s3:ObjectRemoved:DeleteMarkerCreated en SQS y SNS - \"s3:ObjectRemoved:DeleteMarkerCreated\" solo se activa cuando un objeto versionado es marcado para eliminación, pero no cuando un objeto es eliminado definitivamente. Además, Amazon MQ no es un destino compatible para recibir eventos de notificación de S3.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/ways-to-add-notification-config-to-bucket.html\n\nhttps://aws.amazon.com/blogs/aws/s3-event-notification/"
  },
  {
    "q": "Un arquitecto de soluciones está diseñando una estrategia de almacenamiento para una empresa de análisis de datos. El equipo de cumplimiento requiere que los datos almacenados en Amazon S3 sean accesibles durante los primeros 90 días, pero luego se deben trasladar automáticamente a una opción de almacenamiento más económica para reducir costos.\n¿Cuál es la mejor solución para cumplir con este requisito?",
    "o": [
      "Configurar una cola en Amazon SQS para monitorear los datos antiguos y procesarlos antes de moverlos",
      "Definir políticas de ciclo de vida en S3 para trasladar automáticamente los datos a Glacier después de 90 días",
      "Utilizar Amazon Timestream para gestionar la retención y archivo de los datos",
      "Ejecutar un script en una instancia EC2 cada mes para mover los datos a Amazon S3 Glacier"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nDefinir políticas de ciclo de vida en S3 para trasladar automáticamente los datos a Glacier después de 90 días - Configurar políticas de ciclo de vida en Amazon S3 es la mejor opción para automatizar la transición de datos a almacenamiento de menor costo sin intervención manual.\n\n\n\nSe pueden definir reglas que automáticamente transfieran los objetos a S3 Glacier después de 90 días, reduciendo costos sin afectar la accesibilidad a los datos archivados.\nNo requiere administración adicional ni infraestructura adicional como EC2.\nOpciones incorrectas:\n\nUtilizar Amazon Timestream para gestionar la retención y archivo de los datos - Amazon Timestream está diseñado para almacenar datos de series temporales y no es una solución adecuada para la retención y archivo de datos en S3.\n\nConfigurar una cola en Amazon SQS para monitorear los datos antiguos y procesarlos antes de moverlos - Amazon SQS es un servicio de mensajería que no maneja la transferencia de datos de S3 a Glacier.\n\nEjecutar un script en una instancia EC2 cada mes para mover los datos a Amazon S3 Glacier - Ejecutar un script en una instancia EC2 para mover los datos es innecesario y costoso, ya que S3 Lifecycle Policies ya pueden hacerlo de manera automática sin requerir instancias adicionales.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html\n\nhttps://aws.amazon.com/blogs/aws/archive-s3-to-glacier/"
  },
  {
    "q": "Una plataforma de edición de video en línea permite a productores independientes subir y compartir archivos multimedia pesados utilizando Amazon S3.\nUsuarios básicos pueden almacenar hasta 50 GB en total.\nUsuarios profesionales pueden almacenar hasta 20 TB.\nEl tamaño máximo permitido por archivo es de 3 TB.\n¿Cuál es la mejor manera para que la aplicación maneje la carga de estos archivos grandes a S3?",
    "o": [
      "Usar Multipart Upload",
      "Usar una única solicitud PUT para subir el archivo grande",
      "Usar AWS Snowcone",
      "Usar AWS DataSync"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nUsar Multipart Upload - Multipart Upload es la mejor opción para subir archivos grandes a Amazon S3.\n\nDivide el archivo en varias partes que se suben en paralelo, mejorando la eficiencia y reduciendo el tiempo de carga.\nSoporta archivos de hasta 5 TB, lo que lo hace ideal para este escenario.\nMinimiza la pérdida de progreso en caso de fallos, ya que solo es necesario volver a subir las partes fallidas en lugar de todo el archivo.\nOpciones incorrectas:\n\nUsar AWS DataSync - AWS DataSync se usa para mover grandes volúmenes de datos entre entornos on-premises y AWS, pero no es ideal para cargas de archivos individuales en S3.\n\nUsar AWS Snowcone - AWS Snowcone es una solución de transferencia de datos para entornos sin conexión o de baja conectividad, no para cargas regulares de archivos a S3.\n\nUsar una única solicitud PUT para subir el archivo grande - Una única solicitud PUT solo permite subir archivos de hasta 5 GB, por lo que no puede manejar archivos de 3 TB.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/mpuoverview.html\n\nhttps://aws.amazon.com/s3/faqs/"
  },
  {
    "q": "Una empresa multinacional de tecnología tiene una cuenta de AWS con tres VPCs (DESARROLLO, PRUEBAS y PRODUCCIÓN) en la misma región. Actualmente, la VPC de PRUEBAS tiene conexiones de VPC Peering tanto con la VPC de DESARROLLO como con la de PRODUCCIÓN. Todas las VPCs tienen bloques CIDR no superpuestos.\nEl equipo de ingeniería busca agilizar la implementación de cambios desde el entorno de DESARROLLO hacia PRODUCCIÓN para reducir el tiempo de entrega.\n¿Cuál de las siguientes opciones permite establecer esta comunicación de la manera más eficiente?",
    "o": [
      "Actualizar la tabla de enrutamiento de la VPC de DESARROLLO para agregar una nueva ruta hacia PRODUCCIÓN utilizando la conexión existente con PRUEBAS",
      "Modificar los bloques CIDR de las VPCs de DESARROLLO y PRODUCCIÓN para que sean idénticos y puedan compartir tráfico sin necesidad de VPC Peering",
      "Crear una nueva conexión de VPC Peering entre las VPCs de DESARROLLO y PRODUCCIÓN con las rutas adecuadas",
      "No hacer nada. Como ambas VPCs ya están conectadas a PRUEBAS mediante VPC Peering, pueden comunicarse entre sí"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nCrear una nueva conexión de VPC Peering entre las VPCs de DESARROLLO y PRODUCCIÓN con las rutas adecuadas - VPC Peering no es transitivo, lo que significa que el tráfico no puede fluir automáticamente entre DESARROLLO y PRODUCCIÓN a través de PRUEBAS. Para permitir la comunicación directa entre DESARROLLO y PRODUCCIÓN, se debe crear una conexión de VPC Peering entre ambas y actualizar las tablas de enrutamiento para que reconozcan las nuevas rutas.\n\n\n\nOpciones incorrectas:\n\nActualizar la tabla de enrutamiento de la VPC de DESARROLLO para agregar una nueva ruta hacia PRODUCCIÓN utilizando la conexión existente con PRUEBAS - Solo actualizar la tabla de enrutamiento no es suficiente, ya que VPC Peering no admite enrutamiento transitorio. Sin una conexión directa entre DESARROLLO y PRODUCCIÓN, el tráfico no puede fluir entre ambas VPCs.\n\nNo hacer nada. Como ambas VPCs ya están conectadas a PRUEBAS mediante VPC Peering, pueden comunicarse entre sí - VPC Peering no admite tráfico a través de una VPC intermedia. Aunque PRUEBAS está conectada con ambas VPCs, esto no permite la comunicación entre DESARROLLO y PRODUCCIÓN.\n\nModificar los bloques CIDR de las VPCs de DESARROLLO y PRODUCCIÓN para que sean idénticos y puedan compartir tráfico sin necesidad de VPC Peering - No es posible conectar dos VPCs con CIDR superpuestos, ya que AWS requiere que los bloques de direcciones sean únicos para establecer conexiones de VPC Peering o cualquier otro método de interconexión.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-peering.html"
  },
  {
    "q": "Un arquitecto de soluciones está administrando una aplicación que se ejecuta en una instancia Windows EC2 con un Amazon FSx for Windows File Server adjunto.\nPara reducir costos, la empresa ha decidido detener la instancia fuera del horario laboral y reiniciarla solo cuando sea necesario. Se ha observado que la aplicación tarda varios minutos en estar completamente operativa, lo que impacta en la productividad.\n¿Cómo puede el arquitecto de soluciones acelerar el tiempo de carga de la instancia sin aumentar los costos?",
    "o": [
      "Habilitar el modo de hibernación en la instancia EC2",
      "Deshabilitar el Instance Metadata Service para reducir los elementos que deben cargarse en el inicio",
      "Migrar la aplicación a una instancia EC2 basada en Linux",
      "Migrar la aplicación a una instancia EC2 con hibernación habilitada"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nMigrar la aplicación a una instancia EC2 con hibernación habilitada - La hibernación de EC2 permite pausar y reanudar una instancia, guardando su estado actual en el volumen raíz.\n\n\n\nReduce el tiempo de inicio, ya que no es necesario volver a cargar el sistema operativo ni las aplicaciones.\nSolo se paga por los volúmenes EBS y las direcciones IP elásticas, sin costos adicionales por tiempo de ejecución.\nPara usar hibernación, el volumen raíz debe estar cifrado y ser lo suficientemente grande para almacenar los datos de la RAM.\nOpciones incorrectas:\n\nDeshabilitar el Instance Metadata Service para reducir los elementos que deben cargarse en el inicio - Deshabilitar el Instance Metadata Service no afecta el tiempo de inicio de la instancia. Este servicio solo proporciona metadatos sobre la instancia a través de la red.\n\nHabilitar el modo de hibernación en la instancia EC2 - No se puede habilitar la hibernación en una instancia EC2 una vez lanzada. La instancia debe ser creada con la opción de hibernación habilitada desde el principio.\n\nMigrar la aplicación a una instancia EC2 basada en Linux - Migrar la aplicación a Linux no garantiza una carga más rápida. Además, si la aplicación depende de Windows, podría no ser compatible con un sistema operativo diferente.\n\nReferencias:\n\nhttps://aws.amazon.com/about-aws/whats-new/2019/10/amazon-ec2-hibernation-now-available-on-windows/\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/enabling-hibernation.html\n\nhttps://aws.amazon.com/blogs/aws/new-hibernate-your-ec2-instances/"
  },
  {
    "q": "Una empresa está desarrollando una herramienta de automatización para generar informes personalizados sobre el uso de AWS.\nLa empresa debe poder acceder y pronosticar costos de uso de servicios específicos de manera programática.\n¿Cuál de las siguientes opciones cumpliría con los requisitos con el menor esfuerzo operativo?",
    "o": [
      "Usar la API de AWS Cost Explorer con paginación para recuperar programáticamente los datos de costos de uso",
      "Generar informes de AWS Budgets sobre costos de uso y entregarlos mediante Amazon Simple Queue Service (SQS)",
      "Configurar AWS Budgets para enviar datos de costos de uso a la empresa a través de Amazon SNS",
      "Utilizar los archivos .csv descargables de AWS Cost Explorer para acceder a los datos de costos. Predecir los costos de uso con AWS Budgets"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nUsar la API de AWS Cost Explorer con paginación para recuperar programáticamente los datos de costos de uso - AWS Cost Explorer API permite consultar programáticamente los costos y datos de uso de AWS.\n\nSe puede recuperar información agregada (ej. costos mensuales totales) o detallada (ej. operaciones de escritura diarias en DynamoDB).\nLa paginación permite manejar eficientemente grandes volúmenes de datos.\nAutomatiza la recopilación de datos, eliminando la necesidad de descargar manualmente informes o procesar archivos estáticos.\n\n\nOpciones incorrectas:\n\nUtilizar los archivos .csv descargables de AWS Cost Explorer para acceder a los datos de costos. Predecir los costos de uso con AWS Budgets - Descargar archivos .csv de Cost Explorer implica sobrecarga operativa, ya que requiere descargas manuales y procesamiento adicional en lugar de obtener datos en tiempo real.\n\nGenerar informes de AWS Budgets sobre costos de uso y entregarlos mediante Amazon Simple Queue Service (SQS) - AWS Budgets solo genera alertas cuando se superan umbrales de gasto, pero no proporciona acceso a datos detallados de costos y uso.\n\nConfigurar AWS Budgets para enviar datos de costos de uso a la empresa a través de Amazon SNS - AWS Budgets + SNS solo notifica cuando se superan límites de presupuesto, pero no permite recuperar ni analizar datos de costos de uso.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/cost-management/latest/userguide/ce-what-is.html\n\nhttps://docs.aws.amazon.com/cost-management/latest/userguide/ce-api.html"
  },
  {
    "q": "Una empresa tecnológica ha desplegado su aplicación en un clúster de Kubernetes autoadministrado en sus servidores on-premises. El clúster almacena los datos en una base de datos MongoDB local. El equipo de TI quiere trasladar la aplicación a AWS para reducir la carga operativa y mejorar la escalabilidad, pero debido a restricciones internas, no se pueden realizar cambios en el código de la aplicación.\n¿Qué solución cumple mejor con este requisito?",
    "o": [
      "Migrar el clúster a Amazon Elastic Kubernetes Service (EKS) y la base de datos a Amazon DocumentDB (con compatibilidad con MongoDB).",
      "Migrar el clúster a Amazon Elastic Kubernetes Service (EKS) utilizando Amazon EKS Anywhere y mover la base de datos a Amazon DynamoDB.",
      "Migrar el clúster a Amazon Elastic Container Service (ECS) utilizando Amazon ECS Anywhere y mover la base de datos a Amazon Aurora Serverless.",
      "Migrar el clúster a Amazon Elastic Container Service (ECS) con imágenes almacenadas en Amazon Elastic Container Registry (ECR) y trasladar la base de datos a Amazon Neptune."
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nMigrar el clúster a Amazon Elastic Kubernetes Service (EKS) y la base de datos a Amazon DocumentDB (con compatibilidad con MongoDB). - Amazon DocumentDB (con compatibilidad con MongoDB) es un servicio administrado diseñado específicamente para ejecutar cargas de trabajo basadas en MongoDB sin cambios en la aplicación.\n\n\n\nAl trasladar la base de datos de MongoDB a Amazon DocumentDB, se minimiza la carga operativa sin modificar el código. Además, migrar el clúster de Kubernetes autoadministrado a Amazon EKS simplifica la administración y mejora la escalabilidad.\n\nOpciones incorrectas:\n\nMigrar el clúster a Amazon Elastic Container Service (ECS) con imágenes almacenadas en Amazon Elastic Container Registry (ECR) y trasladar la base de datos a Amazon Neptune. - Amazon Neptune es una base de datos de grafos y no es compatible con MongoDB. No se puede migrar una base de datos documental como MongoDB a Neptune sin realizar cambios significativos en el esquema de datos y en la lógica de la aplicación.\n\nMigrar el clúster a Amazon Elastic Container Service (ECS) utilizando Amazon ECS Anywhere y mover la base de datos a Amazon Aurora Serverless. - Amazon Aurora es una base de datos relacional, mientras que MongoDB es NoSQL. Migrar datos de MongoDB a Aurora requeriría cambios en la aplicación, lo que contradice el requisito de mantener el código sin modificaciones. Además, Amazon ECS Anywhere está diseñado para ejecutar contenedores en infraestructura on-premises, lo que no reduce la sobrecarga operativa en la nube.\n\nMigrar el clúster a Amazon Elastic Kubernetes Service (EKS) utilizando Amazon EKS Anywhere y mover la base de datos a Amazon DynamoDB. - DynamoDB es una base de datos NoSQL basada en clave-valor, pero su modelo de datos y API son diferentes a los de MongoDB. Migrar de MongoDB a DynamoDB implicaría cambios en la aplicación. Asimismo, Amazon EKS Anywhere está diseñado para gestionar Kubernetes en entornos on-premises, lo que no ayudaría a reducir la administración en la nube.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/documentdb/latest/developerguide/docdb-migration.html\n\nhttps://aws.amazon.com/eks/"
  },
  {
    "q": "Una empresa de análisis de datos financieros almacena grandes volúmenes de registros históricos en Amazon S3 con una política de ciclo de vida que los mueve a Glacier cada 60 días. Por regulaciones de cumplimiento, la empresa debe garantizar que, en caso de auditoría, cualquier dato solicitado pueda recuperarse en menos de 10 minutos con un rendimiento de al menos 100 MB/s.\n¿Qué opciones debes implementar para cumplir con este requisito? (Selecciona DOS)",
    "o": [
      "Comprar capacidad de recuperación provisionada",
      "Especificar un rango o porción del archivo de datos financieros para recuperar",
      "Recuperar los datos utilizando Amazon Glacier Select",
      "Usar Bulk Retrieval para acceder a los datos financieros",
      "Usar Expedited Retrieval para acceder a los datos financieros"
    ],
    "a": [
      0,
      4
    ],
    "e": "Correcto:\n\nComprar capacidad de recuperación provisionada - Provisioned Retrieval Capacity (Capacidad de recuperación provisionada) en Amazon S3 Glacier garantiza que las recuperaciones Expedited Retrievals estén siempre disponibles cuando se necesiten. Cada unidad de capacidad permite realizar al menos tres recuperaciones aceleradas cada cinco minutos, con un rendimiento de hasta 100 MB/s. Esto asegura que los datos puedan ser recuperados rápidamente en caso de auditoría.\n\nUsar Expedited Retrieval para acceder a los datos financieros - Expedited Retrievals permiten recuperar datos almacenados en Glacier en 1-5 minutos, lo que satisface el requisito de recuperación en menos de 10 minutos. Sin esta opción, las recuperaciones estándar pueden tardar varias horas.\n\nOpciones incorrectas:\n\nRecuperar los datos utilizando Amazon Glacier Select - Amazon Glacier Select permite ejecutar consultas SQL directamente sobre los datos almacenados en Glacier sin recuperarlos completamente. No es una solución para obtener archivos completos de manera rápida.\n\nEspecificar un rango o porción del archivo de datos financieros para recuperar - Especificar un rango de datos solo reduce la cantidad de información recuperada, pero no garantiza tiempos de recuperación de 10 minutos. No proporciona un acceso acelerado ni mejora el rendimiento de la recuperación.\n\nUsar Bulk Retrieval para acceder a los datos financieros - Bulk Retrieval es la opción de recuperación más económica en Glacier, pero tarda entre 5 y 12 horas, lo que no cumple con la exigencia de recuperación rápida.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/amazonglacier/latest/dev/downloading-an-archive-two-steps.html\n\nhttps://docs.aws.amazon.com/amazonglacier/latest/dev/glacier-select.html"
  },
  {
    "q": "Una empresa multinacional está implementando un marco de gobernanza en AWS y ha establecido una política interna que exige que todos los recursos de AWS estén etiquetados (tags) siguiendo una convención estándar.\nEl arquitecto de soluciones debe implementar una solución que detecte automáticamente cualquier recurso en la cuenta de AWS que no tenga las etiquetas requeridas.\n¿Cuál solución requiere el menor esfuerzo para implementarse?",
    "o": [
      "Desarrollar una función AWS Lambda que inspeccione los recursos y programar su ejecución con Amazon EventBridge (CloudWatch Events)",
      "Habilitar una regla administrada de AWS Config para detectar recursos sin etiquetas",
      "Configurar políticas de control de servicio (SCP) en AWS Organizations para identificar recursos sin etiquetas",
      "Usar políticas de etiquetas en AWS Organizations para imponer la nomenclatura de etiquetas y almacenar registros en Amazon S3 con S3 Object Lock habilitado"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nHabilitar una regla administrada de AWS Config para detectar recursos sin etiquetas - **AWS Config ofrece reglas administradas para verificar si los recursos cumplen con requisitos específicos, incluyendo la presencia de etiquetas obligatorias.\n\nLa regla require-tags permite comprobar automáticamente si los recursos tienen las etiquetas requeridas sin necesidad de programar soluciones personalizadas.\nAWS Config puede integrarse con AWS Organizations para aplicar la verificación a todas las cuentas dentro de la organización.\nOpciones incorrectas:\n\nConfigurar políticas de control de servicio (SCP) en AWS Organizations para identificar recursos sin etiquetas - Las políticas de control de servicio (SCP) en AWS Organizations no pueden detectar recursos sin etiquetas. Solo restringen qué acciones pueden realizar los usuarios y roles dentro de una organización.\n\nUsar políticas de etiquetas en AWS Organizations para imponer la nomenclatura de etiquetas y almacenar registros en Amazon S3 con S3 Object Lock habilitado - Las políticas de etiquetas en AWS Organizations pueden ayudar a estandarizar el uso de etiquetas, pero no pueden detectar recursos sin etiquetas de manera automática. Además, almacenar registros en Amazon S3 con S3 Object Lock no es necesario en este contexto.\n\nDesarrollar una función AWS Lambda que inspeccione los recursos y programar su ejecución con Amazon EventBridge (CloudWatch Events) - Implementar una función Lambda para inspeccionar los recursos y programar su ejecución con Amazon EventBridge es viable, pero requiere más esfuerzo que simplemente habilitar una regla de AWS Config.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/config/latest/developerguide/required-tags.html\n\nhttps://docs.aws.amazon.com/general/latest/gr/aws_tagging.html"
  },
  {
    "q": "Una empresa de tecnología ha lanzado recientemente una nueva plataforma de streaming en vivo. A medida que los usuarios intentan acceder a la plataforma, comienzan a recibir errores 503 Service Unavailable. El equipo de operaciones revisa los registros del sistema y descubre que las instancias EC2 han alcanzado su capacidad máxima, afectando la capacidad de procesamiento de las solicitudes entrantes. Para optimizar la respuesta a eventos y obtener información en tiempo real sobre la actividad de los usuarios, necesitan implementar un servicio de análisis que pueda procesar los datos de eventos en lotes. ¿Cuál de las siguientes opciones permite leer registros en lotes?",
    "o": [
      "Crear un Kinesis Data Stream y usar AWS Lambda para leer registros del flujo de datos",
      "Crear un Data Firehose y usar AWS Lambda para leer registros del flujo de datos",
      "Crear un bucket de Amazon S3 para almacenar los datos capturados y usar Amazon Athena para analizarlos",
      "Crear un bucket de Amazon S3 para almacenar los datos capturados y usar Amazon Redshift Spectrum para analizarlos"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nCrear un Kinesis Data Stream y usar AWS Lambda para leer registros del flujo de datos - Kinesis Data Streams es un servicio altamente escalable y duradero para el procesamiento de datos en tiempo real. Permite capturar grandes volúmenes de datos por segundo desde cientos de miles de fuentes. AWS Lambda puede leer registros en lotes desde Kinesis, procesando hasta 10 lotes en paralelo.\n\n\n\nEsta combinación permite un procesamiento en tiempo real eficiente, asegurando que los registros se procesen en orden dentro de cada clave de partición.\n\nOpciones incorrectas:\n\nCrear un bucket de Amazon S3 para almacenar los datos capturados y usar Amazon Redshift Spectrum para analizarlos - Amazon Redshift Spectrum se utiliza para analizar grandes volúmenes de datos almacenados en S3, pero no es una solución en tiempo real.\n\nCrear un Data Firehose y usar AWS Lambda para leer registros del flujo de datos - AWS Lambda no puede consumir datos directamente desde Kinesis Data Firehose. Firehose se usa para entregar datos a destinos como S3, Redshift o OpenSearch, pero no está diseñado para el procesamiento en tiempo real de eventos individuales.\n\nCrear un bucket de Amazon S3 para almacenar los datos capturados y usar Amazon Athena para analizarlos - Amazon Athena permite consultar datos almacenados en S3 utilizando SQL, pero no es una solución de análisis en tiempo real. Esta opción implicaría un retraso significativo en el procesamiento de datos.\n\nReferencias:\n\nhttps://aws.amazon.com/kinesis/data-streams/\n\nhttps://docs.aws.amazon.com/lambda/latest/dg/with-kinesis.html\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/503-error-classic/"
  },
  {
    "q": "Una empresa ofrece un servicio global de almacenamiento de archivos en la nube, donde clientes de diferentes continentes suben grandes volúmenes de datos diariamente a un bucket de Amazon S3.\n¿Qué característica de AWS deberías utilizar en tu sistema para mejorar el rendimiento y garantizar una transferencia de datos rápida y consistente al bucket de S3, sin importar la ubicación del usuario?",
    "o": [
      "Usar CloudFront Origin Access Control (OAC)",
      "SFTP",
      "Amazon S3 Transfer Acceleration",
      "AWS Direct Connect"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nAmazon S3 Transfer Acceleration - Amazon S3 Transfer Acceleration optimiza la velocidad de carga de archivos a un bucket de S3 desde ubicaciones remotas. Utiliza la red global de AWS CloudFront Edge Locations para enrutar los datos de manera más eficiente y reducir la latencia. Es ideal para cargas de datos globales, como en este escenario, donde los clientes están distribuidos en todo el mundo.\n\n\n\nOpciones incorrectas:\n\nSFTP - SFTP (Secure File Transfer Protocol) proporciona una forma segura de transferir archivos, pero no optimiza la velocidad de carga ni aprovecha la infraestructura global de AWS para reducir latencias.\n\nUsar CloudFront Origin Access Control (OAC) - CloudFront Origin Access Control (OAC) solo restringe el acceso a contenido en S3 a través de CloudFront. No mejora la velocidad de carga de datos hacia S3.\n\nAWS Direct Connect - AWS Direct Connect es útil para crear conexiones privadas y dedicadas entre un centro de datos on-premises y AWS. Sin embargo, dado que los clientes están distribuidos globalmente, Direct Connect no es la solución más eficiente ni escalable.\n\nReferencias:\n\nhttp://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration.html"
  },
  {
    "q": "Una empresa de pagos en línea utiliza Amazon VPC con un bloque CIDR de 192.168.1.0/26, el cual está conectado a su centro de datos on-premises. Se ha desarrollado una función AWS Lambda que valida miles de transacciones por minuto y almacena los resultados en un sistema de archivos EFS.\nTras desplegar la arquitectura sin servidor y asociar la función Lambda a la VPC, el arquitecto de soluciones notó un aumento en errores de invocación, en particular con mensajes de error de EC2 como EC2ThrottledException en momentos de alta demanda.\n¿Cuáles podrían ser las posibles causas de este problema? (Selecciona DOS)",
    "o": [
      "El rol de ejecución de IAM de la función Lambda carece de permisos suficientes para acceder a EFS",
      "La función Lambda está ubicada en una subred de VPC con un espacio de direcciones IP muy reducido",
      "La función Lambda ha alcanzado el límite de direcciones IP disponibles en la subred",
      "El grupo de seguridad de la función Lambda bloquea las conexiones salientes",
      "La VPC no tiene una gateway NAT configurada"
    ],
    "a": [
      1,
      2
    ],
    "e": "Correcto:\n\nLa función Lambda ha alcanzado el límite de direcciones IP disponibles en la subred - Cuando una función de Lambda se ejecuta dentro de una VPC, AWS asigna Elastic Network Interfaces (ENIs) para permitir la comunicación con otros servicios dentro de la VPC, como Amazon EFS. Si la función Lambda se escala rápidamente y hay muchas invocaciones concurrentes, puede alcanzar el límite de ENIs o quedarse sin direcciones IP disponibles en la subred, lo que genera el error EC2ThrottledException.\n\nLa función Lambda está ubicada en una subred de VPC con un espacio de direcciones IP muy reducido - Si la función Lambda está en una subred con muy pocas direcciones IP disponibles, se pueden agotar antes de que Lambda pueda asignar nuevas ENIs para escalar. Esto limita la capacidad de invocar nuevas instancias y puede generar fallos intermitentes, especialmente en momentos de alta carga.\n\nOpciones incorrectas:\n\nEl grupo de seguridad de la función Lambda bloquea las conexiones salientes - Si el grupo de seguridad estuviera bloqueando las conexiones salientes, la función Lambda no funcionaría en absoluto. Sin embargo, dado que los errores ocurren de forma intermitente, el problema no está en la configuración del grupo de seguridad.\n\nLa VPC no tiene una gateway NAT configurada - La falta de una NAT Gateway solo afecta a las conexiones a Internet desde subredes privadas, pero no genera el error EC2ThrottledException. El problema aquí es la falta de recursos de red internos en la VPC.\n\nEl rol de ejecución de IAM de la función Lambda carece de permisos suficientes para acceder a EFS - Si los permisos de IAM fueran insuficientes, el error esperado sería EC2AccessDeniedException o un fallo de permisos de EFS, no EC2ThrottledException. Además, dado que la función a veces funciona correctamente, el problema está relacionado con la infraestructura de red, no con los permisos de IAM.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/lambda/latest/dg/vpc.html\n\nhttps://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html"
  },
  {
    "q": "Un arquitecto de soluciones está configurando un conjunto de instancias EC2 en una VPC con un Internet Gateway adjunto.\nTodas las instancias EC2 en una subred existente pueden ser accedidas desde Internet.\nEl arquitecto lanza otra subred y despliega una nueva instancia EC2 en ella, pero no puede acceder a esta instancia desde Internet.\n¿Cuáles podrían ser las posibles razones de este problema? (Selecciona DOS)",
    "o": [
      "La instancia EC2 no es miembro del mismo Auto Scaling Group",
      "La tabla de rutas no está configurada correctamente para enviar tráfico desde la instancia EC2 a Internet a través del Internet Gateway",
      "La instancia EC2 no tiene una dirección IP pública asociada",
      "La tabla de rutas no está configurada correctamente para enviar tráfico desde la instancia EC2 a Internet a través de un Customer Gateway (CGW)",
      "La instancia EC2 no tiene un Elastic Fabric Adapter (EFA) adjunto"
    ],
    "a": [
      1,
      2
    ],
    "e": "Correcto:\n\nLa tabla de rutas no está configurada correctamente para enviar tráfico desde la instancia EC2 a Internet a través del Internet Gateway - Cada subred en una VPC debe estar asociada a una tabla de rutas.\n\n\n\nPara que una instancia EC2 en una subred pueda acceder a Internet, la tabla de rutas de la subred debe incluir una regla que redirija el tráfico a un Internet Gateway (IGW).\nSi la subred no tiene una tabla de rutas correcta, la instancia quedará aislada de Internet.\nLa instancia EC2 no tiene una dirección IP pública asociada - Para que una instancia EC2 sea accesible desde Internet, necesita una dirección IP pública o una Elastic IP (EIP). Si la instancia solo tiene una IP privada, no podrá ser accedida directamente desde fuera de la VPC.\n\nOpciones incorrectas:\n\nLa instancia EC2 no es miembro del mismo Auto Scaling Group - Pertenecer a un Auto Scaling Group no afecta la conectividad de la instancia EC2 a Internet. Los Auto Scaling Groups administran la escalabilidad y disponibilidad, pero no controlan reglas de red.\n\nLa instancia EC2 no tiene un Elastic Fabric Adapter (EFA) adjunto - Elastic Fabric Adapter (EFA) no es necesario para la conectividad a Internet. EFA se usa en cómputo de alto rendimiento (HPC) y machine learning, pero no influye en el acceso de la instancia EC2 a Internet.\n\nLa tabla de rutas no está configurada correctamente para enviar tráfico desde la instancia EC2 a Internet a través de un Customer Gateway (CGW) - Customer Gateway (CGW) solo se usa para conexiones VPN entre una VPC y una red on-premises. Para conectarse a Internet, la subred necesita un Internet Gateway (IGW), no un CGW.\n\nReferencias:\n\nhttp://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario2.html\n\nhttps://docs.aws.amazon.com/vpc/latest/userguide/VPC_Route_Tables.html"
  },
  {
    "q": "Una empresa ejecuta una aplicación en instancias EC2 que constantemente leen y escriben datos en Amazon S3. Debido a nuevas políticas de seguridad, todas las instancias deben moverse a una subred privada. Al mismo tiempo, el equipo de TI quiere minimizar los costos de transferencia de datos al acceder a Amazon S3.\n¿Cuál es la mejor estrategia para cumplir con estos requisitos?",
    "o": [
      "Configurar una NAT Gateway en la subred pública para permitir el acceso a S3",
      "Implementar un AWS Transit Gateway para enrutar el tráfico hacia Amazon S3",
      "Crear un endpoint de interfaz (Interface Endpoint) de Amazon S3",
      "Crear un endpoint de gateway (Gateway Endpoint) de Amazon S3"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nCrear un endpoint de gateway (Gateway Endpoint) de Amazon S3 - Un Amazon S3 Gateway Endpoint permite que las instancias en una subred privada accedan a S3 sin necesidad de usar un NAT Gateway o un Internet Gateway. Esta opción es la más eficiente en costos porque elimina los cargos de transferencia de datos a través de Internet y no genera costos adicionales más allá de los asociados al uso estándar de S3.\n\n\n\nOpciones incorrectas:\n\nImplementar un AWS Transit Gateway para enrutar el tráfico hacia Amazon S3 - AWS Transit Gateway se usa para conectar múltiples VPCs y redes on-premises, pero no es necesario para acceder a S3 desde una VPC privada. Además, tiene costos por hora y por transferencia de datos.\n\nConfigurar una NAT Gateway en la subred pública para permitir el acceso a S3 - Una NAT Gateway permitiría el acceso a S3, pero introduce costos adicionales por cada GB de tráfico de salida. Es una solución funcional, pero no la más eficiente en términos de costos.\n\nCrear un endpoint de interfaz (Interface Endpoint) de Amazon S3 - Un Interface Endpoint para S3 también permite el acceso privado, pero tiene costos adicionales por cada solicitud realizada. Aunque es útil para servicios que requieren conectividad de nivel de aplicación, no es la opción más rentable para acceder a S3.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html\n\nhttps://docs.aws.amazon.com/vpc/latest/privatelink/vpce-gateway.html"
  },
  {
    "q": "Una empresa en rápido crecimiento ha estado creando múltiples usuarios IAM en su cuenta de AWS para gestionar el acceso a diferentes equipos. Un arquitecto de soluciones ha sido asignado para administrar el acceso de estos usuarios, asegurando que solo puedan operar con permisos de solo lectura y que el acceso sea denegado si no tienen MFA habilitado.\nDado que la empresa planea agregar nuevos usuarios de forma frecuente, el arquitecto debe garantizar que la administración de permisos sea escalable y segura.\n¿Cuál es la mejor manera de administrar estos permisos de manera centralizada y con el menor esfuerzo administrativo?",
    "o": [
      "Crear una Service Control Policy (SCP) que requiera autenticación MFA y adjuntarla a cada usuario IAM para restringir el acceso sin MFA",
      "Configurar IAM Roles individuales para cada usuario y aplicar un permissions boundary que restrinja el acceso en caso de no utilizar MFA",
      "Crear un IAM Role que exija autenticación MFA con el menor privilegio posible. Configurar un IAM Group para cada equipo y adjuntar el IAM Role a los grupos",
      "Crear un IAM Group para cada equipo. Crear una IAM Policy que exija autenticación MFA y aplique el principio de menor privilegio. Adjuntar la IAM Policy a los grupos"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nCrear un IAM Group para cada equipo. Crear una IAM Policy que exija autenticación MFA y aplique el principio de menor privilegio. Adjuntar la IAM Policy a los grupos - La forma más segura y escalable de administrar permisos para múltiples usuarios es utilizar IAM Groups en combinación con IAM Policies. Al definir grupos por equipo y adjuntarles una política de solo lectura que exija MFA, se logra:\n\n \n\nGestión centralizada: No es necesario configurar permisos de forma individual para cada usuario.\nMayor seguridad: Se asegura que solo los usuarios con MFA habilitado puedan acceder.\nEscalabilidad: Nuevos usuarios pueden añadirse a los grupos sin necesidad de modificar las políticas existentes.\nOpciones incorrectas:\n\nCrear un IAM Role que exija autenticación MFA con el menor privilegio posible. Configurar un IAM Group para cada equipo y adjuntar el IAM Role a los grupos - IAM Roles no se pueden adjuntar a IAM Groups. Los roles están diseñados para acceso temporal, mientras que los grupos gestionan permisos permanentes para los usuarios IAM.\n\nConfigurar IAM Roles individuales para cada usuario y aplicar un permissions boundary que restrinja el acceso en caso de no utilizar MFA - Un permissions boundary solo establece los permisos máximos posibles para un usuario o rol, pero no impone el uso de MFA ni gestiona permisos de solo lectura de manera eficiente.\n\nCrear una Service Control Policy (SCP) que requiera autenticación MFA y adjuntarla a cada usuario IAM para restringir el acceso sin MFA - Service Control Policies (SCPs) solo están disponibles en cuentas dentro de AWS Organizations. Como el escenario describe una sola cuenta de AWS sin mencionar una organización, las SCPs no pueden aplicarse.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_groups.html\n\nhttps://aws.amazon.com/iam/features/mfa/"
  },
  {
    "q": "Una empresa de atención médica quiere utilizar Inteligencia Artificial (IA) para analizar interacciones entre pacientes y médicos en consultas telefónicas. Las grabaciones están en español y francés, y se necesita generar un informe en inglés con el análisis de sentimiento para determinar si el paciente tuvo una experiencia satisfactoria. En el futuro, la empresa planea expandirse y agregar soporte para otros idiomas como alemán, portugués y japonés.\n¿Cómo puede el arquitecto de soluciones construir la solución sin mantener ningún modelo de aprendizaje automático?",
    "o": [
      "Convertir grabaciones de audio en texto usando Amazon Transcribe. Configurar Amazon Translate para traducir textos en francés al inglés y usar Amazon Comprehend para el análisis de sentimiento",
      "Configurar Amazon Comprehend para convertir grabaciones de audio en texto. Usar Amazon Kendra para traducir textos en francés al inglés y utilizar Amazon Detective para detectar automáticamente comportamientos negativos de los pacientes en el análisis de sentimiento",
      "Utilizar el servicio Amazon Lex para convertir grabaciones de audio en texto. Llamar a la API de Amazon Translate para traducir textos en francés al inglés y usar Amazon SageMaker Clarify para la predicción y análisis de sentimiento",
      "Transcribir grabaciones de audio a texto usando Amazon Polly's StartSpeechSynthesisTask operation. Configurar Amazon Rekognition para reconocer y traducir automáticamente textos en francés al inglés. Usar la combinación de Amazon Fraud Detector y el algoritmo Amazon SageMaker BlazingText para análisis de sentimiento"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nConvertir grabaciones de audio en texto usando Amazon Transcribe. Configurar Amazon Translate para traducir textos en francés al inglés y usar Amazon Comprehend para el análisis de sentimiento - La combinación de Amazon Transcribe, Amazon Translate y Amazon Comprehend es la solución ideal sin necesidad de mantener un modelo de aprendizaje automático. Amazon Transcribe convierte las grabaciones de audio en texto, Amazon Translate traduce los textos en francés al inglés y Amazon Comprehend analiza el sentimiento de los textos en inglés. Estas herramientas son completamente administradas y no requieren entrenamiento ni mantenimiento de modelos de IA.\n\n\n\nOpciones incorrectas:\n\nConfigurar Amazon Comprehend para convertir grabaciones de audio en texto. Usar Amazon Kendra para traducir textos en francés al inglés y utilizar Amazon Detective para detectar automáticamente comportamientos negativos de los pacientes en el análisis de sentimiento - Amazon Comprehend no puede convertir audio en texto, Amazon Kendra no es una herramienta de traducción de idiomas y Amazon Detective no tiene la funcionalidad para detectar automáticamente comportamientos negativos en análisis de sentimiento.\n\nTranscribir grabaciones de audio a texto usando Amazon Polly's StartSpeechSynthesisTask operation. Configurar Amazon Rekognition para reconocer y traducir automáticamente textos en francés al inglés. Usar la combinación de Amazon Fraud Detector y el algoritmo Amazon SageMaker BlazingText para análisis de sentimiento - Amazon Polly no se usa para convertir audio en texto, sino para convertir texto en voz. Amazon Rekognition se usa principalmente para el reconocimiento de imágenes y videos, no para la traducción de texto. Además, Amazon SageMaker requiere la creación y entrenamiento de modelos de aprendizaje automático, lo cual contradice el requisito de la pregunta.\n\nUtilizar el servicio Amazon Lex para convertir grabaciones de audio en texto. Llamar a la API de Amazon Translate para traducir textos en francés al inglés y usar Amazon SageMaker Clarify para la predicción y análisis de sentimiento - Amazon Lex es un servicio para desarrollar chatbots y asistentes de voz, pero no se usa para transcribir audio. Amazon Textract extrae texto de documentos, pero no convierte audio en texto. Además, Amazon SageMaker Clarify se usa para la evaluación de sesgos en modelos de ML y no para el análisis de sentimiento en este caso.\n\nReferencias:\n\nhttps://aws.amazon.com/transcribe/faqs/\n\nhttps://aws.amazon.com/translate/faqs/\n\nhttps://aws.amazon.com/comprehend/faqs/"
  },
  {
    "q": "Una empresa especializada en simulaciones de fluidos ha desplegado un clúster de computación de alto rendimiento (HPC) utilizando múltiples instancias EC2 para ejecutar análisis complejos en entornos meteorológicos.\nEl arquitecto de soluciones ha detectado que el tiempo de procesamiento ha aumentado significativamente debido a problemas de latencia en la comunicación entre los nodos del clúster.\n¿Cuál es la solución más adecuada para optimizar el rendimiento de red y reducir la latencia en este entorno HPC?",
    "o": [
      "Usar instancias EC2 dedicadas con aceleradores de cómputo para mejorar la velocidad de procesamiento.",
      "Configurar un grupo de colocación en clúster (cluster placement group) dentro de una única zona de disponibilidad en la misma región de AWS.",
      "Configurar conexiones AWS Direct Connect en múltiples zonas de disponibilidad para aumentar el ancho de banda de la red.",
      "Configurar un grupo de colocación distribuido (spread placement group) en múltiples zonas de disponibilidad para mejorar la disponibilidad de las instancias."
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nConfigurar un grupo de colocación en clúster (cluster placement group) dentro de una única zona de disponibilidad en la misma región de AWS. - Los cluster placement groups agrupan instancias EC2 dentro de una única zona de disponibilidad, lo que permite una comunicación de red de baja latencia y alto ancho de banda. Esto los hace ideales para entornos HPC, donde los nodos deben intercambiar datos rápidamente para procesar simulaciones de manera eficiente.\n\n\n\n\n\nOpciones incorrectas:\n\nConfigurar un grupo de colocación distribuido (spread placement group) en múltiples zonas de disponibilidad para mejorar la disponibilidad de las instancias. - Los spread placement groups distribuyen las instancias en diferentes racks y zonas de disponibilidad para mejorar la tolerancia a fallos. Sin embargo, este enfoque introduce latencia adicional, lo que lo hace ineficiente para aplicaciones HPC que requieren comunicación rápida entre nodos.\n\nConfigurar conexiones AWS Direct Connect en múltiples zonas de disponibilidad para aumentar el ancho de banda de la red. - AWS Direct Connect se usa para establecer conexiones privadas entre una infraestructura on-premises y AWS. No tiene impacto en la comunicación de red entre instancias EC2 dentro de una misma región de AWS.\n\nUsar instancias EC2 dedicadas con aceleradores de cómputo para mejorar la velocidad de procesamiento. - Aunque las instancias dedicadas con aceleradores de cómputo pueden mejorar el procesamiento, no abordan el problema de latencia en la red. El cuello de botella en este escenario es la comunicación entre nodos, lo que requiere una solución enfocada en reducir la latencia de red.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html\n\nhttps://aws.amazon.com/hpc/"
  },
  {
    "q": "Una startup de tecnología financiera ha implementado una API de pagos en AWS.\nEl backend de la API se ejecuta en instancias Amazon EC2 dentro de un Auto Scaling Group.\nLos datos de clientes y transacciones se almacenan en un clúster Amazon Aurora for PostgreSQL.\nPor razones de cumplimiento y seguridad, es obligatorio almacenar de forma cifrada las claves API, tokens de acceso y credenciales de la base de datos.\nLa solución debe ser escalable y minimizar los costos operativos.\n¿Cuál de las siguientes opciones es la mejor solución para cumplir con estos requisitos?",
    "o": [
      "Almacenar las claves y credenciales en AWS Systems Manager Parameter Store con tipo SecureString y cifrado con AWS KMS. Configurar la API para recuperar los parámetros de forma segura",
      "Guardar las credenciales en archivos de configuración dentro de las instancias EC2 y usar permisos de IAM para restringir el acceso",
      "Guardar las claves API y credenciales en AWS Secrets Manager con cifrado KMS. Configurar la API para recuperar los valores desde Secrets Manager en cada solicitud",
      "Almacenar las claves en un archivo JSON en un bucket de Amazon S3 con cifrado habilitado. Configurar la API para descargar el archivo al iniciar"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nAlmacenar las claves y credenciales en AWS Systems Manager Parameter Store con tipo SecureString y cifrado con AWS KMS. Configurar la API para recuperar los parámetros de forma segura - AWS Systems Manager Parameter Store es la solución más rentable y escalable para almacenar parámetros de configuración de manera segura.\n\n\n\nEl tipo SecureString permite cifrar los valores con AWS KMS, asegurando la protección de datos sensibles.\nSe integra fácilmente con EC2, Lambda y contenedores, permitiendo a la API recuperar credenciales sin exponerlas en el código.\nOpciones incorrectas:\n\nGuardar las claves API y credenciales en AWS Secrets Manager con cifrado KMS. Configurar la API para recuperar los valores desde Secrets Manager en cada solicitud - AWS Secrets Manager es ideal para credenciales de bases de datos con rotación automática, pero tiene un costo adicional por cada secreto almacenado. Para almacenar solo claves API y configuraciones, Parameter Store es una alternativa más económica.\n\nAlmacenar las claves en un archivo JSON en un bucket de Amazon S3 con cifrado habilitado. Configurar la API para descargar el archivo al iniciar - Guardar credenciales en un archivo JSON en S3 no es una práctica recomendada, ya que requiere permisos adicionales y un mecanismo de actualización cada vez que los valores cambian. No ofrece una integración directa con instancias EC2 ni control granular sobre el acceso.\n\nGuardar las credenciales en archivos de configuración dentro de las instancias EC2 y usar permisos de IAM para restringir el acceso - Almacenar credenciales en archivos dentro de las instancias EC2 no es seguro, ya que cualquier usuario con acceso al sistema podría extraerlas. No es una solución escalable para un entorno con Auto Scaling.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-parameter-store.html\n\nhttps://aws.amazon.com/secrets-manager/faqs/"
  },
  {
    "q": "Un arquitecto de soluciones está diseñando una solución para almacenar información sensible en Amazon S3.\nPara cumplir con los requisitos de seguridad y normativas como HIPAA, es obligatorio que todos los datos almacenados en S3 estén cifrados en reposo.\n¿Qué métodos de cifrado se pueden utilizar para garantizar la seguridad de los datos? (Selecciona DOS)",
    "o": [
      "Usar AWS Shield para proteger los datos almacenados en S3",
      "Habilitar cifrado en snapshots de Amazon RDS",
      "Cifrar los datos con claves de cifrado administradas por el cliente antes de subirlos a Amazon S3",
      "Usar Amazon Macie para proteger los datos sensibles en S3",
      "Habilitar Server-Side Encryption (SSE) en S3 con cifrado AES-256"
    ],
    "a": [
      2,
      4
    ],
    "e": "Correcto:\n\nCifrar los datos con claves de cifrado administradas por el cliente antes de subirlos a Amazon S3 - Client-Side Encryption (CSE) permite cifrar los datos antes de ser subidos a Amazon S3, utilizando claves gestionadas por el cliente. Esto garantiza que solo quienes posean la clave de cifrado puedan descifrar los datos almacenados en S3.\n\nHabilitar Server-Side Encryption (SSE) en S3 con cifrado AES-256 - Server-Side Encryption (SSE) es una opción nativa de Amazon S3 que cifra automáticamente los objetos en el bucket utilizando el algoritmo AES-256. Es una de las soluciones más recomendadas para garantizar el cifrado en reposo sin requerir cambios en la aplicación.\n\n\n\nOpciones incorrectas:\n\nUsar AWS Shield para proteger los datos almacenados en S3 - AWS Shield protege contra ataques DDoS, pero no cifra ni protege datos en reposo.\n\nHabilitar cifrado en snapshots de Amazon RDS - Cifrar snapshots de Amazon RDS protege bases de datos en RDS, pero no aplica a datos almacenados en S3.\n\nUsar Amazon Macie para proteger los datos sensibles en S3 - Amazon Macie detecta datos sensibles en S3, pero no proporciona cifrado para proteger los datos en reposo.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/UsingClientSideEncryption.html"
  },
  {
    "q": "Tres cuentas de AWS son propiedad de la misma empresa pero en diferentes regiones. La cuenta Z tiene dos conexiones de AWS Direct Connect a dos oficinas de la empresa separadas. Las cuentas A y B requieren la capacidad de enrutar a través de las conexiones de Direct Connect de la cuenta Z a cada oficina de la empresa. Un arquitecto de soluciones ha creado un gateway de AWS Direct Connect en la cuenta Z.\n¿Cómo se puede configurar la conectividad requerida?",
    "o": [
      "Crear un VPC Endpoint al gateway de Direct Connect en las cuentas A y B",
      "Crear una conexión PrivateLink en la cuenta Z y ENIs en las cuentas A y B",
      "Asociar el gateway de Direct Connect a un transit gateway en cada región",
      "Asociar el gateway de Direct Connect a un gateway privado virtual en las cuentas A y B"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nAsociar el gateway de Direct Connect a un gateway privado virtual en las cuentas A y B - Puede asociar un gateway de AWS Direct Connect con cualquiera de los siguientes gateways:\n\nUn transit gateway cuando tiene múltiples VPCs en la misma Región.\nUn gateway privado virtual.\nEn este caso, la cuenta Z es propietaria del gateway de Direct Connect, por lo que un VPG en las cuentas A y B debe estar asociado con él para que esta configuración funcione. Después de que la cuenta Z acepte las propuestas, las cuentas A y B pueden enrutar el tráfico desde su gateway privado virtual al gateway de Direct Connect.\n\nOpciones incorrectas:\n\nAsociar el gateway de Direct Connect a un transit gateway en cada región - Esta sería una buena solución si las cuentas estuvieran en VPCs dentro de una región en lugar de entre regiones.\n\nCrear un VPC Endpoint al gateway de Direct Connect en las cuentas A y B - No se puede crear un endpoint de VPC para gateways de Direct Connect.\n\nCrear una conexión PrivateLink en la cuenta Z y ENIs en las cuentas A y B - No se pueden usar conexiones PrivateLink para publicar un gateway de Direct Connect.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/directconnect/latest/UserGuide/direct-connect-gateways-intro.html"
  },
  {
    "q": "Una empresa de comercio electrónico ha desplegado su base de datos en Amazon Aurora con una instancia db.r5.large. Durante la mayor parte del día, el rendimiento es estable, pero en eventos de alta demanda, como el Black Friday, la base de datos no escala lo suficientemente rápido para manejar el tráfico masivo de usuarios.\nEl arquitecto de soluciones debe migrar la base de datos a Aurora Serverless con el menor tiempo de inactividad posible para garantizar la continuidad de la aplicación.\n¿Qué estrategia debe implementarse para cumplir con este requisito?",
    "o": [
      "Modificar la configuración del clúster de Aurora para cambiar la clase de instancia a Serverless",
      "Utilizar AWS Database Migration Service (AWS DMS) para migrar a Aurora Serverless con replicación en tiempo real",
      "Añadir una réplica de lectura de Aurora Serverless y promoverla a instancia primaria cuando el tráfico aumente",
      "Tomar un snapshot del clúster actual y restaurarlo en un nuevo clúster de Aurora Serverless"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nUtilizar AWS Database Migration Service (AWS DMS) para migrar a Aurora Serverless con replicación en tiempo real - AWS Database Migration Service (DMS) permite migrar bases de datos a Aurora Serverless con casi cero tiempo de inactividad. DMS puede replicar continuamente los cambios desde la base de datos de origen hasta el nuevo clúster Aurora Serverless, lo que facilita la transición sin interrumpir las operaciones de la aplicación.\n\n\n\nOpciones incorrectas:\n\nModificar la configuración del clúster de Aurora para cambiar la clase de instancia a Serverless - No es posible cambiar una base de datos Aurora provisionada a Serverless directamente. Se requiere desplegar un nuevo clúster con Aurora Serverless y migrar los datos.\n\nTomar un snapshot del clúster actual y restaurarlo en un nuevo clúster de Aurora Serverless - Restaurar un snapshot en un nuevo clúster de Aurora Serverless implica un tiempo de inactividad significativo, ya que no mantiene una replicación activa con la base de datos en producción.\n\nAñadir una réplica de lectura de Aurora Serverless y promoverla a instancia primaria cuando el tráfico aumente - Aurora Serverless no se puede usar como réplica en un clúster con instancias provisionadas. Además, promover una réplica de lectura como instancia primaria introduce un período de indisponibilidad en la aplicación.\n\nReferencias:\n\nhttps://aws.amazon.com/dms/\n\nhttps://aws.amazon.com/rds/aurora/faqs"
  },
  {
    "q": "Un arquitecto de soluciones está escribiendo una función AWS Lambda que procesará documentos cifrados desde un sistema de archivos Amazon FSx for NetApp ONTAP. Los documentos están protegidos con una clave de cliente de AWS KMS. Después de procesar los documentos, la función Lambda almacenará los resultados en un bucket de S3 con la clase de almacenamiento Amazon S3 Glacier Flexible Retrieval. El arquitecto de soluciones debe asegurarse de que la función Lambda pueda descifrar los archivos.\n¿Qué acción cumple con este requisito?",
    "o": [
      "Adjuntar el permiso kms:decrypt al rol de ejecución de la función Lambda. Agregar una declaración en la política de la clave de AWS KMS que otorgue el permiso kms:decrypt al ARN de la función en lugar del rol de ejecución",
      "Adjuntar el permiso kms:decrypt al rol de ejecución de la función Lambda. Agregar una declaración en la política de la clave de AWS KMS que otorgue al rol de ejecución de la función el permiso kms:decrypt",
      "Adjuntar el permiso kms:decrypt a la política de recursos de la función Lambda. Agregar una declaración en la política de la clave de AWS KMS que otorgue el permiso kms:decrypt al rol de ejecución de la función",
      "Adjuntar el permiso kms:decrypt a la política de recursos de la función Lambda. Agregar una declaración en la política de la clave de AWS KMS que otorgue el permiso kms:decrypt al ARN de la política de recursos de la función"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nAdjuntar el permiso kms:decrypt al rol de ejecución de la función Lambda. Agregar una declaración en la política de la clave de AWS KMS que otorgue al rol de ejecución de la función el permiso kms:decrypt - Para que la función Lambda pueda descifrar los archivos protegidos con AWS KMS, se deben realizar dos configuraciones clave:\n\n\n\nAgregar el permiso kms:decrypt al rol de ejecución de la función Lambda, ya que Lambda utiliza los permisos asociados con su rol de ejecución para interactuar con otros servicios de AWS.\nActualizar la política de la clave KMS para otorgar permisos de descifrado al rol de ejecución de la función, ya que las políticas de claves son el método principal para controlar el acceso a las claves de KMS.\nOpciones incorrectas:\n\nAdjuntar el permiso kms:decrypt a la política de recursos de la función Lambda. Agregar una declaración en la política de la clave de AWS KMS que otorgue el permiso kms:decrypt al ARN de la política de recursos de la función - La política de recursos de la función Lambda especifica qué entidades pueden invocar la función, pero no qué acciones puede realizar Lambda con otros servicios como KMS. Por lo tanto, adjuntar el permiso kms:decrypt a la política de recursos no permitirá que Lambda descifre los archivos.\n\nAdjuntar el permiso kms:decrypt a la política de recursos de la función Lambda. Agregar una declaración en la política de la clave de AWS KMS que otorgue el permiso kms:decrypt al rol de ejecución de la función - La política de recursos de Lambda no se usa para definir los permisos que Lambda tiene sobre otros servicios. Para que Lambda descifre datos protegidos con KMS, el permiso debe estar en su rol de ejecución.\n\nAdjuntar el permiso kms:decrypt al rol de ejecución de la función Lambda. Agregar una declaración en la política de la clave de AWS KMS que otorgue el permiso kms:decrypt al ARN de la función en lugar del rol de ejecución - En la política de la clave KMS se debe referenciar el ARN del rol de ejecución de Lambda, no el ARN de la función en sí. Lambda interactúa con otros servicios a través de los permisos asociados a su rol de ejecución.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html#key-policy-default-allow-root-enable-iam\n\nhttps://docs.aws.amazon.com/kms/latest/developerguide/iam-policies.html\n\nhttps://docs.aws.amazon.com/fsx/latest/ONTAPGuide/encryption-at-rest.html"
  },
  {
    "q": "Una empresa ha alojado una aplicación web en una instancia Amazon EC2 con Linux en una subred pública.\nLa instancia utiliza un grupo de seguridad por defecto.\nTiene una dirección IP elástica (EIP) asignada.\nEl Network ACL está configurado para bloquear todo el tráfico entrante y saliente.\nEl arquitecto de soluciones debe permitir tráfico entrante en el puerto 443 para que los usuarios puedan acceder a la aplicación desde cualquier lugar.\n¿Cuáles de los siguientes pasos cumplirán con este requisito? (Selecciona DOS)",
    "o": [
      "En el Security Group, agregar una nueva regla para permitir la conexión TCP en el puerto 443 desde origen 0.0.0.0/0",
      "En el Network ACL, actualizar la regla para permitir tráfico TCP entrante y saliente en el puerto 443 desde origen 0.0.0.0/0 y destino 0.0.0.0/0",
      "En el Network ACL, actualizar la regla para permitir tráfico TCP entrante en el puerto 443 desde origen 0.0.0.0/0 y tráfico TCP saliente en los puertos efímeros (32768 - 65535) con destino 0.0.0.0/0",
      "En el Security Group, crear una nueva regla para permitir la conexión TCP en el puerto 443 a destino 0.0.0.0/0",
      "En el Network ACL, actualizar la regla para permitir tráfico TCP saliente en los puertos efímeros (32768 - 65535) con destino 0.0.0.0/0"
    ],
    "a": [
      0,
      2
    ],
    "e": "Correcto:\n\nEn el Network ACL, actualizar la regla para permitir tráfico TCP entrante en el puerto 443 desde origen 0.0.0.0/0 y tráfico TCP saliente en los puertos efímeros (32768 - 65535) con destino 0.0.0.0/0 - Los Network ACLs son estateless, lo que significa que se deben configurar reglas tanto para tráfico entrante como saliente.\n\nSe debe permitir tráfico entrante en el puerto 443 desde cualquier origen (0.0.0.0/0) para recibir solicitudes HTTPS.\nEl tráfico de respuesta de la instancia debe salir a través de puertos efímeros (32768 - 65535), que es el rango utilizado por los clientes para recibir respuestas.\nEn el Security Group, agregar una nueva regla para permitir la conexión TCP en el puerto 443 desde origen 0.0.0.0/0 - Los Security Groups son stateful, por lo que solo es necesario permitir el tráfico entrante en el puerto 443. El tráfico de respuesta se permitirá automáticamente, por lo que no es necesario configurar reglas de salida en el Security Group.\n\n\n\nOpciones incorrectas:\n\nEn el Security Group, crear una nueva regla para permitir la conexión TCP en el puerto 443 a destino 0.0.0.0/0 - Esta regla solo permitiría tráfico saliente desde la instancia, no tráfico entrante, lo cual no es necesario, ya que los Security Groups por defecto permiten todo el tráfico saliente.\n\nEn el Network ACL, actualizar la regla para permitir tráfico TCP entrante y saliente en el puerto 443 desde origen 0.0.0.0/0 y destino 0.0.0.0/0 - No es necesario permitir tráfico saliente en el puerto 443 en el Network ACL. En su lugar, se deben permitir los puertos efímeros (32768 - 65535) para las respuestas.\n\nEn el Network ACL, actualizar la regla para permitir tráfico TCP saliente en los puertos efímeros (32768 - 65535) con destino 0.0.0.0/0 - Es parcialmente correcto, pero necesita una regla adicional para permitir tráfico entrante en el puerto 443.\n\nReferencias:\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/connect-http-https-ec2/\n\nhttps://docs.amazonaws.cn/en_us/vpc/latest/userguide/vpc-network-acls.html#nacl-ephemeral-ports"
  },
  {
    "q": "Estás automatizando el despliegue de instancias EC2 en tu VPC. Has escrito un script en Python que utiliza la API de Amazon EC2 para lanzar 80 instancias en una sola Availability Zone dentro de una región de AWS. Sin embargo, después de iniciar con éxito 40 instancias, las siguientes solicitudes fallan.\n¿Cuál podría ser la razón de este problema y cómo puedes solucionarlo?",
    "o": [
      "AWS impone un límite de 40 instancias por Availability Zone. Debes cambiar de zona de disponibilidad y volver a intentar",
      "El límite de instancias On-Demand se basa en la cantidad de vCPUs permitidas por región. Debes solicitar un aumento de límite a AWS y reintentar las solicitudes fallidas una vez aprobado",
      "El límite de instancias por región es de 40. Debes seleccionar otra región e intentar nuevamente",
      "El servicio de Amazon EC2 experimentó un problema temporal. Intenta reenviar las solicitudes fallidas"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nEl límite de instancias On-Demand se basa en la cantidad de vCPUs permitidas por región. Debes solicitar un aumento de límite a AWS y reintentar las solicitudes fallidas una vez aprobado - AWS impone un límite basado en la cantidad de vCPUs disponibles para instancias On-Demand por región.\n\nCada tipo de instancia EC2 tiene un número de vCPUs asignado, y al alcanzar el límite regional, las solicitudes fallarán.\nPara lanzar más instancias, debes solicitar un aumento de límite a AWS a través del Service Quotas en la consola de administración.\nOpciones incorrectas:\n\nEl servicio de Amazon EC2 experimentó un problema temporal. Intenta reenviar las solicitudes fallidas - No se trata de una falla en el servicio de Amazon EC2. El problema es un límite de vCPU que impide aprovisionar más instancias.\n\nEl límite de instancias por región es de 40. Debes seleccionar otra región e intentar nuevamente - AWS no impone un límite de instancias de 40 por región, sino por vCPU. Mover las instancias a otra región no es necesario si se solicita un aumento de límite.\n\nAWS impone un límite de 40 instancias por Availability Zone. Debes cambiar de zona de disponibilidad y volver a intentar - No hay un límite de instancias específico por Availability Zone, sino un límite de vCPUs por región. Cambiar de zona de disponibilidad dentro de la misma región no aumentará la capacidad disponible.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html#limits_ec2\n\nhttps://aws.amazon.com/ec2/faqs/#How_many_instances_can_I_run_in_Amazon_EC2"
  },
  {
    "q": "Una plataforma de análisis financiero ha notado una disminución en el rendimiento de su base de datos debido a un alto volumen de consultas de solo lectura.\nEl arquitecto de soluciones debe proponer una estrategia para mejorar el rendimiento y sugiere usar Amazon RDS Read Replicas en lugar de una configuración Multi-AZ Deployments.\n¿Cuáles son dos beneficios clave de usar Read Replicas en este caso? (Selecciona DOS)",
    "o": [
      "Mejora el rendimiento de lectura de la base de datos principal al aumentar sus IOPS y reducir la latencia mediante AWS Global Accelerator",
      "Escala horizontalmente la capacidad de lectura al permitir múltiples instancias adicionales que manejan tráfico de solo lectura",
      "Proporciona replicación síncrona y conmutación por error automática en caso de una falla en la base de datos principal",
      "Permite que las Read Replicas acepten tanto operaciones de lectura como de escritura para aliviar la carga de la base de datos principal",
      "Proporciona replicación asíncrona y permite distribuir la carga de trabajo de lectura entre varias instancias"
    ],
    "a": [
      1,
      4
    ],
    "e": "Correcto:\n\nProporciona replicación asíncrona y permite distribuir la carga de trabajo de lectura entre varias instancias - Amazon RDS Read Replicas utilizan replicación asíncrona, lo que significa que las consultas de solo lectura pueden distribuirse entre varias réplicas sin afectar el rendimiento de la base de datos principal.\n\nEscala horizontalmente la capacidad de lectura al permitir múltiples instancias adicionales que manejan tráfico de solo lectura - Read Replicas permiten escalar horizontalmente las cargas de trabajo de solo lectura agregando más instancias. Esto es útil cuando la base de datos principal no puede manejar todas las consultas de lectura por sí sola.\n\n\n\nOpciones incorrectas:\n\nMejora el rendimiento de lectura de la base de datos principal al aumentar sus IOPS y reducir la latencia mediante AWS Global Accelerator - Read Replicas no aumentan directamente los IOPS de la base de datos principal. Además, AWS Global Accelerator se usa para optimizar la entrega de tráfico de red, no para mejorar el rendimiento de bases de datos.\n\nProporciona replicación síncrona y conmutación por error automática en caso de una falla en la base de datos principal - Multi-AZ Deployments utilizan replicación síncrona y conmutación por error automática para garantizar alta disponibilidad. Sin embargo, Read Replicas no están diseñadas para este propósito, ya que su replicación es asíncrona y su objetivo es mejorar la escalabilidad de lectura.\n\nPermite que las Read Replicas acepten tanto operaciones de lectura como de escritura para aliviar la carga de la base de datos principal - Read Replicas solo admiten operaciones de lectura. No permiten escritura, ya que su función es distribuir la carga de lectura de la base de datos principal.\n\nReferencias:\n\nhttps://aws.amazon.com/rds/details/read-replicas/\n\nhttps://aws.amazon.com/rds/features/multi-az/"
  },
  {
    "q": "Una empresa de manufactura tiene instancias EC2 ejecutándose en AWS. Las instancias EC2 están configuradas con Auto Scaling. Hay muchas solicitudes que se están perdiendo debido a una sobrecarga en los servidores. El Auto Scaling está lanzando nuevas instancias EC2 para manejar la carga, pero aun así, algunas solicitudes siguen perdiéndose.\n¿Cuál de las siguientes es la solución más adecuada para evitar perder las solicitudes enviadas recientemente?",
    "o": [
      "Utilizar una cola de Amazon SQS para desacoplar los componentes de la aplicación y escalar las instancias EC2 basándose en la métrica ApproximateNumberOfMessages en Amazon CloudWatch",
      "Reemplazar el Auto Scaling Group con un cluster placement group para lograr un rendimiento de red de baja latencia necesario para la comunicación entre nodos estrechamente acoplados",
      "Configurar Amazon Aurora Serverless para escalar automáticamente la base de datos bajo demanda y habilitar la función de Amazon Aurora Parallel Query para consultas analíticas más rápidas sobre los datos actuales",
      "Usar instancias más grandes para la aplicación con un Elastic Fabric Adapter (EFA) adjunto"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nUtilizar una cola de Amazon SQS para desacoplar los componentes de la aplicación y escalar las instancias EC2 basándose en la métrica ApproximateNumberOfMessages en Amazon CloudWatch - La mejor solución es utilizar una cola de Amazon SQS para desacoplar los componentes de la aplicación. SQS permite gestionar solicitudes de manera asíncrona y evitar la pérdida de mensajes cuando la demanda es alta. Además, al usar la métrica ApproximateNumberOfMessages en Amazon CloudWatch, puedes ajustar automáticamente la capacidad de las instancias EC2 según la carga de la cola, asegurando que todas las solicitudes sean procesadas sin pérdida de datos.\n\n\n\nOpciones incorrectas:\n\nUsar instancias más grandes para la aplicación con un Elastic Fabric Adapter (EFA) adjunto - Usar instancias EC2 más grandes con un Elastic Fabric Adapter (EFA) no evitará la pérdida de datos en caso de un pico de tráfico repentino. Aunque mejorar el rendimiento de la red es útil para algunas aplicaciones de alto cómputo, este enfoque no aborda el problema principal de pérdida de solicitudes debido a sobrecarga.\n\nConfigurar Amazon Aurora Serverless para escalar automáticamente la base de datos bajo demanda y habilitar la función de Amazon Aurora Parallel Query para consultas analíticas más rápidas sobre los datos actuales - Configurar Amazon Aurora Serverless no es relevante en este caso, ya que el problema ocurre a nivel de las instancias EC2 y no en la base de datos. Aurora Serverless escala automáticamente la base de datos, pero no tiene impacto en la capacidad de procesamiento de las instancias EC2 que están manejando las solicitudes de los usuarios.\n\nReemplazar el Auto Scaling Group con un cluster placement group para lograr un rendimiento de red de baja latencia necesario para la comunicación entre nodos estrechamente acoplados - Un cluster placement group es útil para mejorar la latencia de red entre instancias EC2, pero no resuelve el problema de pérdida de solicitudes debido a sobrecarga. Auto Scaling sigue siendo necesario para agregar más instancias EC2 y manejar la demanda, lo cual no es compatible con un placement group en este caso.\n\nReferencias:\n\nhttps://aws.amazon.com/sqs/\n\nhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/welcome.html\n\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/as-using-sqs-queue.html"
  },
  {
    "q": "Una empresa tiene una aplicación de comercio electrónico que guarda los registros de transacciones en un bucket de S3. El CTO te ha indicado configurar la aplicación para mantener los registros de transacciones durante un mes para propósitos de resolución de problemas y, después de ese período, eliminarlos.\n¿Qué debes hacer para cumplir con este requisito?",
    "o": [
      "Agregar una nueva política de bucket en Amazon S3",
      "Habilitar CORS en el bucket de Amazon S3, lo que permitirá la eliminación automática de datos mensualmente",
      "Configurar reglas de ciclo de vida en el bucket de Amazon S3 para eliminar los registros de transacciones después de un mes",
      "Crear una nueva política de IAM para el bucket de Amazon S3 que elimine automáticamente los registros después de un mes"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nConfigurar reglas de ciclo de vida en el bucket de Amazon S3 para eliminar los registros de transacciones después de un mes - La mejor manera de cumplir con este requisito es configurar las reglas de ciclo de vida en el bucket de Amazon S3. Las reglas de ciclo de vida permiten definir acciones para la gestión de objetos en un bucket, como la eliminación automática de datos después de un período de tiempo determinado. En este caso, se puede establecer una regla para eliminar los registros de transacciones después de 30 días, lo que permite automatizar la limpieza sin necesidad de intervención manual.\n\n\n\n\n\nOpciones incorrectas:\n\nAgregar una nueva política de bucket en Amazon S3 - Agregar una nueva política de bucket en Amazon S3 no es una solución válida, ya que las políticas de bucket solo controlan el acceso a los objetos dentro del bucket, pero no permiten configurar la eliminación automática de datos.\n\nCrear una nueva política de IAM para el bucket de Amazon S3 que elimine automáticamente los registros después de un mes - IAM solo define permisos para los usuarios y servicios en AWS. No se puede configurar una política de IAM para eliminar objetos automáticamente.\n\nHabilitar CORS en el bucket de Amazon S3, lo que permitirá la eliminación automática de datos mensualmente - Habilitar CORS en el bucket de Amazon S3 no tiene relación con la eliminación automática de datos. CORS (Cross-Origin Resource Sharing) se usa para permitir que las aplicaciones web accedan a recursos en un dominio diferente, pero no gestiona el ciclo de vida de los objetos almacenados en S3.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/lifecycle-transition-general-considerations.html"
  },
  {
    "q": "Un arquitecto de soluciones está diseñando la infraestructura para una nueva aplicación serverless basada en contenedores.\nLa aplicación se ejecutará a partir de una imagen de Docker almacenada en Amazon Elastic Container Registry (ECR) y requiere al menos 8 GB de almacenamiento temporal durante su ejecución.\n¿Qué servicio satisface mejor estos requisitos?",
    "o": [
      "Ejecutar la aplicación en AWS Lambda con soporte para imágenes de contenedor. Configurar el almacenamiento temporal en 8 GB",
      "Ejecutar la aplicación en AWS Lambda con soporte para imágenes de contenedor y adjuntar un volumen de Amazon Elastic File System (EFS)",
      "Ejecutar la aplicación en un clúster de Amazon ECS utilizando AWS Fargate",
      "Ejecutar la aplicación en Amazon ECS con instancias EC2 y adjuntar un volumen de Amazon EBS de 8 GB"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nEjecutar la aplicación en un clúster de Amazon ECS utilizando AWS Fargate - AWS Fargate es la mejor opción para ejecutar contenedores en un entorno serverless sin necesidad de gestionar infraestructura.\n\n\n\nProporciona almacenamiento efímero de hasta 20 GiB por tarea, cumpliendo con el requisito de 8 GB de almacenamiento temporal.\nNo requiere administrar instancias EC2, lo que lo hace ideal para una arquitectura serverless.\nSe integra nativamente con Amazon Elastic Container Registry (ECR), facilitando la implementación de imágenes de contenedor.\nOpciones incorrectas:\n\nEjecutar la aplicación en AWS Lambda con soporte para imágenes de contenedor. Configurar el almacenamiento temporal en 8 GB - AWS Lambda no permite configurar 8 GB de almacenamiento temporal. Su límite es de 512 MB por defecto, lo que no es suficiente para esta aplicación.\n\nEjecutar la aplicación en AWS Lambda con soporte para imágenes de contenedor y adjuntar un volumen de Amazon Elastic File System (EFS) - Amazon EFS proporciona almacenamiento persistente, no efímero. Además, EFS es útil cuando varias instancias necesitan compartir datos, pero en este caso se requiere almacenamiento temporal.\n\nEjecutar la aplicación en Amazon ECS con instancias EC2 y adjuntar un volumen de Amazon EBS de 8 GB - Ejecutar la aplicación en ECS con instancias EC2 implica administrar servidores, lo que no cumple con la definición de arquitectura serverless. Fargate es una mejor opción porque elimina la necesidad de gestionar infraestructura.\n\nReferencias:\n\nhttps://aws.amazon.com/fargate/\n\nhttps://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_data_volumes.html"
  },
  {
    "q": "Una empresa tiene un Application Load Balancer (ALB) que acepta tráfico HTTP y HTTPS en los puertos 80 y 443, respectivamente.\nRecientemente, la empresa ha asociado un nuevo dominio a su sitio web y quiere asegurarse de que todo el tráfico HTTP dirigido a este nuevo dominio se redirija automáticamente a HTTPS para mejorar la seguridad.\n¿Qué configuración de ALB debe realizarse para cumplir con este requisito?",
    "o": [
      "Crear un nuevo listener HTTP en el puerto 80 y agregar una acción de redirección al protocolo HTTPS en el puerto 443",
      "Configurar el listener HTTP existente para redirigir el tráfico al puerto 443",
      "Configurar el listener existente en el puerto 443 y agregar una acción de redirección a HTTP en el puerto 80",
      "Crear un nuevo listener en ALB en el puerto 443 y configurarlo para redirigir el tráfico HTTP a HTTPS"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nConfigurar el listener HTTP existente para redirigir el tráfico al puerto 443 - La mejor manera de redirigir automáticamente el tráfico HTTP a HTTPS en un ALB es configurar el listener existente en el puerto 80 para redirigir el tráfico al puerto 443. Esto se logra mediante una regla de redirección en el listener HTTP. De este modo, todo el tráfico HTTP se redirigirá de manera automática y transparente a HTTPS, mejorando la seguridad de la aplicación.\n\nOpciones incorrectas:\n\nConfigurar el listener existente en el puerto 443 y agregar una acción de redirección a HTTP en el puerto 80 - Redirigir el tráfico en el puerto 443 a HTTP en el puerto 80 va en contra del objetivo de la pregunta, ya que el requisito es redirigir HTTP a HTTPS, no al revés.\n\nCrear un nuevo listener en ALB en el puerto 443 y configurarlo para redirigir el tráfico HTTP a HTTPS - No es posible crear un nuevo listener en el puerto 443 para redirigir tráfico HTTP a HTTPS, ya que ALB ya tiene un listener HTTPS en ese puerto.\n\nCrear un nuevo listener HTTP en el puerto 80 y agregar una acción de redirección al protocolo HTTPS en el puerto 443 - Aunque la acción de redirección es correcta, no es posible crear un nuevo listener en el puerto 80 si ya existe uno en ese puerto. En su lugar, se debe configurar la regla de redirección en el listener HTTP existente.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html\n\nhttps://aws.amazon.com/elasticloadbalancing/application-load-balancer/"
  },
  {
    "q": "Una empresa realiza pruebas de rendimiento en una instancia grande de MySQL RDS dos veces por semana.\nUtilizan Performance Insights para analizar y optimizar consultas costosas en términos de rendimiento.\nLa empresa necesita reducir sus costos operativos en la ejecución de las pruebas sin comprometer la integridad de los resultados.\n¿Cuál de las siguientes opciones es la solución más rentable?",
    "o": [
      "Reducir el tamaño de la instancia de la base de datos a una más pequeña",
      "Una vez completada la prueba, tomar un snapshot de la base de datos y terminarla. Restaurar la base de datos desde el snapshot cuando sea necesario",
      "Detener la base de datos una vez finalizada la prueba y reiniciarla solo cuando sea necesario",
      "Realizar un mysqldump para obtener una copia de la base de datos en una máquina local. Usar MySQL Workbench para analizar las consultas"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nUna vez completada la prueba, tomar un snapshot de la base de datos y terminarla. Restaurar la base de datos desde el snapshot cuando sea necesario - Incluyendo datos y configuraciones. Al terminar la instancia, la empresa evita costos asociados a la ejecución inactiva de la base de datos. Luego, pueden restaurar la base de datos desde el snapshot solo cuando sea necesario para las pruebas. Este enfoque optimiza costos al pagar únicamente por la instancia de base de datos durante los períodos de prueba.\n\n\n\nOpciones incorrectas:\n\nDetener la base de datos una vez finalizada la prueba y reiniciarla solo cuando sea necesario - Aunque detener la base de datos puede reducir costos computacionales, una instancia detenida sigue generando costos por el almacenamiento provisionado, por lo que no es la solución más rentable.\n\nRealizar un mysqldump para obtener una copia de la base de datos en una máquina local. Usar MySQL Workbench para analizar las consultas - Ejecutar pruebas en una máquina local con mysqldump puede ser menos costoso, pero es probable que no replique con precisión los recursos y el entorno de una instancia RDS grande. Esto puede afectar la confiabilidad de los resultados de las pruebas.\n\nReducir el tamaño de la instancia de la base de datos a una más pequeña - Reducir el tamaño de la instancia de la base de datos podría ahorrar costos, pero puede comprometer la integridad de las pruebas, ya que la instancia más pequeña podría no simular con precisión los escenarios del mundo real ni la carga de trabajo generada por las pruebas.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_RestoreFromSnapshot.html\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_CreateSnapshot.html"
  },
  {
    "q": "Un arquitecto de soluciones está diseñando una aplicación de computación de alto rendimiento (HPC) usando instancias Linux de Amazon EC2. Todas las instancias EC2 necesitan comunicarse entre sí con bajo rendimiento de red de baja latencia y alto ancho de banda.\n¿Qué solución de EC2 cumple mejor estos requisitos?",
    "o": [
      "Lanzar las instancias EC2 en un grupo de colocación distribuido en una Zona de Disponibilidad",
      "Lanzar las instancias EC2 en un grupo de colocación en clúster en una Zona de Disponibilidad",
      "Lanzar las instancias EC2 en un grupo de Auto Scaling que abarque múltiples Zonas de Disponibilidad",
      "Lanzar las instancias EC2 en un grupo de Auto Scaling en dos Regiones. Colocar un Network Load Balancer delante de las instancias"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nLanzar las instancias EC2 en un grupo de colocación en clúster en una Zona de Disponibilidad - Cuando lanza una nueva instancia EC2, el servicio EC2 intenta colocar la instancia de tal manera que todas sus instancias se distribuyan en el hardware subyacente para minimizar fallos correlacionados. Puede usar grupos de colocación para influir en la colocación de un grupo de instancias interdependientes para satisfacer las necesidades de su carga de trabajo. Dependiendo del tipo de carga de trabajo, puede crear un grupo de colocación usando una de las siguientes estrategias de colocación:\n\nCluster - agrupa instancias juntas dentro de una Zona de Disponibilidad. Esta estrategia permite que las cargas de trabajo logren el rendimiento de red de baja latencia necesario para la comunicación acoplada nodo a nodo que es típica de las aplicaciones HPC.\n\nPara este escenario, se debe usar un grupo de colocación en clúster ya que esta es la mejor opción para proporcionar rendimiento de red de baja latencia para una aplicación HPC.\n\nOpciones incorrectas:\n\nLanzar las instancias EC2 en un grupo de Auto Scaling que abarque múltiples Zonas de Disponibilidad - Esto no reduce la latencia de red ni mejora el rendimiento.\n\nLanzar las instancias EC2 en un grupo de Auto Scaling en dos Regiones. Colocar un Network Load Balancer delante de las instancias - Esto no logra el requisito establecido de proporcionar rendimiento de red de baja latencia y alto ancho de banda entre instancias. Además, no se puede usar un ELB entre Regiones.\n\nLanzar las instancias EC2 en un grupo de colocación distribuido en una Zona de Disponibilidad - El grupo de colocación distribuido se usa para distribuir instancias en hardware subyacente distinto.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html"
  },
  {
    "q": "Una empresa tiene una aplicación web alojada en la nube de AWS, donde los registros de la aplicación se envían a Amazon CloudWatch. Últimamente, la aplicación ha experimentado algunos errores que pueden resolverse simplemente reiniciando la instancia.\n¿Qué harías para reiniciar automáticamente las instancias EC2 cada vez que ocurra el mismo error de aplicación?",
    "o": [
      "Primero, revisar los registros de CloudWatch en busca de palabras clave relacionadas con el error de la aplicación para crear una métrica personalizada. Luego, crear una alarma en Amazon SNS para esa métrica personalizada que invoque una acción para reiniciar la instancia EC2",
      "Primero, revisar los registros de CloudWatch en busca de palabras clave relacionadas con el error de la aplicación para crear una métrica personalizada. Luego, crear una alarma de CloudWatch para esa métrica personalizada que invoque una acción para reiniciar la instancia EC2",
      "Primero, revisar los registros de CloudWatch en busca de palabras clave relacionadas con el error de la aplicación para crear una métrica personalizada. Luego, crear una alarma de CloudWatch para esa métrica personalizada que invoque una función Lambda que inicie la acción para reiniciar la instancia EC2",
      "Primero, revisar los registros de Flow Logs en busca de palabras clave relacionadas con el error de la aplicación para crear una métrica personalizada. Luego, crear una alarma de CloudWatch para esa métrica personalizada que invoque una acción para reiniciar la instancia EC2"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nPrimero, revisar los registros de CloudWatch en busca de palabras clave relacionadas con el error de la aplicación para crear una métrica personalizada. Luego, crear una alarma de CloudWatch para esa métrica personalizada que invoque una acción para reiniciar la instancia EC2 - Amazon CloudWatch Alarm Actions permite configurar una alarma basada en métricas personalizadas para reiniciar automáticamente una instancia EC2 cuando se detecta un error en los registros de la aplicación.\n\nCloudWatch Logs Insights puede filtrar registros en busca de palabras clave de errores recurrentes.\nSe puede crear una métrica personalizada basada en estos errores detectados.\nSe configura una alarma de CloudWatch para monitorear la métrica y, si se activa, reiniciar automáticamente la instancia EC2.\nOpciones incorrectas:\n\nPrimero, revisar los registros de CloudWatch en busca de palabras clave relacionadas con el error de la aplicación para crear una métrica personalizada. Luego, crear una alarma en Amazon SNS para esa métrica personalizada que invoque una acción para reiniciar la instancia EC2 - Amazon SNS no es compatible con acciones automáticas de reinicio de EC2. SNS solo envía notificaciones y no puede ejecutar acciones como reiniciar instancias.\n\nPrimero, revisar los registros de Flow Logs en busca de palabras clave relacionadas con el error de la aplicación para crear una métrica personalizada. Luego, crear una alarma de CloudWatch para esa métrica personalizada que invoque una acción para reiniciar la instancia EC2 - AWS VPC Flow Logs se usa para capturar información sobre el tráfico de red, no sobre errores específicos de aplicaciones dentro de EC2. No es útil para detectar fallos en la aplicación.\n\nPrimero, revisar los registros de CloudWatch en busca de palabras clave relacionadas con el error de la aplicación para crear una métrica personalizada. Luego, crear una alarma de CloudWatch para esa métrica personalizada que invoque una función Lambda que inicie la acción para reiniciar la instancia EC2 - Aunque usar AWS Lambda es una opción válida, no es necesario en este caso porque CloudWatch Alarm Actions ya puede reiniciar automáticamente la instancia sin requerir una función Lambda adicional.\n\nReferencia:\n\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/UsingAlarmActions.html"
  },
  {
    "q": "Una empresa automotriz está trabajando en un proyecto de desarrollo y despliegue web autónomo utilizando AWS. La solución requiere High Performance Computing (HPC) para recopilar, almacenar y administrar grandes volúmenes de datos, además de admitir marcos de aprendizaje profundo.\nLas instancias EC2 de Linux que se utilizarán deben ofrecer baja latencia y mayor ancho de banda en comparación con el transporte TCP tradicional en sistemas HPC basados en la nube. También deben mejorar el rendimiento de la comunicación entre instancias e incluir una funcionalidad que permita a HPC comunicarse directamente con el hardware de la interfaz de red, proporcionando una transferencia confiable y de baja latencia.\n¿Cuál de las siguientes opciones es la solución más adecuada para lograr estos requisitos?",
    "o": [
      "Adjuntar una Private Virtual Interface (VIF) a cada instancia Amazon EC2 para acelerar High Performance Computing (HPC)",
      "Adjuntar un Elastic Network Adapter (ENA) a cada instancia Amazon EC2 para acelerar High Performance Computing (HPC)",
      "Adjuntar un Elastic Fabric Adapter (EFA) a cada instancia Amazon EC2 para acelerar High Performance Computing (HPC)",
      "Adjuntar un Elastic Network Interface (ENI) a cada instancia Amazon EC2 para acelerar High Performance Computing (HPC)"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nAdjuntar un Elastic Fabric Adapter (EFA) a cada instancia Amazon EC2 para acelerar High Performance Computing (HPC) - Elastic Fabric Adapter (EFA) es una interfaz de red avanzada que se puede conectar a instancias EC2 para mejorar el rendimiento de High Performance Computing (HPC) y aplicaciones de aprendizaje automático. Permite que las aplicaciones HPC alcancen un rendimiento similar al de un clúster on-premises, proporcionando menor latencia y mayor ancho de banda en comparación con el transporte TCP tradicional.\n\nEFA también soporta la funcionalidad OS-bypass, lo que permite a las aplicaciones HPC y de aprendizaje automático comunicarse directamente con el dispositivo EFA, evitando la sobrecarga del sistema operativo y mejorando la eficiencia de la red.\n\nOpciones incorrectas:\n\nAdjuntar un Elastic Network Adapter (ENA) a cada instancia Amazon EC2 para acelerar High Performance Computing (HPC) - Elastic Network Adapter (ENA) proporciona características tradicionales de red IP para instancias EC2 y soporta redes de alto rendimiento, pero no ofrece capacidades de OS-bypass, lo que lo hace menos adecuado para HPC en comparación con EFA.\n\nAdjuntar un Elastic Network Interface (ENI) a cada instancia Amazon EC2 para acelerar High Performance Computing (HPC) - Elastic Network Interface (ENI) es simplemente un componente de red lógico dentro de una VPC que representa una interfaz de red virtual. No proporciona las capacidades necesarias para HPC, como OS-bypass o comunicación de baja latencia.\n\nAdjuntar una Private Virtual Interface (VIF) a cada instancia Amazon EC2 para acelerar High Performance Computing (HPC) - Private Virtual Interface (VIF) permite la conectividad entre la VPC y una dirección IP privada o un endpoint dentro de una red privada. No mejora el rendimiento de HPC ni proporciona características avanzadas de comunicación de red.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/efa.html\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/enhanced-networking-ena.html"
  },
  {
    "q": "Para ahorrar costos, tu gerente te pidió que analices y revises la configuración de la infraestructura en la nube de AWS. También debes proporcionar una estimación de cuánto pagará la empresa por todos los recursos de AWS en uso.\nEn este escenario, ¿cuáles de los siguientes elementos generarán costos? (Selecciona DOS)",
    "o": [
      "Conjunto de datos públicos (Public Data Set)",
      "Uso de una VPC de Amazon",
      "Una instancia EC2 en ejecución",
      "Una instancia On-Demand EC2 detenida",
      "Volúmenes EBS adjuntos a instancias EC2 detenidas"
    ],
    "a": [
      2,
      4
    ],
    "e": "Correcto:\n\nUna instancia EC2 en ejecución - Las instancias EC2 en ejecución generan costos desde el momento en que se inician hasta que se terminan. AWS cobra por uso por hora o por segundo, dependiendo del tipo de instancia y su configuración.\n\nVolúmenes EBS adjuntos a instancias EC2 detenidas - Los volúmenes EBS adjuntos a instancias EC2 detenidas continúan generando costos. Aunque una instancia EC2 detenida no incurre en cargos de cómputo, el almacenamiento asociado (EBS) se sigue cobrando.\n\nOpciones incorrectas:\n\nUna instancia On-Demand EC2 detenida - Las instancias On-Demand EC2 detenidas no generan costos de cómputo. Solo se cobra el almacenamiento asociado (EBS), pero la instancia en sí no incurre en costos mientras está detenida.\n\nConjunto de datos públicos (Public Data Set) - Los conjuntos de datos públicos (Public Data Sets) en AWS no tienen costos asociados por almacenamiento. Sin embargo, si se transfieren o procesan, puede haber cargos por el uso de servicios adicionales.\n\nUso de una VPC de Amazon - Crear y usar una VPC no genera costos adicionales. Sin embargo, los recursos desplegados dentro de la VPC, como instancias EC2 o Gateways de Internet, sí pueden generar cargos según su uso.\n\nReferencias:\n\nhttps://aws.amazon.com/cloudtrail/\n\nhttps://aws.amazon.com/vpc/faqs\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-public-data-sets.html"
  },
  {
    "q": "Una nueva política de la empresa requiere que los usuarios de IAM cambien la longitud mínima de sus contraseñas a 12 caracteres. Tras una inspección aleatoria, descubres que todavía hay empleados que no siguen la política.\n¿Cómo puedes verificar y evaluar automáticamente si la política de contraseñas actual de una cuenta cumple con la política de contraseñas de la empresa?",
    "o": [
      "Configurar AWS Config para activar una evaluación que verifique periódicamente el cumplimiento de la política de contraseñas de los usuarios",
      "Crear una regla en Amazon CloudWatch Event. Construir un patrón de eventos que coincida con eventos de IAM. Configurar el nombre del evento como 'ChangePassword' en el patrón de eventos. Configurar SNS para enviar notificaciones cada vez que un usuario cambie su contraseña",
      "Crear una función Lambda programada que ejecute un script personalizado para verificar periódicamente el cumplimiento de los cambios realizados en las contraseñas",
      "Crear un CloudTrail trail. Filtrar el resultado configurando el atributo 'Event Name' y estableciendo el valor de búsqueda en 'ChangePassword'. Esto te dará una lista de usuarios que han realizado cambios en sus contraseñas"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nConfigurar AWS Config para activar una evaluación que verifique periódicamente el cumplimiento de la política de contraseñas de los usuarios - AWS Config es la mejor solución para verificar automáticamente si la política de contraseñas cumple con los requisitos de la empresa.\n\nAWS Config permite evaluar continuamente la configuración de los recursos de AWS, incluidas las políticas de contraseñas de IAM.\nSe puede configurar una regla en AWS Config para verificar la conformidad con la política IAM_PASSWORD_POLICY.\nAWS Config se integra con AWS Organizations, lo que permite una evaluación centralizada de las políticas de contraseña en múltiples cuentas.\n\n\nOpciones incorrectas:\n\nCrear una función Lambda programada que ejecute un script personalizado para verificar periódicamente el cumplimiento de los cambios realizados en las contraseñas - Aunque una función Lambda puede ejecutarse de forma programada para verificar el cumplimiento, AWS Config ya está integrado con AWS Lambda y permite realizar evaluaciones sin necesidad de implementar una función Lambda personalizada.\n\nCrear un CloudTrail trail. Filtrar el resultado configurando el atributo 'Event Name' y estableciendo el valor de búsqueda en 'ChangePassword'. Esto te dará una lista de usuarios que han realizado cambios en sus contraseñas - Filtrar eventos en AWS CloudTrail con 'ChangePassword' solo proporciona una lista de usuarios que han cambiado sus contraseñas, pero no verifica si cumplen con la política de longitud mínima requerida.\n\nCrear una regla en Amazon CloudWatch Event. Construir un patrón de eventos que coincida con eventos de IAM. Configurar el nombre del evento como 'ChangePassword' en el patrón de eventos. Configurar SNS para enviar notificaciones cada vez que un usuario cambie su contraseña - Configurar una regla de Amazon CloudWatch Event para monitorear eventos 'ChangePassword' solo enviará alertas cuando un usuario cambie su contraseña. No verifica automáticamente si la nueva contraseña cumple con la política establecida.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/config/latest/developerguide/evaluate-config-rules.html\n\nhttps://aws.amazon.com/config/"
  },
  {
    "q": "Una empresa debe integrar su servicio de directorio Lightweight Directory Access Protocol (LDAP) desde el centro de datos on-premises a la VPC de AWS utilizando IAM.\nEl almacén de identidades que se está utilizando actualmente no es compatible con SAML.\n¿Cuál de las siguientes opciones es el enfoque más válido para implementar la integración?",
    "o": [
      "Desarrollar una aplicación de broker de identidad personalizada on-premises y usar STS para emitir credenciales temporales de AWS",
      "Usar AWS IAM Identity Center para gestionar el acceso entre AWS y LDAP",
      "Usar roles de IAM para rotar las credenciales de IAM cada vez que las credenciales de LDAP se actualicen",
      "Usar una política de IAM que haga referencia a los identificadores de LDAP y credenciales de AWS"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nDesarrollar una aplicación de broker de identidad personalizada on-premises y usar STS para emitir credenciales temporales de AWS - Si el almacén de identidades no es compatible con SAML 2.0, una solución válida es construir una aplicación de broker de identidad personalizada on-premises. Esta aplicación autentica a los usuarios contra LDAP, solicita credenciales temporales de AWS mediante STS y las proporciona a los usuarios para acceder a los recursos de AWS.\n\n\n\nOpciones incorrectas:\n\nUsar una política de IAM que haga referencia a los identificadores de LDAP y credenciales de AWS - Simplemente utilizar una política de IAM no es suficiente para integrar un servicio LDAP con IAM. Se requiere un mecanismo de federación como SAML, STS o un broker de identidad personalizado.\n\nUsar AWS IAM Identity Center para gestionar el acceso entre AWS y LDAP - AWS IAM Identity Center admite la integración con proveedores de identidad externos, pero su principal soporte es para proveedores basados en SAML 2.0. Como el enunciado especifica que LDAP no es compatible con SAML, esta opción no es adecuada.\n\nUsar roles de IAM para rotar las credenciales de IAM cada vez que las credenciales de LDAP se actualicen - Rotar manualmente las credenciales de IAM cuando se actualizan las credenciales de LDAP no es una solución óptima para integrar una red on-premises con AWS. Se necesita un sistema automatizado como STS para la gestión de credenciales temporales.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_common-scenarios_federated-users.html\n\nhttps://aws.amazon.com/blogs/aws/aws-identity-and-access-management-now-with-identity-federation/"
  },
  {
    "q": "Un hospital tiene una aplicación de misión crítica que utiliza una API RESTful impulsada por Amazon API Gateway y AWS Lambda. Los médicos suben informes en formato PDF al sistema, que luego se almacenan como contenido de medios estáticos en un bucket de Amazon S3.\nEl equipo de seguridad desea mejorar la visibilidad en cuanto a ciberataques y garantizar el cumplimiento de HIPAA (Ley de Portabilidad y Responsabilidad del Seguro Médico). La empresa busca una solución que monitoree continuamente las operaciones a nivel de objeto en S3 e identifique información de salud protegida (PHI) en los informes, con un impacto mínimo en la función Lambda existente.\n¿Cuál de las siguientes soluciones cumple con estos requisitos con el menor sobrecarga operativa?",
    "o": [
      "Utilizar Amazon Textract para extraer el texto de los informes en PDF. Integrar Amazon Comprehend Medical con la función Lambda existente para identificar la PHI en el texto extraído",
      "Utilizar Amazon Transcribe para leer y analizar los informes en PDF mediante la operación de API StartTranscriptionJob. Usar Amazon CloudWatch Logs para detectar contenido de información de salud protegida (PHI) mediante el seguimiento de registros de acceso y eventos de seguridad",
      "Utilizar Amazon Textract Medical con la redacción de PII activada para extraer y filtrar información sensible de los informes en PDF. Crear una nueva función Lambda que llame a la API de Amazon Comprehend para identificar la PHI en el texto extraído",
      "Utilizar Amazon Textract con la operación de API StartDocumentTextDetection para extraer texto de informes en PDF. Analizar los datos extraídos con un algoritmo personalizado de detección de PHI dentro de la función Lambda"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nUtilizar Amazon Textract para extraer el texto de los informes en PDF. Integrar Amazon Comprehend Medical con la función Lambda existente para identificar la PHI en el texto extraído - Utilizar Amazon Textract para extraer el texto de los informes en PDF e integrar Amazon Comprehend Medical con la función Lambda existente es la mejor opción, ya que minimiza la sobrecarga operativa. Amazon Comprehend Medical es un servicio de procesamiento de lenguaje natural que puede identificar información médica relevante y PHI de manera precisa sin necesidad de desarrollar modelos personalizados ni escribir reglas manuales.\n\n\n\nOpciones incorrectas:\n\nUtilizar Amazon Textract Medical con la redacción de PII activada para extraer y filtrar información sensible de los informes en PDF. Crear una nueva función Lambda que llame a la API de Amazon Comprehend para identificar la PHI en el texto extraído - La redacción de PII (Información de Identificación Personal) en Amazon Textract Medical no es suficiente para identificar la Información de Salud Protegida (PHI) en los informes PDF. Además, esta opción requiere la creación de una nueva función Lambda, lo cual va en contra del requisito de minimizar el impacto en la función Lambda existente.\n\nUtilizar Amazon Textract con la operación de API StartDocumentTextDetection para extraer texto de informes en PDF. Analizar los datos extraídos con un algoritmo personalizado de detección de PHI dentro de la función Lambda - Desarrollar un algoritmo personalizado para detectar PHI dentro de la función Lambda implica una sobrecarga operativa significativa. Mantener un algoritmo propio de detección de PHI es ineficiente en comparación con la integración de un servicio preconstruido y compatible con HIPAA, como Amazon Comprehend Medical.\n\nUtilizar Amazon Transcribe para leer y analizar los informes en PDF mediante la operación de API StartTranscriptionJob. Usar Amazon CloudWatch Logs para detectar contenido de información de salud protegida (PHI) mediante el seguimiento de registros de acceso y eventos de seguridad - Amazon Transcribe es un servicio de reconocimiento de voz diseñado para convertir audio en texto y no está optimizado para extraer texto de imágenes o archivos PDF. Además, Amazon CloudWatch Logs no puede realizar detección de PHI directamente, por lo que esta solución no cumple con los requisitos del escenario.\n\nReferencias:\n\nhttps://aws.amazon.com/comprehend/medical/\n\nhttps://docs.aws.amazon.com/comprehend-medical/latest/dev/textanalysis-phi.html"
  },
  {
    "q": "Un arquitecto de soluciones tiene la tarea de diseñar una solución de infraestructura escalable para una empresa que utiliza Amazon Elastic Kubernetes Service (Amazon EKS) para ejecutar aplicaciones en contenedores. Dado que la carga de trabajo de la empresa varía a lo largo del día, quieren asegurarse de que la infraestructura subyacente se escale automáticamente en respuesta a la demanda.\n¿Cuál de las siguientes opciones cumpliría con los requisitos con la menor cantidad de sobrecarga operativa?",
    "o": [
      "Usar Amazon EC2 Auto Scaling Groups con políticas de escalado personalizadas para gestionar el escalado de los nodos de trabajo de EKS",
      "Integrar un endpoint de API optimizado para la periferia en Amazon API Gateway con Amazon EKS para gestionar y exponer APIs para las aplicaciones en contenedores que se ejecutan en EKS",
      "Usar una combinación de Kubernetes Metrics y Kubernetes Cluster Autoscaler para gestionar la cantidad de nodos",
      "Configurar alarmas de CloudWatch para el uso de CPU o el recuento de solicitudes para monitorear las métricas relevantes de las aplicaciones en contenedores que se ejecutan en Amazon EKS"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nUsar una combinación de Kubernetes Metrics y Kubernetes Cluster Autoscaler para gestionar la cantidad de nodos - Kubernetes Cluster Autoscaler y Kubernetes Metrics proporcionan una solución automatizada y eficiente para escalar los nodos del clúster en función de la demanda.\n\nKubernetes Cluster Autoscaler ajusta automáticamente el número de nodos en el clúster basándose en la necesidad de programar nuevos pods o la falla de nodos existentes.\nKubernetes Metrics proporciona la fuente de métricas necesaria para que Kubernetes Horizontal Pod Autoscaler (HPA) escale dinámicamente el número de pods en función del uso de CPU y otras métricas.\nOpciones incorrectas:\n\nUsar Amazon EC2 Auto Scaling Groups con políticas de escalado personalizadas para gestionar el escalado de los nodos de trabajo de EKS - Si bien los grupos de Auto Scaling de Amazon EC2 pueden utilizarse para gestionar los nodos de trabajo de EKS, este enfoque requiere más configuración y administración de políticas de escalado. No ofrece el mismo nivel de integración y automatización que Kubernetes Cluster Autoscaler, que está optimizado para cargas de trabajo en Kubernetes.\n\nIntegrar un endpoint de API optimizado para la periferia en Amazon API Gateway con Amazon EKS para gestionar y exponer APIs para las aplicaciones en contenedores que se ejecutan en EKS - API Gateway se utiliza principalmente para gestionar y exponer APIs, no para escalar automáticamente los recursos del clúster de EKS. Un endpoint optimizado en la periferia es útil para clientes distribuidos geográficamente, pero no aborda directamente la necesidad de escalado de la infraestructura.\n\nConfigurar alarmas de CloudWatch para el uso de CPU o el recuento de solicitudes para monitorear las métricas relevantes de las aplicaciones en contenedores que se ejecutan en Amazon EKS - Aunque las alarmas de CloudWatch pueden monitorear métricas del clúster de Amazon EKS, esta solución por sí sola no permite el escalado automático del clúster en respuesta a la demanda.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/eks/latest/userguide/autoscaling.html\n\nhttps://docs.aws.amazon.com/eks/latest/userguide/horizontal-pod-autoscaler.html"
  },
  {
    "q": "Una empresa ha refactorizado una aplicación heredada para ejecutarse como dos microservicios usando Amazon ECS. La aplicación procesa datos en dos partes y la segunda parte del proceso tarda más que la primera.\n¿Cómo puede un arquitecto de soluciones integrar los microservicios y permitir que escalen independientemente?",
    "o": [
      "Implementar código en microservicio 1 para enviar datos a una cola de Amazon SQS. Implementar código en microservicio 2 para procesar mensajes de la cola",
      "Implementar código en microservicio 1 para enviar datos a un bucket de Amazon S3. Usar notificaciones de eventos de S3 para invocar microservicio 2",
      "Implementar código en microservicio 1 para publicar datos en un tema de Amazon SNS. Implementar código en microservicio 2 para suscribirse a este tema",
      "Implementar código en microservicio 1 para enviar datos a Amazon Kinesis Data Firehose. Implementar código en microservicio 2 para leer desde Kinesis Data Firehose"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nImplementar código en microservicio 1 para enviar datos a una cola de Amazon SQS. Implementar código en microservicio 2 para procesar mensajes de la cola - Este es un buen caso de uso para Amazon SQS. Los microservicios deben estar desacoplados para que puedan escalar independientemente. Una cola de Amazon SQS permitirá que el microservicio 1 agregue mensajes a la cola. El microservicio 2 puede luego recoger los mensajes y procesarlos. Esto asegura que si hay un pico de tráfico en el frontend, los mensajes no se pierdan debido a que el proceso backend no esté listo para procesarlos.\n\nOpciones incorrectas:\n\nImplementar código en microservicio 1 para enviar datos a un bucket de Amazon S3. Usar notificaciones de eventos de S3 para invocar microservicio 2 - Una cola de mensajes sería preferible a un bucket S3.\n\nImplementar código en microservicio 1 para enviar datos a Amazon Kinesis Data Firehose. Implementar código en microservicio 2 para leer desde Kinesis Data Firehose - Esto no es cómo funciona Firehose. Firehose envía datos directamente a destinos, no es una cola de mensajes.\n\nImplementar código en microservicio 1 para publicar datos en un tema de Amazon SNS. Implementar código en microservicio 2 para suscribirse a este tema - Las notificaciones a temas se envían a los suscriptores. En este caso queremos que el segundo microservicio recoja los mensajes cuando esté listo (tirar de ellos).\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/welcome.html"
  },
  {
    "q": "Una empresa tiene una aplicación OLTP (Procesamiento de Transacciones en Línea) alojada en un clúster de Amazon ECS utilizando el tipo de lanzamiento Fargate. Esta aplicación utiliza una base de datos Amazon RDS que almacena los datos del sitio web de producción. El equipo de análisis de datos necesita ejecutar consultas sobre la base de datos para rastrear y auditar todas las transacciones de los usuarios. Estas consultas no deben afectar el rendimiento de la base de datos de producción de ninguna manera.\n¿Cuál de las siguientes es la solución más adecuada y rentable que debes implementar?",
    "o": [
      "Configurar una nueva réplica de lectura de Amazon RDS de la base de datos de producción. Dirigir al equipo de análisis de datos para que consulten los datos de producción desde la réplica",
      "Configurar una implementación Multi-AZ para la base de datos de producción en RDS. Dirigir al equipo de análisis de datos para que consulten los datos de producción desde la instancia en espera",
      "Actualizar el tipo de instancia de la base de datos RDS a una instancia más grande",
      "Configurar un nuevo clúster de base de datos Amazon Redshift. Migrar la base de datos de producción a Redshift y permitir que el equipo de análisis de datos obtenga información desde allí"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nConfigurar una nueva réplica de lectura de Amazon RDS de la base de datos de producción. Dirigir al equipo de análisis de datos para que consulten los datos de producción desde la réplica - Configurar una réplica de lectura de Amazon RDS permite distribuir la carga de consultas entre la base de datos de producción y una instancia separada optimizada para lectura. Esto ayuda a escalar horizontalmente el rendimiento de las consultas sin afectar el desempeño de la base de datos principal. Las réplicas de lectura pueden promoverse a instancias independientes si es necesario.\n\n\n\nOpciones incorrectas:\n\nConfigurar un nuevo clúster de base de datos Amazon Redshift. Migrar la base de datos de producción a Redshift y permitir que el equipo de análisis de datos obtenga información desde allí - Redshift está diseñado principalmente para cargas de trabajo OLAP (Procesamiento Analítico en Línea) y no para OLTP (Procesamiento de Transacciones en Línea). Migrar la base de datos de producción a Redshift no es una solución adecuada ni rentable para este escenario.\n\nConfigurar una implementación Multi-AZ para la base de datos de producción en RDS. Dirigir al equipo de análisis de datos para que consulten los datos de producción desde la instancia en espera - En una configuración Multi-AZ, la instancia en espera no está disponible para consultas directas. Su propósito es actuar como una réplica de respaldo en caso de que la instancia principal falle, no para manejar cargas de trabajo de análisis de datos.\n\nActualizar el tipo de instancia de la base de datos RDS a una instancia más grande - Aumentar el tamaño de la instancia de RDS generaría un costo significativo sin abordar el problema de escalabilidad para consultas de solo lectura. La base de datos de producción seguiría viéndose afectada por las consultas del equipo de análisis de datos. Una mejor solución es usar una réplica de lectura.\n\nReferencias:\n\nhttps://aws.amazon.com/caching/database-caching/\n\nhttps://aws.amazon.com/rds/details/read-replicas/\n\nhttps://aws.amazon.com/elasticache/"
  },
  {
    "q": "Una empresa tiene varias aplicaciones web con usuarios en todo el mundo. Cada aplicación está alojada en un grupo de Auto Scaling de instancias EC2 en múltiples zonas de disponibilidad (AZs) detrás de un Application Load Balancer (ALB). Todas las aplicaciones tienen su propio nombre de dominio completamente calificado.\nPara mayor seguridad, las aplicaciones deben utilizar un certificado SSL público de confianza.\n¿Cuál de las siguientes soluciones cumple con este requisito con la menor sobrecarga operativa?",
    "o": [
      "Emitir un certificado SSL/TLS usando AWS Certificate Manager Private Certificate Authority. Asociar el nuevo certificado al listener HTTPS de los ALBs",
      "Usar AWS Certificate Manager (ACM) para generar un certificado SSL/TLS público. Asociar el nuevo certificado SSL/TLS al listener HTTPS de los ALBs",
      "Usar OpenSSL para generar un certificado autofirmado. Importar el certificado SSL/TLS a AWS Certificate Manager (ACM) y asociarlo con el listener HTTPS de los ALBs",
      "Lanzar una autoridad certificadora (CA) autoalojada usando la herramienta Let's Encrypt en una instancia EC2 de Amazon. Utilizar el certificado raíz confiable ISRG Root X1. Generar un nuevo certificado SSL/TLS usando la utilidad CLI certbot. Asociar el nuevo certificado al listener HTTPS de los ALBs"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nUsar AWS Certificate Manager (ACM) para generar un certificado SSL/TLS público. Asociar el nuevo certificado SSL/TLS al listener HTTPS de los ALBs - La opción con menor sobrecarga operativa para generar y administrar certificados SSL/TLS públicos de confianza.\n\nACM proporciona certificados públicos gratuitos y administrados, eliminando la necesidad de renovar manualmente los certificados.\nSe integra automáticamente con ALB, CloudFront y API Gateway, simplificando la implementación.\nRenovaciones automáticas, lo que reduce la carga administrativa y evita la expiración accidental de los certificados.\n\n\nOpciones incorrectas:\n\nLanzar una autoridad certificadora (CA) autoalojada usando la herramienta Let's Encrypt en una instancia EC2 de Amazon. Utilizar el certificado raíz confiable ISRG Root X1. Generar un nuevo certificado SSL/TLS usando la utilidad CLI certbot. Asociar el nuevo certificado al listener HTTPS de los ALBs - Aunque Let's Encrypt proporciona certificados gratuitos, requiere configurar y administrar una autoridad certificadora autoalojada en una instancia EC2, lo que introduce costos operativos y mantenimiento adicional. Además, los certificados deben renovarse y reinstalarse manualmente cada 90 días.\n\nEmitir un certificado SSL/TLS usando AWS Certificate Manager Private Certificate Authority. Asociar el nuevo certificado al listener HTTPS de los ALBs - AWS Certificate Manager Private Certificate Authority (ACM PCA) emite certificados privados que no son confiables públicamente en internet. Este servicio está diseñado para entornos internos dentro de una organización, como autenticación de dispositivos o VPNs, y no cumple con el requisito de un certificado SSL público.\n\nUsar OpenSSL para generar un certificado autofirmado. Importar el certificado SSL/TLS a AWS Certificate Manager (ACM) y asociarlo con el listener HTTPS de los ALBs - Los certificados autofirmados generados con OpenSSL no son confiables públicamente y no cumplen con el requisito de seguridad de la empresa. Además, la importación manual en ACM y la renovación periódica aumentan la sobrecarga operativa.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/acm/latest/userguide/acm-overview.html\n\nhttps://docs.aws.amazon.com/acm-pca/latest/userguide/PcaWelcome.html\n\nhttps://docs.aws.amazon.com/acm/latest/userguide/import-certificate.html"
  },
  {
    "q": "Una organización planea utilizar una conexión AWS Direct Connect para establecer un enlace dedicado entre su red on-premises y AWS.\nLa organización necesita lanzar una solución totalmente administrada que automatice y acelere la replicación de datos hacia y desde varios servicios de almacenamiento en AWS.\n¿Cuál de las siguientes soluciones recomendarías?",
    "o": [
      "Usar un agente de AWS DataSync para transferir rápidamente los datos a través de un endpoint de servicio",
      "Usar una puerta de enlace de archivos (File Gateway) de AWS Storage Gateway para almacenar y recuperar archivos directamente usando el protocolo SMB",
      "Usar un agente de AWS DataSync para transferir rápidamente los datos a través de Internet",
      "Usar una puerta de enlace de cintas (Tape Gateway) de AWS Storage Gateway para almacenar datos en cintas virtuales y copiar tus backups a AWS de manera asíncrona"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nUsar un agente de AWS DataSync para transferir rápidamente los datos a través de un endpoint de servicio - El servicio ideal para este caso, ya que permite copiar grandes volúmenes de datos de manera rápida y automatizada hacia y desde los servicios de almacenamiento de AWS a través de AWS Direct Connect.\n\nAWS DataSync simplifica y acelera la transferencia de datos mediante un agente que puedes instalar en tu entorno on-premises o en una instancia EC2.\nAdmite múltiples protocolos como NFS, SMB y API de Amazon S3.\nUtilizar AWS Direct Connect como endpoint de servicio garantiza una conexión privada y segura sin pasar por la Internet pública.\n\n\nOpciones incorrectas:\n\nUsar una puerta de enlace de cintas (Tape Gateway) de AWS Storage Gateway para almacenar datos en cintas virtuales y copiar tus backups a AWS de manera asíncrona - AWS Storage Gateway (Tape Gateway) no es la mejor opción aquí porque está diseñado para almacenar backups en AWS usando cintas virtuales. No proporciona un método eficiente para acelerar la transferencia de datos operacionales entre on-premises y AWS.\n\nUsar un agente de AWS DataSync para transferir rápidamente los datos a través de Internet - Usar DataSync a través de Internet es incorrecto porque la organización ha decidido usar AWS Direct Connect para garantizar un canal de transferencia privado y seguro. Transferir datos a través de Internet no aprovecharía esta conexión dedicada.\n\nUsar una puerta de enlace de archivos (File Gateway) de AWS Storage Gateway para almacenar y recuperar archivos directamente usando el protocolo SMB - AWS Storage Gateway (File Gateway) es más adecuado para crear un almacenamiento híbrido en la nube, no para acelerar la migración o replicación de datos. Además, solo soporta unos pocos servicios de almacenamiento específicos, lo que limita su utilidad en este caso.\n\nReferencias:\n\nhttps://aws.amazon.com/datasync/faqs/\n\nhttps://docs.aws.amazon.com/datasync/latest/userguide/what-is-datasync.html\n\nhttps://docs.aws.amazon.com/general/latest/gr/dc.html"
  },
  {
    "q": "Una empresa necesita almacenar sus archivos financieros confidenciales en AWS, los cuales se acceden cada semana.\nEl arquitecto de soluciones recibió la instrucción de configurar un sistema de almacenamiento que utilice cifrado mediante envelope encryption y automatice la rotación de claves.\nAdemás, debe proporcionar un registro de auditoría que muestre quién usó la clave de cifrado y cuándo, con fines de seguridad.\n¿Qué combinación de acciones debe implementar el arquitecto para cumplir con el requisito de la manera más rentable? (Selecciona DOS)",
    "o": [
      "Usar Amazon S3 Glacier Deep Archive para almacenar los datos",
      "Usar Amazon S3 para almacenar los datos",
      "Configurar cifrado del lado del servidor con claves administradas por AWS Key Management Service (SSE-KMS)",
      "Configurar cifrado del lado del servidor con claves proporcionadas por el cliente (SSE-C)",
      "Configurar cifrado del lado del servidor con claves administradas por Amazon S3 (SSE-S3)"
    ],
    "a": [
      1,
      2
    ],
    "e": "Correcto:\n\nUsar Amazon S3 para almacenar los datos - Es la mejor opción para almacenar archivos que se acceden con frecuencia y requieren cifrado seguro con control de acceso y auditoría.\n\nConfigurar cifrado del lado del servidor con claves administradas por AWS Key Management Service (SSE-KMS) - El cifrado del lado del servidor con AWS KMS (SSE-KMS) permite la rotación automática de claves y proporciona un registro de auditoría que muestra quién usó la clave y cuándo. Además, SSE-KMS permite un mayor control sobre las claves de cifrado en comparación con otras opciones.\n\n\n\nOpciones incorrectas:\n\nConfigurar cifrado del lado del servidor con claves proporcionadas por el cliente (SSE-C) - SSE-C requiere que el cliente administre sus propias claves de cifrado, lo que significa que Amazon S3 no las almacena ni las gestiona. Esto no cumple con el requisito de proporcionar un registro de auditoría sobre el uso de claves.\n\nConfigurar cifrado del lado del servidor con claves administradas por Amazon S3 (SSE-S3) - SSE-S3 cifra los objetos con claves generadas y administradas por Amazon S3, pero no proporciona un registro de auditoría detallado sobre quién usó la clave de cifrado y cuándo. SSE-KMS es una mejor opción para cumplir con este requisito.\n\nUsar Amazon S3 Glacier Deep Archive para almacenar los datos - Amazon S3 Glacier Deep Archive está diseñado para almacenamiento a largo plazo de datos de acceso infrecuente. En este caso, los archivos se acceden cada semana, por lo que S3 estándar con cifrado SSE-KMS es una opción más adecuada.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html\n\nhttps://docs.aws.amazon.com/kms/latest/developerguide/services-s3.html"
  },
  {
    "q": "Una empresa de desarrollo de software está ejecutando una aplicación en una instancia EC2 bajo demanda. Como parte de la automatización, necesitan un script en shell que obtenga dinámicamente la dirección IP pública y privada de la instancia para configurar correctamente las conexiones de red.\n¿Cuál es la mejor manera de obtener estas direcciones IP dentro del script?",
    "o": [
      "Ejecutar un comando Curl o Get para obtener la información más reciente del usuario desde http://169.254.169.254/latest/user-data/",
      "Extraer la dirección IP desde una métrica de CloudWatch",
      "Ejecutar un comando Curl o Get para obtener la información más reciente de la metadata desde http://169.254.169.254/latest/meta-data/",
      "Consultar los permisos de IAM asociados a la instancia para obtener su dirección IP"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nEjecutar un comando Curl o Get para obtener la información más reciente de la metadata desde http://169.254.169.254/latest/meta-data/ - La metadata de la instancia EC2 proporciona información útil sobre la configuración de la instancia, incluyendo direcciones IP privadas y públicas. Se puede acceder a esta metadata dentro de la instancia ejecutando el siguiente comando:\n\ncurl http://169.254.169.254/latest/meta-data/\n\nDesde esta URL, se pueden obtener detalles como la dirección IP privada, la dirección IP pública (si existe), el hostname, los volúmenes de almacenamiento y otra información relevante.\n\nOpciones incorrectas:\n\nEjecutar un comando Curl o Get para obtener la información más reciente del usuario desde http://169.254.169.254/latest/user-data/ - La opción de user-data se usa para ejecutar scripts de inicio cuando la instancia se lanza, pero no almacena información sobre la dirección IP de la instancia.\n\nConsultar los permisos de IAM asociados a la instancia para obtener su dirección IP - IAM administra permisos y roles en AWS, pero no proporciona información sobre direcciones IP de instancias EC2.\n\nExtraer la dirección IP desde una métrica de CloudWatch - CloudWatch monitorea métricas de rendimiento, como CPU, memoria y tráfico de red, pero no permite obtener la dirección IP de una instancia EC2.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html"
  },
  {
    "q": "Un banco de inversión multinacional tiene una aplicación web que requiere un mínimo de 6 instancias EC2 en ejecución para atender a sus usuarios en todo el mundo.\nSe te ha instruido para garantizar la tolerancia a fallos de este sistema.\n¿Cuál de las siguientes opciones es la mejor?",
    "o": [
      "Desplegar un grupo de Auto Scaling con 3 instancias en cada una de 2 zonas de disponibilidad detrás de un Application Load Balancer",
      "Desplegar un grupo de Auto Scaling con 2 instancias en cada una de las 3 zonas de disponibilidad detrás de un Application Load Balancer",
      "Desplegar un grupo de Auto Scaling con 6 instancias en una sola zona de disponibilidad detrás de un Application Load Balancer",
      "Desplegar un grupo de Auto Scaling con 3 instancias en cada una de 3 zonas de disponibilidad detrás de un Application Load Balancer"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nDesplegar un grupo de Auto Scaling con 3 instancias en cada una de 3 zonas de disponibilidad detrás de un Application Load Balancer - Para garantizar la tolerancia a fallos, el sistema debe mantener un mínimo de 6 instancias en ejecución incluso si una zona de disponibilidad falla.\n\nAl desplegar 3 instancias en cada una de 3 Zonas de Disponibilidad, hay un total de 9 instancias en funcionamiento. En caso de que una zona falle y se pierdan 3 instancias, todavía quedarán 6 instancias activas, cumpliendo con el requisito mínimo.\n\n\n\nOpciones incorrectas:\n\nDesplegar un grupo de Auto Scaling con 2 instancias en cada una de las 3 zonas de disponibilidad detrás de un Application Load Balancer - Tener 2 instancias en cada una de las 3 zonas de disponibilidad da un total de 6, pero si una zona falla, se perderían 2, quedando solo 4 instancias activas, lo cual es insuficiente.\n\nDesplegar un grupo de Auto Scaling con 6 instancias en una sola zona de disponibilidad detrás de un Application Load Balancer - Desplegar 6 instancias en una sola zona de disponibilidad no proporciona tolerancia a fallos. Si la zona falla, todas las instancias quedarían inoperativas.\n\nDesplegar un grupo de Auto Scaling con 3 instancias en cada una de 2 zonas de disponibilidad detrás de un Application Load Balancer - Tener 3 instancias en cada una de 2 zonas da un total de 6, pero si una zona falla, se perderían 3, quedando solo 3 instancias activas, lo cual no cumple el requisito mínimo.\n\nReferencias:\n\nhttps://media.amazonwebservices.com/AWS_Building_Fault_Tolerant_Applications.pdf\n\nhttps://d1.awsstatic.com/whitepapers/aws-building-fault-tolerant-applications.pdf"
  },
  {
    "q": "Una empresa de medios necesita configurar un bucket de Amazon S3 para servir activos estáticos a una aplicación web pública. ¿Qué métodos garantizan que todos los objetos cargados en el bucket de S3 puedan ser leídos públicamente en Internet? (Selecciona DOS)",
    "o": [
      "No hacer nada. Los objetos de Amazon S3 ya son públicos por defecto",
      "Conceder acceso público de lectura al objeto al momento de cargarlo mediante la Consola de S3",
      "Configurar la política del bucket de S3 para establecer todos los objetos como lectura pública",
      "Configurar el uso compartido de recursos de origen cruzado (CORS) en el bucket de S3 para permitir que los objetos sean accesibles públicamente desde todos los dominios",
      "Crear un rol de IAM para establecer los objetos dentro del bucket de S3 como lectura pública"
    ],
    "a": [
      1,
      2
    ],
    "e": "Correcto:\n\nConfigurar la política del bucket de S3 para establecer todos los objetos como lectura pública - Configurar la política del bucket para establecer todos los objetos como públicos permite que cualquier usuario en Internet pueda leerlos. Las políticas de bucket son una de las formas más eficaces de administrar permisos en S3 a nivel de recurso.\n\nConceder acceso público de lectura al objeto al momento de cargarlo mediante la Consola de S3 - Otorgar acceso público de lectura al objeto al momento de la carga es otra forma de hacer que los objetos sean accesibles públicamente. En la Consola de S3, se puede habilitar esta opción manualmente durante la carga de archivos.\n\nOpciones incorrectas:\n\nCrear un rol de IAM para establecer los objetos dentro del bucket de S3 como lectura pública - Crear un rol de IAM para establecer los objetos dentro del bucket como públicos no es una solución válida. Los roles de IAM se utilizan para conceder permisos a usuarios y servicios dentro de AWS, pero no pueden hacer que los objetos de S3 sean públicos directamente.\n\nNo hacer nada. Los objetos de Amazon S3 ya son públicos por defecto - Por defecto, todos los recursos de Amazon S3 (buckets y objetos) son privados. Solo el propietario del recurso (la cuenta de AWS que los creó) tiene acceso a ellos a menos que se concedan permisos explícitos.\n\nConfigurar el uso compartido de recursos de origen cruzado (CORS) en el bucket de S3 para permitir que los objetos sean accesibles públicamente desde todos los dominios - Configurar CORS en el bucket de S3 no hace que los objetos sean accesibles públicamente. CORS solo permite que ciertos dominios accedan a los recursos del bucket cuando se hacen solicitudes desde un navegador, pero no cambia la configuración de permisos de los objetos.\n\nReferencias:\n\nhttp://docs.aws.amazon.com/AmazonS3/latest/dev/s3-access-control.html\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html"
  },
  {
    "q": "Una plataforma de transmisión de contenido digital está utilizando Amazon EC2, ELB y S3 para alojar su catálogo de videos. Actualmente, almacenan los archivos en la clase de almacenamiento estándar de S3, pero han identificado que los videos son accedidos con frecuencia solo durante los primeros tres meses después de su publicación.\nComo arquitecto de soluciones, ¿qué debes hacer para automatizar la transferencia de estos archivos a una solución de almacenamiento más rentable después de ese período?",
    "o": [
      "Usar Amazon SWF para coordinar la transferencia de datos entre S3 y Glacier",
      "Configurar Lifecycle Policies en S3 para mover automáticamente los archivos a Glacier después de tres meses",
      "Crear un script en shell personalizado que transfiera los datos manualmente de S3 a Glacier cada trimestre",
      "Usar Amazon SQS para gestionar las solicitudes de transferencia y programar un proceso de migración"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nConfigurar Lifecycle Policies en S3 para mover automáticamente los archivos a Glacier después de tres meses - Configurar Lifecycle Policies en Amazon S3 permite automatizar la transición de datos a diferentes clases de almacenamiento. En este caso, se puede definir una política que mueva los videos a S3 Glacier después de tres meses, reduciendo los costos sin necesidad de intervención manual.\n\nOpciones incorrectas:\n\nUsar Amazon SWF para coordinar la transferencia de datos entre S3 y Glacier - Amazon SWF (Simple Workflow Service) es un servicio para coordinar flujos de trabajo complejos, pero no está diseñado para la gestión del ciclo de vida de objetos en S3.\n\nUsar Amazon SQS para gestionar las solicitudes de transferencia y programar un proceso de migración - Amazon SQS (Simple Queue Service) es un servicio de mensajería utilizado para desacoplar aplicaciones, pero no gestiona transiciones de almacenamiento en S3.\n\nCrear un script en shell personalizado que transfiera los datos manualmente de S3 a Glacier cada trimestre - Un script en shell personalizado podría realizar la transferencia manualmente, pero esto requiere intervención constante y mantenimiento, lo que lo hace menos eficiente que una política de ciclo de vida automatizada.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html"
  },
  {
    "q": "Un popular juego móvil de realidad aumentada (AR) depende en gran medida de una API RESTful alojada en AWS.\nLa API utiliza Amazon API Gateway y una tabla DynamoDB con una capacidad de lectura y escritura provisionada preconfigurada.\nSegún el monitoreo del sistema, la tabla DynamoDB comienza a rechazar solicitudes (throttling) durante picos de carga, lo que causa una degradación en el rendimiento de la aplicación.\n¿Qué puedes hacer para mejorar el rendimiento de tu aplicación?",
    "o": [
      "Usar DynamoDB Auto Scaling",
      "Añadir la tabla DynamoDB a un Auto Scaling Group",
      "Crear una cola SQS frente a la tabla DynamoDB",
      "Integrar un Application Load Balancer con tu tabla DynamoDB"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nUsar DynamoDB Auto Scaling - DynamoDB Auto Scaling utiliza AWS Application Auto Scaling para ajustar dinámicamente la capacidad de lectura y escritura provisionada en función de los patrones reales de tráfico. Esto permite que la tabla aumente su capacidad en momentos de alta demanda sin experimentar throttling, y la reduzca cuando la carga disminuye, optimizando costos y rendimiento.\n\nOpciones incorrectas:\n\nIntegrar un Application Load Balancer con tu tabla DynamoDB - Application Load Balancer no es compatible con DynamoDB, ya que se usa para distribuir tráfico HTTP/HTTPS, mientras que DynamoDB maneja almacenamiento de datos y no tráfico de red directamente.\n\nCrear una cola SQS frente a la tabla DynamoDB - Usar Amazon SQS puede ayudar a gestionar cargas de solicitudes, pero no aumenta el rendimiento de DynamoDB. En este caso, el problema es el throttling de la tabla, lo cual SQS no resuelve.\n\nAñadir la tabla DynamoDB a un Auto Scaling Group - Auto Scaling Groups se utilizan para escalar instancias EC2, no para bases de datos NoSQL como DynamoDB. La forma correcta de escalar una tabla DynamoDB es mediante DynamoDB Auto Scaling.\n\nReferencia:\n\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/AutoScaling.html"
  },
  {
    "q": "Un líder técnico del equipo de Infraestructura en la Nube fue consultado por un desarrollador de software sobre los recursos de AWS necesarios para la aplicación web que está construyendo.\nEl desarrollador sabe que Instance Store solo proporciona almacenamiento efímero, lo que significa que los datos se eliminan automáticamente cuando la instancia se termina.\nPara garantizar la persistencia de los datos, la aplicación debe lanzarse en una instancia EC2 con un volumen EBS adjunto. Sin embargo, el desarrollador no está seguro de qué tipo de volumen EBS usar.\nEn este escenario, ¿cuáles de las siguientes afirmaciones sobre los volúmenes de Amazon EBS y sus respectivos usos son correctas? (Selecciona DOS)",
    "o": [
      "La virtualización de entrada/salida de un solo root (SR-IOV) es adecuada para una amplia gama de cargas de trabajo, incluidas bases de datos pequeñas y medianas, entornos de desarrollo y prueba, y volúmenes de arranque",
      "Los volúmenes 'Spot' proporcionan el costo más bajo por GB de todos los volúmenes EBS y son ideales para cargas de trabajo donde los datos se acceden con poca frecuencia y el costo de almacenamiento más bajo es importante",
      "Los volúmenes SSD de propósito general (gp3) con multi-attach habilitado ofrecen almacenamiento consistente y de baja latencia, y están diseñados para aplicaciones que requieren resiliencia multi-AZ",
      "Los volúmenes de IOPS aprovisionados ofrecen almacenamiento con rendimiento consistente y baja latencia, y están diseñados para aplicaciones intensivas en I/O como bases de datos relacionales o NoSQL",
      "Los volúmenes magnéticos ofrecen el costo más bajo por GB de todos los tipos de volúmenes EBS y son ideales para cargas de trabajo donde los datos se acceden con poca frecuencia y las aplicaciones donde el costo de almacenamiento más bajo es importante"
    ],
    "a": [
      3,
      4
    ],
    "e": "Correcto:\n\nLos volúmenes magnéticos ofrecen el costo más bajo por GB de todos los tipos de volúmenes EBS y son ideales para cargas de trabajo donde los datos se acceden con poca frecuencia y las aplicaciones donde el costo de almacenamiento más bajo es importante - Los volúmenes magnéticos son una opción de bajo costo en Amazon EBS, ideales para datos accedidos con poca frecuencia. Aunque han sido reemplazados en gran medida por Cold HDD (sc1) y Throughput Optimized HDD (st1), todavía pueden ser útiles para cargas de trabajo con requerimientos mínimos de rendimiento.\n\nLos volúmenes de IOPS aprovisionados ofrecen almacenamiento con rendimiento consistente y baja latencia, y están diseñados para aplicaciones intensivas en I/O como bases de datos relacionales o NoSQL - Los volúmenes de IOPS aprovisionados (io1/io2) están diseñados para aplicaciones altamente sensibles a la latencia y que requieren un rendimiento de IOPS constante, como bases de datos transaccionales, NoSQL y cargas de trabajo intensivas en I/O. Estos volúmenes permiten especificar un número fijo de IOPS al momento de la creación.\n\n\n\nOpciones incorrectas:\n\nLa virtualización de entrada/salida de un solo root (SR-IOV) es adecuada para una amplia gama de cargas de trabajo, incluidas bases de datos pequeñas y medianas, entornos de desarrollo y prueba, y volúmenes de arranque - SR-IOV (Single Root I/O Virtualization) no está relacionado con los volúmenes EBS, sino con la optimización de rendimiento en redes para instancias EC2 con Enhanced Networking.\n\nLos volúmenes 'Spot' proporcionan el costo más bajo por GB de todos los volúmenes EBS y son ideales para cargas de trabajo donde los datos se acceden con poca frecuencia y el costo de almacenamiento más bajo es importante - No existe un tipo de volumen EBS llamado 'Spot'. Spot Instances sí existen en EC2, pero los volúmenes EBS no tienen una modalidad \"Spot\".\n\nLos volúmenes SSD de propósito general (gp3) con multi-attach habilitado ofrecen almacenamiento consistente y de baja latencia, y están diseñados para aplicaciones que requieren resiliencia multi-AZ - El soporte de 'multi-attach' solo está disponible en los volúmenes de IOPS aprovisionados io1 e io2. Además, multi-attach no proporciona resiliencia multi-AZ, sino que simplemente permite que varias instancias dentro de la misma AZ compartan un volumen EBS.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AmazonEBS.html"
  },
  {
    "q": "Una empresa ha almacenado 200 TB de archivos de respaldo en Amazon S3. Los archivos están en un formato propietario del proveedor.\nEl arquitecto de soluciones necesita usar el software de conversión del proveedor para recuperar los archivos desde S3, transformarlos a un formato estándar y volver a cargarlos en S3.\nLa solución debe minimizar los costos de transferencia de datos.\n¿Cuál de las siguientes opciones puede satisfacer este requisito?",
    "o": [
      "Instalar el software de conversión en Amazon S3. Usar S3 Batch Operations para realizar la transformación de datos",
      "Desplegar la instancia EC2 en la misma Región que Amazon S3. Instalar el software de conversión en la instancia. Realizar la transformación de datos y volver a cargar los archivos en Amazon S3",
      "Desplegar la instancia EC2 en una Región diferente. Instalar el software de conversión en la instancia. Realizar la transformación de datos y volver a cargar los archivos en Amazon S3",
      "Exportar los datos usando un dispositivo AWS Snowball Edge. Instalar el software de conversión en el dispositivo. Transformar los datos y volver a cargarlos en Amazon S3"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nDesplegar la instancia EC2 en la misma Región que Amazon S3. Instalar el software de conversión en la instancia. Realizar la transformación de datos y volver a cargar los archivos en Amazon S3 - Desplegar la instancia EC2 en la misma Región que Amazon S3 permite minimizar los costos de transferencia de datos.\n\nAWS no cobra por la transferencia de datos entre S3 y EC2 cuando están en la misma Región. Instalar el software de conversión en EC2 y procesar los archivos dentro de la misma Región evita cargos adicionales por transferencia de datos.\n\n\n\nOpciones incorrectas:\n\nDesplegar la instancia EC2 en una Región diferente. Instalar el software de conversión en la instancia. Realizar la transformación de datos y volver a cargar los archivos en Amazon S3 - Desplegar la instancia EC2 en una Región diferente generaría costos innecesarios, ya que AWS cobra por la transferencia de datos entre Regiones.\n\nExportar los datos usando un dispositivo AWS Snowball Edge. Instalar el software de conversión en el dispositivo. Transformar los datos y volver a cargarlos en Amazon S3 - AWS Snowball Edge es útil para transferencias de datos entre on-premises y AWS, pero en este caso, todos los datos ya están en AWS. Snowball no es necesario.\n\nInstalar el software de conversión en Amazon S3. Usar S3 Batch Operations para realizar la transformación de datos - S3 Batch Operations no permite ejecutar software personalizado en S3. Solo facilita la ejecución de operaciones masivas sobre objetos almacenados en S3, pero no puede realizar la transformación de datos requerida.\n\nReferencias:\n\nhttps://aws.amazon.com/s3/pricing/\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AmazonS3.html"
  },
  {
    "q": "Una empresa de tecnología financiera permite que su equipo de ingenieros aprovisione y gestione recursos en AWS. Para automatizar procesos y realizar pruebas, los ingenieros utilizan claves de acceso de IAM en sus scripts y herramientas de desarrollo.\nEl equipo de seguridad ha establecido una nueva política que requiere que todas las claves de acceso de IAM sean rotadas cada 75 días. Además, cualquier clave que supere este límite debe desactivarse y eliminarse automáticamente sin intervención manual.\n¿Cuál de las siguientes soluciones proporciona el menor esfuerzo operativo para cumplir con estos requisitos?",
    "o": [
      "Utilizar la regla administrada de AWS Config para verificar si las claves de acceso de IAM de usuario no se han rotado en 75 días. Configurar una regla de Amazon EventBridge (Amazon CloudWatch Events) para capturar eventos de no conformidad y activar una función Lambda que elimine automáticamente las claves afectadas",
      "Crear una regla de Amazon EventBridge (Amazon CloudWatch Events) para monitorear claves de acceso de IAM con más de 75 días. Programar un trabajo de AWS Batch para ejecutarse cada 24 horas y eliminar todas las claves no conformes",
      "Crear una regla personalizada de AWS Config para verificar la antigüedad de las claves de acceso de IAM. Configurar un trabajo de AWS Batch que se ejecute cada 24 horas para identificar y eliminar las claves no conformes",
      "Crear una regla de Amazon EventBridge (Amazon CloudWatch Events) para detectar claves de acceso de IAM con más de 75 días. Configurar un destino para invocar una función Lambda que desactive y elimine automáticamente las claves antiguas"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nUtilizar la regla administrada de AWS Config para verificar si las claves de acceso de IAM de usuario no se han rotado en 75 días. Configurar una regla de Amazon EventBridge (Amazon CloudWatch Events) para capturar eventos de no conformidad y activar una función Lambda que elimine automáticamente las claves afectadas - AWS Config ofrece reglas administradas que permiten rastrear la antigüedad de las claves de acceso de IAM y etiquetarlas como NO CUMPLEN (NON_COMPLIANT) si superan el umbral de 75 días.\n\nAmazon EventBridge puede capturar estos eventos de no conformidad y activar una función Lambda que desactive y elimine automáticamente las claves antiguas. Esta solución es la más eficiente y automatizada, minimizando la intervención manual.\n\nOpciones incorrectas:\n\nCrear una regla personalizada de AWS Config para verificar la antigüedad de las claves de acceso de IAM. Configurar un trabajo de AWS Batch que se ejecute cada 24 horas para identificar y eliminar las claves no conformes - AWS Config no se integra directamente con AWS Batch para la remediación. AWS Batch es un servicio diseñado para procesamiento en paralelo, no para gestionar credenciales de IAM.\n\nCrear una regla de Amazon EventBridge (Amazon CloudWatch Events) para detectar claves de acceso de IAM con más de 75 días. Configurar un destino para invocar una función Lambda que desactive y elimine automáticamente las claves antiguas - Amazon EventBridge no puede detectar claves de IAM basándose en su antigüedad. Se requiere AWS Config para evaluar la antigüedad de las claves antes de que EventBridge pueda actuar sobre los eventos generados.\n\nCrear una regla de Amazon EventBridge (Amazon CloudWatch Events) para monitorear claves de acceso de IAM con más de 75 días. Programar un trabajo de AWS Batch para ejecutarse cada 24 horas y eliminar todas las claves no conformes - EventBridge no puede calcular directamente la antigüedad de las claves. AWS Config es necesario para identificar claves no conformes, y EventBridge se encarga únicamente de reaccionar ante estos eventos.\n\nReferencias:\n\nhttps://aws.amazon.com/blogs/mt/managing-aged-access-keys-through-aws-config-remediations/\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/config-resource-non-compliant/\n\nhttps://docs.aws.amazon.com/config/latest/developerguide/how-does-config-work.html"
  },
  {
    "q": "Una empresa tiene un conjunto fijo de instancias de Amazon EC2 dentro de una VPC en la nube de AWS. Estas instancias ejecutan una aplicación de misión crítica. En un incidente reciente, una de las instancias de EC2 se apagó repentinamente, afectando la disponibilidad de la aplicación. Para evitar este incidente en el futuro, la gerencia quiere recibir notificaciones sobre cualquier evento de AWS que pueda afectar estas instancias de EC2.\n¿Cuál de las siguientes opciones es la acción recomendada para cumplir con estos requisitos?",
    "o": [
      "Crea una regla de Amazon EventBridge (Amazon CloudWatch Events) que se ejecute cada 24 horas. Establece como destino una función de AWS Lambda que verificará el AWS Service Health Dashboard y enviará notificaciones sobre cualquier evento que pueda afectar a las instancias de Amazon EC2",
      "Crea una regla de Amazon EventBridge (Amazon CloudWatch Events) para verificar eventos en el AWS Personal Health Dashboard relacionados con instancias de Amazon EC2. Para enviar notificaciones, establece un tema de Amazon SNS como destino de la regla",
      "Configura una regla de Amazon EventBridge (Amazon CloudWatch Events) para verificar eventos en el AWS Service Health Dashboard relacionados con instancias de Amazon EC2. Para enviar notificaciones, establece un tema de Amazon SNS como destino de la regla",
      "Configura una regla de Amazon EventBridge (Amazon CloudWatch Events) para verificar cualquier cambio de estado en instancias de Amazon EC2. Establece como destino una función de AWS Lambda que enviará una notificación y reiniciará las instancias de Amazon EC2 afectadas"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nCrea una regla de Amazon EventBridge (Amazon CloudWatch Events) para verificar eventos en el AWS Personal Health Dashboard relacionados con instancias de Amazon EC2. Para enviar notificaciones, establece un tema de Amazon SNS como destino de la regla - AWS Personal Health Dashboard proporciona información específica de la cuenta sobre eventos que pueden afectar a los recursos de AWS, incluidas las instancias de Amazon EC2. Al configurar una regla de Amazon EventBridge para monitorear estos eventos y establecer un tema de Amazon SNS como destino, la empresa puede recibir notificaciones sobre problemas que puedan impactar su infraestructura.\n\nOpciones incorrectas:\n\nCrea una regla de Amazon EventBridge (Amazon CloudWatch Events) que se ejecute cada 24 horas. Establece como destino una función de AWS Lambda que verificará el AWS Service Health Dashboard y enviará notificaciones sobre cualquier evento que pueda afectar a las instancias de Amazon EC2 - AWS Service Health Dashboard solo muestra eventos públicos que pueden afectar a múltiples clientes en una región específica. No proporciona detalles sobre instancias de EC2 individuales en una cuenta. Por lo tanto, una regla de EventBridge que dependa de esta fuente no garantizaría que la empresa reciba notificaciones oportunas sobre problemas en sus propias instancias de EC2.\n\nConfigura una regla de Amazon EventBridge (Amazon CloudWatch Events) para verificar eventos en el AWS Service Health Dashboard relacionados con instancias de Amazon EC2. Para enviar notificaciones, establece un tema de Amazon SNS como destino de la regla - AWS Service Health Dashboard informa sobre problemas generales en los servicios de AWS, pero no sobre instancias EC2 específicas dentro de una cuenta determinada. Para obtener información relevante a nivel de cuenta, es necesario utilizar AWS Personal Health Dashboard.\n\nConfigura una regla de Amazon EventBridge (Amazon CloudWatch Events) para verificar cualquier cambio de estado en instancias de Amazon EC2. Establece como destino una función de AWS Lambda que enviará una notificación y reiniciará las instancias de Amazon EC2 afectadas - Esta opción no cumple con el requisito de recibir notificaciones sobre eventos futuros o programados que puedan afectar a las instancias EC2. En su lugar, esta configuración solo enviaría notificaciones después de que las instancias se hayan detenido, sin prevenir interrupciones de manera proactiva.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/health/latest/ug/cloudwatch-events-health.html\n\nhttps://docs.aws.amazon.com/health/latest/ug/what-is-aws-health.html\n\nhttps://docs.aws.amazon.com/health/latest/ug/getting-started-health-dashboard.html"
  },
  {
    "q": "Una empresa de análisis de datos está construyendo una aplicación de alto rendimiento que requiere escrituras concurrentes a un volumen de almacenamiento en bloque compartido desde múltiples instancias de Amazon EC2.\nLas instancias EC2 están basadas en Nitro y residen dentro de la misma Zona de Disponibilidad. La empresa necesita una solución de almacenamiento que admita conexiones simultáneas para facilitar la resistencia de datos y alta disponibilidad.\n¿Qué solución cumplirá estos requisitos?",
    "o": [
      "Usar volúmenes EBS SSD de Propósito General (gp2) con Amazon EBS Multi-Attach.",
      "Usar Amazon EFS con protocolo NFSv4.1 a través de múltiples instancias EC2.",
      "Usar volúmenes EBS SSD de IOPS Provisionadas (io2) con Amazon EBS Multi-Attach.",
      "Usar Amazon S3 con S3 Transfer Acceleration para mejorar la velocidad."
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nUsar volúmenes EBS SSD de IOPS Provisionadas (io2) con Amazon EBS Multi-Attach. - Los volúmenes io2 están diseñados para cargas de trabajo intensivas en I/O, particularmente cargas de trabajo de bases de datos, que requieren alto rendimiento y baja latencia. Los volúmenes io1 e io2 admiten Multi-Attach, lo que permite adjuntar un solo volumen a múltiples instancias EC2 en la misma Zona de Disponibilidad.\n\nOpciones incorrectas:\n\nUsar Amazon S3 con S3 Transfer Acceleration para mejorar la velocidad. - Amazon S3 es un servicio de almacenamiento de objetos. Aunque S3 Transfer Acceleration mejora la velocidad de transferencias de archivos en tránsito, no es una solución de almacenamiento en bloque, es una solución de almacenamiento de objetos y no es adecuada para este caso de uso.\n\nUsar Amazon EFS con protocolo NFSv4.1 a través de múltiples instancias EC2. - Amazon Elastic File System (EFS) es un almacenamiento de archivos escalable para usar con Amazon EC2. Puede usar un sistema de archivos de Amazon EFS como fuente de datos común para cargas de trabajo y aplicaciones que se ejecutan en múltiples instancias, pero no proporciona el almacenamiento a nivel de bloque requerido para operaciones de alto IOPS.\n\nUsar volúmenes EBS SSD de Propósito General (gp2) con Amazon EBS Multi-Attach. - Amazon EBS Multi-Attach solo admite volúmenes io1 e io2, y no está soportado en volúmenes gp2.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volumes-multi.html"
  },
  {
    "q": "Un arquitecto de soluciones está diseñando la arquitectura en la nube para la suite de aplicaciones empresariales de la compañía. Tanto el nivel web como el de aplicación necesitan acceder a Internet para obtener datos de API públicas. Sin embargo, estos servidores deben ser inaccesibles desde Internet.\n¿Qué pasos debe implementar el arquitecto para cumplir con estos requisitos?",
    "o": [
      "Desplegar una NAT gateway en la subred privada y agregarle una ruta desde la subred pública donde están alojados los niveles web y de aplicación",
      "Desplegar una NAT gateway en la subred pública y agregarle una ruta desde la subred privada donde están alojados los niveles web y de aplicación",
      "Desplegar las instancias de los niveles web y de aplicación en una subred pública y luego asignar una dirección Elastic IP a cada instancia de EC2",
      "Desplegar las instancias de los niveles web y de aplicación en una subred privada y luego asignar una dirección Elastic IP a cada instancia de EC2"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nDesplegar una NAT gateway en la subred pública y agregarle una ruta desde la subred privada donde están alojados los niveles web y de aplicación - Desplegar una NAT Gateway en la subred pública y agregar una ruta desde la subred privada es la mejor opción para permitir que las instancias en la subred privada accedan a Internet sin ser accesibles desde Internet.\n\nUna NAT Gateway permite que las instancias en una subred privada inicien conexiones salientes a Internet (por ejemplo, para consumir APIs públicas), pero evita conexiones entrantes no deseadas desde Internet.\nLa NAT Gateway debe residir en una subred pública y estar asociada con una Elastic IP (EIP).\nSe debe actualizar la tabla de enrutamiento de la subred privada para redirigir el tráfico saliente a la NAT Gateway.\nOpciones incorrectas:\n\nDesplegar las instancias de los niveles web y de aplicación en una subred privada y luego asignar una dirección Elastic IP a cada instancia de EC2 - Asignar Elastic IPs a instancias en una subred privada no permite el acceso a Internet. Las direcciones EIP solo proporcionan una dirección IPv4 estática pública, pero no modifican las reglas de enrutamiento necesarias para habilitar el tráfico saliente.\n\nDesplegar una NAT gateway en la subred privada y agregarle una ruta desde la subred pública donde están alojados los niveles web y de aplicación - Desplegar la NAT Gateway en la subred privada es incorrecto porque una NAT Gateway solo puede residir en una subred pública. No se puede colocar en una subred privada y cumplir su propósito.\n\nDesplegar las instancias de los niveles web y de aplicación en una subred pública y luego asignar una dirección Elastic IP a cada instancia de EC2 - Colocar las instancias en una subred pública contradice el requisito de seguridad de que las instancias no sean accesibles desde Internet. Además, asignar Elastic IPs haría que las instancias fueran directamente accesibles públicamente, lo que no es deseado en este escenario.\n\nReferencia:\n\nhttps://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html"
  },
  {
    "q": "Una empresa líder en consultoría de TI tiene una aplicación que procesa un flujo masivo de datos financieros utilizando un cluster de Amazon ECS, que luego almacena los resultados en una tabla de Amazon DynamoDB.\nDebes diseñar una solución para detectar nuevas entradas en la tabla DynamoDB y automáticamente activar una función Lambda para realizar pruebas en los datos procesados.\n¿Qué solución puede implementarse fácilmente para notificar a la función Lambda sobre las nuevas entradas con mínimos cambios de configuración en la arquitectura?",
    "o": [
      "Habilitar DynamoDB Streams para capturar la actividad de la tabla y activar automáticamente la función Lambda",
      "Invocar las funciones Lambda usando SNS cada vez que el clúster de ECS procese exitosamente los datos financieros",
      "Utilizar CloudWatch Alarms para activar la función Lambda cuando se cree una nueva entrada en la tabla DynamoDB",
      "Usar AWS Systems Manager Automation para detectar nuevas entradas en la tabla DynamoDB y luego invocar automáticamente la función Lambda para procesarlas"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nHabilitar DynamoDB Streams para capturar la actividad de la tabla y activar automáticamente la función Lambda - Permite detectar cambios en la tabla DynamoDB y activar automáticamente una función Lambda. DynamoDB Streams almacena eventos cuando se insertan, actualizan o eliminan elementos en la tabla. Luego, AWS Lambda puede ser configurado para procesar estos eventos y ejecutar código sin necesidad de configuraciones adicionales.\n\n\n\nOpciones incorrectas:\n\nInvocar las funciones Lambda usando SNS cada vez que el clúster de ECS procese exitosamente los datos financieros - Invocar Lambda usando SNS no es la mejor opción, ya que requeriría modificar el clúster ECS para publicar eventos en un tema SNS. DynamoDB Streams es una solución más directa y eficiente para este caso.\n\nUtilizar CloudWatch Alarms para activar la función Lambda cuando se cree una nueva entrada en la tabla DynamoDB - CloudWatch Alarms no puede detectar cambios en una tabla DynamoDB. Solo monitorea métricas de servicio, no modificaciones en los datos almacenados.\n\nUsar AWS Systems Manager Automation para detectar nuevas entradas en la tabla DynamoDB y luego invocar automáticamente la función Lambda para procesarlas - AWS Systems Manager Automation se usa para automatizar tareas de mantenimiento y despliegues en EC2 y otros recursos de AWS. No puede detectar nuevas entradas en DynamoDB.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Streams.Lambda.html\n\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Streams.html"
  },
  {
    "q": "Un arquitecto de soluciones está diseñando un sistema de registro para auditar todas las operaciones realizadas en la infraestructura de AWS de la empresa.\nEl equipo de cumplimiento y seguridad exige que los registros de auditoría sean retenidos durante 5 años sin posibilidad de eliminación o modificación antes de que puedan ser descartados.\n¿Cuál es la mejor solución para cumplir con este requisito?",
    "o": [
      "Almacenar los registros en Amazon EFS con bloqueo de archivos habilitado en Network File System versión 4 (NFSv4)",
      "Almacenar los registros de auditoría en un volumen de Amazon EBS y tomar snapshots cada mes",
      "Almacenar los registros en un bucket de Amazon S3 y habilitar Multi-Factor Authentication Delete (MFA Delete) para evitar eliminaciones accidentales",
      "Almacenar los registros en un vault de Amazon S3 Glacier y aplicar la función Vault Lock"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nAlmacenar los registros en un vault de Amazon S3 Glacier y aplicar la función Vault Lock - Amazon S3 Glacier Vault Lock es la mejor opción, ya que permite aplicar políticas de retención inmutables para garantizar que los registros no puedan ser eliminados o modificados antes de que haya transcurrido el período de retención obligatorio (5 años en este caso). Esto ayuda a cumplir con regulaciones de seguridad y auditoría.\n\nOpciones incorrectas:\n\nAlmacenar los registros en un bucket de Amazon S3 y habilitar Multi-Factor Authentication Delete (MFA Delete) para evitar eliminaciones accidentales - Aunque habilitar MFA Delete en Amazon S3 proporciona una capa adicional de seguridad contra eliminaciones accidentales, no impide que los datos sean modificados ni garantiza la retención obligatoria de los registros durante 5 años.\n\nAlmacenar los registros de auditoría en un volumen de Amazon EBS y tomar snapshots cada mes - Tomar snapshots de Amazon EBS cada mes no asegura la inmutabilidad de los registros de auditoría, ya que los volúmenes de EBS pueden ser modificados antes de la creación del snapshot, y estos pueden ser eliminados manualmente.\n\nAlmacenar los registros en Amazon EFS con bloqueo de archivos habilitado en Network File System versión 4 (NFSv4) - Amazon EFS con NFSv4 file-locking no garantiza una retención inmutable de los registros de auditoría, ya que los archivos podrían ser sobrescritos o eliminados con privilegios administrativos.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/amazonglacier/latest/dev/vault-lock.html\n\nhttps://aws.amazon.com/blogs/aws/glacier-vault-lock/"
  },
  {
    "q": "Una organización utiliza una base de datos Microsoft SQL Server para soportar su conjunto de aplicaciones.\nLa organización planea migrar a una base de datos Amazon Aurora PostgreSQL mientras minimiza las modificaciones en el código de las aplicaciones.\n¿Qué combinación de acciones permitirá lograr estos objetivos? (Selecciona DOS)",
    "o": [
      "Usar AWS Glue para transformar las consultas SQL de las aplicaciones para compatibilidad con Aurora PostgreSQL",
      "Usar AWS Schema Conversion Tool (AWS SCT) para convertir el esquema de base de datos y AWS Database Migration Service (AWS DMS) para migrar los datos",
      "Habilitar Babelfish en Aurora PostgreSQL para permitir que las aplicaciones continúen utilizando las consultas SQL existentes",
      "Usar Amazon Kinesis Data Streams para la replicación de datos en tiempo real a Aurora PostgreSQL",
      "Usar AWS AppConfig para administrar las actualizaciones de configuración durante la migración"
    ],
    "a": [
      1,
      2
    ],
    "e": "Correcto:\n\nUsar AWS Schema Conversion Tool (AWS SCT) para convertir el esquema de base de datos y AWS Database Migration Service (AWS DMS) para migrar los datos - AWS Schema Conversion Tool (SCT) y AWS Database Migration Service (DMS) son herramientas clave para la migración de bases de datos. AWS SCT convierte el esquema de Microsoft SQL Server al esquema de Aurora PostgreSQL, mientras que AWS DMS facilita la migración de datos con el menor tiempo de inactividad posible.\n\nHabilitar Babelfish en Aurora PostgreSQL para permitir que las aplicaciones continúen utilizando las consultas SQL existentes - Babelfish for Aurora PostgreSQL permite que las aplicaciones existentes que usan T-SQL (dialecto SQL de Microsoft) sigan ejecutándose en Aurora PostgreSQL con mínimos cambios en el código. Esto facilita la transición al nuevo motor de base de datos sin necesidad de reescribir completamente las consultas SQL.\n\nOpciones incorrectas:\n\nUsar Amazon Kinesis Data Streams para la replicación de datos en tiempo real a Aurora PostgreSQL - Amazon Kinesis Data Streams se utiliza para la ingesta y procesamiento de datos en tiempo real, pero no está diseñado para la conversión de esquemas de bases de datos ni para la migración. Aunque puede manejar replicación en tiempo real, no elimina la necesidad de convertir el esquema ni de ajustar la compatibilidad con SQL.\n\nUsar AWS AppConfig para administrar las actualizaciones de configuración durante la migración - AWS AppConfig es una herramienta útil para administrar actualizaciones de configuración, pero no aborda los desafíos principales de la migración, como la conversión de esquema, la migración de datos o la compatibilidad con SQL.\n\nUsar AWS Glue para transformar las consultas SQL de las aplicaciones para compatibilidad con Aurora PostgreSQL - AWS Glue es un servicio de extracción, transformación y carga (ETL) utilizado principalmente para la preparación y carga de datos en análisis. No está diseñado para transformar consultas SQL de aplicaciones con el fin de hacerlas compatibles con Aurora PostgreSQL.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/babelfish.html\n\nhttps://docs.aws.amazon.com/SchemaConversionTool/latest/userguide/CHAP.Welcome.html\n\nhttps://docs.aws.amazon.com/dms/latest/userguide/Welcome.html"
  },
  {
    "q": "Una empresa planea migrar una base de datos NoSQL a una instancia de EC2. La base de datos está configurada para replicar automáticamente los datos y mantener múltiples copias para redundancia. El arquitecto de soluciones necesita lanzar una instancia que tenga altos IOPS y acceso de lectura/escritura secuencial.\n¿Cuál de las siguientes opciones cumple con el requisito si el rendimiento de E/S es la máxima prioridad?",
    "o": [
      "Usar una instancia optimizada para cómputo con volúmenes instance store",
      "Usar instancias optimizadas para almacenamiento con volúmenes instance store",
      "Usar instancias de propósito general con volúmenes EBS",
      "Usar una instancia optimizada para memoria con volúmenes EBS"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nUsar instancias optimizadas para almacenamiento con volúmenes instance store - Las instancias optimizadas para almacenamiento están diseñadas para cargas de trabajo que requieren alto rendimiento de lectura/escritura secuencial y baja latencia en grandes volúmenes de datos locales.\n\nEstas instancias están optimizadas para manejar decenas de miles de operaciones de E/S por segundo (IOPS), lo que las hace ideales para bases de datos NoSQL con requisitos intensivos de almacenamiento.\nUtilizan volúmenes de instance store NVMe SSD, que proporcionan un mayor rendimiento de IOPS que los volúmenes de EBS.\nSe pueden combinar múltiples volúmenes en una configuración RAID 0 para maximizar el ancho de banda disponible.\nOpciones incorrectas:\n\nUsar una instancia optimizada para cómputo con volúmenes instance store - Las instancias optimizadas para cómputo están diseñadas para cargas de trabajo que requieren alto rendimiento de procesamiento, no de almacenamiento. No son adecuadas para bases de datos NoSQL con requisitos de alto I/O.\n\nUsar una instancia optimizada para memoria con volúmenes EBS - Las instancias optimizadas para memoria son adecuadas para bases de datos en memoria y aplicaciones de alto consumo de RAM, pero no están diseñadas para manejar grandes volúmenes de almacenamiento con altas tasas de lectura/escritura.\n\nUsar instancias de propósito general con volúmenes EBS - Las instancias de propósito general con volúmenes EBS no ofrecen el rendimiento de IOPS y el acceso de lectura/escritura secuencial necesarios para este caso de uso. EBS proporciona almacenamiento persistente, pero su rendimiento de I/O está limitado en comparación con instance store NVMe.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/storage-optimized-instances.html\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html"
  },
  {
    "q": "Una universidad ha implementado un sistema de inscripción en línea que se ejecuta en Amazon RDS. El arquitecto de soluciones debe monitorear métricas mejoradas en Amazon CloudWatch para garantizar la disponibilidad del sistema de inscripción.\n¿Cuáles son las métricas mejoradas que Amazon CloudWatch recopila de instancias de Amazon RDS que proporcionan información más precisa? (Selecciona DOS)",
    "o": [
      "Conexiones a la base de datos (Database Connections)",
      "Utilización de CPU (CPU Utilization)",
      "Procesos del sistema operativo (OS processes)",
      "Procesos secundarios de RDS (RDS child processes)",
      "Memoria libre (Freeable Memory)"
    ],
    "a": [
      2,
      3
    ],
    "e": "Correcto:\n\nProcesos secundarios de RDS (RDS child processes) - RDS child processes (Procesos secundarios de RDS) muestran un resumen de los procesos que soportan la instancia de base de datos, como aurora para Amazon Aurora y mysqld para bases de datos MySQL en RDS. Estos procesos incluyen información sobre hilos de procesos y utilización de CPU, lo que ayuda a identificar qué procesos tienen el mayor impacto en el rendimiento.\n\nProcesos del sistema operativo (OS processes) - OS processes (Procesos del sistema operativo) presentan un resumen de los procesos del kernel y del sistema que se ejecutan en la instancia de base de datos. Aunque generalmente tienen un impacto mínimo en el rendimiento, estas métricas pueden ser útiles para el diagnóstico del sistema.\n\nOpciones incorrectas:\n\nConexiones a la base de datos (Database Connections) - Database Connections (Conexiones a la base de datos) es una métrica regular de Amazon RDS en CloudWatch, no una métrica mejorada.\n\nMemoria libre (Freeable Memory) - Freeable Memory (Memoria libre) es una métrica estándar de RDS, pero no es parte de las métricas mejoradas que proporciona Enhanced Monitoring.\n\nUtilización de CPU (CPU Utilization) - CPU Utilization (Utilización de CPU) es recopilada a nivel de hipervisor por CloudWatch, mientras que Enhanced Monitoring usa un agente para recopilar métricas más detalladas desde el sistema operativo subyacente.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/rds-metricscollected.html\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Monitoring.OS.html#USER_Monitoring.OS.CloudWatchLogs"
  },
  {
    "q": "Una empresa de tecnología está desarrollando una nueva plataforma de trading de criptomonedas que permite la compra y venta de Bitcoin, Ethereum, Ripple, Tether y muchas otras. Se contrató a un ingeniero de la nube para construir la infraestructura necesaria para esta plataforma. Durante la primera semana, el ingeniero comenzó a crear scripts de CloudFormation en YAML para definir todos los recursos de AWS necesarios para la aplicación. El gerente se sorprendió de que el ingeniero no hubiera configurado de inmediato las instancias EC2, los buckets de S3 y otros recursos de AWS. No entiende el propósito de los scripts basados en texto que el ingeniero ha escrito y ha solicitado una aclaración.\nEn este escenario, ¿cuáles son los beneficios de usar Amazon CloudFormation que el gerente debería conocer para abordar sus inquietudes? (Selecciona DOS)",
    "o": [
      "Te permite modelar toda tu infraestructura en un archivo de texto",
      "Permite modelar, aprovisionar y controlar versiones de toda tu infraestructura en AWS",
      "Ubicación de almacenamiento para el código de tu aplicación",
      "Proporciona un almacenamiento de datos altamente duradero y escalable",
      "El uso de CloudFormation en sí mismo es gratuito, incluidos los recursos de AWS que se han creado"
    ],
    "a": [
      0,
      1
    ],
    "e": "Correcto:\n\nPermite modelar, aprovisionar y controlar versiones de toda tu infraestructura en AWS - AWS CloudFormation permite definir, aprovisionar y gestionar toda la infraestructura en AWS mediante código. Con CloudFormation, se pueden modelar los recursos, gestionar versiones de los entornos y automatizar despliegues de infraestructura.\n\nTe permite modelar toda tu infraestructura en un archivo de texto - CloudFormation usa archivos en formato JSON o YAML para modelar la infraestructura en un enfoque de \"Infraestructura como Código\". Esto facilita la gestión, automatización y replicación de entornos en AWS.\n\n\n\nOpciones incorrectas:\n\nProporciona un almacenamiento de datos altamente duradero y escalable - AWS CloudFormation no es un servicio de almacenamiento de datos. Su propósito es definir y gestionar la infraestructura en AWS, pero no proporciona almacenamiento escalable como S3 o EBS.\n\nUbicación de almacenamiento para el código de tu aplicación - CloudFormation no está diseñado para almacenar el código de una aplicación. Su función es definir y desplegar recursos de infraestructura, pero el almacenamiento del código de la aplicación generalmente se realiza en repositorios como S3, GitHub o AWS CodeCommit (AWS CodeCommit ya no está disponible para nuevos clientes).\n\nEl uso de CloudFormation en sí mismo es gratuito, incluidos los recursos de AWS que se han creado - Aunque el uso de CloudFormation en sí mismo no tiene costo adicional, los recursos de AWS que se crean mediante CloudFormation sí tienen costos asociados. La empresa aún debe pagar por el uso de instancias EC2, buckets de S3 y otros recursos aprovisionados.\n\nReferencias:\n\nhttps://aws.amazon.com/cloudformation/\n\nhttps://aws.amazon.com/cloudformation/faqs/"
  },
  {
    "q": "Un arquitecto de soluciones está trabajando para una gran empresa de medios con múltiples oficinas en todo el mundo. Se le ha encomendado construir un sistema para distribuir videos de entrenamiento a todos los empleados.\nUsando CloudFront, ¿qué método se debe utilizar para servir contenido almacenado en S3 sin que sea accesible públicamente desde S3 directamente?",
    "o": [
      "Crear una Origin Access Identity (OAI) para CloudFront y conceder acceso a los objetos en tu bucket de S3 a esa OAI",
      "Crear una política de bucket de S3 que liste la ID de distribución de CloudFront como el principal y el bucket de destino como el Amazon Resource Name (ARN)",
      "Crear una web ACL en AWS WAF para bloquear cualquier acceso público a S3 y adjuntarla a la distribución de Amazon CloudFront",
      "Crear un usuario de Identity and Access Management (IAM) para CloudFront y conceder acceso a los objetos en tu bucket de S3 a ese usuario de IAM"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nCrear una Origin Access Identity (OAI) para CloudFront y conceder acceso a los objetos en tu bucket de S3 a esa OAI - La mejor práctica para restringir el acceso a los objetos en S3 solo a través de CloudFront es usar una Origin Access Identity (OAI). Al crear una OAI y concederle permisos en el bucket de S3, CloudFront podrá acceder a los objetos mientras que el acceso público directo desde S3 queda bloqueado.\n\n\n\nOpciones incorrectas:\n\nCrear un usuario de Identity and Access Management (IAM) para CloudFront y conceder acceso a los objetos en tu bucket de S3 a ese usuario de IAM - No se puede crear directamente un usuario de IAM para una distribución específica de CloudFront. En su lugar, se debe usar una OAI, que es la forma recomendada de otorgar acceso a CloudFront a los objetos de S3.\n\nCrear una política de bucket de S3 que liste la ID de distribución de CloudFront como el principal y el bucket de destino como el Amazon Resource Name (ARN) - Configurar una política de bucket de S3 que incluya la ID de distribución de CloudFront no es suficiente. Primero, es necesario crear una OAI en CloudFront y luego usar esa OAI como una identidad autorizada en el bucket de S3.\n\nCrear una web ACL en AWS WAF para bloquear cualquier acceso público a S3 y adjuntarla a la distribución de Amazon CloudFront - AWS WAF se usa principalmente para proteger aplicaciones contra vulnerabilidades web comunes, pero no para restringir el acceso a CloudFront. No garantiza que los objetos de S3 solo sean accesibles a través de CloudFront.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-restricting-access-to-s3.html#private-content-granting-permissions-to-oai"
  },
  {
    "q": "Una empresa tiene un conjunto de servidores Linux ejecutándose en múltiples instancias EC2 On-Demand.\nEl equipo de auditoría necesita recopilar y procesar los archivos de registro (logs) de las aplicaciones generados por estos servidores para su informe.\n¿Cuál de los siguientes servicios es el mejor para usar en este caso?",
    "o": [
      "Amazon S3 Glacier para almacenar los archivos de logs de la aplicación y Spot EC2 Instances para procesarlos",
      "Amazon S3 para almacenar los archivos de logs de la aplicación y Amazon Elastic MapReduce para procesar los archivos de logs",
      "Amazon S3 Glacier Deep Archive para almacenar los archivos de logs de la aplicación y AWS ParallelCluster para procesarlos",
      "Una única instancia EC2 On-Demand para almacenar y procesar los archivos de logs"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nAmazon S3 para almacenar los archivos de logs de la aplicación y Amazon Elastic MapReduce para procesar los archivos de logs - Son la mejor combinación para este caso.\n\nS3 es una solución de almacenamiento duradero, altamente escalable y rentable para almacenar grandes volúmenes de archivos de logs.\nAmazon EMR facilita el procesamiento de grandes cantidades de datos mediante herramientas como Apache Hadoop, Apache Spark y Apache Hive, ideales para el análisis de logs y generación de reportes de auditoría.\n\n\nOpciones incorrectas:\n\nAmazon S3 Glacier para almacenar los archivos de logs de la aplicación y Spot EC2 Instances para procesarlos - Amazon S3 Glacier y Spot EC2 Instances no son adecuados porque Glacier está diseñado para archivado a largo plazo y no para el almacenamiento de logs que necesitan análisis frecuente. Además, Spot EC2 Instances pueden interrumpirse en cualquier momento, lo que podría afectar el procesamiento continuo de logs.\n\nUna única instancia EC2 On-Demand para almacenar y procesar los archivos de logs - Una única instancia EC2 On-Demand no es la mejor opción porque EC2 no es un servicio de almacenamiento recomendado para grandes volúmenes de logs ni tiene herramientas de procesamiento optimizadas como las que ofrece EMR.\n\nAmazon S3 Glacier Deep Archive para almacenar los archivos de logs de la aplicación y AWS ParallelCluster para procesarlos - S3 Glacier Deep Archive y AWS ParallelCluster no son adecuados porque Glacier Deep Archive tiene tiempos de recuperación muy largos, lo que lo hace poco práctico para análisis de logs. Además, AWS ParallelCluster está diseñado para cargas de trabajo HPC (High-Performance Computing), no para procesamiento de logs.\n\nReferencias:\n\nhttp://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-what-is-emr.html\n\nhttps://aws.amazon.com/hpc/parallelcluster/"
  },
  {
    "q": "Una aplicación de análisis de datos en tiempo real está utilizando AWS Lambda para procesar datos y almacenar los resultados en formato JSON en un bucket de S3. Para acelerar el flujo de trabajo existente, se necesita un servicio donde se puedan ejecutar análisis avanzados de Big Data sin mover los datos a un sistema de análisis independiente.\n¿Cuál de los siguientes grupos de servicios puedes usar para cumplir con este requisito?",
    "o": [
      "Amazon X-Ray, Amazon Neptune, DynamoDB",
      "Amazon Glue, Amazon Redshift, Amazon S3",
      "Amazon Athena, Amazon Redshift Spectrum, AWS Glue",
      "Amazon Neptune, DynamoDB DAX, Amazon Redshift Spectrum"
    ],
    "a": [
      2
    ],
    "e": "Correcto:\n\nAmazon Athena, Amazon Redshift Spectrum, AWS Glue - Son servicios altamente relevantes para realizar análisis de Big Data directamente en datos almacenados en Amazon S3, sin necesidad de moverlos a un sistema separado:\n\nAmazon Athena permite realizar consultas SQL interactivas directamente sobre datos almacenados en S3 en formatos estructurados y semiestructurados como JSON.\nAmazon Redshift Spectrum extiende las capacidades de consulta de Amazon Redshift para acceder y analizar datos estructurados y semiestructurados en S3, lo que facilita el análisis a gran escala.\nAWS Glue es un servicio de ETL (Extract, Transform, Load) completamente administrado que ayuda a catalogar, preparar y transformar datos en S3 para análisis.\n\n\nOpciones incorrectas:\n\nAmazon X-Ray, Amazon Neptune, DynamoDB - Amazon X-Ray es un servicio de trazabilidad de aplicaciones y no se usa para análisis de Big Data en S3. Amazon Neptune es una base de datos orientada a grafos, y DynamoDB no está diseñado para realizar análisis en datos almacenados en S3.\n\nAmazon Neptune, DynamoDB DAX, Amazon Redshift Spectrum - Aunque Amazon Redshift Spectrum es útil para análisis en S3, Amazon Neptune y DynamoDB DAX no ofrecen capacidades de análisis o consulta sobre datos almacenados en S3. Neptune se usa para bases de datos de grafos y DAX es un servicio de caché para DynamoDB.\n\nAmazon Glue, Amazon Redshift, Amazon S3 - Amazon Glue permite transformar y catalogar datos en S3, pero Redshift requiere cargar los datos en su clúster para realizar análisis. Esto contradice el requisito de realizar análisis directamente sobre los datos en S3 sin moverlos.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/athena/latest/ug/what-is.html\n\nhttps://docs.aws.amazon.com/redshift/latest/dg/c-using-spectrum.html\n\nhttps://docs.aws.amazon.com/glue/latest/dg/what-is-glue.html"
  },
  {
    "q": "Una empresa tiene un sistema de procesamiento de pedidos basado en la web que actualmente utiliza una cola estándar en Amazon SQS. El gerente de TI notó que en muchas ocasiones un pedido se procesó dos veces. Este problema ha causado muchos inconvenientes en el procesamiento y ha generado insatisfacción en los clientes. El objetivo es asegurarse de que este problema no vuelva a ocurrir.\n¿Qué solución se debe implementar para evitar que esto ocurra nuevamente en el futuro?",
    "o": [
      "Modificar el tiempo de visibilidad de SQS",
      "Usar una cola Amazon SQS FIFO en su lugar",
      "Modificar el período de retención en SQS",
      "Cambiar el tamaño del mensaje en SQS"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nUsar una cola Amazon SQS FIFO en su lugar - Usar una cola FIFO (First-In-First-Out) de Amazon SQS garantiza que los mensajes se procesen exactamente una vez y en el mismo orden en que fueron enviados. Las colas FIFO eliminan el problema de mensajes duplicados asegurando que cada mensaje se entregue una sola vez mediante mecanismos de deduplicación y secuenciación de mensajes.\n\n\n\nOpciones incorrectas:\n\nCambiar el tamaño del mensaje en SQS - Cambiar el tamaño del mensaje en SQS no está relacionado con este problema. Ajustar el tamaño del mensaje no afecta la duplicación de mensajes, ya que el problema principal se debe a la entrega al menos una vez (at-least-once delivery) de las colas estándar de SQS.\n\nModificar el tiempo de visibilidad de SQS - Modificar el tiempo de visibilidad en SQS no es una solución adecuada, ya que para las colas estándar este tiempo no garantiza que un mensaje no se reciba más de una vez. En su lugar, las aplicaciones deben diseñarse para ser idempotentes, lo que significa que no deben verse afectadas si procesan el mismo mensaje más de una vez.\n\nModificar el período de retención en SQS - Modificar el período de retención en SQS no es correcto, ya que este parámetro solo define cuánto tiempo Amazon SQS debe conservar los mensajes en la cola antes de eliminarlos automáticamente. No resuelve el problema de duplicación de mensajes.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-queue-types.html\n\nhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues-exactly-once-processing.html\n\nhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-visibility-timeout.html"
  },
  {
    "q": "Una empresa lanzó una instancia EC2 en una VPC recién creada. Notaron que la instancia generada no tiene un nombre de host DNS asociado.\n¿Cuál de las siguientes opciones podría ser una razón válida para este problema?",
    "o": [
      "La VPC recién creada tiene un bloque CIDR no válido",
      "Es necesario modificar el grupo de seguridad de la instancia EC2",
      "Amazon Route 53 no está habilitado",
      "Se deben habilitar la resolución DNS y el nombre de host DNS en la configuración de la VPC"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nSe deben habilitar la resolución DNS y el nombre de host DNS en la configuración de la VPC - Cuando se lanza una instancia EC2 en una VPC que no es predeterminada, AWS solo le proporciona un nombre de host DNS privado. Para que la instancia reciba un nombre de host DNS público, es necesario habilitar las opciones DNS resolution y DNS hostnames en la configuración de la VPC. Si estas opciones están deshabilitadas, la instancia no tendrá un nombre de host DNS asignado.\n\nOpciones incorrectas:\n\nLa VPC recién creada tiene un bloque CIDR no válido - Es poco probable que una VPC tenga un bloque CIDR no válido, ya que AWS valida estos bloques antes de permitir su creación. Además, un bloque CIDR no válido no está relacionado con la asignación de nombres de host DNS.\n\nAmazon Route 53 no está habilitado - Amazon Route 53 no necesita estar habilitado para que una instancia EC2 reciba un nombre de host DNS. Route 53 es el servicio de resolución de DNS de AWS, pero la configuración de la VPC es la que controla la asignación de nombres de host.\n\nEs necesario modificar el grupo de seguridad de la instancia EC2 - Los grupos de seguridad de EC2 actúan como firewalls para filtrar tráfico de red, pero no tienen ninguna relación con la asignación de nombres de host DNS.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-dns.html\n\nhttps://aws.amazon.com/vpc/"
  },
  {
    "q": "Una empresa está ejecutando una aplicación web en AWS. La aplicación está compuesta por un grupo de Auto Scaling detrás de un Application Load Balancer y una tabla de Amazon DynamoDB donde se almacenan los datos de los usuarios. El arquitecto de soluciones debe diseñar la aplicación para que permanezca disponible en caso de una falla regional.\nSe requiere una solución para monitorear automáticamente el estado de las cargas de trabajo en toda la cuenta de AWS, realizar revisiones arquitectónicas y verificar las mejores prácticas de AWS.\n¿Qué configuración cumple con este requisito con el menor tiempo de inactividad posible?",
    "o": [
      "En una región secundaria, crear una tabla global de DynamoDB y replicar el grupo de Auto Scaling y el Application Load Balancer. Usar el failover de Route 53 para enrutar automáticamente el tráfico a los recursos en la región secundaria. Configurar la herramienta AWS Well-Architected Tool para obtener fácilmente recomendaciones sobre las mejores prácticas de AWS",
      "Escribir una plantilla de CloudFormation que incluya el grupo de Auto Scaling, el Application Load Balancer y la tabla DynamoDB. En caso de una falla, desplegar la plantilla en una región secundaria. Configurar Amazon EventBridge (Amazon CloudWatch Events) para activar una función Lambda que actualice el registro DNS de Route 53. Lanzar un workspace de Amazon Managed Grafana para recibir automáticamente consejos y elementos de acción para mejorar las cargas de trabajo en función de las mejores prácticas de AWS",
      "Escribir una plantilla de CloudFormation que incluya el grupo de Auto Scaling, el Application Load Balancer y la tabla DynamoDB. En caso de una falla, desplegar la plantilla en una región secundaria. Usar el failover de Route 53 para enrutar automáticamente el tráfico a los recursos en la región secundaria. Configurar Amazon Managed Service for Prometheus para recibir información sobre las mejores prácticas de AWS",
      "En una región secundaria, crear un índice secundario global de la tabla DynamoDB y replicar el grupo de Auto Scaling y el Application Load Balancer. Usar el failover de Route 53 para enrutar automáticamente el tráfico a los recursos en la región secundaria. Configurar AWS Compute Optimizer para obtener recomendaciones sobre la mejora de las cargas de trabajo en función de las mejores prácticas de AWS"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nEn una región secundaria, crear una tabla global de DynamoDB y replicar el grupo de Auto Scaling y el Application Load Balancer. Usar el failover de Route 53 para enrutar automáticamente el tráfico a los recursos en la región secundaria. Configurar la herramienta AWS Well-Architected Tool para obtener fácilmente recomendaciones sobre las mejores prácticas de AWS - Replicar la capa de proceso (instancias EC2, Application Load Balancer) en una región secundaria y crear una tabla global de DynamoDB permite mantener la disponibilidad de los datos con mínimo tiempo de inactividad en caso de falla regional. Configurar Route 53 con failover garantiza la redirección automática del tráfico hacia la región secundaria. Además, AWS Well-Architected Tool permite monitorear la infraestructura y recibir recomendaciones para mejorar la arquitectura basada en mejores prácticas de AWS.\n\nOpciones incorrectas:\n\nEscribir una plantilla de CloudFormation que incluya el grupo de Auto Scaling, el Application Load Balancer y la tabla DynamoDB. En caso de una falla, desplegar la plantilla en una región secundaria. Configurar Amazon EventBridge (Amazon CloudWatch Events) para activar una función Lambda que actualice el registro DNS de Route 53. Lanzar un workspace de Amazon Managed Grafana para recibir automáticamente consejos y elementos de acción para mejorar las cargas de trabajo en función de las mejores prácticas de AWS - Esta solución implica la creación de los recursos solo después de que ocurra una falla regional, lo que genera más tiempo de inactividad. Además, Amazon Managed Grafana no proporciona recomendaciones sobre mejores prácticas de AWS, por lo que su inclusión es irrelevante en este contexto.\n\nEn una región secundaria, crear un índice secundario global de la tabla DynamoDB y replicar el grupo de Auto Scaling y el Application Load Balancer. Usar el failover de Route 53 para enrutar automáticamente el tráfico a los recursos en la región secundaria. Configurar AWS Compute Optimizer para obtener recomendaciones sobre la mejora de las cargas de trabajo en función de las mejores prácticas de AWS - Un índice secundario global de DynamoDB no puede crearse en una región diferente a la de la tabla principal, lo que hace que esta configuración sea imposible de implementar. Además, AWS Compute Optimizer solo proporciona sugerencias para la optimización de recursos, pero no mejora directamente la disponibilidad de la aplicación.\n\nEscribir una plantilla de CloudFormation que incluya el grupo de Auto Scaling, el Application Load Balancer y la tabla DynamoDB. En caso de una falla, desplegar la plantilla en una región secundaria. Usar el failover de Route 53 para enrutar automáticamente el tráfico a los recursos en la región secundaria. Configurar Amazon Managed Service for Prometheus para recibir información sobre las mejores prácticas de AWS - Amazon Managed Service for Prometheus es una herramienta de monitoreo para contenedores, pero no proporciona recomendaciones sobre mejores prácticas de AWS. Además, la solución propuesta requiere desplegar manualmente la infraestructura en la región secundaria después de un fallo, lo que aumenta el tiempo de inactividad.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-configuring.html\n\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/creating-disaster-recovery-mechanisms-using-amazon-route-53/\n\nhttps://aws.amazon.com/well-architected-tool"
  },
  {
    "q": "Una empresa tiene un clúster de High Performance Computing (HPC) compuesto por instancias EC2 con volúmenes Provisioned IOPS (io1) para procesar cargas de trabajo transaccionales intensivas y de baja latencia.\nEl arquitecto de soluciones debe mantener altos IOPS mientras minimiza la latencia ajustando la longitud óptima de la cola para el volumen.\nEl tamaño de cada volumen es de 10 GiB.\n¿Cuál de las siguientes configuraciones es la más adecuada que el arquitecto debe establecer?",
    "o": [
      "Configurar los IOPS en 1000 y luego habilitar burst performance",
      "Configurar los IOPS en 300 y luego priorizar throughput sobre latencia",
      "Configurar los IOPS en 500 y luego mantener una longitud de cola baja",
      "Configurar los IOPS en 200 y luego mantener una longitud de cola media"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nConfigurar los IOPS en 500 y luego mantener una longitud de cola baja - Los volúmenes io1 permiten configurar un rendimiento de IOPS consistente y se utilizan para cargas de trabajo sensibles a la latencia. El volumen de 10 GiB permite un máximo de 500 IOPS (aplicando la regla de 50:1, es decir, 50 × 10 GiB = 500 IOPS).\n\nPara optimizar la latencia, es recomendable mantener una longitud de cola baja, asegurando que haya suficientes IOPS disponibles sin generar una acumulación excesiva de solicitudes de E/S pendientes.\n\nOpciones incorrectas:\n\nConfigurar los IOPS en 200 y luego mantener una longitud de cola media - Configurar los IOPS en 200 con una longitud de cola media no maximiza el potencial del volumen ni garantiza la mínima latencia que requiere una carga de trabajo HPC.\n\nConfigurar los IOPS en 1000 y luego habilitar burst performance - La opción de configurar 1000 IOPS excede el límite permitido para un volumen io1 de 10 GiB. Además, la funcionalidad de \"burst\" no aplica a volúmenes io1, sino a volúmenes gp2/gp3.\n\nConfigurar los IOPS en 300 y luego priorizar throughput sobre latencia - Configurar 300 IOPS y enfocar el ajuste en throughput en lugar de latencia no es adecuado para cargas transaccionales, que dependen de tiempos de respuesta bajos y alta disponibilidad de IOPS.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-io-characteristics.html"
  },
  {
    "q": "Una empresa de análisis de datos ha estado recopilando información sobre patrones de consumo energético en América del Norte durante varios años. Actualmente, la empresa tiene un total de 8 TB de datos almacenados en un bucket de Amazon S3 en la región us-west-2.\nEstos datos deben ser compartidos con un socio europeo que también utiliza Amazon S3 para almacenamiento. Sin embargo, debido a restricciones presupuestarias, la empresa necesita minimizar los costos de transferencia de datos y garantizar que el acceso a los datos solo sea posible para usuarios autenticados.\n¿Qué solución cumple con estos requisitos de la manera más rentable?",
    "o": [
      "Habilitar la función El Solicitante Paga (Requester Pays) en el bucket de Amazon S3 para transferir los costos de descarga al socio y deshabilitar el acceso anónimo",
      "Configurar una política de acceso entre cuentas en el bucket de S3 para permitir la descarga de datos exclusivamente desde la cuenta de AWS del socio",
      "Habilitar Cross-Region Replication (CRR) en el bucket de S3 para copiar automáticamente el contenido al bucket del socio en Europa",
      "Habilitar S3 Object Lock en modo governance para reducir los costos de transferencia de datos y establecer un Legal Hold para cada objeto con el fin de restringir el acceso anónimo"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nHabilitar la función El Solicitante Paga (Requester Pays) en el bucket de Amazon S3 para transferir los costos de descarga al socio y deshabilitar el acceso anónimo - Habilitar la función El Solicitante Paga (Requester Pays) en un bucket de S3 transfiere los costos de descarga de datos al solicitante (en este caso, el socio europeo), en lugar de la empresa propietaria del bucket. Esto reduce significativamente los costos de transferencia de datos. Además, Requester Pays deshabilita automáticamente el acceso anónimo, garantizando que solo los usuarios autenticados puedan acceder a los datos.\n\n\n\nOpciones incorrectas:\n\nHabilitar Cross-Region Replication (CRR) en el bucket de S3 para copiar automáticamente el contenido al bucket del socio en Europa - No es rentable en este caso, ya que genera costos adicionales de transferencia de datos al replicar los objetos a una región diferente.\n\nHabilitar S3 Object Lock en modo governance para reducir los costos de transferencia de datos y establecer un Legal Hold para cada objeto con el fin de restringir el acceso anónimo - Es útil para evitar modificaciones o eliminaciones de datos, pero no ayuda a reducir los costos de transferencia ni afecta el acceso anónimo.\n\nConfigurar una política de acceso entre cuentas en el bucket de S3 para permitir la descarga de datos exclusivamente desde la cuenta de AWS del socio - El acceso entre cuentas en el bucket de S3 solo permite que el socio acceda a los datos, pero no evita que la empresa propietaria pague por la transferencia de datos cuando el socio descargue los archivos.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/RequesterPaysBuckets.html\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/RequesterPaysExamples.html"
  },
  {
    "q": "Hay lectores de tarjetas ubicados en cada entrada de los almacenes de una organización. Se envía un mensaje sobre HTTPS cuando se escanean las tarjetas para indicar quién intentó acceder a la entrada.\nUn arquitecto de soluciones debe diseñar un sistema para procesar estos mensajes. Se requiere una solución altamente disponible. La solución debe almacenar resultados en un almacén de datos duradero para análisis posterior.\n¿Qué arquitectura de sistema debe recomendar el arquitecto de soluciones?",
    "o": [
      "Configurar un endpoint HTTPS en Amazon API Gateway. Para procesar los mensajes y guardar los resultados en Amazon DynamoDB, configurar un endpoint de API Gateway para invocar una función de AWS Lambda.",
      "Configurar un endpoint de gateway de Amazon S3 en su VPC. Conectar la red de la instalación a la VPC a través de una conexión VPN Site-to-Site para que los datos del sensor puedan escribirse directamente en un bucket S3.",
      "Crear una instancia de Amazon EC2 para servir como endpoint HTTPS y procesar mensajes. Se debe configurar un bucket de Amazon S3 para la instancia EC2 para guardar los resultados.",
      "Dirigir mensajes entrantes del sensor a una función de AWS Lambda usando Amazon Route 53. Crear una función Lambda que procese mensajes y guarde resultados en Amazon DynamoDB."
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nConfigurar un endpoint HTTPS en Amazon API Gateway. Para procesar los mensajes y guardar los resultados en Amazon DynamoDB, configurar un endpoint de API Gateway para invocar una función de AWS Lambda. - Amazon API Gateway sería ideal para proporcionar un punto de entrada seguro para su aplicación y para que el tráfico se envíe vía HTTPS. AWS Lambda se integraría perfectamente con API Gateway para procesar los datos, ya que una solución basada en eventos como esta sería perfecta al diseñar un sistema escalable basado en uso esporádico. Finalmente, DynamoDB es altamente escalable y es un repositorio perfecto para datos que se almacenarán para análisis futuro.\n\nOpciones incorrectas:\n\nCrear una instancia de Amazon EC2 para servir como endpoint HTTPS y procesar mensajes. Se debe configurar un bucket de Amazon S3 para la instancia EC2 para guardar los resultados. - Como la acción de leer una tarjeta para iniciar el acceso a un almacén debería tomar solo unos segundos, iniciar una instancia EC2 para servir como endpoint HTTPS tomaría minutos y no es adecuado para este caso de uso.\n\nConfigurar un endpoint de gateway de Amazon S3 en su VPC. Conectar la red de la instalación a la VPC a través de una conexión VPN Site-to-Site para que los datos del sensor puedan escribirse directamente en un bucket S3. - Los endpoints de VPC están diseñados para facilitar el tráfico a través de la red troncal de AWS entre servicios de AWS y no se usan para crear conexiones entre endpoints externos fuera de la red de AWS y un bucket de Amazon S3.\n\nDirigir mensajes entrantes del sensor a una función de AWS Lambda usando Amazon Route 53. Crear una función Lambda que procese mensajes y guarde resultados en Amazon DynamoDB. - Amazon Route 53 es un servicio DNS administrado, y DNS no es necesario en este caso ya que el lector de tarjetas no tiene un nombre DNS.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/lambda/latest/dg/services-apigateway.html"
  },
  {
    "q": "Una plataforma de e-learning ha sido lanzada en AWS y utiliza una base de datos MySQL en Amazon RDS. El sitio web experimenta un alto tráfico de estudiantes que acceden a material de estudio, lo que genera una carga de trabajo intensiva en lectura en la base de datos.\nPara garantizar la consistencia y precisión de los datos, todas las transacciones en la base de datos deben cumplir con el modelo ACID.\nEn este contexto, ¿cuál de las siguientes opciones es la mejor solución para mejorar el rendimiento de lectura en la base de datos MySQL?",
    "o": [
      "Utilizar Amazon SQS para poner en cola las solicitudes de lectura",
      "Configurar Amazon RDS en un entorno Multi-AZ",
      "Habilitar Amazon RDS Standby Replicas",
      "Habilitar Amazon RDS Read Replicas"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nHabilitar Amazon RDS Read Replicas - Permite escalar horizontalmente el rendimiento de lectura al crear una o más réplicas de solo lectura de la base de datos. Las aplicaciones pueden dirigir consultas de solo lectura a estas réplicas, reduciendo la carga en la instancia principal y mejorando la capacidad de respuesta.\n\n\n\nOpciones incorrectas:\n\nUtilizar Amazon SQS para poner en cola las solicitudes de lectura - Ayudando a gestionar la carga de solicitudes, pero no mejora directamente el rendimiento de lectura de la base de datos. SQS se utiliza para desacoplar componentes en arquitecturas distribuidas, no para escalar bases de datos.\n\nHabilitar Amazon RDS Standby Replicas - Forman parte de una configuración Multi-AZ y están diseñadas para recuperación ante fallos, no para mejorar la capacidad de lectura. No pueden ser utilizadas activamente para consultas de lectura.\n\nConfigurar Amazon RDS en un entorno Multi-AZ - Proporciona alta disponibilidad al replicar datos a una instancia en espera, pero no mejora el rendimiento de lectura. La instancia en espera solo se activa en caso de fallo de la instancia principal.\n\nReferencias:\n\nhttps://aws.amazon.com/rds/details/read-replicas/\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html"
  },
  {
    "q": "Un grupo de Auto Scaling (ASG) de instancias Linux EC2 tiene un sistema de archivos Amazon FSx para OpenZFS con monitoreo básico habilitado en CloudWatch.\nEl arquitecto de soluciones notó que la aplicación heredada alojada en el ASG tarda mucho en cargarse.\nDespués de revisar las instancias, el arquitecto se dio cuenta de que el ASG no está lanzando más instancias como debería, a pesar de que los servidores ya tienen un alto uso de memoria.\n¿Cuál de las siguientes opciones debería implementar el arquitecto para resolver este problema?",
    "o": [
      "Configurar Amazon Rekognition para identificar automáticamente la causa del alto uso de memoria. Usar la herramienta AWS Well-Architected para activar automáticamente el evento de escalado del ASG basado en el uso general de memoria",
      "Habilitar el monitoreo detallado en las instancias EC2 del grupo de Auto Scaling. Usar AWS Auto Scaling con métricas personalizadas para escalar el grupo de Auto Scaling en función del uso de memoria agregado de las instancias EC2 de Amazon",
      "Implementar una solución de IA que aproveche Amazon Comprehend para rastrear el uso de memoria en tiempo real de cada instancia EC2. Usar Amazon SageMaker para activar automáticamente el evento de escalado de Auto Scaling si hay un alto uso de memoria",
      "Instalar el agente unificado de CloudWatch en las instancias EC2. Configurar un parámetro en AWS Systems Manager Parameter Store con la configuración del agente de CloudWatch para crear una métrica agregada sobre el porcentaje de uso de memoria. Escalar el grupo de Auto Scaling basado en la métrica agregada"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nInstalar el agente unificado de CloudWatch en las instancias EC2. Configurar un parámetro en AWS Systems Manager Parameter Store con la configuración del agente de CloudWatch para crear una métrica agregada sobre el porcentaje de uso de memoria. Escalar el grupo de Auto Scaling basado en la métrica agregada - De forma predeterminada, CloudWatch no monitorea el uso de memoria de las instancias EC2. Para recopilar esta métrica, es necesario instalar el agente unificado de CloudWatch en cada instancia EC2. Además, AWS Systems Manager Parameter Store permite almacenar y gestionar configuraciones de parámetros, lo que facilita la configuración automatizada del monitoreo del uso de memoria en CloudWatch. Esto permite que el grupo de Auto Scaling utilice esta métrica personalizada para escalar según el uso de memoria.\n\n\n\nOpciones incorrectas:\n\nImplementar una solución de IA que aproveche Amazon Comprehend para rastrear el uso de memoria en tiempo real de cada instancia EC2. Usar Amazon SageMaker para activar automáticamente el evento de escalado de Auto Scaling si hay un alto uso de memoria - Amazon Comprehend es un servicio de procesamiento de lenguaje natural (NLP) y no puede rastrear el uso de memoria en tiempo real en instancias EC2. Además, el uso de Amazon SageMaker en este contexto no es adecuado, ya que no hay un requisito de aprendizaje automático.\n\nConfigurar Amazon Rekognition para identificar automáticamente la causa del alto uso de memoria. Usar la herramienta AWS Well-Architected para activar automáticamente el evento de escalado del ASG basado en el uso general de memoria - Amazon Rekognition es un servicio de reconocimiento de imágenes y no puede analizar métricas del sistema de instancias EC2. La herramienta AWS Well-Architected tampoco tiene la capacidad de activar eventos de escalado automático en un ASG.\n\nHabilitar el monitoreo detallado en las instancias EC2 del grupo de Auto Scaling. Usar AWS Auto Scaling con métricas personalizadas para escalar el grupo de Auto Scaling en función del uso de memoria agregado de las instancias EC2 de Amazon - Aunque las métricas personalizadas pueden integrarse con AWS Auto Scaling, la habilitación del monitoreo detallado en CloudWatch solo mejora la granularidad de métricas estándar como la utilización de CPU. Para rastrear el uso de memoria, es necesario instalar el agente unificado de CloudWatch, que maneja directamente esta métrica.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Install-CloudWatch-Agent.html\n\nhttps://aws.amazon.com/blogs/mt/create-amazon-ec2-auto-scaling-policy-memory-utilization-metric-linux/\n\nhttps://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-parameter-store.html"
  },
  {
    "q": "Una startup está planificando configurar y gobernar un entorno de múltiples cuentas en AWS que sea seguro y compatible, en preparación para sus próximos proyectos. El gerente de TI requiere que la solución tenga un panel de control para la detección continua de recursos no conformes con las políticas y recursos fuera de cumplimiento en toda la empresa, además de cumplir con las mejores prácticas de estrategia de múltiples cuentas en AWS.\n¿Cuál de las siguientes opciones proporciona la forma más sencilla de cumplir con esta tarea?",
    "o": [
      "Usar AWS Control Tower para lanzar una zona de aterrizaje y aprovisionar automáticamente nuevas cuentas a través de un Account Factory. Utilizar el panel de control de AWS Control Tower para monitorear cuentas aprovisionadas en toda la empresa. Configurar guardrails preventivos y de detección para la aplicación de políticas",
      "Lanzar nuevas cuentas de AWS utilizando AWS CloudFormation StackSets. Usar AWS Config para rastrear continuamente los cambios de configuración y configurar reglas para monitorear recursos fuera de cumplimiento. Configurar un Multi-Account Multi-Region Data Aggregator para monitorear datos de cumplimiento de reglas y cuentas en una vista agregada",
      "Usar AWS Organizations para crear una zona de aterrizaje y aprovisionar automáticamente nuevas cuentas de AWS. Utilizar el AWS Personal Health Dashboard para ver las cuentas aprovisionadas en toda la empresa. Habilitar guardrails preventivos y de detección para la aplicación de políticas",
      "Usar AWS Service Catalog para lanzar nuevas cuentas de miembros de AWS. Configurar AWS Service Catalog Launch Constraints para rastrear cambios de configuración y monitorear recursos fuera de cumplimiento. Configurar un Multi-Account Multi-Region Data Aggregator para monitorear datos de cumplimiento de reglas y cuentas en una vista agregada"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nUsar AWS Control Tower para lanzar una zona de aterrizaje y aprovisionar automáticamente nuevas cuentas a través de un Account Factory. Utilizar el panel de control de AWS Control Tower para monitorear cuentas aprovisionadas en toda la empresa. Configurar guardrails preventivos y de detección para la aplicación de políticas - AWS Control Tower es la mejor solución para configurar y gobernar entornos de múltiples cuentas en AWS de manera sencilla y siguiendo las mejores prácticas.\n\nAWS Control Tower facilita la creación de una zona de aterrizaje (landing zone), lo que permite aprovisionar y gestionar múltiples cuentas de AWS de manera automatizada.\nProporciona un panel centralizado para visualizar todas las cuentas aprovisionadas y su estado de cumplimiento.\nImplementa guardrails preventivos y de detección, que permiten la gobernanza y supervisión de recursos en la organización de AWS.\nOrquesta servicios como AWS Organizations, AWS IAM Identity Center, AWS Service Catalog y AWS Config para brindar una solución completa de múltiples cuentas.\nOpciones incorrectas:\n\nUsar AWS Organizations para crear una zona de aterrizaje y aprovisionar automáticamente nuevas cuentas de AWS. Utilizar el AWS Personal Health Dashboard para ver las cuentas aprovisionadas en toda la empresa. Habilitar guardrails preventivos y de detección para la aplicación de políticas - AWS Organizations permite gestionar múltiples cuentas, pero no proporciona una zona de aterrizaje ni un panel de monitoreo de cumplimiento. Además, el AWS Personal Health Dashboard solo informa sobre eventos que afectan los recursos de AWS, pero no está diseñado para monitorear nuevas cuentas aprovisionadas ni su cumplimiento de políticas.\n\nLanzar nuevas cuentas de AWS utilizando AWS CloudFormation StackSets. Usar AWS Config para rastrear continuamente los cambios de configuración y configurar reglas para monitorear recursos fuera de cumplimiento. Configurar un Multi-Account Multi-Region Data Aggregator para monitorear datos de cumplimiento de reglas y cuentas en una vista agregada - Usar AWS CloudFormation StackSets y AWS Config puede monitorear el cumplimiento de recursos, pero requiere demasiada configuración manual y no facilita la creación automatizada de múltiples cuentas como AWS Control Tower.\n\nUsar AWS Service Catalog para lanzar nuevas cuentas de miembros de AWS. Configurar AWS Service Catalog Launch Constraints para rastrear cambios de configuración y monitorear recursos fuera de cumplimiento. Configurar un Multi-Account Multi-Region Data Aggregator para monitorear datos de cumplimiento de reglas y cuentas en una vista agregada - AWS Service Catalog se usa para la gestión centralizada de catálogos de productos de TI, como imágenes de máquinas virtuales y software, pero no es adecuado para la gobernanza de múltiples cuentas ni para monitorear recursos fuera de cumplimiento a nivel organizacional.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/controltower/latest/userguide/what-is-control-tower.html\n\nhttps://docs.aws.amazon.com/controltower/latest/userguide/how-control-tower-works.html\n\nhttps://docs.aws.amazon.com/controltower/latest/userguide/aws-multi-account-landing-zone.html#multi-account-guidance"
  },
  {
    "q": "Una empresa está buscando formas de incorporar su gasto actual de uso de AWS en su panel de seguimiento de gastos operativos. Se ha encargado a un arquitecto de soluciones proponer un método que permita a la empresa obtener los datos de costo del año actual y proyectar los costos para los próximos 12 meses de forma programática.\n¿Qué enfoque cumpliría estas necesidades con la MÍNIMA carga operativa?",
    "o": [
      "Generar informes de AWS Budgets sobre datos de costo de uso y enviar los datos a la corporación a través de SMTP.",
      "Configurar acciones de AWS Budgets para transmitir datos de costo de uso a la corporación vía FTP.",
      "Hacer uso de archivos de informes descargables de AWS Cost Explorer en formato .csv para acceder a datos relacionados con el costo de uso.",
      "Aprovechar la API de AWS Cost Explorer para recuperar datos relacionados con el costo de uso, usando paginación para conjuntos de datos más grandes."
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nAprovechar la API de AWS Cost Explorer para recuperar datos relacionados con el costo de uso, usando paginación para conjuntos de datos más grandes. - La API de AWS Cost Explorer proporciona acceso programático a información de costo y uso de AWS. El usuario puede consultar datos agregados como costos mensuales totales o uso diario total con esta API.\n\nAdemás, la API de Cost Explorer admite paginación para gestionar conjuntos de datos más grandes, lo que la hace eficiente para consultas más grandes.\n\nOpciones incorrectas:\n\nGenerar informes de AWS Budgets sobre datos de costo de uso y enviar los datos a la corporación a través de SMTP. - AWS Budgets no admite el envío de datos a través de SMTP. AWS Budgets es principalmente una herramienta para configurar alertas sobre sus costos o uso de AWS para controlar sus costos, en lugar de una herramienta para exportar o transmitir datos de costo.\n\nConfigurar acciones de AWS Budgets para transmitir datos de costo de uso a la corporación vía FTP. - Las acciones de AWS Budgets permiten establecer presupuestos personalizados de costo y uso que activan acciones (como apagar instancias EC2) cuando se superan los umbrales de presupuesto establecidos. Sin embargo, AWS Budgets no admite la transmisión de datos vía FTP.\n\nHacer uso de archivos de informes descargables de AWS Cost Explorer en formato .csv para acceder a datos relacionados con el costo de uso. - Aunque AWS Cost Explorer permite descargar informes .csv de sus datos de costo, este método no sería accesible de forma programática e implicaría pasos manuales para descargar y procesar los datos.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/aws-cost-management/latest/APIReference/API_Operations_AWS_Cost_Explorer_Service.html"
  },
  {
    "q": "Una firma financiera está diseñando una arquitectura de aplicación para su plataforma de trading en línea, la cual debe tener alta disponibilidad y tolerancia a fallos. El arquitecto de soluciones configuró la aplicación para utilizar un bucket de Amazon S3 en la región us-east-1 con el fin de almacenar grandes volúmenes de datos financieros intradía.\nEl almacenamiento de datos en el bucket no debe verse afectado incluso si hay una interrupción en una de las zonas de disponibilidad (AZs) o una falla a nivel regional.\n¿Qué debe hacer el arquitecto para evitar interrupciones costosas en el servicio y garantizar la durabilidad de los datos?",
    "o": [
      "Crear una Lifecycle Policy para respaldar periódicamente el bucket de S3 en Amazon Glacier",
      "Copiar el bucket de S3 a una instancia EC2 respaldada por EBS",
      "Habilitar Cross-Region Replication",
      "Crear un nuevo bucket de S3 en otra región y configurar Cross-Account Access al bucket ubicado en us-east-1"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nHabilitar Cross-Region Replication - En S3 es la mejor solución para garantizar la alta disponibilidad y durabilidad de los datos en caso de una interrupción regional.\n\nCRR replica automáticamente los objetos de un bucket de S3 a otro en una región diferente, asegurando que los datos sigan estando accesibles si la región principal experimenta una falla.\nProtege contra la pérdida total de datos debido a interrupciones regionales o eventos catastróficos en una región de AWS.\nPermite acceso ininterrumpido a los datos en otra región, minimizando los tiempos de inactividad y garantizando la continuidad operativa.\n\n\nOpciones incorrectas:\n\nCopiar el bucket de S3 a una instancia EC2 respaldada por EBS - Copiar los datos a una instancia EC2 con volúmenes EBS no es una solución ideal porque EBS está limitado a una sola AZ. Si la AZ donde está alojado el volumen de EBS experimenta una interrupción, los datos no estarán disponibles.\n\nCrear una Lifecycle Policy para respaldar periódicamente el bucket de S3 en Amazon Glacier - Amazon Glacier se usa para archivado de datos a largo plazo, no para garantizar alta disponibilidad y tolerancia a fallos en caso de una interrupción regional. Además, recuperar datos desde Glacier puede ser un proceso lento y costoso.\n\nCrear un nuevo bucket de S3 en otra región y configurar Cross-Account Access al bucket ubicado en us-east-1 - Cross-Account Access en S3 permite compartir objetos entre cuentas de AWS, pero no replica datos entre regiones. Para garantizar la disponibilidad de los datos en otra región, Cross-Region Replication (CRR) es la solución correcta.\n\nReferencias:\n\nhttps://aws.amazon.com/s3/faqs/\n\nhttps://aws.amazon.com/s3/features/replication/"
  },
  {
    "q": "Una empresa opera múltiples cuentas de AWS bajo AWS Organizations. Para gestionar mejor los costos, la empresa quiere asignar diferentes presupuestos para cada una de estas cuentas. La empresa también quiere prevenir el aprovisionamiento adicional de recursos en una cuenta de AWS si alcanza su presupuesto asignado antes del final del período presupuestario.\n¿Qué combinación de soluciones cumplirá estos requisitos? (Selecciona TRES.)",
    "o": [
      "Usar AWS Budgets para establecer diferentes presupuestos para cada cuenta de AWS. Configurar los presupuestos en la consola de Billing and Cost Management.",
      "Crear un usuario IAM con permisos adecuados para permitir a AWS Budgets hacer cumplir las acciones de presupuesto.",
      "Configurar un rol IAM con los permisos necesarios que permitan a AWS Budgets ejecutar acciones de presupuesto.",
      "Usar AWS Budgets en la consola de AWS Management Console para configurar presupuestos y especificar el umbral de costo para cada cuenta de AWS.",
      "Configurar alertas en AWS Budgets para notificar a la empresa cuando una cuenta esté a punto de alcanzar su umbral de presupuesto. Luego usar una acción de presupuesto que se vincule al rol IAM para prevenir el aprovisionamiento adicional de recursos.",
      "Configurar una alerta en AWS Budgets para notificar a la empresa cuando una cuenta particular alcance su umbral de presupuesto. Habilitar monitoreo en tiempo real para notificación inmediata."
    ],
    "a": [
      0,
      2,
      4
    ],
    "e": "Correcto:\n\nConfigurar un rol IAM con los permisos necesarios que permitan a AWS Budgets ejecutar acciones de presupuesto. - AWS Budgets puede ejecutar acciones de presupuesto (como prevenir el aprovisionamiento adicional de recursos) usando un rol IAM con los permisos necesarios.\n\nConfigurar alertas en AWS Budgets para notificar a la empresa cuando una cuenta esté a punto de alcanzar su umbral de presupuesto. Luego usar una acción de presupuesto que se vincule al rol IAM para prevenir el aprovisionamiento adicional de recursos. - Configurar alertas en AWS Budgets y vincular una acción de presupuesto a un rol IAM para la prevención automática del aprovisionamiento adicional de recursos es una forma correcta y eficiente de gestionar costos.\n\nUsar AWS Budgets para establecer diferentes presupuestos para cada cuenta de AWS. Configurar los presupuestos en la consola de Billing and Cost Management. - AWS Budgets es una herramienta que permite establecer presupuestos personalizados de costo y uso. Puede establecer su monto de presupuesto, y AWS le proporciona cargos estimados y costos pronosticados para su uso de AWS. Configurar los presupuestos en la consola de Billing and Cost Management es un paso recomendado.\n\nOpciones incorrectas:\n\nConfigurar una alerta en AWS Budgets para notificar a la empresa cuando una cuenta particular alcance su umbral de presupuesto. Habilitar monitoreo en tiempo real para notificación inmediata. - AWS Budgets no permite monitoreo en tiempo real; los datos pueden retrasarse hasta 24 horas. La frecuencia de las notificaciones de alertas de presupuesto no es personalizable al minuto o hora; típicamente se envían diariamente, semanalmente o cuando se cruza un cierto umbral.\n\nUsar AWS Budgets en la consola de AWS Management Console para configurar presupuestos y especificar el umbral de costo para cada cuenta de AWS. - Aunque AWS Budgets puede configurarse en la consola de AWS Management Console, los presupuestos no se establecen en el contexto de umbrales de costo para cada cuenta de AWS. Esta opción no es completamente precisa.\n\nCrear un usuario IAM con permisos adecuados para permitir a AWS Budgets hacer cumplir las acciones de presupuesto. - Aunque puede crear un usuario IAM con permisos necesarios, usar un rol IAM es generalmente una mejor práctica. Un usuario IAM es una entidad que crea en AWS para representar a la persona o servicio que lo usa para interactuar con AWS, mientras que un rol IAM es una identidad de AWS con políticas de permisos que determinan lo que la identidad puede y no puede hacer en AWS. Un rol no tiene credenciales a largo plazo asociadas como lo tiene un usuario IAM.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/cost-management/latest/userguide/budgets-controls.html"
  },
  {
    "q": "Una empresa aloja todas sus aplicaciones en su centro de datos en la costa este de EE.UU. La mayoría de las cargas de trabajo son aplicaciones heredadas que se ejecutan en máquinas virtuales individuales con sistemas operativos Linux y Windows. La empresa planea migrar todas sus cargas de trabajo en máquinas virtuales a la nube de AWS. Para minimizar cambios en las aplicaciones durante el proceso de migración, se ha decidido utilizar una estrategia de 'lift-and-shift'. Además, la empresa desea minimizar el tiempo de inactividad durante la migración.\n¿Cuál de las siguientes opciones debe implementar el arquitecto de soluciones para este escenario?",
    "o": [
      "Instalar el AWS Replication Agent en cada una de las máquinas virtuales on-premises para replicar continuamente los servidores en AWS. Usar AWS Migration Service (AWS MGN) para lanzar instancias de prueba y realizar el cambio final una vez completadas las pruebas",
      "Usar AWS Application Discovery Service para migraciones 'lift-and-shift'. Desplegar el AWS Application Discovery Agent en el centro de datos on-premises para iniciar el proceso de replicación. Una vez completada la replicación, lanzar instancias de Amazon EC2 basadas en las AMIs creadas",
      "Exportar las máquinas virtuales on-premises y subir las imágenes a un bucket de Amazon S3. Usar el servicio VM Import/Export para importar las imágenes y lanzarlas como instancias de Amazon EC2",
      "Utilizar AWS DataSync para migrar las cargas de trabajo de la aplicación a AWS. Desplegar la máquina virtual de AWS DataSync en el centro de datos on-premises. Una vez completada la replicación, lanzar instancias de Amazon EC2 basadas en las AMIs creadas"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nInstalar el AWS Replication Agent en cada una de las máquinas virtuales on-premises para replicar continuamente los servidores en AWS. Usar AWS Migration Service (AWS MGN) para lanzar instancias de prueba y realizar el cambio final una vez completadas las pruebas - La mejor opción para migraciones 'lift-and-shift'.\n\nAWS MGN permite la migración sin necesidad de modificar la aplicación, la arquitectura o los servidores migrados.\nReduce procesos manuales propensos a errores y minimiza el tiempo de inactividad.\nAl instalar AWS Replication Agent en los servidores de origen, estos pueden replicarse continuamente en AWS, permitiendo pruebas antes del cambio final.\n\n\nOpciones incorrectas:\n\nExportar las máquinas virtuales on-premises y subir las imágenes a un bucket de Amazon S3. Usar el servicio VM Import/Export para importar las imágenes y lanzarlas como instancias de Amazon EC2 - Exportar las máquinas virtuales on-premises y subirlas a S3 requiere una importación manual a EC2 mediante VM Import/Export. Este proceso es tedioso y puede provocar que las imágenes queden desactualizadas si hay cambios en las máquinas virtuales después de la exportación.\n\nUsar AWS Application Discovery Service para migraciones 'lift-and-shift'. Desplegar el AWS Application Discovery Agent en el centro de datos on-premises para iniciar el proceso de replicación. Una vez completada la replicación, lanzar instancias de Amazon EC2 basadas en las AMIs creadas - AWS Application Discovery Service se utiliza para rastrear el estado de migración de las aplicaciones on-premises desde el Migration Hub, pero no realiza la migración real de los servidores.\n\nUtilizar AWS DataSync para migrar las cargas de trabajo de la aplicación a AWS. Desplegar la máquina virtual de AWS DataSync en el centro de datos on-premises. Una vez completada la replicación, lanzar instancias de Amazon EC2 basadas en las AMIs creadas - AWS DataSync está diseñado para transferencias de datos entre almacenamiento on-premises y AWS, pero no es adecuado para migrar máquinas virtuales. No cumple con el requisito de migración de servidores completos a EC2.\n\nReferencias:\n\nhttps://aws.amazon.com/blogs/aws/how-to-use-the-new-aws-application-migration-service-for-lift-and-shift-migrations/\n\nhttps://docs.aws.amazon.com/mgn/latest/ug/what-is-application-migration-service.html\n\nhttps://docs.aws.amazon.com/mgn/latest/ug/first-time-setup-gs.html"
  },
  {
    "q": "Una empresa ejecuta una aplicación financiera usando un grupo de Auto Scaling de Amazon EC2 detrás de un Application Load Balancer (ALB). Cuando ejecuta informes de fin de mes en un día y hora específicos cada mes, la aplicación se vuelve inaceptablemente lenta. Las métricas de Amazon CloudWatch muestran que la utilización de CPU alcanza el 100%.\n¿Qué debe recomendar un arquitecto de soluciones para asegurar que la aplicación pueda manejar la carga de trabajo y evitar tiempo de inactividad?",
    "o": [
      "Configurar Amazon ElastiCache para eliminar parte de la carga de trabajo de las instancias EC2",
      "Configurar una política de escalado programado de EC2 Auto Scaling basada en el horario mensual",
      "Configurar una política de escalado simple de EC2 Auto Scaling basada en la utilización de CPU",
      "Configurar una distribución de Amazon CloudFront delante del ALB"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nConfigurar una política de escalado programado de EC2 Auto Scaling basada en el horario mensual - El escalado programado permite establecer su propio horario de escalado. En este caso, la acción de escalado puede programarse para ocurrir justo antes de la hora en que se ejecutarán los informes cada mes. Las acciones de escalado se realizan automáticamente en función del tiempo y la fecha. Esto asegurará que haya suficientes instancias EC2 para servir la demanda y prevenir que la aplicación se ralentice.\n\nOpciones incorrectas:\n\nConfigurar Amazon ElastiCache para eliminar parte de la carga de trabajo de las instancias EC2 - ElastiCache es una caché de base de datos, no puede reemplazar las funciones de cómputo de una instancia EC2.\n\nConfigurar una distribución de Amazon CloudFront delante del ALB - Esto sería más adecuado para proporcionar acceso a usuarios globales mediante el almacenamiento en caché de contenido.\n\nConfigurar una política de escalado simple de EC2 Auto Scaling basada en la utilización de CPU - Esto no evitaría que ocurra la ralentización ya que habría un retraso entre cuando la CPU alcanza el 100% y la métrica siendo reportada y las instancias adicionales siendo lanzadas.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/schedule_time.html"
  },
  {
    "q": "Como arquitecto de soluciones en AWS, te han asignado el diseño de una arquitectura que cumpla con una nueva norma de cumplimiento, la cual exige auditar mensualmente todas las instancias EC2 (tanto Windows como Linux) en producción para identificar problemas de rendimiento.\nLa empresa opera más de cien instancias EC2, y cada una debe contar con una solución de monitoreo centralizado que recopile métricas y registros detallados del sistema.\nEl equipo de operaciones utilizará herramientas nativas de análisis en AWS para revisar periódicamente estos registros y almacenar los resultados en un bucket de S3 para propósitos de auditoría.\nEn este escenario, ¿cuál es la forma más eficiente de recopilar y analizar los registros de las instancias con el menor esfuerzo?",
    "o": [
      "Instalar el AWS Inspector Agent en cada instancia, lo que permitirá recopilar y enviar periódicamente los registros a CloudWatch Logs. Configurar un panel de CloudWatch para analizar adecuadamente los datos de registro de todas las instancias",
      "Instalar el agente unificado de CloudWatch Logs en cada instancia, lo que permitirá recopilar y enviar automáticamente los registros a CloudWatch Logs. Analizar los datos de registro con CloudWatch Logs Insights",
      "Instalar AWS SDK en cada instancia y crear un script daemon personalizado que recopile y envíe periódicamente los registros a CloudWatch Logs. Habilitar el monitoreo detallado de CloudWatch y usar CloudWatch Logs Insights para analizar los datos de registro de todas las instancias",
      "Instalar el AWS Systems Manager Agent (SSM Agent) en cada instancia, lo que permitirá recopilar y enviar automáticamente los registros a CloudWatch Logs. Analizar los datos de registro con CloudWatch Logs Insights"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nInstalar el agente unificado de CloudWatch Logs en cada instancia, lo que permitirá recopilar y enviar automáticamente los registros a CloudWatch Logs. Analizar los datos de registro con CloudWatch Logs Insights - Es la opción más eficiente para recopilar y enviar automáticamente los registros a CloudWatch Logs desde todas las instancias EC2. Además, CloudWatch Logs Insights permite realizar consultas y análisis avanzados sobre los registros recopilados, facilitando la identificación de problemas de rendimiento.\n\n\n\nOpciones incorrectas:\n\nInstalar el AWS Systems Manager Agent (SSM Agent) en cada instancia, lo que permitirá recopilar y enviar automáticamente los registros a CloudWatch Logs. Analizar los datos de registro con CloudWatch Logs Insights - Aunque el agente de AWS Systems Manager (SSM Agent) puede recopilar registros, su enfoque principal es la administración remota y automatización de tareas en instancias EC2. No es la mejor opción para un monitoreo centralizado de registros en CloudWatch Logs.\n\nInstalar el AWS Inspector Agent en cada instancia, lo que permitirá recopilar y enviar periódicamente los registros a CloudWatch Logs. Configurar un panel de CloudWatch para analizar adecuadamente los datos de registro de todas las instancias - AWS Inspector es un servicio de evaluación de seguridad, no una herramienta de monitoreo de registros. Su propósito es identificar vulnerabilidades en las instancias EC2, pero no está diseñado para recopilar y analizar registros de sistema.\n\nInstalar AWS SDK en cada instancia y crear un script daemon personalizado que recopile y envíe periódicamente los registros a CloudWatch Logs. Habilitar el monitoreo detallado de CloudWatch y usar CloudWatch Logs Insights para analizar los datos de registro de todas las instancias - Usar AWS SDK y crear un script daemon personalizado requiere un esfuerzo significativo de implementación y mantenimiento. En su lugar, es más eficiente utilizar el agente unificado de CloudWatch Logs, que proporciona una solución lista para usar con integración nativa en CloudWatch Logs.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html\n\nhttps://docs.aws.amazon.com/systems-manager/latest/userguide/monitoring-ssm-agent.html\n\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AnalyzingLogData.html"
  },
  {
    "q": "Una empresa tiene un API Gateway regional en la región us-east-2 que actúa como proxy para un servicio backend.\nLos clientes se conectan al servicio utilizando la URL de invocación del API Gateway.\nPara mejorar la usabilidad, la empresa quiere asociar un dominio personalizado (api.blockstellart.com) con la API. Además, el nombre de dominio debe soportar HTTPS para asegurar conexiones seguras.\nLa empresa tiene una zona alojada en Amazon Route 53 para su dominio.\n¿Cuál sería el siguiente paso para lograr este objetivo?",
    "o": [
      "Solicitar un certificado público en la región us-east-1 para api.blockstellart.com utilizando AWS Certificate Manager (ACM). Crear un dominio personalizado en el API Gateway regional y asociarlo con api.blockstellart.com y el certificado ACM. En Route 53, crear un registro alias para api.blockstellart.com que apunte al dominio del API Gateway",
      "Solicitar un certificado público en la región us-east-2 para api.blockstellart.com utilizando AWS Certificate Manager (ACM). Crear un dominio personalizado en el API Gateway regional y asociarlo con api.blockstellart.com y el certificado ACM. En Route 53, crear un registro alias para api.blockstellart.com que apunte al dominio del API Gateway",
      "Importar un certificado público existente para api.blockstellart.com en AWS Certificate Manager (ACM) en la región us-east-2. En Route 53, crear un registro CNAME para api.blockstellart.com que apunte a la URL de invocación del API Gateway",
      "Usar AWS Certificate Manager Private Certificate Authority (ACM PCA) para generar un certificado privado para api.blockstellart.com. Sobrescribir la URL de invocación usando variables de entorno"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nSolicitar un certificado público en la región us-east-2 para api.blockstellart.com utilizando AWS Certificate Manager (ACM). Crear un dominio personalizado en el API Gateway regional y asociarlo con api.blockstellart.com y el certificado ACM. En Route 53, crear un registro alias para api.blockstellart.com que apunte al dominio del API Gateway - Primero debes solicitar un certificado público en la misma región donde está desplegado el API Gateway (en este caso, us-east-2) utilizando AWS Certificate Manager (ACM). Luego, debes configurar el dominio personalizado en el API Gateway y asociarlo con el certificado ACM. Finalmente, debes crear un registro alias en Route 53 que apunte al dominio del API Gateway.\n\nOpciones incorrectas:\n\nUsar AWS Certificate Manager Private Certificate Authority (ACM PCA) para generar un certificado privado para api.blockstellart.com. Sobrescribir la URL de invocación usando variables de entorno - Los certificados privados de ACM PCA se usan para entornos internos, no para asegurar conexiones HTTPS públicas. Además, sobrescribir la URL de invocación con variables de entorno no es relevante para este caso.\n\nImportar un certificado público existente para api.blockstellart.com en AWS Certificate Manager (ACM) en la región us-east-2. En Route 53, crear un registro CNAME para api.blockstellart.com que apunte a la URL de invocación del API Gateway - No se puede usar un CNAME para apuntar a la URL de invocación del API Gateway en este caso. Se debe utilizar la funcionalidad de Custom Domain Names de API Gateway para mapear el dominio personalizado al API Gateway correctamente.\n\nSolicitar un certificado público en la región us-east-1 para api.blockstellart.com utilizando AWS Certificate Manager (ACM). Crear un dominio personalizado en el API Gateway regional y asociarlo con api.blockstellart.com y el certificado ACM. En Route 53, crear un registro alias para api.blockstellart.com que apunte al dominio del API Gateway - Para un API Gateway regional, el certificado debe solicitarse en la misma región donde está desplegada la API. En este caso, el API Gateway está en us-east-2, por lo que solicitar el certificado en us-east-1 no funcionará.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-api-endpoint-types.html\n\nhttps://docs.aws.amazon.com/acm/latest/userguide/acm-overview.html\n\nhttps://docs.aws.amazon.com/route53/"
  },
  {
    "q": "Una multinacional está almacenando archivos confidenciales en un bucket de S3. El equipo de seguridad realizó recientemente una auditoría y el informe mostró que varios archivos se habían subido sin cifrado del lado del servidor (SSE) con AES-256.\nPara una protección adicional, la clave de cifrado debe rotarse automáticamente cada año. El arquitecto de soluciones debe garantizar que en el futuro no se suban archivos sin cifrar en el bucket de S3.\n¿Cuál de las siguientes opciones cumplirá estos requisitos con el menor esfuerzo operativo?",
    "o": [
      "Crear una bucket policy en S3 que deniegue los permisos para subir un objeto a menos que la solicitud incluya el encabezado s3:x-amz-server-side-encryption: \"AES256\". Habilitar el cifrado del lado del servidor con claves administradas por Amazon S3 (SSE-S3) y confiar en la rotación automática de claves integrada de SSE-S3",
      "Crear una nueva clave administrada por el cliente en AWS Key Management Service (AWS KMS). Configurar el comportamiento de cifrado predeterminado del bucket para usar la clave administrada por el cliente. Rotar manualmente la clave KMS cada año",
      "Crear una Service Control Policy (SCP) para el bucket de S3 que rechace cualquier carga de objetos a menos que la solicitud incluya el encabezado s3:x-amz-server-side-encryption: \"AES256\". Habilitar el cifrado del lado del servidor con claves administradas por Amazon S3 (SSE-S3) y modificar la rotación de claves integrada de SSE-S3 para rotar la clave anualmente",
      "Crear una bucket policy en S3 que rechace cualquier carga de objetos a menos que la solicitud incluya el encabezado s3:x-amz-server-side-encryption: \"aws:kms\". Habilitar el S3 Object Lock en modo de cumplimiento para que todos los objetos roten automáticamente la clave administrada por el cliente AES256 del bucket"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nCrear una bucket policy en S3 que deniegue los permisos para subir un objeto a menos que la solicitud incluya el encabezado s3:x-amz-server-side-encryption: \"AES256\". Habilitar el cifrado del lado del servidor con claves administradas por Amazon S3 (SSE-S3) y confiar en la rotación automática de claves integrada de SSE-S3 - La mejor manera de garantizar que todos los objetos cargados en el bucket de S3 estén cifrados con AES-256 y con la menor sobrecarga operativa es usar una bucket policy que deniegue la carga de archivos sin el encabezado s3:x-amz-server-side-encryption: \"AES256\".\n\nAdicionalmente, habilitar SSE-S3 permite aprovechar la rotación automática de claves cada 365 días sin necesidad de configuración manual, ya que estas claves son administradas por AWS.\n\n\n\n\n\nOpciones incorrectas:\n\nCrear una Service Control Policy (SCP) para el bucket de S3 que rechace cualquier carga de objetos a menos que la solicitud incluya el encabezado s3:x-amz-server-side-encryption: \"AES256\". Habilitar el cifrado del lado del servidor con claves administradas por Amazon S3 (SSE-S3) y modificar la rotación de claves integrada de SSE-S3 para rotar la clave anualmente - Una Service Control Policy (SCP) no es la opción adecuada porque SCP se aplica a cuentas de AWS completas, no a buckets individuales de S3. Además, no es posible modificar la rotación automática de claves en SSE-S3.\n\nCrear una nueva clave administrada por el cliente en AWS Key Management Service (AWS KMS). Configurar el comportamiento de cifrado predeterminado del bucket para usar la clave administrada por el cliente. Rotar manualmente la clave KMS cada año - Utilizar AWS KMS con claves administradas por el cliente requiere rotar manualmente la clave cada año, lo que agrega sobrecarga operativa. Además, KMS incurre en costos adicionales en comparación con SSE-S3.\n\nCrear una bucket policy en S3 que rechace cualquier carga de objetos a menos que la solicitud incluya el encabezado s3:x-amz-server-side-encryption: \"aws:kms\". Habilitar el S3 Object Lock en modo de cumplimiento para que todos los objetos roten automáticamente la clave administrada por el cliente AES256 del bucket - S3 Object Lock no está diseñado para la rotación de claves, sino para prevenir la eliminación o sobrescritura de archivos durante un período de tiempo definido. Además, la política solo permitiría SSE-KMS, no SSE-S3 con AES-256.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/bucket-policies.html\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingServerSideEncryption.html\n\nhttps://docs.aws.amazon.com/kms/latest/developerguide/rotate-keys.html"
  },
  {
    "q": "Una empresa necesita almacenar datos de una aplicación. Los datos en la aplicación cambian frecuentemente. Todos los niveles de datos almacenados deben ser auditados bajo una nueva regulación a la que la empresa se adhiere.\nLa capacidad de almacenamiento de la aplicación se está agotando en la infraestructura on-premises de la empresa. Para cumplir con la nueva regulación, un arquitecto de soluciones debe descargar algunos datos de forma segura a AWS para aliviar los problemas de capacidad on-premises.\n¿Qué solución cumplirá estos requisitos?",
    "o": [
      "Usar AWS Storage Gateway para mover los datos existentes a Amazon S3. Usar AWS CloudTrail para registrar eventos de gestión.",
      "Mover los datos existentes a Amazon S3 con AWS Snowcone. Usando AWS CloudTrail, puede registrar eventos de gestión.",
      "Mover datos existentes a Amazon S3 usando AWS DataSync. Registrar eventos de datos usando AWS CloudTrail.",
      "Los datos existentes pueden transferirse a Amazon S3 con la ayuda de Amazon S3 Transfer Acceleration. Registrar eventos de datos usando AWS CloudTrail."
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nUsar AWS Storage Gateway para mover los datos existentes a Amazon S3. Usar AWS CloudTrail para registrar eventos de gestión. - AWS Storage Gateway es un conjunto de servicios de almacenamiento en la nube híbrida que proporcionan acceso on-premises a almacenamiento en la nube virtualmente ilimitado. En segundo lugar, AWS CloudTrail monitorea y registra la actividad de la cuenta en toda su infraestructura de AWS, dándole control sobre almacenamiento, análisis y acciones de remediación.\n\nOpciones incorrectas:\n\nMover los datos existentes a Amazon S3 con AWS Snowcone. Usando AWS CloudTrail, puede registrar eventos de gestión. - AWS Snowcone no es adecuado como servicio de nube híbrida.\n\nLos datos existentes pueden transferirse a Amazon S3 con la ayuda de Amazon S3 Transfer Acceleration. Registrar eventos de datos usando AWS CloudTrail. - Amazon S3 Transfer Acceleration es una característica a nivel de bucket que permite transferencias rápidas, fáciles y seguras de archivos a largas distancias entre su cliente y un bucket S3. Transfer Acceleration está diseñado para optimizar velocidades de transferencia desde todo el mundo hacia buckets S3 y no es un servicio de migración.\n\nMover datos existentes a Amazon S3 usando AWS DataSync. Registrar eventos de datos usando AWS CloudTrail. - AWS DataSync es un servicio en línea seguro que automatiza y acelera el movimiento de datos entre servicios de almacenamiento on-premises y AWS y no está diseñado como un servicio de almacenamiento híbrido.\n\nReferencias:\n\nhttps://aws.amazon.com/storagegateway/"
  },
  {
    "q": "Una organización de servicios financieros está desarrollando una aplicación nativa en la nube en AWS para procesar y analizar datos de transacciones de clientes. La aplicación utiliza Amazon Aurora como base de datos, Amazon EFS para almacenamiento de archivos y Amazon EventBridge para activar AWS Step Functions en la orquestación de flujos de trabajo.\nLa organización ha implementado AWS IAM Identity Center para la autenticación de usuarios. Los equipos de ciencia de datos, ingeniería y cumplimiento requieren acceso seguro a Amazon Aurora y Amazon EFS, manteniendo altos estándares de privacidad de datos. La solución debe adherirse al principio de privilegio mínimo y minimizar la sobrecarga administrativa.\n¿Qué enfoque satisface mejor estos requisitos?",
    "o": [
      "Habilitar IAM Identity Center con un directorio de Identity Center y crear conjuntos de permisos para acceso granular a Amazon Aurora y Amazon EFS. Asignar equipos a grupos vinculados a conjuntos de permisos según sus roles",
      "Usar Amazon Cognito User Pools para autenticación y Cognito Identity Pools para proporcionar credenciales temporales de AWS. Crear roles de IAM con permisos granulares para Aurora y EFS en cada equipo",
      "Crear cuentas de AWS separadas para cada equipo utilizando AWS Organizations. Configurar roles de IAM entre cuentas con privilegio mínimo y asignar permisos específicos para Aurora y EFS basados en roles de equipo",
      "Configurar AWS Control Tower para gestionar el acceso multi-cuenta. Usar Service Control Policies (SCPs) para restringir el acceso a Aurora y EFS a nivel organizacional. Crear roles de IAM en cada cuenta con permisos específicos"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nHabilitar IAM Identity Center con un directorio de Identity Center y crear conjuntos de permisos para acceso granular a Amazon Aurora y Amazon EFS. Asignar equipos a grupos vinculados a conjuntos de permisos según sus roles - IAM Identity Center centraliza la administración del acceso y permite la asignación eficiente de permisos según los roles de equipo.\n\nIAM Identity Center permite la gestión centralizada de usuarios y permisos en múltiples cuentas de AWS.\nLos conjuntos de permisos (permission sets) permiten definir políticas de IAM y asignarlas a grupos de usuarios según sus roles.\nEsta solución se integra bien con el IAM Identity Center ya implementado, garantizando un control de acceso granular a Amazon Aurora y Amazon EFS con privilegio mínimo.\n\n\nOpciones incorrectas:\n\nCrear cuentas de AWS separadas para cada equipo utilizando AWS Organizations. Configurar roles de IAM entre cuentas con privilegio mínimo y asignar permisos específicos para Aurora y EFS basados en roles de equipo - Usar cuentas separadas de AWS para cada equipo introduce una sobrecarga administrativa innecesaria. Si bien los roles de IAM entre cuentas pueden gestionar permisos de manera segura, no es la mejor opción para minimizar la complejidad en este escenario.\n\nUsar Amazon Cognito User Pools para autenticación y Cognito Identity Pools para proporcionar credenciales temporales de AWS. Crear roles de IAM con permisos granulares para Aurora y EFS en cada equipo - Amazon Cognito se utiliza principalmente para la autenticación de usuarios y proporciona acceso temporal a los recursos de AWS. Sin embargo, Cognito no se integra directamente con IAM Identity Center, lo que introduce complejidad adicional y no se alinea con la estrategia de autenticación existente de la organización.\n\nConfigurar AWS Control Tower para gestionar el acceso multi-cuenta. Usar Service Control Policies (SCPs) para restringir el acceso a Aurora y EFS a nivel organizacional. Crear roles de IAM en cada cuenta con permisos específicos - AWS Control Tower y las SCPs se utilizan para la gobernanza y el cumplimiento a nivel organizacional. Sin embargo, las SCPs operan a nivel de cuenta o unidad organizativa y no proporcionan el nivel de acceso granular requerido para recursos individuales como Amazon Aurora o Amazon EFS. Este enfoque aumenta la complejidad administrativa en lugar de reducirla.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/singlesignon/latest/userguide/get-set-up-for-idc.html\n\nhttps://docs.aws.amazon.com/singlesignon/latest/userguide/what-is.html"
  },
  {
    "q": "Una empresa de tecnología lanzó un nuevo servidor SFTP utilizando una instancia EC2 bajo demanda en una VPC recién creada con configuraciones predeterminadas. El servidor no debe ser accesible públicamente, solo desde la dirección IP 192.168.50.25 y desde ningún otro origen. ¿Cuál de las siguientes es la mejor manera de implementar este requisito?",
    "o": [
      "Crear una nueva regla de entrada en el grupo de seguridad de la instancia EC2 con los siguientes detalles: Protocolo: TCP Rango de puertos: 22 Origen: 192.168.50.25/32",
      "Crear una nueva regla de entrada en el grupo de seguridad de la instancia EC2 con los siguientes detalles: Protocolo: UDP Rango de puertos: 22 Origen: 192.168.50.25/32",
      "Crear una nueva regla de entrada en la ACL de red de la subred de la instancia EC2 con los siguientes detalles: Protocolo: TCP Rango de puertos: 22 Origen: 192.168.50.25/0 Permitir/Denegar: PERMITIR",
      "Crear una nueva regla de entrada en la ACL de red de la subred de la instancia EC2 con los siguientes detalles: Protocolo: UDP Rango de puertos: 22 Origen: 192.168.50.25/0 Permitir/Denegar: PERMITIR"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nCrear una nueva regla de entrada en el grupo de seguridad de la instancia EC2 con los siguientes detalles: Protocolo: TCP Rango de puertos: 22 Origen: 192.168.50.25/32 - El protocolo SFTP (Secure File Transfer Protocol) usa el puerto 22 sobre TCP. La mejor solución es crear una regla en el grupo de seguridad de la instancia EC2 que permita el acceso únicamente desde la dirección IP 192.168.50.25. Utilizar la notación /32 restringe la conexión exclusivamente a esta IP específica.\n\nOpciones incorrectas:\n\nCrear una nueva regla de entrada en el grupo de seguridad de la instancia EC2 con los siguientes detalles: Protocolo: UDP Rango de puertos: 22 Origen: 192.168.50.25/32 - SFTP no utiliza el protocolo UDP, sino TCP. Configurar una regla con UDP evitaría que el tráfico legítimo llegara al servidor.\n\nCrear una nueva regla de entrada en la ACL de red de la subred de la instancia EC2 con los siguientes detalles: Protocolo: TCP Rango de puertos: 22 Origen: 192.168.50.25/0 Permitir/Denegar: PERMITIR - Aunque las ACL de red pueden filtrar tráfico, la configuración presentada usa 192.168.50.25/0, lo que realmente autoriza el acceso desde toda la red en lugar de restringirlo a una sola IP. Además, las ACL de red en una VPC con configuración predeterminada ya permiten todo el tráfico entrante y saliente, lo que hace innecesario este ajuste.\n\nCrear una nueva regla de entrada en la ACL de red de la subred de la instancia EC2 con los siguientes detalles: Protocolo: UDP Rango de puertos: 22 Origen: 192.168.50.25/0 Permitir/Denegar: PERMITIR - Utilizar UDP en lugar de TCP y permite el acceso desde toda la red en lugar de restringirlo a una dirección IP específica.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html\n\nhttps://docs.aws.amazon.com/vpc/latest/userguide/vpc-network-acls.html"
  },
  {
    "q": "Una empresa decidió cambiar su herramienta de análisis de datos de terceros por una solución más económica. Enviaron una exportación completa de datos en un archivo CSV que contiene toda la información de análisis. Luego, se guardó el archivo CSV en un bucket de S3 para almacenamiento. Tu gerente te ha pedido que realices una validación en los datos exportados.\nEn este escenario, ¿cuál es la forma más rentable y sencilla de analizar los datos de exportación utilizando SQL estándar?",
    "o": [
      "Crear una herramienta de migración para cargar el archivo CSV desde S3 a una instancia de DynamoDB. Una vez que los datos se hayan cargado, ejecutar consultas usando DynamoDB",
      "Usar el cliente mysqlimport para cargar el archivo CSV desde S3 a una instancia MySQL en RDS. Ejecutar algunas consultas SQL una vez que los datos se hayan cargado para completar la validación",
      "Para poder ejecutar consultas SQL, usar Amazon Athena para analizar el archivo de datos exportados en S3",
      "Utilizar una herramienta de migración para cargar el archivo CSV desde S3 a una base de datos diseñada para procesamiento analítico en línea (OLAP) como AWS Redshift. Ejecutar algunas consultas una vez que los datos se hayan cargado para completar la validación"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nPara poder ejecutar consultas SQL, usar Amazon Athena para analizar el archivo de datos exportados en S3 - Es la opción más rentable y sencilla para analizar datos almacenados en S3 utilizando SQL estándar.\n\nAthena es un servicio sin servidor, lo que significa que no requiere infraestructura adicional ni administración de bases de datos.\nPermite ejecutar consultas directamente sobre archivos CSV almacenados en S3 usando ANSI SQL, sin necesidad de importar los datos a una base de datos.\nSolo pagas por las consultas que ejecutas, lo que lo hace una solución más rentable en comparación con configurar y administrar una base de datos completa para la validación de datos.\n\n\nOpciones incorrectas:\n\nUtilizar una herramienta de migración para cargar el archivo CSV desde S3 a una base de datos diseñada para procesamiento analítico en línea (OLAP) como AWS Redshift. Ejecutar algunas consultas una vez que los datos se hayan cargado para completar la validación - Cargar el archivo CSV en una base de datos OLAP como Redshift implica costos adicionales y tiempo de configuración innecesario. Para una simple validación, Athena permite consultar directamente los datos en S3 sin necesidad de este paso.\n\nUsar el cliente mysqlimport para cargar el archivo CSV desde S3 a una instancia MySQL en RDS. Ejecutar algunas consultas SQL una vez que los datos se hayan cargado para completar la validación - Utilizar mysqlimport para cargar los datos en una instancia de MySQL RDS requiere aprovisionar y administrar una base de datos. Esto introduce costos adicionales y complejidad innecesaria en comparación con el uso de Athena.\n\nCrear una herramienta de migración para cargar el archivo CSV desde S3 a una instancia de DynamoDB. Una vez que los datos se hayan cargado, ejecutar consultas usando DynamoDB - DynamoDB no es una base de datos relacional y no está diseñado para ejecutar consultas SQL estándar sobre datos tabulares almacenados en CSV. Además, la carga de datos en DynamoDB sería un proceso innecesariamente complejo para este caso de uso.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/athena/latest/ug/what-is.html"
  },
  {
    "q": "Una empresa planea desarrollar un servicio de mensajería personalizado que será utilizado para entrenar una IA con una función de respuesta automática. Se espera que el servicio reciba miles de mensajes por día, los cuales serán procesados por un clúster de Amazon EMR. Es crucial que ninguno de los mensajes se pierda, que no se generen duplicados y que los mensajes sean procesados en EMR en el mismo orden en que llegaron.\n¿Cuál de las siguientes opciones puede cumplir con este requisito?",
    "o": [
      "Configurar una cola predeterminada de Amazon SQS para gestionar los mensajes",
      "Crear un Amazon Kinesis Data Stream para recopilar los mensajes",
      "Crear un Amazon Data Firehose para gestionar los mensajes",
      "Configurar un tema de Amazon SNS para gestionar los mensajes"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nCrear un Amazon Kinesis Data Stream para recopilar los mensajes - La mejor opción para este caso de uso porque:\n\nPermite el procesamiento de datos en tiempo real y mantiene el orden de los registros, lo cual es un requisito clave en este escenario.\nOfrece durabilidad y la capacidad de reprocesar datos, asegurando que no se pierdan mensajes.\nUsa la Kinesis Client Library (KCL) para entregar todos los registros con la misma clave de partición al mismo procesador de registros, facilitando el procesamiento ordenado de los datos en Amazon EMR.\n\n\nOpciones incorrectas:\n\nConfigurar un tema de Amazon SNS para gestionar los mensajes - Amazon SNS es un servicio de mensajería basado en publicación/suscripción (pub-sub). No garantiza que los mensajes se entreguen en el mismo orden en que fueron recibidos y puede no manejar eficientemente un alto volumen de mensajes simultáneos.\n\nConfigurar una cola predeterminada de Amazon SQS para gestionar los mensajes - Amazon SQS es un servicio de colas de mensajes, pero una cola estándar no garantiza el orden de los mensajes ni evita la duplicación. Una cola FIFO podría ser una alternativa, pero Kinesis Data Streams está mejor optimizado para la ingesta y el procesamiento de datos en tiempo real.\n\nCrear un Amazon Data Firehose para gestionar los mensajes - Amazon Kinesis Data Firehose está diseñado principalmente para la entrega de datos en tiempo real a almacenes de datos y sistemas de análisis, como Amazon S3 o Amazon Redshift. No está optimizado para garantizar el procesamiento en el orden exacto de llegada.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/streams/latest/dev/introduction.html\n\nhttps://aws.amazon.com/kinesis/data-streams/faqs/"
  },
  {
    "q": "Una empresa tiene cientos de VPC con múltiples conexiones VPN a sus centros de datos que abarcan 5 regiones de AWS. A medida que crece la cantidad de cargas de trabajo, la empresa debe escalar sus redes en múltiples cuentas y VPC para mantenerse al día con el crecimiento.\nUn arquitecto de soluciones debe interconectar todas las redes on-premises de la empresa, VPNs y VPCs en un solo gateway, que incluya soporte para el enrutamiento entre regiones de AWS.\n¿Cuál de las siguientes opciones es la mejor solución que el arquitecto debe implementar para soportar la interconectividad requerida?",
    "o": [
      "Configurar un AWS Transit Gateway en cada región para interconectar todas las redes dentro de ella. Luego, enrutar el tráfico entre los Transit Gateway a través de una conexión de peering",
      "Configurar un AWS Direct Connect Gateway para lograr acceso VPC entre regiones a todos los recursos de AWS y centros de datos on-premises. Configurar un grupo de agregación de enlaces (LAG) para agrupar múltiples conexiones en un único endpoint de AWS Direct Connect y tratarlas como una conexión administrada única. Lanzar un gateway virtual en cada VPC y luego crear una interfaz pública virtual para cada conexión de AWS Direct Connect al Direct Connect Gateway",
      "Configurar un AWS VPN CloudHub para acceso VPC entre regiones y un AWS Direct Connect Gateway para las conexiones VPN a los centros de datos on-premises. Crear un gateway virtual privado en cada VPC y luego crear una interfaz virtual privada para cada conexión de AWS Direct Connect al Direct Connect Gateway",
      "Habilitar el peering VPC entre regiones que permite establecer relaciones de enrutamiento entre múltiples VPC en diferentes regiones de AWS. Configurar una arquitectura de red que garantice que el tráfico siempre se mantenga dentro de la red global de AWS y nunca atraviese Internet público"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nConfigurar un AWS Transit Gateway en cada región para interconectar todas las redes dentro de ella. Luego, enrutar el tráfico entre los Transit Gateway a través de una conexión de peering - La mejor opción para este escenario, ya que permite conectar múltiples VPCs y redes on-premises en una única puerta de enlace a nivel regional. Al configurar un Transit Gateway en cada región y conectar los Transit Gateways entre regiones mediante peering, la empresa puede lograr una conectividad escalable, segura y administrable en toda su infraestructura de red.\n\n\n\nOpciones incorrectas:\n\nConfigurar un AWS Direct Connect Gateway para lograr acceso VPC entre regiones a todos los recursos de AWS y centros de datos on-premises. Configurar un grupo de agregación de enlaces (LAG) para agrupar múltiples conexiones en un único endpoint de AWS Direct Connect y tratarlas como una conexión administrada única. Lanzar un gateway virtual en cada VPC y luego crear una interfaz pública virtual para cada conexión de AWS Direct Connect al Direct Connect Gateway - AWS Direct Connect Gateway permite la conexión de múltiples VPCs a un solo endpoint de Direct Connect, pero no es una solución óptima para interconectar grandes cantidades de VPCs y redes on-premises en múltiples regiones. Además, LAG es una optimización para Direct Connect, pero no resuelve la necesidad de comunicación eficiente entre múltiples VPCs.\n\nConfigurar un AWS VPN CloudHub para acceso VPC entre regiones y un AWS Direct Connect Gateway para las conexiones VPN a los centros de datos on-premises. Crear un gateway virtual privado en cada VPC y luego crear una interfaz virtual privada para cada conexión de AWS Direct Connect al Direct Connect Gateway - AWS VPN CloudHub es solo para VPNs y no para interconectar VPCs. No es escalable para una infraestructura con cientos de VPCs y conexiones VPN en múltiples regiones.\n\nHabilitar el peering VPC entre regiones que permite establecer relaciones de enrutamiento entre múltiples VPC en diferentes regiones de AWS. Configurar una arquitectura de red que garantice que el tráfico siempre se mantenga dentro de la red global de AWS y nunca atraviese Internet público - El Peering VPC entre regiones es útil para conectar VPCs individuales, pero no es escalable ni fácil de administrar cuando hay cientos de VPCs. AWS Transit Gateway proporciona una mejor solución de enrutamiento y gestión para este escenario.\n\nReferencias:\n\nhttps://aws.amazon.com/transit-gateway/\n\nhttps://docs.aws.amazon.com/vpc/latest/tgw/how-transit-gateways-work.html\n\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/building-a-global-network-using-aws-transit-gateway-inter-region-peering/"
  },
  {
    "q": "Una empresa de medios digitales usa una instancia de Amazon RDS MySQL para su sistema de gestión de contenido. Recientemente, la empresa ha observado que su instancia RDS se está acercando a su capacidad de almacenamiento debido al flujo constante de nuevos datos. La empresa quiere asegurar que siempre haya suficiente almacenamiento sin ninguna interrupción operativa o intervención manual.\n¿Qué solución debe usar la empresa para abordar esta situación con la MENOR sobrecarga operativa?",
    "o": [
      "Habilitar el escalado automático de almacenamiento para la instancia MySQL.",
      "Utilizar Amazon ElastiCache para descargar parte del tráfico de lectura y reducir la carga de la base de datos.",
      "Migrar la base de datos a una instancia de Amazon RDS MySQL más grande.",
      "Implementar una política de ciclo de vida para eliminar datos antiguos de la instancia MySQL."
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nHabilitar el escalado automático de almacenamiento para la instancia MySQL. - El escalado automático de almacenamiento de Amazon RDS permite que la base de datos aumente automáticamente su capacidad de almacenamiento cuando el almacenamiento disponible es bajo. Esta característica ayuda a prevenir situaciones de falta de almacenamiento y no requiere sobrecarga operativa.\n\nOpciones incorrectas:\n\nImplementar una política de ciclo de vida para eliminar datos antiguos de la instancia MySQL. - Aunque esto podría ayudar a liberar algo de almacenamiento, podría no ser adecuado si todos los datos son esenciales para las operaciones comerciales. Además, esto no proporciona una solución a largo plazo si el crecimiento de datos continúa.\n\nMigrar la base de datos a una instancia de Amazon RDS MySQL más grande. - Aunque esto proporcionaría más almacenamiento, no aborda el problema de posibles escaseces futuras de almacenamiento y requiere un esfuerzo operativo significativo para la migración.\n\nUtilizar Amazon ElastiCache para descargar parte del tráfico de lectura y reducir la carga de la base de datos. - Aunque ElastiCache puede ayudar a mejorar la eficiencia de lectura de la base de datos, no aborda directamente la preocupación del espacio en disco para la instancia RDS.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PIOPS.StorageTypes.html"
  },
  {
    "q": "Una empresa opera una aplicación crítica basada en Python que analiza datos en tiempo real entrantes. La aplicación se ejecuta cada 15 minutos y tarda aproximadamente 2 minutos en completar una ejecución. Requiere 1.5 GB de memoria y usa la CPU intensivamente durante su operación. La empresa quiere minimizar los costos asociados con ejecutar esta aplicación.\n¿Qué solución cumplirá estos requisitos?",
    "o": [
      "Implementar la aplicación como una función de AWS Lambda configurada con 1.5 GB de memoria. Usar Amazon EventBridge para programar la función para que se ejecute cada 15 minutos.",
      "Usar AWS App2Container (A2C) para containerizar la aplicación. Desplegar el contenedor en una instancia de Amazon EC2, configurar una alarma de Amazon CloudWatch para detener la instancia cuando la aplicación no esté en ejecución.",
      "Desplegar la aplicación en una instancia de Amazon EC2 y iniciar y detener manualmente la instancia en alineación con el horario de ejecución de la aplicación.",
      "Usar AWS App2Container (A2C) para containerizar la aplicación. Ejecutar la aplicación como una tarea de Amazon Elastic Container Service (Amazon ECS) en AWS Fargate con 1 CPU virtual (vCPU) y 1.5 GB de memoria."
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nImplementar la aplicación como una función de AWS Lambda configurada con 1.5 GB de memoria. Usar Amazon EventBridge para programar la función para que se ejecute cada 15 minutos. - Esta es la solución más rentable. AWS Lambda está diseñado para ejecutar código en respuesta a eventos o en un horario, y solo paga por el tiempo de cómputo que consume. Configurar la función con 1.5GB de memoria aseguraría que la función tenga suficientes recursos, y usar Amazon EventBridge para programar permitiría ejecutar la función cada 15 minutos.\n\nOpciones incorrectas:\n\nUsar AWS App2Container (A2C) para containerizar la aplicación. Desplegar el contenedor en una instancia de Amazon EC2, configurar una alarma de Amazon CloudWatch para detener la instancia cuando la aplicación no esté en ejecución. - AWS App2Container (A2C) se usa para ayudar a containerizar aplicaciones, pero esto no optimiza el costo porque requiere ejecutar una instancia EC2 continuamente y detener la instancia cuando no está en uso puede ser complejo y podría no ser oportuno, resultando en costos innecesarios potenciales.\n\nDesplegar la aplicación en una instancia de Amazon EC2 y iniciar y detener manualmente la instancia en alineación con el horario de ejecución de la aplicación. - Esta solución implica intervención manual significativa y administración de instancias EC2. Aunque puede funcionar, no es una forma optimizada, especialmente en términos de costo y sobrecarga operativa. No aprovecha el modelo de pago por uso y escalado automático proporcionado por AWS Lambda.\n\nUsar AWS App2Container (A2C) para containerizar la aplicación. Ejecutar la aplicación como una tarea de Amazon Elastic Container Service (Amazon ECS) en AWS Fargate con 1 CPU virtual (vCPU) y 1.5 GB de memoria. - Esta no es la solución más rentable. Aunque AWS App2Container (A2C) ayudaría a containerizar la aplicación y AWS Fargate abstraería la necesidad de administrar instancias EC2 subyacentes, sigue siendo excesivo para una aplicación que se ejecuta por períodos cortos de manera intermitente. Aún resultaría en pagar por recursos de cómputo no utilizados.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/eventbridge/latest/userguide/eb-run-lambda-schedule.html"
  },
  {
    "q": "Un arquitecto de soluciones recién contratado está revisando todos los grupos de seguridad y las reglas de listas de control de acceso a la red (ACL) en los recursos de AWS de la empresa.\nPor razones de seguridad, la conexión MS SQL a través del puerto 1433 de la capa de base de datos debe asegurarse.\nA continuación se muestra la configuración del grupo de seguridad para la base de datos Microsoft SQL Server:\n| Tipo | Protocolo | Puerto | Origen | |----------|-----------|--------|---------| | MS SQL | TCP | 1433 | 0.0.0.0/0 |\nEl servidor de aplicaciones alojado en un grupo de Auto Scaling de instancias EC2 es el único recurso identificado que necesita conectarse a la base de datos.\nEl arquitecto debe asegurarse de que la arquitectura cumpla con la mejor práctica de aplicar el principio de menor privilegio.\n¿Qué cambios deben hacerse en la configuración del grupo de seguridad?",
    "o": [
      "Para la regla de MS SQL, cambiar el Source al ID de la Network ACL adjunta a la capa de aplicación",
      "Para la regla de MS SQL, cambiar el Source a la dirección IP AnyCast estática adjunta a la capa de aplicación",
      "Para la regla de MS SQL, cambiar el Source al ID del grupo de seguridad adjunto a la capa de aplicación",
      "Para la regla de MS SQL, cambiar el Source a los IDs de las instancias EC2 subyacentes del grupo de Auto Scaling"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nPara la regla de MS SQL, cambiar el Source al ID del grupo de seguridad adjunto a la capa de aplicación - La mejor práctica de seguridad en AWS es permitir el acceso a la base de datos únicamente desde el grupo de seguridad que protege la capa de aplicación. De este modo, solo las instancias EC2 dentro de ese grupo de seguridad podrán conectarse a la base de datos en el puerto 1433, cumpliendo con el principio de menor privilegio.\n\nOpciones incorrectas:\n\nPara la regla de MS SQL, cambiar el Source a los IDs de las instancias EC2 subyacentes del grupo de Auto Scaling - Usar los IDs de las instancias EC2 subyacentes del grupo de Auto Scaling es problemático, ya que las instancias se agregan y eliminan dinámicamente. Esto obligaría a actualizar manualmente el grupo de seguridad cada vez que haya cambios en las instancias, lo que no es una solución escalable ni eficiente.\n\nPara la regla de MS SQL, cambiar el Source al ID de la Network ACL adjunta a la capa de aplicación - Network ACLs operan a nivel de subred y no pueden usarse para restringir el tráfico a instancias específicas dentro de una subred. Usar el ID de la Network ACL no aseguraría que solo la capa de aplicación pueda acceder a la base de datos.\n\nPara la regla de MS SQL, cambiar el Source a la dirección IP AnyCast estática adjunta a la capa de aplicación - AnyCast se utiliza en servicios como AWS Global Accelerator, pero no es aplicable para la configuración de grupos de seguridad en este caso. Un grupo de seguridad solo acepta direcciones IP específicas o IDs de otros grupos de seguridad, no direcciones AnyCast.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html\n\nhttps://docs.aws.amazon.com/vpc/latest/userguide/VPC_Security.html"
  },
  {
    "q": "Una plataforma de comercio electrónico ha experimentado un aumento significativo en el tráfico de usuarios, lo que ha provocado tiempos de carga más lentos en su sitio web alojado en instancias EC2.\nEl equipo de tecnología ha identificado que los usuarios abandonan el sitio si no carga en menos de 5 segundos, lo que impacta directamente en las ventas. Se necesita una solución que optimice la velocidad de carga de una manera rentable.\n¿Cuáles de los siguientes servicios en AWS pueden usarse para resolver este problema? (Selecciona DOS)",
    "o": [
      "Implementar Amazon ElastiCache para almacenar en caché los datos de acceso frecuente",
      "Habilitar Multi-AZ en Amazon RDS para mejorar la escalabilidad y reducir la latencia",
      "Configurar Amazon CloudFront como una CDN para distribuir el contenido y reducir la latencia",
      "Utilizar AWS Storage Gateway para reducir los tiempos de carga de los recursos estáticos",
      "Desplegar el sitio web en múltiples regiones para mejorar la disponibilidad"
    ],
    "a": [
      0,
      2
    ],
    "e": "Correcto:\n\nImplementar Amazon ElastiCache para almacenar en caché los datos de acceso frecuente - Amazon ElastiCache ayuda a reducir la carga en la base de datos y mejora el rendimiento del sitio web almacenando en caché datos consultados con frecuencia. Esto disminuye los tiempos de respuesta y optimiza la experiencia del usuario.\n\nConfigurar Amazon CloudFront como una CDN para distribuir el contenido y reducir la latencia - Amazon CloudFront actúa como una CDN que distribuye el contenido del sitio web en ubicaciones de borde globales, reduciendo la latencia y mejorando la velocidad de carga para los usuarios de diferentes regiones.\n\nOpciones incorrectas:\n\nHabilitar Multi-AZ en Amazon RDS para mejorar la escalabilidad y reducir la latencia - Multi-AZ en Amazon RDS mejora la disponibilidad, pero no reduce directamente la latencia de las consultas ni optimiza el tiempo de carga del sitio web.\n\nDesplegar el sitio web en múltiples regiones para mejorar la disponibilidad - Desplegar el sitio en múltiples regiones puede mejorar la disponibilidad, pero no es la solución más rentable para optimizar la velocidad de carga. CloudFront es una alternativa más eficiente y económica.\n\nUtilizar AWS Storage Gateway para reducir los tiempos de carga de los recursos estáticos - AWS Storage Gateway está diseñado para extender el almacenamiento on-premises a la nube, pero no mejora el rendimiento de carga de un sitio web.\n\nReferencias:\n\nhttps://aws.amazon.com/elasticache/\n\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Introduction.html"
  },
  {
    "q": "Una empresa de análisis de datos que utiliza aprendizaje automático para recopilar y analizar datos de consumidores está utilizando un clúster de Redshift como su almacén de datos. Se te ha indicado que implementes un plan de recuperación ante desastres para garantizar la continuidad del negocio incluso en caso de una interrupción en una región de AWS.\n¿Cuál de las siguientes es la mejor estrategia para cumplir con este requisito?",
    "o": [
      "Crear un trabajo programado que tomará automáticamente una instantánea de tu clúster de Redshift y la almacenará en un bucket de S3. Restaurar la instantánea en caso de una interrupción en una región de AWS",
      "No hacer nada porque Amazon Redshift es un almacén de datos altamente disponible y completamente administrado que puede resistir una interrupción de toda una región de AWS",
      "Habilitar la copia de instantáneas entre regiones en tu clúster de Amazon Redshift",
      "Usar instantáneas automatizadas de tu clúster de Redshift"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nHabilitar la copia de instantáneas entre regiones en tu clúster de Amazon Redshift - Habilitar la copia de instantáneas entre regiones en Amazon Redshift es la mejor opción, ya que permite que todas las instantáneas nuevas, tanto manuales como automáticas, se copien en la región de destino especificada. Esto garantiza que haya una copia de respaldo en otra región en caso de que ocurra una interrupción en la región de AWS original.\n\nOpciones incorrectas:\n\nNo hacer nada porque Amazon Redshift es un almacén de datos altamente disponible y completamente administrado que puede resistir una interrupción de toda una región de AWS - Aunque Amazon Redshift es un almacén de datos administrado y altamente disponible, esto no significa que pueda resistir una interrupción completa de una región sin una estrategia de respaldo en otra región. Se requiere configurar la copia de instantáneas entre regiones para garantizar la recuperación de datos en caso de un desastre.\n\nCrear un trabajo programado que tomará automáticamente una instantánea de tu clúster de Redshift y la almacenará en un bucket de S3. Restaurar la instantánea en caso de una interrupción en una región de AWS - Aunque programar un trabajo que tome instantáneas y las almacene en S3 es una opción posible, implica mucho trabajo manual y no es la mejor estrategia. La copia de instantáneas entre regiones es una solución más automatizada y confiable para la recuperación ante desastres.\n\nUsar instantáneas automatizadas de tu clúster de Redshift - El uso de instantáneas automatizadas por sí solo no es suficiente, ya que estas solo están disponibles dentro de la misma región donde se crean. En caso de una interrupción de la región, estas instantáneas no estarían accesibles, lo que hace que esta opción no sea viable para garantizar la continuidad del negocio.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/redshift/latest/mgmt/managing-snapshots-console.html"
  },
  {
    "q": "Un cliente necesita almacenar en AWS algunos archivos fácilmente reproducibles pero confidenciales, sin preocuparse por la capacidad de almacenamiento.\nDurante el primer mes, todos los archivos se accederán con frecuencia, pero después de ese período, su acceso será poco frecuente.\nLos archivos antiguos solo serán accedidos por desarrolladores, por lo que no hay un requisito de recuperación en milisegundos.\nSin embargo, los archivos bajo el prefijo blockstellart-demo en el bucket de S3 se utilizarán para postprocesamiento y requieren tiempos de recuperación en milisegundos.\nDadas estas condiciones, ¿cuál de las siguientes opciones sería la más rentable para satisfacer las necesidades de almacenamiento del cliente?",
    "o": [
      "Almacenar los archivos en S3 y luego, después de un mes, cambiar la clase de almacenamiento de todo el bucket a S3-IA utilizando una política de ciclo de vida",
      "Almacenar los archivos en S3 y luego, después de un mes, cambiar la clase de almacenamiento del prefijo blockstellart-demo a S3-IA, mientras que el resto se mueve a Glacier utilizando una política de ciclo de vida",
      "Almacenar los archivos en S3 y luego, después de un mes, cambiar la clase de almacenamiento del prefijo blockstellart-demo a One Zone-IA, mientras que el resto se mueve a Glacier utilizando una política de ciclo de vida",
      "Almacenar los archivos en S3 y luego, después de un mes, cambiar la clase de almacenamiento de todo el bucket a Intelligent-Tiering utilizando una política de ciclo de vida"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nAlmacenar los archivos en S3 y luego, después de un mes, cambiar la clase de almacenamiento del prefijo blockstellart-demo a One Zone-IA, mientras que el resto se mueve a Glacier utilizando una política de ciclo de vida - La estrategia más rentable y eficiente es mover los archivos con el prefijo a S3 One Zone-IA porque estos archivos necesitan tiempos de recuperación rápidos (milisegundos) pero no requieren alta disponibilidad.\n\nPara los otros archivos, moverlos a S3 Glacier reducirá costos al tratarse de datos de acceso poco frecuente sin necesidad de recuperación inmediata.\n\n\n\n\n\nOpciones incorrectas:\n\nAlmacenar los archivos en S3 y luego, después de un mes, cambiar la clase de almacenamiento del prefijo blockstellart-demo a S3-IA, mientras que el resto se mueve a Glacier utilizando una política de ciclo de vida - Mover los archivos de blockstellart-demo a S3-IA no es la mejor opción porque S3-IA tiene costos de almacenamiento más altos que One Zone-IA. Dado que estos archivos son fácilmente reproducibles, One Zone-IA es la opción más rentable.\n\nAlmacenar los archivos en S3 y luego, después de un mes, cambiar la clase de almacenamiento de todo el bucket a Intelligent-Tiering utilizando una política de ciclo de vida - S3 Intelligent-Tiering es más costoso cuando ya se conocen los patrones de acceso. En este caso, ya sabemos que los archivos requieren recuperación rápida y los demás no, por lo que se puede aplicar una política de ciclo de vida más óptima.\n\nAlmacenar los archivos en S3 y luego, después de un mes, cambiar la clase de almacenamiento de todo el bucket a S3-IA utilizando una política de ciclo de vida - Mover todos los archivos a S3-IA después de un mes no es la opción más rentable. One Zone-IA es más barato para los archivos de recuperación rápida, y Glacier es una mejor alternativa para los archivos de acceso poco frecuente.\n\nReferencias:\n\nhttps://aws.amazon.com/blogs/compute/amazon-s3-adds-prefix-and-suffix-filters-for-lambda-function-triggering/\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/lifecycle-configuration-examples.html\n\nhttps://docs.aws.amazon.com/s3/pricing"
  },
  {
    "q": "Una aplicación web está alojada en un grupo de Auto Scaling de instancias EC2 desplegadas en múltiples zonas de disponibilidad detrás de un Application Load Balancer. Debes implementar una solución SSL para mejorar la seguridad del sistema, por lo que solicitaste un certificado SSL/TLS a una autoridad certificadora (CA) de terceros.\n¿Dónde puedes importar de forma segura el certificado SSL/TLS de tu aplicación? (Selecciona DOS)",
    "o": [
      "Un bucket de S3 configurado con cifrado del lado del servidor con claves de cifrado proporcionadas por el cliente (SSE-C)",
      "CloudFront",
      "Un bucket privado de S3 con versionado habilitado",
      "Almacén de certificados de IAM (IAM certificate store)",
      "AWS Certificate Manager"
    ],
    "a": [
      3,
      4
    ],
    "e": "Correcto:\n\nAWS Certificate Manager - Permite importar certificados SSL/TLS de terceros desde la consola de ACM o de forma programática. Una vez importado, el certificado puede ser utilizado en servicios como Elastic Load Balancing (ALB/NLB) y CloudFront.\n\nAlmacén de certificados de IAM (IAM certificate store) - Si ACM no está disponible en una región específica, puedes usar AWS CLI para importar el certificado SSL/TLS en el almacén de certificados de IAM (IAM certificate store). Esto permite utilizar el certificado con Elastic Load Balancer (ELB) o en otros servicios compatibles.\n\n\n\nOpciones incorrectas:\n\nUn bucket de S3 configurado con cifrado del lado del servidor con claves de cifrado proporcionadas por el cliente (SSE-C) - S3 no es un lugar adecuado para almacenar certificados SSL/TLS, incluso si se configura con cifrado del lado del servidor (SSE-C). S3 está diseñado para el almacenamiento de objetos, no para gestionar certificados SSL/TLS.\n\nUn bucket privado de S3 con versionado habilitado - Al igual que la opción anterior, un bucket de S3 con versionado habilitado no es un repositorio válido para certificados SSL/TLS, ya que no proporciona la integración necesaria con los servicios de AWS que requieren certificados.\n\nCloudFront - CloudFront permite usar certificados SSL/TLS, pero no se pueden importar directamente en él. Los certificados deben ser administrados a través de ACM o IAM Certificate Store. Además, los certificados en CloudFront solo pueden ser utilizados dentro de esa distribución específica y no pueden asignarse a ALB o ELB.\n\nReferencia:\n\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/cnames-and-https-procedures.html#cnames-and-https-uploading-certificates"
  },
  {
    "q": "Amazon Elastic Kubernetes Service (Amazon EKS) es utilizado por una empresa de comercio electrónico para desplegar y administrar sus aplicaciones en contenedores. El sitio web experimenta un aumento en el tráfico durante las festividades, lo que incrementa significativamente la carga. El objetivo es garantizar que la infraestructura subyacente se escale de manera automática en respuesta a la demanda.\n¿Cuáles de las siguientes opciones cumplirían con los requisitos con la menor cantidad de sobrecarga operativa? (Selecciona DOS)",
    "o": [
      "Utilizar Alarmas de CloudWatch para activar el escalado de aplicaciones en contenedores",
      "Habilitar el Cluster Autoscaler para Amazon EKS con el fin de administrar automáticamente la cantidad de nodos en función de las necesidades de los pods",
      "Instalar el servidor de métricas de Kubernetes en el clúster de Amazon EKS y activar el Horizontal Pod Autoscaling",
      "Configurar Karpenter para ajustar automáticamente el número de nodos en el clúster de EKS cuando los pods fallen o sean reasignados a otros nodos",
      "Instalar el servidor de métricas de Kubernetes en el clúster de Amazon EKS y activar el Vertical Pod Autoscaler"
    ],
    "a": [
      2,
      3
    ],
    "e": "Correcto:\n\nConfigurar Karpenter para ajustar automáticamente el número de nodos en el clúster de EKS cuando los pods fallen o sean reasignados a otros nodos - Karpenter es un autoscaler de clústeres de Kubernetes de alto rendimiento y flexible que lanza recursos de cómputo apropiadamente dimensionados, como instancias EC2 de Amazon, en respuesta a cambios en la carga de la aplicación. Se integra con AWS para aprovisionar recursos de cómputo que coincidan precisamente con los requisitos de la carga de trabajo. Su automatización y eficiencia reducen significativamente la sobrecarga operativa en comparación con otros métodos.\n\nInstalar el servidor de métricas de Kubernetes en el clúster de Amazon EKS y activar el Horizontal Pod Autoscaling - El Horizontal Pod Autoscaler escala automáticamente la cantidad de pods en un despliegue, controlador de replicación o conjunto de réplicas según la utilización de la CPU del recurso. Esto permite que las aplicaciones escalen en respuesta al aumento de la demanda y reduzcan el consumo de recursos cuando no son necesarios, liberando así nodos para otras aplicaciones. Es una solución eficiente y con baja sobrecarga operativa para gestionar cargas variables.\n\n\n\nOpciones incorrectas:\n\nInstalar el servidor de métricas de Kubernetes en el clúster de Amazon EKS y activar el Vertical Pod Autoscaler - El Vertical Pod Autoscaler no es la solución adecuada para este escenario, ya que se centra en escalar los recursos asignados a cada pod (CPU y memoria) en lugar de escalar la cantidad de pods o nodos en el clúster. Dado que el problema menciona explícitamente \"escalado hacia dentro y hacia fuera\", el Horizontal Pod Autoscaler es la opción correcta para este tipo de escalado dinámico.\n\nUtilizar Alarmas de CloudWatch para activar el escalado de aplicaciones en contenedores - Aunque las Alarmas de CloudWatch pueden proporcionar cierto nivel de automatización, carecen de la capacidad dinámica necesaria para gestionar rápidamente patrones de tráfico variables. El retraso entre el disparo de la alarma y la acción de escalado puede provocar problemas de rendimiento durante picos de tráfico.\n\nHabilitar el Cluster Autoscaler para Amazon EKS con el fin de administrar automáticamente la cantidad de nodos en función de las necesidades de los pods - El Cluster Autoscaler es una herramienta nativa de Kubernetes para escalar nodos en un clúster de EKS, pero en comparación con Karpenter, requiere más configuración y ajuste manual. Karpenter optimiza mejor la utilización de nodos ajustando dinámicamente los tipos de instancias y aprovisionándolos según los requisitos de la carga de trabajo, lo que reduce la sobrecarga operativa.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/eks/latest/userguide/horizontal-pod-autoscaler.html\n\nhttps://docs.aws.amazon.com/eks/latest/userguide/autoscaling.html"
  },
  {
    "q": "Una empresa de redes sociales necesita capturar información detallada de todas las solicitudes HTTP que pasen por su Application Load Balancer público cada cinco minutos. Además, deben rastrear la dirección IP del cliente y las latencias de la red. Quieren usar estos datos para analizar patrones de tráfico y solucionar problemas en sus aplicaciones Docker desplegadas en el servicio Amazon ECS Anywhere.\n¿Cuál de las siguientes opciones cumple con los requisitos con la menor sobrecarga?",
    "o": [
      "Integrar Amazon EventBridge (Amazon CloudWatch Events) en el Application Load Balancer para capturar la dirección IP del cliente. Usar Amazon CloudWatch Container Insights para analizar patrones de tráfico",
      "Habilitar AWS CloudTrail para su Application Load Balancer. Usar AWS CloudTrail Lake para analizar y solucionar problemas del tráfico de la aplicación",
      "Habilitar registros de acceso en el Application Load Balancer. Integrar el clúster de Amazon ECS con Amazon CloudWatch Application Insights para analizar patrones de tráfico y simplificar la solución de problemas",
      "Instalar y ejecutar el daemon AWS X-Ray en el clúster de Amazon ECS. Usar Amazon CloudWatch ServiceLens para analizar el tráfico que atraviesa la aplicación"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nHabilitar registros de acceso en el Application Load Balancer. Integrar el clúster de Amazon ECS con Amazon CloudWatch Application Insights para analizar patrones de tráfico y simplificar la solución de problemas - Habilitar los registros de acceso en el Application Load Balancer permite capturar información detallada de cada solicitud enviada al balanceador de carga, incluyendo la dirección IP del cliente, latencias, rutas de solicitud y respuestas del servidor. Esta información es clave para analizar patrones de tráfico y solucionar problemas en la aplicación. Además, integrar el clúster de Amazon ECS con Amazon CloudWatch Application Insights proporciona una mayor visibilidad y herramientas de diagnóstico para la aplicación.\n\nOpciones incorrectas:\n\nHabilitar AWS CloudTrail para su Application Load Balancer. Usar AWS CloudTrail Lake para analizar y solucionar problemas del tráfico de la aplicación - AWS CloudTrail está diseñado principalmente para rastrear la actividad de las cuentas y los recursos de AWS, no para capturar tráfico de aplicaciones web. No puede registrar detalles completos de todas las solicitudes HTTP que pasan por el Application Load Balancer, ya que solo rastrea cambios en los recursos del ALB y no el tráfico real que lo atraviesa. Por esta razón, CloudTrail no es adecuado para este caso.\n\nIntegrar Amazon EventBridge (Amazon CloudWatch Events) en el Application Load Balancer para capturar la dirección IP del cliente. Usar Amazon CloudWatch Container Insights para analizar patrones de tráfico - Amazon EventBridge (CloudWatch Events) no analiza directamente el tráfico del Application Load Balancer. Aunque permite capturar la dirección IP del cliente, no proporciona una visión completa del tráfico que fluye a través del balanceador. CloudWatch Container Insights, por otro lado, está enfocado en recopilar métricas y registros de contenedores en ejecución, pero no en analizar el tráfico del ALB.\n\nInstalar y ejecutar el daemon AWS X-Ray en el clúster de Amazon ECS. Usar Amazon CloudWatch ServiceLens para analizar el tráfico que atraviesa la aplicación - AWS X-Ray es útil para rastrear solicitudes a través de una arquitectura de microservicios, pero no está diseñado para capturar direcciones IP de clientes, lo que es un requisito clave en este escenario. Además, CloudWatch ServiceLens se usa para obtener visibilidad del rendimiento y la conectividad de los servicios en la nube, pero no captura el tráfico de la aplicación desde el balanceador de carga.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch-application-insights.html\n\nhttp://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-access-logs.html\n\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-monitoring.html"
  },
  {
    "q": "Una empresa planea desplegar una aplicación basada en Docker en AWS. La aplicación se utilizará para procesar tanto datos críticos como trabajos por lotes no esenciales.\n¿Cuál de las siguientes opciones es la más rentable para implementar esta arquitectura?",
    "o": [
      "Usar ECS como el servicio de gestión de contenedores y configurar instancias bajo demanda de EC2 para procesar tanto trabajos por lotes críticos como no esenciales",
      "Usar ECS como el servicio de gestión de contenedores y configurar instancias reservadas de EC2 para procesar tanto trabajos por lotes críticos como no esenciales",
      "Usar ECS como el servicio de gestión de contenedores y configurar instancias Spot de EC2 para procesar tanto trabajos por lotes críticos como no esenciales",
      "Usar ECS como el servicio de gestión de contenedores y configurar una combinación de instancias reservadas y Spot de EC2 para procesar trabajos por lotes críticos y no esenciales respectivamente"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nUsar ECS como el servicio de gestión de contenedores y configurar una combinación de instancias reservadas y Spot de EC2 para procesar trabajos por lotes críticos y no esenciales respectivamente - La opción más rentable es utilizar Amazon ECS para la gestión de contenedores y una combinación de instancias Reservadas y Spot de EC2. Las instancias reservadas aseguran capacidad para trabajos críticos, mientras que las instancias Spot permiten reducir costos al procesar trabajos no esenciales, ya que pueden ser terminadas por AWS en cualquier momento sin afectar las cargas de trabajo críticas.\n\nOpciones incorrectas:\n\nUsar ECS como el servicio de gestión de contenedores y configurar instancias Spot de EC2 para procesar tanto trabajos por lotes críticos como no esenciales - Usar solo instancias Spot puede ser la opción más barata, pero no es adecuado para cargas de trabajo críticas.\n\nLas instancias Spot pueden ser terminadas por AWS en cualquier momento, lo que afectaría la continuidad de los procesos importantes.\n\nUsar ECS como el servicio de gestión de contenedores y configurar instancias bajo demanda de EC2 para procesar tanto trabajos por lotes críticos como no esenciales - Usar solo instancias bajo demanda no es la opción más rentable.\n\nLas instancias bajo demanda tienen costos más altos que las Spot, y los trabajos no esenciales podrían manejarse con Spot en lugar de bajo demanda.\n\nUsar ECS como el servicio de gestión de contenedores y configurar instancias reservadas de EC2 para procesar tanto trabajos por lotes críticos como no esenciales - Usar únicamente instancias reservadas es innecesariamente costoso.\n\nLos trabajos no esenciales pueden ejecutarse en instancias Spot, reduciendo costos en comparación con las instancias reservadas.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonECS/latest/developerguide/Welcome.html\n\nhttps://aws.amazon.com/ec2/spot/containers-for-less/get-started/"
  },
  {
    "q": "Un instituto de investigación ha desarrollado un software de simulación que requiere una potencia computacional significativa. Actualmente, el software se ejecuta en un servidor local con recursos limitados, tardando varias horas en completar cada simulación. El servidor tiene 32 vCPUs y 256 GiB de memoria. El instituto planea migrar el software a AWS con el objetivo de acelerar las simulaciones ejecutándolas en paralelo.\nComo arquitecto de soluciones, ¿qué solución logrará este objetivo con la MENOR sobrecarga operativa?",
    "o": [
      "Considerar el uso de instancias EC2 Spot para ejecutar las simulaciones",
      "Ejecutar las simulaciones usando AWS Fargate",
      "Usar funciones Lambda para procesar tareas de simulación en paralelo",
      "Utilizar AWS Batch para gestionar la ejecución del software"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nUtilizar AWS Batch para gestionar la ejecución del software - Es una herramienta poderosa que permite a los desarrolladores, científicos e ingenieros ejecutar grandes volúmenes de trabajos por lotes (batch) y cargas de trabajo de machine learning. AWS Batch se encarga de distribuir automáticamente la carga de trabajo entre múltiples instancias EC2, escalando según la demanda y gestionando el entorno de ejecución. Proporciona una interfaz fácil de usar y automatización para administrar las simulaciones sin preocuparse por la infraestructura subyacente.\n\n\n\nOpciones incorrectas:\n\nConsiderar el uso de instancias EC2 Spot para ejecutar las simulaciones - Las instancias Spot de EC2 no garantizan disponibilidad en todo momento. Si el precio Spot supera la oferta establecida, AWS puede interrumpir la instancia, lo que puede afectar la ejecución de las simulaciones en curso.\n\nUsar funciones Lambda para procesar tareas de simulación en paralelo - AWS Lambda no es una solución adecuada para simulaciones complejas que requieren alta capacidad computacional y tiempos de ejecución prolongados. Lambda está diseñado para tareas event-driven y de corta duración, por lo que las limitaciones de tiempo de ejecución podrían impedir que las simulaciones se completen dentro del plazo requerido.\n\nEjecutar las simulaciones usando AWS Fargate - AWS Fargate no es la mejor opción para este tipo de trabajos complejos debido a las limitaciones en la potencia de procesamiento que se puede asignar a una tarea de Fargate. Además, Fargate no tiene un sistema propio para gestionar la ejecución y programación de tareas de simulación, lo que aumentaría la carga operativa al requerir un sistema adicional para esta gestión.\n\nReferencias:\n\nhttps://aws.amazon.com/batch/\n\nhttps://docs.aws.amazon.com/batch/"
  },
  {
    "q": "Una organización con múltiples equipos de desarrollo ha desplegado una variedad de recursos en AWS para distintas iniciativas de innovación.\nCada equipo tiene autonomía para crear recursos según sus necesidades. Para evitar interrupciones operativas, la organización quiere monitorear proactivamente el uso de sus servicios en AWS y prevenir que se superen los límites de cuota establecidos.\n¿Qué combinación de acciones debería implementar el arquitecto de soluciones para satisfacer estos requerimientos? (Selecciona DOS)",
    "o": [
      "Capturar los eventos usando Amazon EventBridge (Amazon CloudWatch Events) y usar un tema de Amazon Simple Notification Service (Amazon SNS) como destino para las notificaciones",
      "Utilizar la regla administrada de AWS Config para monitorear las cuotas de servicio de los recursos de AWS. Programar esta verificación usando una función AWS Lambda",
      "Escribir una función AWS Lambda que actualice las verificaciones de Service Limits en AWS Trusted Advisor y programarla para que se ejecute cada 24 horas",
      "Crear un tema de Amazon Simple Notification Service (Amazon SNS) y configurarlo como un destino para notificaciones",
      "Consultar los límites de Service Limits de AWS Trusted Advisor cada 24 horas mediante la operación de la API DescribeTrustedAdvisorChecks. Asegurar que la cuenta de AWS tenga un plan de soporte Developer"
    ],
    "a": [
      0,
      2
    ],
    "e": "Correcto:\n\nEscribir una función AWS Lambda que actualice las verificaciones de Service Limits en AWS Trusted Advisor y programarla para que se ejecute cada 24 horas - AWS Trusted Advisor proporciona recomendaciones sobre el uso de recursos y monitorea el cumplimiento de límites de servicio. Una función AWS Lambda puede automatizar la actualización de estas verificaciones cada 24 horas para asegurar que los datos estén siempre al día y así anticipar posibles sobreutilizaciones.\n\nCapturar los eventos usando Amazon EventBridge (Amazon CloudWatch Events) y usar un tema de Amazon Simple Notification Service (Amazon SNS) como destino para las notificaciones - Amazon EventBridge puede detectar eventos generados por Trusted Advisor y enviar alertas automatizadas. Al integrarlo con Amazon SNS, se pueden enviar notificaciones a múltiples destinatarios (como administradores, funciones Lambda u otras aplicaciones), ayudando a reaccionar a tiempo ante eventos críticos de límite de servicio.\n\n\n\nOpciones incorrectas:\n\nUtilizar la regla administrada de AWS Config para monitorear las cuotas de servicio de los recursos de AWS. Programar esta verificación usando una función AWS Lambda - Aunque AWS Config permite realizar auditorías de configuración, no está diseñado para supervisar dinámicamente los límites de servicio ni enviar alertas inmediatas sobre su uso.\n\nCrear un tema de Amazon Simple Notification Service (Amazon SNS) y configurarlo como un destino para notificaciones - Crear un tema de SNS sin conectarlo a una fuente de eventos (como Trusted Advisor a través de EventBridge) no sirve por sí solo. Se requiere un mecanismo de generación de alertas.\n\nConsultar los límites de Service Limits de AWS Trusted Advisor cada 24 horas mediante la operación de la API DescribeTrustedAdvisorChecks. Asegurar que la cuenta de AWS tenga un plan de soporte Developer - La operación DescribeTrustedAdvisorChecks solo retorna la lista de verificaciones disponibles, no los resultados actualizados. Además, las capacidades avanzadas de Trusted Advisor, incluida la API, solo están disponibles con planes de soporte Business o superiores, no con el plan Developer.\n\nReferencias:\n\nhttps://aws.amazon.com/solutions/implementations/quota-monitor/\n\nhttps://aws.amazon.com/blogs/mt/monitoring-service-limits-with-trusted-advisor-and-amazon-cloudwatch/"
  },
  {
    "q": "Una compañía del sector financiero tiene un portal web alojado en un conjunto de instancias EC2 distribuidas entre dos Zonas de Disponibilidad, todas gestionadas detrás de un Application Load Balancer.\nComo arquitecto de soluciones en la nube, se te ha solicitado implementar una verificación de estado (health check) que garantice la alta disponibilidad del sistema en caso de fallos en las instancias. ¿Qué tipo de verificación de estado deberías configurar para cumplir con este objetivo?",
    "o": [
      "Verificación de estado FTP",
      "Verificación de estado HTTP o HTTPS",
      "Verificación de estado TCP",
      "Verificación de estado ICMP"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nVerificación de estado HTTP o HTTPS - Los Application Load Balancers (ALB) utilizan verificaciones de estado de tipo HTTP o HTTPS para evaluar si las instancias EC2 están respondiendo correctamente. Esto permite que el balanceador de carga enrute solo hacia instancias saludables, lo cual es esencial para mantener la alta disponibilidad de aplicaciones web como un portal financiero.\n\nOpciones incorrectas:\n\nVerificación de estado ICMP - ICMP, utilizado comúnmente para comandos como ping, no es compatible con ALB para propósitos de verificación de estado de aplicaciones.\n\nVerificación de estado FTP - Las verificaciones de tipo FTP no son soportadas por ALB y no tienen utilidad en el contexto de una aplicación web orientada al cliente.\n\nVerificación de estado TCP - Las verificaciones de estado basadas en TCP son propias de los Network Load Balancers o Classic Load Balancers, pero no aplican a un ALB, el cual se orienta a tráfico HTTP/HTTPS.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-healthchecks.html\n\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html"
  },
  {
    "q": "Un importante banco de inversión está en proceso de construir una plataforma de trading de Forex. Para garantizar alta disponibilidad y escalabilidad, diseñaste la plataforma de trading para utilizar un Elastic Load Balancer frente a un grupo de Auto Scaling de instancias EC2 On-Demand distribuidas en múltiples Zonas de Disponibilidad. Para la capa de base de datos, elegiste utilizar una única instancia de Amazon Aurora para aprovechar su sistema de almacenamiento distribuido, tolerante a fallos y auto-reparable.\nEn caso de que la instancia de base de datos principal falle, ¿qué sucede con Amazon Aurora durante la conmutación por error?",
    "o": [
      "Aurora intentará primero crear una nueva instancia de base de datos en una zona de disponibilidad diferente a la de la instancia original. Si no es posible, Aurora intentará crear una nueva instancia de base de datos en la zona de disponibilidad original donde la instancia fue inicialmente lanzada",
      "Aurora intentará crear una nueva instancia de base de datos en la misma zona de disponibilidad que la instancia original y se hace en base a un mejor esfuerzo",
      "Amazon Aurora cambia el registro A de tu instancia de base de datos para apuntar a la réplica saludable, que a su vez se promociona como la nueva instancia principal",
      "Amazon Aurora cambia el nombre de dominio canónico (CNAME) de tu instancia de base de datos para apuntar a la réplica saludable, que a su vez se promociona como la nueva instancia principal"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nAurora intentará crear una nueva instancia de base de datos en la misma zona de disponibilidad que la instancia original y se hace en base a un mejor esfuerzo - Creando una nueva instancia de base de datos en la misma zona de disponibilidad que la instancia original. Esta reposición se realiza en base a un mejor esfuerzo y puede fallar si hay problemas que afecten ampliamente la Zona de Disponibilidad.\n\n\n\nOpciones incorrectas:\n\nAmazon Aurora cambia el nombre de dominio canónico (CNAME) de tu instancia de base de datos para apuntar a la réplica saludable, que a su vez se promociona como la nueva instancia principal - Amazon Aurora solo cambia el nombre de dominio canónico (CNAME) cuando hay una réplica disponible en otra Zona de Disponibilidad. En este escenario, no se menciona que haya una réplica configurada, por lo que esta opción no aplica.\n\nAmazon Aurora cambia el registro A de tu instancia de base de datos para apuntar a la réplica saludable, que a su vez se promociona como la nueva instancia principal - Amazon Aurora cambia el CNAME y no el registro A (IP) de la instancia cuando se produce una conmutación por error.\n\nAurora intentará primero crear una nueva instancia de base de datos en una zona de disponibilidad diferente a la de la instancia original. Si no es posible, Aurora intentará crear una nueva instancia de base de datos en la zona de disponibilidad original donde la instancia fue inicialmente lanzada - Aurora primero intentará crear una nueva instancia en la misma zona de disponibilidad de la instancia original. Si no puede hacerlo, intentará crear la nueva instancia en una zona de disponibilidad diferente, y no al revés como menciona esta opción.\n\nReferencias:\n\nhttps://aws.amazon.com/rds/aurora/faqs/\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Concepts.AuroraHighAvailability.html"
  },
  {
    "q": "Una empresa está ejecutando un trabajo por lotes en una instancia EC2 dentro de una subred privada. La instancia obtiene datos de entrada desde un bucket de S3 en la misma región a través de un NAT Gateway.\nLa empresa busca una solución que reduzca costos sin comprometer la redundancia o la disponibilidad. ¿Qué solución logrará esto?",
    "o": [
      "Reasignar el NAT Gateway a un tipo de instancia EC2 más económico",
      "Reemplazar el NAT Gateway con una instancia NAT alojada en un tipo de instancia con ráfagas (burstable)",
      "Desplegar un Transit Gateway para establecer una conexión entre la instancia y el bucket de S3",
      "Eliminar el NAT Gateway y usar un Gateway VPC Endpoint para acceder al bucket de S3 desde la instancia"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nEliminar el NAT Gateway y usar un Gateway VPC Endpoint para acceder al bucket de S3 desde la instancia - Un Gateway VPC Endpoint permite a los recursos en una VPC comunicarse con Amazon S3 sin necesidad de un NAT Gateway o una conexión a Internet. Esto reduce costos al eliminar los cargos asociados al tráfico de salida a través del NAT Gateway, sin comprometer la seguridad, redundancia o disponibilidad.\n\nOpciones incorrectas:\n\nReemplazar el NAT Gateway con una instancia NAT alojada en un tipo de instancia con ráfagas (burstable) - Usar una instancia NAT en lugar de un NAT Gateway podría reducir costos, pero introduce riesgos de puntos únicos de falla y requiere administración adicional.\n\nDesplegar un Transit Gateway para establecer una conexión entre la instancia y el bucket de S3 - Transit Gateway no es la solución adecuada, ya que está diseñado para conectar múltiples VPCs en una arquitectura centralizada. No es necesario para la comunicación entre una instancia EC2 y un bucket de S3 dentro de la misma región.\n\nReasignar el NAT Gateway a un tipo de instancia EC2 más económico - No es posible cambiar el tipo de instancia de un NAT Gateway, ya que es un servicio completamente administrado y no permite modificaciones en su infraestructura subyacente.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html\n\nhttps://docs.aws.amazon.com/vpc/latest/privatelink/vpce-gateway.html"
  },
  {
    "q": "Una startup del sector educativo busca acelerar el desarrollo de sus APIs GraphQL para una nueva plataforma de cursos en línea. La solución debe ser completamente serverless con el fin de minimizar los costos operativos mensuales. Además, las APIs deben estar disponibles mediante HTTPS y deben utilizar un dominio personalizado para mejorar la experiencia del usuario.\n¿Qué alternativa debería elegir el arquitecto de soluciones para cumplir con estos requerimientos?",
    "o": [
      "Utilizar AWS Elastic Beanstalk para el despliegue de las APIs y configurar un dominio personalizado con Amazon Route 53. Habilitar DNSSEC para permitir la comunicación segura por HTTPS",
      "Construir las APIs utilizando AWS AppSync y configurar un dominio personalizado directamente desde el servicio. Asociar un certificado SSL emitido por AWS Certificate Manager (ACM) para habilitar el acceso seguro mediante HTTPS",
      "Implementar las APIs GraphQL como contenedores en pods de Kubernetes gestionados por AWS Fargate y desplegados a través de Amazon EKS Anywhere sobre AWS Outposts. Utilizar Amazon CloudFront con Origin Shield para exponerlas mediante HTTPS",
      "Desplegar las APIs en VMware Cloud sobre AWS y conectar un dominio personalizado usando AWS Directory Service con múltiples controladores de dominio para garantizar la seguridad HTTPS"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nConstruir las APIs utilizando AWS AppSync y configurar un dominio personalizado directamente desde el servicio. Asociar un certificado SSL emitido por AWS Certificate Manager (ACM) para habilitar el acceso seguro mediante HTTPS - AWS AppSync permite desarrollar APIs GraphQL de forma completamente serverless, con integración directa para dominios personalizados y compatibilidad con HTTPS a través de AWS Certificate Manager (ACM). Es ideal para cargas modernas y altamente escalables como una plataforma educativa en línea.\n\n\n\nOpciones incorrectas:\n\nImplementar las APIs GraphQL como contenedores en pods de Kubernetes gestionados por AWS Fargate y desplegados a través de Amazon EKS Anywhere sobre AWS Outposts. Utilizar Amazon CloudFront con Origin Shield para exponerlas mediante HTTPS - Aunque Fargate es serverless, Outposts no lo es. Además, Origin Shield no tiene relación directa con la habilitación de HTTPS.\n\nDesplegar las APIs en VMware Cloud sobre AWS y conectar un dominio personalizado usando AWS Directory Service con múltiples controladores de dominio para garantizar la seguridad HTTPS - VMware Cloud en AWS está pensado para entornos basados en vSphere, no para soluciones modernas de APIs GraphQL. Directory Service no es una herramienta apropiada para gestionar HTTPS.\n\nUtilizar AWS Elastic Beanstalk para el despliegue de las APIs y configurar un dominio personalizado con Amazon Route 53. Habilitar DNSSEC para permitir la comunicación segura por HTTPS - Elastic Beanstalk no es un servicio completamente serverless, ya que requiere gestión de instancias EC2. Además, DNSSEC se utiliza para validar respuestas DNS, no para habilitar HTTPS.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/appsync/latest/devguide/custom-domain-name.html\n\nhttps://docs.aws.amazon.com/appsync/latest/devguide/what-is-appsync.html\n\nhttps://aws.amazon.com/appsync/"
  },
  {
    "q": "Un arquitecto de soluciones está migrando varias aplicaciones basadas en Windows a AWS que requieren un almacenamiento de sistema de archivos escalable para computación de alto rendimiento (HPC). El servicio de almacenamiento debe tener soporte completo para el protocolo SMB, Windows NTFS, integración con Active Directory (AD) y Distributed File System (DFS).\n¿Cuál de los siguientes servicios de almacenamiento es el más adecuado para cumplir con este escenario?",
    "o": [
      "AWS DataSync",
      "Amazon S3 Glacier Deep Archive",
      "Amazon FSx for Lustre",
      "Amazon FSx for Windows File Server"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nAmazon FSx for Windows File Server - Este servicio proporciona servidores de archivos Windows administrados con características optimizadas para la migración de cargas de trabajo empresariales, como directorios de inicio, flujos de trabajo multimedia y aplicaciones ERP. FSx for Windows File Server es totalmente compatible con SMB, Windows NTFS, Active Directory (AD) y DFS, lo que lo hace ideal para este caso de uso.\n\nOpciones incorrectas:\n\nAmazon FSx for Lustre - Amazon FSx for Lustre está diseñado para cargas de trabajo de alto rendimiento en computación intensiva (HPC), pero no es compatible con Windows. Lustre es ideal para machine learning, procesamiento de medios y automatización de diseño electrónico (EDA), pero no soporta NTFS ni Active Directory.\n\nAmazon S3 Glacier Deep Archive - Amazon S3 Glacier Deep Archive está diseñado para archivado de datos a largo plazo y no proporciona almacenamiento de sistema de archivos. No es adecuado para aplicaciones que requieren acceso en tiempo real a archivos.\n\nAWS DataSync - AWS DataSync es un servicio para migrar grandes volúmenes de datos entre almacenamiento on-premises y AWS, pero no es un sistema de archivos. DataSync se usa para mover datos hacia Amazon S3 o Amazon EFS, pero no proporciona almacenamiento compatible con SMB o NTFS.\n\nReferencias:\n\nhttps://aws.amazon.com/fsx/\n\nhttps://aws.amazon.com/getting-started/use-cases/hpc/"
  },
  {
    "q": "Un banco local tiene una aplicación interna que maneja datos financieros sensibles dentro de una subred privada. Después de que los datos son procesados por las instancias EC2 de trabajo, deben enviarse a S3 para su posterior procesamiento por otros servicios.\n¿Cómo debes diseñar esta solución para que los datos no pasen por Internet público?",
    "o": [
      "Provisionar una NAT Gateway en la subred privada con una entrada de ruta correspondiente que dirija los datos a S3",
      "Configurar un VPC Endpoint junto con una entrada de ruta correspondiente que dirija los datos a S3",
      "Configurar una Transit Gateway junto con una entrada de ruta correspondiente que dirija los datos a S3",
      "Crear una Internet Gateway en la subred pública con una entrada de ruta correspondiente que dirija los datos a S3"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nConfigurar un VPC Endpoint junto con una entrada de ruta correspondiente que dirija los datos a S3 - Permite conectar de manera privada una VPC con servicios de AWS, como S3, sin necesidad de utilizar una Internet Gateway, NAT Gateway, VPN o AWS Direct Connect. Al usar un VPC Endpoint para S3, el tráfico de la VPC a S3 se mantiene dentro de la red privada de AWS, lo que protege los datos en tránsito y evita que pasen por Internet público.\n\n\n\nOpciones incorrectas:\n\nCrear una Internet Gateway en la subred pública con una entrada de ruta correspondiente que dirija los datos a S3 - Una Internet Gateway permite que instancias en una subred pública accedan a Internet. Sin embargo, en este caso, los datos deben permanecer dentro de la red privada de AWS y no viajar a través de Internet.\n\nConfigurar una Transit Gateway junto con una entrada de ruta correspondiente que dirija los datos a S3 - Una Transit Gateway se usa para interconectar múltiples VPCs o redes locales a través de un hub central, pero no permite conectar directamente una VPC con S3 de manera privada.\n\nProvisionar una NAT Gateway en la subred privada con una entrada de ruta correspondiente que dirija los datos a S3 - Una NAT Gateway permite que instancias en una subred privada accedan a Internet, pero no proporciona una conexión privada entre la VPC y S3. Los datos seguirían pasando por Internet en lugar de mantenerse dentro de la red de AWS.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/vpc/latest/userguide/vpc-endpoints.html\n\nhttps://docs.aws.amazon.com/vpc/latest/userguide/vpce-gateway.html"
  },
  {
    "q": "Una empresa de noticias planea utilizar un Módulo de Seguridad de Hardware (CloudHSM) en AWS para el almacenamiento seguro de claves de sus aplicaciones web. Has lanzado el clúster de CloudHSM, pero después de unas pocas horas, un miembro del equipo intentó iniciar sesión como administrador tres veces con una contraseña inválida en el Hardware Security Module. Esto causó que el HSM se reiniciara (zeroized), lo que significa que todas las claves de cifrado almacenadas en él fueron eliminadas.\nDesafortunadamente, no tenías copias de seguridad de las claves almacenadas en otro lugar.\n¿Cómo puedes obtener una nueva copia de las claves que tenías almacenadas en el Módulo de Seguridad de Hardware?",
    "o": [
      "Contactar con el soporte de AWS para que te proporcionen una copia de las claves",
      "Usar la CLI de Amazon para obtener una copia de las claves",
      "Restaurar una instantánea del Módulo de Seguridad de Hardware",
      "Las claves se pierden permanentemente si no tenías una copia"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nLas claves se pierden permanentemente si no tenías una copia - Cuando un CloudHSM es reiniciado (zeroized), se eliminan de forma permanente todas las claves de cifrado almacenadas en él. AWS no tiene acceso a las claves ni a las credenciales del usuario, por lo que no puede recuperarlas en caso de pérdida. Si no se cuenta con una copia de seguridad externa, las claves están irremediablemente perdidas.\n\nOpciones incorrectas:\n\nUsar la CLI de Amazon para obtener una copia de las claves - No es posible recuperar las claves mediante la CLI de Amazon. AWS no almacena ni tiene acceso a las claves de cifrado dentro de CloudHSM.\n\nContactar con el soporte de AWS para que te proporcionen una copia de las claves - AWS Support no puede recuperar ni proporcionar copias de las claves de un CloudHSM, ya que la administración y seguridad de las claves es responsabilidad exclusiva del usuario.\n\nRestaurar una instantánea del Módulo de Seguridad de Hardware - No se pueden restaurar instantáneas de un Módulo de Seguridad de Hardware (HSM). Para evitar la pérdida de claves, AWS recomienda usar múltiples HSMs en diferentes zonas de disponibilidad y realizar copias de seguridad periódicas.\n\nReferencias:\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/stop-cloudhsm/\n\nhttps://aws.amazon.com/cloudhsm/faqs/\n\nhttps://d1.awsstatic.com/whitepapers/Security/security-of-aws-cloudhsm-backups.pdf"
  },
  {
    "q": "Una empresa planea diseñar una arquitectura altamente disponible en AWS. Tienen dos target groups con tres instancias EC2 cada uno, los cuales están añadidos a un Application Load Balancer. En el grupo de seguridad de la instancia EC2, has verificado que el puerto 80 para HTTP está permitido. Sin embargo, las instancias siguen apareciendo como fuera de servicio en el balanceador de carga.\n¿Cuál podría ser la causa raíz de este problema?",
    "o": [
      "La configuración del health check no está definida correctamente",
      "Se usó una subred incorrecta en tu VPC",
      "Las instancias están usando una AMI incorrecta",
      "Se utilizó un tipo de instancia incorrecto para la instancia EC2"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nLa configuración del health check no está definida correctamente - El Application Load Balancer envía periódicamente solicitudes a sus objetivos registrados para verificar su estado. Estas pruebas se denominan health checks.\n\nSi las instancias están registradas en el target group pero aparecen como fuera de servicio, es probable que la configuración del health check no sea correcta. Esto puede incluir errores en la ruta del endpoint de health check, en los puertos de escucha o en los códigos de éxito configurados.\nPara que una instancia sea considerada saludable, debe aprobar al menos un health check. Si la configuración del health check es incorrecta, el balanceador de carga no enviará tráfico a las instancias, incluso si el puerto 80 está abierto en el grupo de seguridad.\nOpciones incorrectas:\n\nSe usó una subred incorrecta en tu VPC - Si se hubiera usado una subred incorrecta, las instancias probablemente no estarían disponibles en la red, pero eso no explicaría por qué el balanceador de carga las detecta como no saludables.\n\nSe utilizó un tipo de instancia incorrecto para la instancia EC2 - El tipo de instancia EC2 no afecta directamente la capacidad de pasar un health check. Si la instancia está en funcionamiento y responde a las solicitudes, el tipo de instancia no sería la causa del problema.\n\nLas instancias están usando una AMI incorrecta - Usar una AMI incorrecta podría causar problemas de configuración en la instancia, pero no explicaría por qué las instancias se muestran como fuera de servicio en el balanceador de carga. El problema está específicamente en la configuración del health check.\n\nReferencia:\n\nhttp://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-healthchecks.html"
  },
  {
    "q": "Un banco de inversión tiene una aplicación de procesamiento por lotes distribuida, alojada en un grupo de Auto Scaling de instancias Spot de EC2 con una cola de Amazon SQS. Has configurado los componentes para utilizar almacenamiento en búfer del lado del cliente, de modo que las llamadas realizadas desde el cliente se almacenen en búfer antes de enviarse como una solicitud por lotes a SQS.\n¿Cuál es el período de tiempo durante el cual la cola de SQS evita que otros componentes consumidores reciban y procesen un mensaje?",
    "o": [
      "Processing Timeout (Tiempo de procesamiento)",
      "Receiving Timeout (Tiempo de recepción)",
      "Visibility Timeout (Tiempo de visibilidad)",
      "Component Timeout (Tiempo de componente)"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nVisibility Timeout (Tiempo de visibilidad) - El \"Visibility Timeout\" (Tiempo de visibilidad) es el período de tiempo durante el cual Amazon SQS evita que otros consumidores reciban y procesen un mensaje una vez que ha sido recuperado de la cola. Cuando un consumidor recibe un mensaje, este sigue existiendo en la cola hasta que el consumidor lo elimine manualmente después de procesarlo. Para evitar que otros consumidores procesen el mismo mensaje simultáneamente, Amazon SQS aplica un \"Visibility Timeout\", asegurando que solo un consumidor lo procese a la vez. El tiempo de visibilidad predeterminado de un mensaje es de 30 segundos, y el máximo es de 12 horas.\n\nOpciones incorrectas:\n\nProcessing Timeout (Tiempo de procesamiento) - \"Processing Timeout\" (Tiempo de procesamiento) no es un término utilizado en SQS. El tiempo de visibilidad es el concepto correcto para evitar que otros consumidores procesen un mensaje mientras está siendo trabajado.\n\nComponent Timeout (Tiempo de componente) - \"Component Timeout\" (Tiempo de componente) no es un concepto de SQS. No hay un mecanismo en SQS denominado \"Component Timeout\" que regule el acceso a los mensajes.\n\nReceiving Timeout (Tiempo de recepción) - \"Receiving Timeout\" (Tiempo de recepción) no es un término válido en Amazon SQS. La recepción de mensajes se maneja a través de métodos como \"long polling\" y \"short polling\", pero no existe un tiempo de espera de recepción específico como parte de la funcionalidad de SQS.\n\nReferencias:\n\nhttps://aws.amazon.com/sqs/faqs/\n\nhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-visibility-timeout.html"
  },
  {
    "q": "Una empresa tiene varios microservicios que envían mensajes a una cola de Amazon SQS y una aplicación backend que consulta la cola para procesar los mensajes.\nLa empresa también tiene un Acuerdo de Nivel de Servicio (SLA) que define el tiempo máximo aceptable entre el momento en que los mensajes son recibidos y el momento en que se envía una respuesta.\nDado que las operaciones en el backend son intensivas en I/O y el número de mensajes está aumentando constantemente, la empresa está en riesgo de no cumplir con su SLA.\nEl arquitecto de soluciones debe implementar una nueva arquitectura que mejore el tiempo de procesamiento de la aplicación y la gestión de la carga.\n¿Cuál de las siguientes es la solución más efectiva para satisfacer este requisito?",
    "o": [
      "Crear una AMI de la instancia EC2 de la aplicación backend y lanzarla en un cluster placement group",
      "Crear una AMI de la instancia EC2 de la aplicación backend. Usar la imagen para configurar un Auto Scaling Group y definir una política de escalado basada en la métrica ApproximateAgeOfOldestMessage",
      "Crear una AMI de la instancia EC2 de la aplicación backend y reemplazarla por una instancia de mayor tamaño",
      "Crear una AMI de la instancia EC2 de la aplicación backend. Usar la imagen para configurar un Auto Scaling Group y definir una política de escalado basada en la métrica CPUUtilization con un objetivo del 80%"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nCrear una AMI de la instancia EC2 de la aplicación backend. Usar la imagen para configurar un Auto Scaling Group y definir una política de escalado basada en la métrica ApproximateAgeOfOldestMessage - La métrica ApproximateAgeOfOldestMessage de Amazon SQS es útil cuando las aplicaciones tienen restricciones de tiempo y necesitan garantizar que los mensajes sean procesados dentro de un período determinado. Al configurar un Auto Scaling Group con una política basada en esta métrica, se pueden escalar dinámicamente las instancias de backend para manejar el volumen de mensajes y cumplir con el SLA.\n\nOpciones incorrectas:\n\nCrear una AMI de la instancia EC2 de la aplicación backend y reemplazarla por una instancia de mayor tamaño - Reemplazar la instancia con una más grande no es una solución escalable ni dinámica. Un Auto Scaling Group es necesario para ajustar automáticamente la capacidad según la carga de trabajo.\n\nCrear una AMI de la instancia EC2 de la aplicación backend. Usar la imagen para configurar un Auto Scaling Group y definir una política de escalado basada en la métrica CPUUtilization con un objetivo del 80% - La métrica CPUUtilization solo activa el escalado basado en el uso de CPU de las instancias actuales, no en la antigüedad de los mensajes en la cola. Esto no garantiza que los mensajes sean procesados dentro del tiempo requerido.\n\nCrear una AMI de la instancia EC2 de la aplicación backend y lanzarla en un cluster placement group - Un cluster placement group solo agrupa lógicamente instancias EC2 para mejorar la latencia entre ellas, pero no soluciona el problema de escalabilidad ni garantiza que los mensajes se procesen a tiempo.\n\nReferencias:\n\nhttps://aws.amazon.com/about-aws/whats-new/2016/08/new-amazon-cloudwatch-metric-for-amazon-sqs-monitors-the-age-of-the-oldest-message/\n\nhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-available-cloudwatch-metrics.html\n\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/as-using-sqs-queue.html"
  },
  {
    "q": "Una aplicación genera archivos únicos que se devuelven a los clientes después de que envían solicitudes a la aplicación. La aplicación usa una distribución de Amazon CloudFront para enviar los archivos a los clientes. La empresa desea reducir los costos de transferencia de datos sin modificar la aplicación.\n¿Cómo se puede lograr esto?",
    "o": [
      "Habilitar el almacenamiento en caché en la distribución de CloudFront para almacenar archivos generados en el edge.",
      "Habilitar Amazon S3 Transfer Acceleration para reducir los tiempos de transferencia.",
      "Usar AWS Global Accelerator para reducir la latencia de la aplicación para los clientes.",
      "Usar Lambda@Edge para comprimir los archivos mientras se envían a los usuarios."
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nUsar Lambda@Edge para comprimir los archivos mientras se envían a los usuarios. - Lambda@Edge es una característica de Amazon CloudFront que le permite ejecutar código más cerca de los usuarios de su aplicación, lo que mejora el rendimiento y reduce la latencia. Lambda@Edge ejecuta código en respuesta a eventos generados por Amazon CloudFront.\n\nSimplemente carga el código a AWS Lambda, y se encarga de todo lo necesario para ejecutar y escalar su código con alta disponibilidad en una ubicación de AWS más cercana a su usuario final.\n\nEn este caso, Lambda@Edge puede comprimir los archivos antes de enviarlos a los usuarios, lo que reducirá los costos de salida de datos.\n\nOpciones incorrectas:\n\nHabilitar Amazon S3 Transfer Acceleration para reducir los tiempos de transferencia. - Esto no reduce los costos.\n\nUsar AWS Global Accelerator para reducir la latencia de la aplicación para los clientes. - El objetivo es reducir el costo, no la latencia, y AWS GA usa la misma red que CloudFront, por lo que no ayuda con la latencia de todos modos.\n\nHabilitar el almacenamiento en caché en la distribución de CloudFront para almacenar archivos generados en el edge. - Los archivos son únicos para cada solicitud de cliente, por lo que el almacenamiento en caché no ayuda.\n\nReferencias:\n\nhttps://aws.amazon.com/lambda/edge/"
  },
  {
    "q": "Una empresa necesita utilizar Amazon S3 para almacenar documentos financieros irreproducibles. Para sus informes trimestrales, los archivos deben recuperarse después de un período de 3 meses. Ocasionalmente, se realizarán auditorías sorpresa que requieren acceso inmediato a los datos archivados. ¿Qué harías para cumplir con este requisito de manera rentable?",
    "o": [
      "Usar Amazon S3 Standard - Infrequent Access",
      "Usar Amazon S3 Standard",
      "Usar Amazon Glacier Deep Archive",
      "Usar Amazon S3 - Intelligent Tiering"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nUsar Amazon S3 Standard - Infrequent Access - Amazon S3 Standard - Infrequent Access (S3 Standard-IA) es una clase de almacenamiento diseñada para datos que se acceden con poca frecuencia pero que requieren recuperación rápida cuando sea necesario. Ofrece la misma durabilidad y baja latencia que S3 Standard, pero con un menor costo por GB almacenado y una pequeña tarifa por recuperación de datos. Es una opción rentable para documentos que se deben recuperar cada tres meses y que pueden ser requeridos de manera imprevista para auditorías.\n\nOpciones incorrectas:\n\nUsar Amazon S3 Standard - Amazon S3 Standard no es la opción más rentable en este caso, ya que tiene un costo de almacenamiento más alto en comparación con S3 Standard-IA y no se necesita acceso frecuente a los datos.\n\nUsar Amazon S3 - Intelligent Tiering - Amazon S3 Intelligent-Tiering no es la mejor opción porque, aunque optimiza los costos automáticamente al mover datos entre diferentes clases de almacenamiento, implica un costo adicional por objeto monitoreado, lo cual no es necesario en este escenario.\n\nUsar Amazon Glacier Deep Archive - Amazon Glacier Deep Archive no es adecuado porque, aunque es la opción más barata para almacenamiento a largo plazo, no permite la recuperación inmediata de los datos. La recuperación en Glacier Deep Archive puede tardar varias horas, lo que no es viable para auditorías sorpresa.\n\nReferencias:\n\nhttps://aws.amazon.com/s3/storage-classes/\n\nhttps://aws.amazon.com/s3/faqs/"
  },
  {
    "q": "Un cliente está alojando su sitio web en un clúster de servidores web que están detrás de un Application Load Balancer (AWS ALB) público. Además, el cliente usa Amazon Route 53 para administrar su DNS público.\n¿Cómo debe configurar el registro de la zona DNS para que apunte al balanceador de carga?",
    "o": [
      "Crear un alias para el registro CNAME que apunte al nombre DNS del balanceador de carga",
      "Crear un registro A que apunte a la dirección IP del balanceador de carga",
      "Crear un registro CNAME que apunte al nombre DNS del balanceador de carga",
      "Crear un registro A con alias al nombre DNS del balanceador de carga"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nCrear un registro A con alias al nombre DNS del balanceador de carga - Route 53 permite la creación de registros alias para mapear directamente el nombre DNS de la zona apex (por ejemplo, blockstellart.com) al nombre DNS del balanceador de carga (elb.amazonaws.com). Los registros alias son recomendados para balanceadores de carga en AWS, ya que Route 53 responde a cada solicitud con una dirección IP específica del balanceador, incluso si estas direcciones cambian por escalamiento o actualizaciones.\n\n\n\nOpciones incorrectas:\n\nCrear un registro A que apunte a la dirección IP del balanceador de carga - No se recomienda apuntar un registro A a la dirección IP del balanceador de carga porque estas direcciones pueden cambiar dinámicamente debido a escalamiento o mantenimiento. Usar un alias a su nombre DNS es la mejor práctica.\n\nCrear un registro CNAME que apunte al nombre DNS del balanceador de carga - No es posible crear un registro CNAME para el dominio raíz (zona apex), ya que los registros CNAME solo se pueden usar en subdominios. Si necesitas apuntar la zona apex (blockstellart.com) al balanceador de carga, debes utilizar un registro alias.\n\nCrear un alias para el registro CNAME que apunte al nombre DNS del balanceador de carga - Crear un alias para un registro CNAME no es una opción válida en Route 53. En su lugar, se debe crear un registro A con alias directamente apuntando al nombre DNS del balanceador de carga.\n\nReferencias:\n\nhttp://docs.aws.amazon.com/govcloud-us/latest/UserGuide/setting-up-route53-zoneapex-elb.html\n\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resource-record-sets-choosing-alias-non-alias.html"
  },
  {
    "q": "Una consultoría de TI de alto nivel tiene una VPC con dos instancias EC2 bajo demanda que tienen direcciones Elastic IP. Recibiste una notificación de que las instancias EC2 están siendo atacadas con intentos de fuerza bruta en SSH desde Internet.\nEl equipo de seguridad de TI ha identificado las direcciones IP desde donde se originaron estos ataques. Debes implementar de inmediato una solución temporal para detener estos ataques mientras el equipo configura AWS WAF, GuardDuty y AWS Shield Advanced para solucionar permanentemente la vulnerabilidad.\n¿Cuál de las siguientes opciones proporciona la manera más rápida de detener los ataques a las instancias?",
    "o": [
      "Eliminar la Internet Gateway de la VPC",
      "Bloquear las direcciones IP en la Network Access Control List",
      "Colocar las instancias EC2 en subredes privadas",
      "Asignar una dirección Anycast IP estática a cada instancia EC2"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nBloquear las direcciones IP en la Network Access Control List - Una Network ACL (NACL) es una capa opcional de seguridad para una VPC que actúa como un firewall a nivel de subred. Dado que el equipo de seguridad ya identificó las direcciones IP ofensivas, la manera más rápida de detener los ataques es agregarlas a la NACL para bloquear el tráfico de entrada de esas IPs.\n\nOpciones incorrectas:\n\nColocar las instancias EC2 en subredes privadas - Mover las instancias a subredes privadas ayudaría a protegerlas, pero haría que fueran inaccesibles desde Internet, lo que podría afectar su funcionalidad. Además, esta opción requiere más tiempo de configuración.\n\nAsignar una dirección Anycast IP estática a cada instancia EC2 - Anycast IP es una característica utilizada principalmente por AWS Global Accelerator para mejorar el rendimiento y la disponibilidad del tráfico global. No es una solución adecuada para bloquear ataques dirigidos a instancias EC2.\n\nEliminar la Internet Gateway de la VPC - Eliminar la Internet Gateway cortaría completamente el acceso a Internet para las instancias EC2, haciéndolas inaccesibles incluso para usuarios legítimos.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_ACLs.html\n\nhttps://docs.aws.amazon.com/vpc/latest/userguide/VPC_Security.html"
  },
  {
    "q": "Una startup lanzó un grupo de instancias EC2 bajo demanda para alojar un juego de rol multijugador masivo en línea (MMORPG). Las instancias EC2 están configuradas con Auto Scaling y AWS Systems Manager.\n¿Qué se puede utilizar para configurar las instancias EC2 sin necesidad de establecer una conexión RDP o SSH con cada instancia?",
    "o": [
      "AWS CodePipeline",
      "AWS Config",
      "EC2Config",
      "Run Command"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nRun Command - Permite administrar de manera remota y segura la configuración de instancias EC2 administradas, sin necesidad de iniciar sesión en cada instancia mediante RDP o SSH. Run Command permite automatizar tareas administrativas comunes y realizar cambios de configuración de manera centralizada y a gran escala. Se puede ejecutar desde la consola de AWS, la CLI, AWS Tools for Windows PowerShell o los SDK de AWS, sin costos adicionales.\n\n\n\nOpciones incorrectas:\n\nAWS Config - AWS Config se usa para auditar y evaluar configuraciones de recursos en AWS, pero no permite modificar la configuración de instancias EC2 directamente sin conexión SSH o RDP.\n\nAWS CodePipeline - AWS CodePipeline es un servicio de integración y entrega continua (CI/CD) diseñado para automatizar despliegues de software, pero no proporciona una manera directa de administrar y configurar instancias EC2.\n\nEC2Config - EC2Config es un agente obsoleto que solía permitir la administración de instancias Windows en AWS. Hoy en día, AWS recomienda usar el agente de AWS Systems Manager (SSM Agent) junto con Run Command para estas tareas.\n\nReferencia:\n\nhttps://docs.aws.amazon.com/systems-manager/latest/userguide/execute-remote-commands.html"
  },
  {
    "q": "Una empresa de bienestar está desarrollando un dispositivo portátil que monitorea métricas clave de salud como la frecuencia cardíaca, el sueño y los pasos por día. El dispositivo envía datos a un bucket de Amazon S3 para almacenamiento y análisis. Diariamente, el dispositivo genera 1 MB de datos. Para procesar y resumir rápidamente esta información, la empresa necesita 512 MB de memoria y completar la tarea en un máximo de 10 segundos.\n¿Qué solución puede cumplir con estos requisitos de la manera más rentable?",
    "o": [
      "Crear un trabajo de AWS Glue PySpark para procesar los datos",
      "Almacenar los datos en Amazon Redshift y procesarlos con AWS Lambda",
      "Usar Amazon Data Firehose para enviar los datos del dispositivo a Amazon S3. Procesar los datos en una instancia EC2 con al menos 512 MB de memoria",
      "Usar AWS Lambda con una biblioteca de Python para el procesamiento"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nUsar AWS Lambda con una biblioteca de Python para el procesamiento - AWS Lambda es la solución más rentable para este caso, ya que permite el procesamiento bajo demanda sin necesidad de administrar servidores. Lambda se integra fácilmente con S3, lo que permite procesar los datos de manera eficiente con una biblioteca de Python. Además, el uso de Lambda elimina la sobrecarga de infraestructura y escala automáticamente según la carga de trabajo.\n\n\n\nOpciones incorrectas:\n\nUsar Amazon Data Firehose para enviar los datos del dispositivo a Amazon S3. Procesar los datos en una instancia EC2 con al menos 512 MB de memoria - Amazon Data Firehose está diseñado para transmitir grandes volúmenes de datos a S3 u otros servicios, lo cual es innecesario para manejar solo 1 MB de datos al día. Además, procesar los datos en una instancia EC2 implicaría mayores costos de administración y operación en comparación con AWS Lambda.\n\nCrear un trabajo de AWS Glue PySpark para procesar los datos - AWS Glue es una opción válida para procesar grandes volúmenes de datos, pero es un exceso para este caso, ya que Glue tiene una duración mínima de facturación de 1 minuto (en la versión 2.0 y posteriores), lo cual no es rentable para tareas pequeñas que pueden completarse en solo 10 segundos con Lambda.\n\nAlmacenar los datos en Amazon Redshift y procesarlos con AWS Lambda - Amazon Redshift es una excelente opción para almacenamiento y análisis de grandes volúmenes de datos, pero utilizarlo para solo 1 MB de datos diarios sería un gasto innecesario. Redshift tiene costos significativamente más altos en comparación con simplemente procesar los datos en S3 utilizando AWS Lambda.\n\nReferencias:\n\nhttps://aws.amazon.com/what-is/python/\n\nhttps://aws.amazon.com/lambda/pricing/"
  },
  {
    "q": "Un laboratorio de investigación genética está planeando lanzar un clúster de computación de alto rendimiento (HPC) en AWS para ejecutar análisis masivos de secuencias de ADN. La solución debe escalar automáticamente los análisis para evaluar grandes volúmenes de datos y generar resultados de forma más rápida y precisa.\nEl clúster está compuesto por servidores Windows que se ejecutan en instancias EC2 t3a.medium. Como Solutions Architect, debes garantizar que la arquitectura proporcione mayor ancho de banda, mayor rendimiento de paquetes por segundo (PPS) y menores latencias entre instancias de manera consistente.\n¿Cuál es la solución más adecuada y rentable que el arquitecto debería implementar para cumplir con estos requisitos?",
    "o": [
      "Habilitar Enhanced Networking con la interfaz Intel 82599 Virtual Function (VF) en las instancias Windows EC2",
      "Habilitar Enhanced Networking con Elastic Network Adapter (ENA) en las instancias Windows EC2",
      "Habilitar Enhanced Networking con Elastic Fabric Adapter (EFA) en las instancias Windows EC2",
      "Usar AWS ParallelCluster para desplegar y gestionar el clúster HPC con mayor ancho de banda, mayor rendimiento de paquetes por segundo (PPS) y menores latencias entre instancias"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nHabilitar Enhanced Networking con Elastic Network Adapter (ENA) en las instancias Windows EC2 - Amazon EC2 proporciona capacidades de red mejoradas a través de Elastic Network Adapter (ENA). ENA admite velocidades de red de hasta 100 Gbps en tipos de instancias compatibles. Además, ofrece características de red IP tradicionales necesarias para soportar redes VPC de alto rendimiento. Habilitar ENA en las instancias Windows EC2 del clúster permitirá mejorar el ancho de banda, el rendimiento de paquetes por segundo (PPS) y reducir la latencia entre instancias.\n\nOpciones incorrectas:\n\nHabilitar Enhanced Networking con la interfaz Intel 82599 Virtual Function (VF) en las instancias Windows EC2 - Aunque puedes adjuntar una interfaz Intel 82599 Virtual Function (VF) a instancias EC2 para mejorar sus capacidades de red, este método no es compatible con el tipo de instancia t3a.medium utilizado en el clúster HPC.\n\nHabilitar Enhanced Networking con Elastic Fabric Adapter (EFA) en las instancias Windows EC2 - Elastic Fabric Adapter (EFA) es una versión mejorada de ENA con capacidades adicionales de OS-bypass, diseñadas para cargas de trabajo de HPC y machine learning. Sin embargo, EFA no es compatible con instancias Windows, por lo que aunque se adjunte a una instancia Windows, esta solo funcionará como un ENA estándar sin los beneficios adicionales de EFA.\n\nUsar AWS ParallelCluster para desplegar y gestionar el clúster HPC con mayor ancho de banda, mayor rendimiento de paquetes por segundo (PPS) y menores latencias entre instancias - AWS ParallelCluster es una herramienta de gestión para clústeres HPC en AWS, pero no proporciona directamente mayor ancho de banda, mayor rendimiento de paquetes por segundo (PPS) ni menores latencias entre instancias, como sí lo hace ENA o EFA.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/enhanced-networking.html\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/efa.html"
  },
  {
    "q": "Una empresa planea implementar una arquitectura híbrida. Necesitan crear una conexión dedicada desde su Amazon Virtual Private Cloud (VPC) a su red on-premises.\nLa conexión debe proporcionar un alto rendimiento en ancho de banda y una experiencia de red más consistente que las soluciones basadas en Internet.\n¿Cuál de las siguientes opciones se puede utilizar para crear una conexión privada entre la VPC y la red on-premises de la empresa?",
    "o": [
      "AWS Site-to-Site VPN",
      "AWS Direct Connect",
      "Transit VPC",
      "Transit Gateway con enrutamiento multipath de costo igual (ECMP)"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nAWS Direct Connect - Proporciona una conexión privada entre la infraestructura on-premises y AWS a través de un enlace de fibra óptica, evitando el tráfico de Internet. Esta conexión ofrece mayor ancho de banda y una experiencia de red más estable y predecible en comparación con VPNs basadas en Internet.\n\n\n\nOpciones incorrectas:\n\nTransit VPC - Un Transit VPC se usa principalmente para conectar múltiples VPCs y redes remotas, pero no establece una conexión directa dedicada entre una red on-premises y AWS.\n\nAWS Site-to-Site VPN - AWS Site-to-Site VPN atraviesa Internet, lo que introduce latencia e inconsistencias en el rendimiento. No es adecuado para necesidades de alta capacidad y estabilidad en la conexión.\n\nTransit Gateway con enrutamiento multipath de costo igual (ECMP) - AWS Transit Gateway se usa para conectar múltiples VPCs y redes remotas a través de un hub central, pero no proporciona una conexión directa y dedicada a una red on-premises como lo hace Direct Connect.\n\nReferencias:\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/connect-vpc/\n\nhttps://docs.aws.amazon.com/directconnect/latest/UserGuide/Welcome.html"
  },
  {
    "q": "Una empresa está desarrollando una aplicación basada en web que se usará para funcionalidad de chat en tiempo real. La aplicación debe usar APIs WebSocket para mantener una conexión persistente con el cliente. Los servicios backend de la aplicación, alojados en contenedores dentro de subredes privadas de una VPC, necesitan ser accedidos de forma segura.\n¿Qué solución cumplirá estos requisitos?",
    "o": [
      "Desarrollar una API REST usando Amazon API Gateway. Alojar la aplicación en Amazon Elastic Kubernetes Service (EKS) en una subred privada. Establecer un VPC link privado para que API Gateway acceda de forma segura al clúster de Amazon EKS.",
      "Desarrollar una API WebSocket usando Amazon API Gateway. Alojar la aplicación en Amazon Elastic Kubernetes Service (EKS) en una subred privada. Establecer un VPC link privado para que API Gateway acceda de forma segura al clúster de Amazon EKS.",
      "Desarrollar una API REST usando Amazon API Gateway. Alojar la aplicación en Amazon Elastic Kubernetes Service (EKS) en una subred privada. Crear un grupo de seguridad que permita a API Gateway acceder al clúster de Amazon EKS.",
      "Desarrollar una API WebSocket usando Amazon API Gateway. Alojar la aplicación en Amazon Elastic Kubernetes Service (EKS) en una subred privada. Crear un grupo de seguridad que permita a API Gateway acceder al clúster de Amazon EKS."
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nDesarrollar una API WebSocket usando Amazon API Gateway. Alojar la aplicación en Amazon Elastic Kubernetes Service (EKS) en una subred privada. Establecer un VPC link privado para que API Gateway acceda de forma segura al clúster de Amazon EKS. - El requisito es para una aplicación de chat en tiempo real, lo que hace que el uso de APIs WebSocket sea más adecuado. Alojar la aplicación en Amazon EKS dentro de una subred privada permite una gestión segura y escalable de la aplicación. Crear un VPC link proporciona conectividad privada y segura entre API Gateway y el servicio de Amazon EKS alojado dentro de la VPC.\n\nOpciones incorrectas:\n\nDesarrollar una API REST usando Amazon API Gateway. Alojar la aplicación en Amazon Elastic Kubernetes Service (EKS) en una subred privada. Crear un grupo de seguridad que permita a API Gateway acceder al clúster de Amazon EKS. - Las APIs REST no son adecuadas para una aplicación de chat en tiempo real. Además, gestionar el acceso a través de un grupo de seguridad no es el método más seguro para acceder a servicios alojados dentro de subredes privadas en una VPC.\n\nDesarrollar una API REST usando Amazon API Gateway. Alojar la aplicación en Amazon Elastic Kubernetes Service (EKS) en una subred privada. Establecer un VPC link privado para que API Gateway acceda de forma segura al clúster de Amazon EKS. - Esta solución proporciona el entorno de alojamiento seguro y la conectividad privada entre API Gateway y el clúster de Amazon EKS, pero las APIs REST no son adecuadas para aplicaciones en tiempo real como un servicio de chat. Esto se debe a que las APIs REST usan un modelo de solicitud-respuesta que no proporciona la conexión continua necesaria para la comunicación en tiempo real.\n\nDesarrollar una API WebSocket usando Amazon API Gateway. Alojar la aplicación en Amazon Elastic Kubernetes Service (EKS) en una subred privada. Crear un grupo de seguridad que permita a API Gateway acceder al clúster de Amazon EKS. - Esta opción, aunque sugiere correctamente el uso de APIs WebSocket y Amazon EKS, propone el uso de un grupo de seguridad para conectividad. Sin embargo, los grupos de seguridad actúan como un firewall para instancias de Amazon EC2 asociadas, controlando tanto el tráfico entrante como saliente a nivel de instancia, mientras que el acceso a servicios dentro de VPCs se gestiona de forma más segura a través de VPC links.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/whitepapers/latest/best-practices-api-gateway-private-apis-integration/websocket-api.html"
  },
  {
    "q": "Una organización gubernamental está desarrollando una plataforma para gestión de trámites ciudadanos, desplegada en instancias EC2 dentro de una VPC de Amazon. Planean utilizar un Network Load Balancer para distribuir el tráfico entrante entre las instancias de la aplicación.\nEl equipo de cumplimiento normativo exige que se inspeccione todo el tráfico que entra y sale de la VPC para cumplir con los estándares de seguridad nacional.\n¿Cuál de los siguientes enfoques satisface los requisitos?",
    "o": [
      "Usar el Network Access Analyzer en la VPC de la aplicación para inspeccionar el tráfico de entrada y salida. Crear un nuevo Network Access Scope para filtrar y analizar todas las solicitudes entrantes y salientes",
      "Crear un firewall a nivel de subred utilizando el servicio Amazon Detective. Inspeccionar el tráfico de entrada y salida utilizando el VPC Reachability Analyzer",
      "Habilitar Traffic Mirroring en el Network Load Balancer y reenviar el tráfico a las instancias. Crear un filtro de tráfico espejo para inspeccionar el tráfico de entrada y salida que atraviesa la VPC de Amazon",
      "Crear un firewall utilizando el servicio AWS Network Firewall a nivel de VPC, luego agregar grupos de reglas personalizadas para inspeccionar el tráfico de entrada y salida. Actualizar las tablas de rutas de la VPC según sea necesario"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nCrear un firewall utilizando el servicio AWS Network Firewall a nivel de VPC, luego agregar grupos de reglas personalizadas para inspeccionar el tráfico de entrada y salida. Actualizar las tablas de rutas de la VPC según sea necesario - Firewall administrado con capacidades de inspección de tráfico de red y prevención de intrusiones para una VPC. Permite analizar tráfico entrante y saliente en el perímetro de la VPC, incluyendo tráfico hacia y desde una gateway de Internet (IGW), un NAT Gateway, una VPN o AWS Direct Connect. Se debe actualizar la tabla de rutas para garantizar que todo el tráfico pase a través del firewall.\n\n\n\nOpciones incorrectas:\n\nHabilitar Traffic Mirroring en el Network Load Balancer y reenviar el tráfico a las instancias. Crear un filtro de tráfico espejo para inspeccionar el tráfico de entrada y salida que atraviesa la VPC de Amazon - Traffic Mirroring copia el tráfico de una interfaz de red elástica a un destino de análisis, como una instancia EC2 con un sistema de detección de intrusiones (IDS). Sin embargo, no inspecciona el tráfico en tránsito ni proporciona filtrado de seguridad avanzado.\n\nCrear un firewall a nivel de subred utilizando el servicio Amazon Detective. Inspeccionar el tráfico de entrada y salida utilizando el VPC Reachability Analyzer - Amazon Detective es un servicio de análisis de seguridad que recopila y correlaciona datos de AWS para identificar actividades sospechosas, pero no se puede usar para crear un firewall ni inspeccionar tráfico en tiempo real. Además, VPC Reachability Analyzer solo evalúa rutas de conectividad dentro de la VPC, sin capacidades de inspección profunda de tráfico.\n\nUsar el Network Access Analyzer en la VPC de la aplicación para inspeccionar el tráfico de entrada y salida. Crear un nuevo Network Access Scope para filtrar y analizar todas las solicitudes entrantes y salientes - Network Access Analyzer es una herramienta para detectar configuraciones de acceso involuntario a los recursos de AWS según políticas de seguridad definidas. No puede inspeccionar tráfico en tiempo real ni realizar filtrado avanzado como lo hace AWS Network Firewall.\n\nReferencias:\n\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/deployment-models-for-aws-network-firewall/\n\nhttps://docs.aws.amazon.com/network-firewall/latest/developerguide/what-is-aws-network-firewall.html"
  },
  {
    "q": "Una aplicación web se ejecuta en una flota de instancias de Amazon EC2 usando un grupo de Auto Scaling. Se desea que el uso de CPU en la flota se mantenga al 40%.\n¿Cómo se debe configurar el escalado?",
    "o": [
      "Usar una política de escalado por pasos que use el valor PercentChangeInCapacity para ajustar el tamaño del grupo según sea necesario",
      "Usar una política de escalado simple que lance instancias cuando la CPU promedio alcance el 40%",
      "Usar una alarma personalizada de CloudWatch para monitorear el uso de CPU y notificar al ASG usando Amazon SNS",
      "Usar una política de seguimiento de objetivos que mantenga la utilización promedio agregada de CPU al 40%"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nUsar una política de seguimiento de objetivos que mantenga la utilización promedio agregada de CPU al 40% - Este es un caso de uso perfecto para una política de escalado de seguimiento de objetivos. Con las políticas de escalado de seguimiento de objetivos, selecciona una métrica de escalado y establece un valor objetivo. En este caso, puede establecer el valor objetivo al 40% de utilización promedio agregada de CPU.\n\nOpciones incorrectas:\n\nUsar una alarma personalizada de CloudWatch para monitorear el uso de CPU y notificar al ASG usando Amazon SNS - No necesita crear una alarma personalizada de Amazon CloudWatch ya que el ASG puede escalar usando una política basada en utilización de CPU usando configuración estándar.\n\nUsar una política de escalado por pasos que use el valor PercentChangeInCapacity para ajustar el tamaño del grupo según sea necesario - La política de escalado por pasos hace ajustes de escalado basados en varios factores. El valor PercentChangeInCapacity incrementa o decrementa el tamaño del grupo en un porcentaje especificado. Esto no se relaciona con la utilización de CPU.\n\nUsar una política de escalado simple que lance instancias cuando la CPU promedio alcance el 40% - Una política de escalado simple agregará instancias cuando se alcance el 40% de utilización de CPU, pero no está diseñada para mantener el 40% de utilización de CPU en todo el grupo.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-target-tracking.html\n\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-simple-step.html"
  },
  {
    "q": "Una aplicación usa una base de datos de Amazon RDS e instancias de Amazon EC2 en un nivel web. Las instancias del nivel web no deben ser directamente accesibles desde internet para mejorar la seguridad.\n¿Cómo puede un arquitecto de soluciones cumplir estos requisitos?",
    "o": [
      "Lanzar las instancias EC2 en una subred privada y crear un Application Load Balancer en una subred pública",
      "Lanzar las instancias EC2 en una subred pública y crear un Application Load Balancer en una subred pública",
      "Lanzar las instancias EC2 en una subred privada con un NAT gateway y actualizar la tabla de enrutamiento",
      "Lanzar las instancias EC2 en una subred pública y usar AWS WAF para proteger las instancias de ataques basados en internet"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nLanzar las instancias EC2 en una subred privada y crear un Application Load Balancer en una subred pública - Para prevenir la conectividad directa a las instancias EC2 desde internet, puede desplegar sus instancias EC2 en una subred privada y tener el ELB en una subred pública. Para configurar esto, debe habilitar una subred pública en el ELB que esté en la misma AZ que la subred privada.\n\nOpciones incorrectas:\n\nLanzar las instancias EC2 en una subred pública y usar AWS WAF para proteger las instancias de ataques basados en internet - Con las instancias EC2 en una subred pública, el acceso directo desde internet es posible. Solo se necesita una mala configuración del grupo de seguridad o una explotación de software y la instancia se vuelve vulnerable a ataques.\n\nLanzar las instancias EC2 en una subred pública y crear un Application Load Balancer en una subred pública - Las instancias EC2 deben lanzarse en una subred privada.\n\nLanzar las instancias EC2 en una subred privada con un NAT gateway y actualizar la tabla de enrutamiento - Esta configuración no permitirá que la aplicación sea accesible desde internet; el objetivo es solo prevenir el acceso directo a las instancias EC2.\n\nReferencias:\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/public-load-balancer-private-ec2/"
  },
  {
    "q": "Una empresa de medios digitales ejecuta una tarea de análisis de datos en una instancia EC2, la cual está configurada para procesar mensajes desde una cola en Amazon SQS usando los valores por defecto. La aplicación está diseñada para ejecutarse cada 10 días y procesar todos los mensajes acumulados.\nSin embargo, después de algunas ejecuciones, se observa que varios mensajes no están siendo procesados como se esperaba. ¿Cuál es la causa raíz más probable de este comportamiento?",
    "o": [
      "La cola SQS está configurada con short-polling (sondeo corto)",
      "Faltan permisos en SQS",
      "La aplicación de análisis por lotes está configurada para long polling (sondeo largo)",
      "Amazon SQS ha eliminado automáticamente los mensajes que han permanecido en la cola por más tiempo del período máximo de retención"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nAmazon SQS ha eliminado automáticamente los mensajes que han permanecido en la cola por más tiempo del período máximo de retención - Amazon SQS elimina automáticamente los mensajes que han estado en la cola por más tiempo que el período de retención configurado. El valor por defecto es de 4 días, lo que significa que si la aplicación se ejecuta cada 10 días, muchos mensajes ya habrán sido eliminados antes de que se intente procesarlos. La solución consiste en aumentar el período de retención de la cola hasta un máximo de 14 días mediante la acción SetQueueAttributes.\n\nOpciones incorrectas:\n\nLa cola SQS está configurada con short-polling (sondeo corto) - El uso de short-polling afecta cómo se obtienen los mensajes cuando se realiza una solicitud, pero no afecta cuánto tiempo permanecen en la cola.\n\nFaltan permisos en SQS - La ausencia de permisos impediría el acceso a todos los mensajes, no solo a algunos. En este caso, el procesamiento parcial sugiere un problema distinto.\n\nLa aplicación de análisis por lotes está configurada para long polling (sondeo largo) - Long polling mejora la eficiencia de las solicitudes de recepción de mensajes, pero no influye en la duración que permanecen los mensajes en la cola.\n\nReferencias:\n\nhttps://aws.amazon.com/sqs/faqs/\n\nhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-message-lifecycle.html"
  },
  {
    "q": "Un arquitecto de soluciones necesita una solución para alojar un sitio web que será usado por un equipo de desarrollo. El contenido del sitio web consistirá en HTML, CSS, JavaScript del lado del cliente e imágenes.\n¿Qué solución es más rentable?",
    "o": [
      "Lanzar una instancia de Amazon EC2 y alojar el sitio web allí.",
      "Usar un contenedor Docker para alojar el sitio web en AWS Fargate.",
      "Crear un Application Load Balancer con un objetivo de AWS Lambda.",
      "Crear un bucket de Amazon S3 y alojar el sitio web allí."
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nCrear un bucket de Amazon S3 y alojar el sitio web allí. - Amazon S3 puede usarse para alojar sitios web estáticos y no puede usarse para contenido dinámico. En este caso, el contenido es puramente estático con código del lado del cliente ejecutándose. Por lo tanto, un sitio web estático en S3 será la solución más rentable para alojar este sitio web.\n\nOpciones incorrectas:\n\nUsar un contenedor Docker para alojar el sitio web en AWS Fargate. - Un sitio web estático en S3 es suficiente para este caso de uso y será más rentable que Fargate.\n\nLanzar una instancia de Amazon EC2 y alojar el sitio web allí. - Esto será más costoso ya que usa instancias EC2.\n\nCrear un Application Load Balancer con un objetivo de AWS Lambda. - Esta también es una solución más costosa e innecesaria para este caso de uso.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/WebsiteHosting.html"
  },
  {
    "q": "Una empresa usa un grupo de Auto Scaling con instancias EC2 detrás de un ALB. Algunas instancias fallan en verificaciones de estado HTTPS y se terminan, perdiendo registros efímeros.\n¿Cómo puede un AWS Solutions Architect recopilar automáticamente los registros antes de la terminación de las instancias?",
    "o": [
      "Usar un lifecycle hook en Terminating:Wait, eventos de CloudWatch y AWS Systems Manager Run Command para recopilar y cargar registros",
      "Usar un lifecycle hook en Terminating:Wait, una regla de eventos de CloudWatch y una Lambda para enviar registros a CloudWatch Logs antes de la terminación",
      "Usar un lifecycle hook en Terminating:Wait y AWS Step Functions para recopilar registros y enviarlos a CloudWatch Logs",
      "Usar un lifecycle hook en Pending:Wait, una regla de eventos de CloudWatch y un script de AWS Systems Manager para recopilar y cargar registros en CloudWatch Logs"
    ],
    "a": [
      1
    ],
    "e": "Usar un lifecycle hook en Terminating:Wait, una regla de eventos de CloudWatch y una Lambda para enviar registros a CloudWatch Logs antes de la terminación - El lifecycle hook en Terminating:Wait permite retrasar la terminación y ejecutar acciones como recopilar registros. La combinación de eventos de CloudWatch y Lambda automatiza este proceso eficientemente.\n\nOpciones incorrectas:\n\nUsar un lifecycle hook en Pending:Wait, una regla de eventos de CloudWatch y un script de AWS Systems Manager para recopilar y cargar registros en CloudWatch Logs - Pending:Wait es para escalado hacia afuera, no para terminación de instancias.\n\nUsar un lifecycle hook en Terminating:Wait y AWS Step Functions para recopilar registros y enviarlos a CloudWatch Logs - AWS Step Functions no es la mejor opción para recopilar registros de EC2.\n\nUsar un lifecycle hook en Terminating:Wait, eventos de CloudWatch y AWS Systems Manager Run Command para recopilar y cargar registros - AWS Systems Manager Run Command requiere más configuración y esfuerzo comparado con CloudWatch y Lambda.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/AutoScalingGroupLifecycle.html\n\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/cloud-watch-events-instance-terminate-successful.html\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/auto-scaling-terminate-lifecycle/"
  },
  {
    "q": "Un Solutions Architect está trabajando para una startup de rápido crecimiento que comenzó a operar hace tres meses. Actualmente, cuentan con un Active Directory local y 10 computadoras. Para reducir costos en la compra de estaciones de trabajo físicas, decidieron implementar escritorios virtuales para sus nuevos empleados en una nube privada virtual en AWS.\nLa nueva infraestructura en la nube debe aprovechar los controles de seguridad existentes en AWS, pero al mismo tiempo permitir la comunicación con la red local.\n¿Qué conjunto de servicios de AWS debe usar el arquitecto para cumplir con estos requisitos?",
    "o": [
      "AWS Directory Services, conexión VPN y ClassicLink",
      "AWS Directory Services, conexión VPN y AWS Identity and Access Management",
      "AWS Directory Services, conexión VPN y Amazon S3",
      "AWS Directory Services, conexión VPN y Amazon Workspaces"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nAWS Directory Services, conexión VPN y Amazon Workspaces - Para este escenario, la mejor opción es utilizar AWS Directory Services para integrar AWS con el Active Directory local, una conexión VPN para conectar la VPC con la red local y Amazon Workspaces para implementar los escritorios virtuales en la nube. Esto permite a los empleados acceder a escritorios seguros y gestionados en AWS mientras se mantienen las políticas de seguridad existentes.\n\nOpciones incorrectas:\n\nAWS Directory Services, conexión VPN y ClassicLink - ClassicLink se usaba para conectar instancias EC2 en una VPC con instancias en EC2-Classic, pero este servicio ha sido descontinuado y no es relevante para este caso.\n\nAWS Directory Services, conexión VPN y Amazon S3 - Amazon S3 no es necesario para este escenario, ya que no se menciona almacenamiento de objetos como parte del requisito.\n\nAWS Directory Services, conexión VPN y AWS Identity and Access Management - AWS IAM se utiliza para la gestión de identidades y accesos en AWS, pero en este caso, se requiere AWS Directory Services para la integración con Active Directory local, lo que hace que IAM no sea la mejor opción.\n\nReferencias:\n\nhttps://aws.amazon.com/directoryservice/\n\nhttps://docs.aws.amazon.com/AmazonPC/latest/UserGuide/vpn-connections.html\n\nhttps://aws.amazon.com/workspaces/"
  },
  {
    "q": "Una empresa del sector salud administra datos de pacientes mediante un sistema distribuido. La organización utiliza una aplicación serverless basada en microservicios para manejar distintos aspectos de los datos de los pacientes. Los datos deben recuperarse y escribirse desde múltiples tablas de Amazon DynamoDB. El objetivo principal es habilitar una recuperación y escritura eficiente de datos sin afectar el rendimiento base de la aplicación, asegurando un acceso fluido a la información de los pacientes para los profesionales de la salud.\n¿Cuál de las siguientes es la solución más eficiente operativamente?",
    "o": [
      "Utilizar los resolvers de pipeline de AWS AppSync",
      "Usar funciones de CloudFront",
      "Configurar el conector de DynamoDB para Amazon Athena Federated Query",
      "Lanzar funciones AWS Lambda con un Amazon API Gateway optimizado para edge"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nUtilizar los resolvers de pipeline de AWS AppSync - Los resolvers de pipeline de AWS AppSync ofrecen una solución server-side eficiente para el desafío común de las aplicaciones web: agregar datos desde múltiples tablas de bases de datos. En lugar de invocar múltiples llamadas a la API en diferentes fuentes de datos (lo que podría afectar el rendimiento de la aplicación), los resolvers de pipeline permiten recuperar datos de múltiples fuentes en una sola llamada. Al aprovechar funciones de pipeline, los resolvers optimizan la consolidación y presentación de datos a los usuarios, sin afectar el rendimiento de la aplicación.\n\nOpciones incorrectas:\n\nLanzar funciones AWS Lambda con un Amazon API Gateway optimizado para edge - Lanzar funciones AWS Lambda con un Amazon API Gateway optimizado para edge no es la mejor opción porque un API Gateway optimizado para edge solo mejora la latencia de los clientes al distribuir solicitudes a la ubicación más cercana. Sin embargo, no proporciona una solución eficiente para recuperar datos desde múltiples tablas de DynamoDB.\n\nConfigurar el conector de DynamoDB para Amazon Athena Federated Query - Amazon Athena Federated Query permite consultar tablas de DynamoDB, pero no soporta operaciones de escritura. Además, el escenario requiere una solución que optimice tanto la lectura como la escritura de datos, por lo que Athena no es adecuado.\n\nUsar funciones de CloudFront - CloudFront Functions está diseñado para procesar solicitudes web ligeras, como manipulaciones en caché, redirecciones de URL y manipulación de encabezados HTTP. No es una solución adecuada para recuperar datos desde múltiples tablas de DynamoDB.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/appsync/latest/devguide/resolver-mapping-template-reference-dynamodb.html\n\nhttps://aws.amazon.com/blogs/mobile/appsync-pipeline-resolvers-2/\n\nhttps://aws.amazon.com/blogs/mobile/aws-appsync-pipeline-resolvers-and-functions-now-support-additional-array-methods-and-arrow-functions/"
  },
  {
    "q": "Una organización de salud está utilizando una instancia dedicada de EC2 con múltiples volúmenes EBS para alojar su aplicación web de registros médicos. Los volúmenes EBS deben estar cifrados debido a la confidencialidad de los datos que manejan y para cumplir con el estándar HIPAA (Health Insurance Portability and Accountability Act).\nEn el cifrado de EBS, ¿qué servicio utiliza AWS para asegurar los datos en reposo del volumen? (Selecciona DOS)",
    "o": [
      "Mediante claves administradas por AWS en AWS Key Management Service (KMS)",
      "Mediante una contraseña almacenada en CloudHSM",
      "Mediante los certificados SSL proporcionados por AWS Certificate Manager (ACM)",
      "Mediante el cifrado del lado del servidor de S3 (S3 Server-Side Encryption)",
      "Mediante claves propias en AWS Key Management Service (KMS)",
      "Mediante el cifrado del lado del cliente de S3 (S3 Client-Side Encryption)"
    ],
    "a": [
      0,
      4
    ],
    "e": "Correcto:\n\nMediante claves propias en AWS Key Management Service (KMS) - AWS Key Management Service (KMS) permite a los usuarios administrar sus propias claves de cifrado para proteger los datos en volúmenes EBS. Esto permite un control total sobre la administración y el acceso a las claves, lo que es fundamental para cumplir con requisitos de seguridad y cumplimiento.\n\nMediante claves administradas por AWS en AWS Key Management Service (KMS) - AWS también ofrece la opción de utilizar claves administradas por AWS en KMS. Estas claves son generadas y administradas automáticamente por AWS, facilitando el cifrado de volúmenes EBS sin que el usuario tenga que gestionar manualmente las claves.\n\nOpciones incorrectas:\n\nMediante el cifrado del lado del cliente de S3 (S3 Client-Side Encryption) - El cifrado del lado del cliente de S3 (S3 Client-Side Encryption) solo se aplica a objetos almacenados en Amazon S3 y no está relacionado con el cifrado de volúmenes EBS.\n\nMediante los certificados SSL proporcionados por AWS Certificate Manager (ACM) - AWS Certificate Manager (ACM) solo proporciona certificados SSL/TLS para cifrar el tráfico de red, pero no cifra datos en volúmenes EBS.\n\nMediante el cifrado del lado del servidor de S3 (S3 Server-Side Encryption) - El cifrado del lado del servidor de S3 (S3 Server-Side Encryption) se aplica únicamente a objetos de S3 y no a volúmenes EBS.\n\nMediante una contraseña almacenada en CloudHSM - CloudHSM almacena claves criptográficas, pero no contraseñas. Además, CloudHSM no se utiliza directamente para cifrar volúmenes EBS.\n\nReferencia:\n\nhttps://aws.amazon.com/ebs/faqs/"
  },
  {
    "q": "Una plataforma de análisis de datos en tiempo real está desplegada sobre un grupo de Auto Scaling de instancias EC2. Para mejorar la eficiencia operativa, es necesario configurar la capacidad del grupo para que aumente o disminuya automáticamente con base en métricas específicas y valores umbral definidos. Estas métricas deben activar alarmas en Amazon CloudWatch que inicien el proceso de escalado.\n¿Qué tipo de política de escalado sería la más adecuada para implementar en este caso?",
    "o": [
      "Simple scaling (escalado simple)",
      "Scheduled scaling (escalado programado)",
      "Target tracking scaling (escalado basado en seguimiento de objetivos)",
      "Step scaling (escalado por pasos)"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nStep scaling (escalado por pasos) - Step scaling (escalado por pasos) permite configurar diferentes niveles de ajustes de escalado en función de cuánto se desvíen las métricas de los valores umbral definidos. Esto proporciona mayor control y granularidad, lo cual es ideal para cargas de trabajo variables como una plataforma de análisis en tiempo real, permitiendo que el grupo escale de forma progresiva y reactiva ante los cambios de demanda.\n\nOpciones incorrectas:\n\nSimple scaling (escalado simple) - Simple scaling (escalado simple) responde a una alarma realizando un solo ajuste de escalado y espera a que se complete antes de responder a otras alarmas, lo que puede no ser lo suficientemente ágil.\n\nTarget tracking scaling (escalado basado en seguimiento de objetivos) - Target tracking scaling (escalado basado en seguimiento de objetivos) se basa en mantener una métrica en un valor objetivo constante (como CPU al 50%). Aunque es útil en muchos casos, este escenario requiere escalado según umbrales variables, lo que hace más adecuado el uso de step scaling.\n\nScheduled scaling (escalado programado) - Scheduled scaling (escalado programado) se basa en eventos programados (por ejemplo, aumentar capacidad a las 9am), pero no responde dinámicamente a los cambios en la carga, lo cual es un requisito en este caso.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scale-based-on-demand.html\n\nhttps://docs.aws.amazon.com/autoscaling/application/userguide/application-auto-scaling-step-scaling-policies.html"
  },
  {
    "q": "El Director de Seguridad de la Información (CISO) de una empresa de comercio electrónico ha tomado las medidas necesarias para garantizar que los datos sensibles de los clientes estén seguros en la nube. Sin embargo, la empresa descubrió recientemente que cierta Información de Identificación Personal (PII) de los clientes fue cargada por error en un bucket de S3.\nLa empresa quiere corregir este error de inmediato y evitar que incidentes similares ocurran en el futuro. Además, desean recibir notificaciones en caso de que este error ocurra nuevamente.\nComo Solutions Architect, ¿qué combinación de opciones deberías implementar en este escenario? (Selecciona DOS)",
    "o": [
      "Configurar una cola de Amazon SQS como destino de una regla de Amazon EventBridge (Amazon CloudWatch Events) que envíe notificaciones cuando ocurra nuevamente el error",
      "Identificar datos sensibles utilizando Amazon GuardDuty creando una regla en Amazon EventBridge (Amazon CloudWatch Events) para incluir los eventos de tipo CRITICAL provenientes de los hallazgos de GuardDuty",
      "Identificar datos sensibles utilizando Amazon Macie y crear una regla en Amazon EventBridge (Amazon CloudWatch Events) para capturar el evento SensitiveData",
      "Configurar un AWS IoT Message Broker como destino de una regla de Amazon EventBridge (Amazon CloudWatch Events) que envíe notificaciones cuando ocurra nuevamente el evento SensitiveData:S3Object/Personal",
      "Configurar un tema de Amazon SNS como destino de una regla de Amazon EventBridge (Amazon CloudWatch Events) que envíe notificaciones cuando ocurra nuevamente el error"
    ],
    "a": [
      2,
      4
    ],
    "e": "Correcto:\n\nConfigurar un tema de Amazon SNS como destino de una regla de Amazon EventBridge (Amazon CloudWatch Events) que envíe notificaciones cuando ocurra nuevamente el error - Amazon SNS permite enviar notificaciones a múltiples suscriptores a través de diversos canales como correo electrónico, mensajes móviles o notificaciones push. Al configurar un tema de SNS como destino de una regla de Amazon EventBridge, la empresa podrá recibir alertas cada vez que el evento que indica la presencia de PII en S3 ocurra nuevamente.\n\nIdentificar datos sensibles utilizando Amazon Macie y crear una regla en Amazon EventBridge (Amazon CloudWatch Events) para capturar el evento SensitiveData - Amazon Macie es un servicio de seguridad que utiliza machine learning para detectar, clasificar y proteger datos sensibles en AWS, incluyendo información de identificación personal (PII). Se puede configurar una regla de Amazon EventBridge para capturar eventos de tipo SensitiveData generados por Macie, lo que permite a la empresa monitorear y responder de manera efectiva cuando se detecten datos sensibles en S3.\n\nOpciones incorrectas:\n\nConfigurar un AWS IoT Message Broker como destino de una regla de Amazon EventBridge (Amazon CloudWatch Events) que envíe notificaciones cuando ocurra nuevamente el evento SensitiveData:S3Object/Personal - AWS IoT Message Broker no es un destino compatible en la consola de Amazon EventBridge. Además, su uso principal está enfocado en la comunicación y el enrutamiento de mensajes dentro de dispositivos IoT, lo que lo hace inapropiado para este caso.\n\nIdentificar datos sensibles utilizando Amazon GuardDuty creando una regla en Amazon EventBridge (Amazon CloudWatch Events) para incluir los eventos de tipo CRITICAL provenientes de los hallazgos de GuardDuty - Amazon GuardDuty no está diseñado específicamente para detectar PII en S3. En su lugar, Amazon Macie es la opción correcta para identificar información sensible dentro de los buckets de S3.\n\nConfigurar una cola de Amazon SQS como destino de una regla de Amazon EventBridge (Amazon CloudWatch Events) que envíe notificaciones cuando ocurra nuevamente el error - Amazon SQS es útil para desacoplar componentes y manejar comunicación asíncrona, pero no es la mejor opción para notificaciones en tiempo real. En este caso, SNS es la opción más adecuada para enviar alertas inmediatas sobre la detección de datos sensibles.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/eventbridge/latest/userguide/EventBridge.html\n\nhttps://docs.aws.amazon.com/macie/latest/user/findings-types.html#findings-sensitive-data-types\n\nhttps://docs.aws.amazon.com/macie/latest/user/findings-publish-event-schemas.html"
  },
  {
    "q": "Una empresa líder en medios ha adoptado recientemente una arquitectura híbrida en la nube, lo que requiere migrar sus servidores de aplicaciones y bases de datos a AWS.\nUna de sus aplicaciones requiere una migración de base de datos heterogénea, en la que necesitas transformar tu base de datos Oracle on-premises a PostgreSQL en AWS.\nEsto implica una conversión de esquema y transformación de código antes de que comience la migración de datos.\n¿Cuál de las siguientes opciones es el enfoque más adecuado para migrar la base de datos a AWS?",
    "o": [
      "Primero, usar AWS Schema Conversion Tool para convertir el esquema de origen y el código de la aplicación al de la base de datos de destino. Luego, usar AWS Database Migration Service para migrar los datos de la base de datos de origen a la de destino",
      "Configurar una Launch Template que convierta automáticamente el esquema y código fuente para que coincidan con los de la base de datos de destino. Luego, usar AWS Database Migration Service para migrar los datos de la base de datos de origen a la de destino",
      "La migración de bases de datos heterogéneas no es compatible en AWS. Debes transformar tu base de datos primero a PostgreSQL y luego migrarla a RDS",
      "Usar Amazon Neptune para convertir el esquema y código fuente para que coincida con el de la base de datos de destino en RDS. Luego, usar AWS Batch para migrar los datos de manera eficiente en un proceso por lotes"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nPrimero, usar AWS Schema Conversion Tool para convertir el esquema de origen y el código de la aplicación al de la base de datos de destino. Luego, usar AWS Database Migration Service para migrar los datos de la base de datos de origen a la de destino - AWS Schema Conversion Tool (SCT) permite convertir esquemas y código de bases de datos de origen para que sean compatibles con bases de datos de destino de diferente motor, como de Oracle a PostgreSQL. Una vez completada la conversión del esquema y código, AWS Database Migration Service (DMS) se encarga de migrar los datos de manera segura y eficiente sin interrumpir la base de datos de origen.\n\nOpciones incorrectas:\n\nLa migración de bases de datos heterogéneas no es compatible en AWS. Debes transformar tu base de datos primero a PostgreSQL y luego migrarla a RDS - AWS sí admite la migración de bases de datos heterogéneas mediante AWS SCT y AWS DMS, por lo que no es necesario transformar manualmente la base de datos antes de la migración.\n\nUsar Amazon Neptune para convertir el esquema y código fuente para que coincida con el de la base de datos de destino en RDS. Luego, usar AWS Batch para migrar los datos de manera eficiente en un proceso por lotes - Amazon Neptune es una base de datos de grafos y no una herramienta de conversión de esquemas. AWS Batch tampoco es un servicio de migración de bases de datos, por lo que no es una opción adecuada en este escenario.\n\nConfigurar una Launch Template que convierta automáticamente el esquema y código fuente para que coincidan con los de la base de datos de destino. Luego, usar AWS Database Migration Service para migrar los datos de la base de datos de origen a la de destino - Las plantillas de lanzamiento se utilizan principalmente en EC2 para definir configuraciones de instancia y no son una herramienta para la conversión de esquemas ni la migración de bases de datos.\n\nReferencias:\n\nhttps://aws.amazon.com/dms/\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-launch-templates.html\n\nhttps://docs.aws.amazon.com/batch/"
  },
  {
    "q": "Una empresa tiene múltiples conexiones AWS Site-to-Site VPN establecidas entre sus VPCs y su red remota. Durante las horas pico, muchos empleados experimentan problemas de conectividad lenta, lo que limita su productividad. La empresa ha solicitado a un arquitecto de soluciones que escale el rendimiento de las conexiones VPN.\n¿Qué solución debe implementar el arquitecto?",
    "o": [
      "Asociar las VPCs a un Transit Gateway con Equal Cost Multipath Routing (ECMR) habilitado y adjuntar túneles VPN adicionales",
      "Agregar más virtual private gateways a una VPC y habilitar Equal Cost Multipath Routing (ECMR) para obtener mayor ancho de banda en la VPN",
      "Redirigir algunas de las conexiones VPN a un dispositivo secundario de gateway en el extremo de la red remota",
      "Modificar la configuración de la VPN aumentando el número de túneles para escalar el rendimiento"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nAsociar las VPCs a un Transit Gateway con Equal Cost Multipath Routing (ECMR) habilitado y adjuntar túneles VPN adicionales - AWS Transit Gateway permite simplificar la conectividad entre múltiples VPCs y permite conectar cualquier VPC adjunta mediante una única conexión VPN. Además, habilitando Equal Cost Multipath Routing (ECMR), se puede escalar el rendimiento del tráfico IPsec VPN utilizando múltiples túneles VPN en paralelo. Un solo túnel VPN tiene un rendimiento máximo de 1.25 Gbps, pero con múltiples túneles adjuntos a un Transit Gateway con ECMR, el rendimiento puede escalar más allá de este límite.\n\nOpciones incorrectas:\n\nRedirigir algunas de las conexiones VPN a un dispositivo secundario de gateway en el extremo de la red remota - Redirigir algunas de las conexiones VPN a un gateway secundario en la red remota solo aumentaría la redundancia, pero no mejoraría el rendimiento de la conexión VPN. Esta solución es útil en caso de fallas, pero no para escalar el ancho de banda de las conexiones.\n\nAgregar más virtual private gateways a una VPC y habilitar Equal Cost Multipath Routing (ECMR) para obtener mayor ancho de banda en la VPN - No es posible agregar múltiples virtual private gateways a una sola VPC. Una VPC solo puede tener un virtual private gateway adjunto a la vez, y además, no es posible habilitar ECMR en un virtual private gateway.\n\nModificar la configuración de la VPN aumentando el número de túneles para escalar el rendimiento - Aumentar el número de túneles VPN no incrementa el rendimiento más allá del límite máximo de 1.25 Gbps por túnel. Para escalar más allá de este límite, es necesario utilizar AWS Transit Gateway con ECMR habilitado.\n\nReferencias:\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/transit-gateway-ecmp-multiple-tunnels/\n\nhttps://aws.amazon.com/blogs/networking-and-content-delivery/scaling-vpn-throughput-using-aws-transit-gateway/"
  },
  {
    "q": "Una aplicación está alojada en una instancia EC2 bajo demanda y utiliza el SDK de Amazon para comunicarse con otros servicios de AWS, como S3, DynamoDB y muchos más.\nComo parte de una próxima auditoría de TI, necesitas asegurarte de que todas las llamadas a la API de tus recursos de AWS sean registradas y almacenadas de manera duradera.\n¿Cuál es el servicio más adecuado para cumplir con este requisito?",
    "o": [
      "AWS CloudTrail",
      "AWS X-Ray",
      "Amazon CloudWatch",
      "Amazon API Gateway"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nAWS CloudTrail - AWS CloudTrail proporciona visibilidad sobre la actividad de los usuarios y recursos al registrar las acciones realizadas en la Consola de Administración de AWS y las llamadas a la API. Con CloudTrail, puedes identificar qué usuarios y cuentas realizaron solicitudes a AWS, la dirección IP de origen desde donde se hicieron las llamadas y el momento en que ocurrieron. Esto lo convierte en la mejor opción para auditar y rastrear todas las llamadas a la API de tus recursos en AWS.\n\nOpciones incorrectas:\n\nAmazon API Gateway - Amazon API Gateway no se utiliza para registrar cada llamada a la API de tus recursos en AWS. Su propósito es facilitar a los desarrolladores la creación, publicación, mantenimiento, monitoreo y seguridad de las API a cualquier escala.\n\nAWS X-Ray - AWS X-Ray se usa principalmente para la depuración y análisis del rendimiento de aplicaciones de microservicios mediante el rastreo de solicitudes. A diferencia de CloudTrail, no registra las llamadas a la API realizadas a tus recursos en AWS.\n\nAmazon CloudWatch - Amazon CloudWatch se usa principalmente para el monitoreo de sistemas basado en métricas del servidor. No tiene la capacidad de rastrear llamadas a la API realizadas a tus recursos en AWS.\n\nReferencia:\n\nhttps://aws.amazon.com/cloudtrail/"
  },
  {
    "q": "Una empresa financiera quiere almacenar sus datos en Amazon S3, pero al mismo tiempo, desean almacenar localmente en sus servidores on-premises los datos a los que acceden con más frecuencia.\nEsto se debe a que no tienen la opción de ampliar su almacenamiento on-premises, por lo que buscan un servicio de almacenamiento duradero y escalable en AWS. ¿Cuál es la mejor solución para este escenario?",
    "o": [
      "Usar tanto ElastiCache como S3 para los datos a los que se accede con frecuencia",
      "Usar Amazon Glacier",
      "Usar un grupo de instancias EC2 con volúmenes EBS para almacenar los datos de uso frecuente",
      "Usar AWS Storage Gateway - Cached Volumes"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nUsar AWS Storage Gateway - Cached Volumes - Los datos se almacenan en Amazon S3 mientras que los subconjuntos de datos a los que se accede con mayor frecuencia se retienen en caché localmente en la infraestructura on-premises. Esto proporciona un ahorro significativo en costos de almacenamiento primario y minimiza la necesidad de escalar el almacenamiento local, a la vez que garantiza baja latencia en el acceso a los datos utilizados con frecuencia. Es la mejor solución para este escenario.\n\n\n\nOpciones incorrectas:\n\nUsar tanto ElastiCache como S3 para los datos a los que se accede con frecuencia - Usar ElastiCache junto con S3 no es una solución eficiente para este caso. Además, la pregunta especifica que los datos de acceso frecuente deben almacenarse localmente en los servidores on-premises y no en AWS.\n\nUsar Amazon Glacier - Amazon Glacier está diseñado principalmente para archivado de datos a largo plazo y no para acceso frecuente, por lo que no es una opción viable en este escenario.\n\nUsar un grupo de instancias EC2 con volúmenes EBS para almacenar los datos de uso frecuente - Usar un grupo de instancias EC2 con volúmenes EBS no es una solución de almacenamiento escalable y duradera. EC2 no es un servicio de almacenamiento y no proporciona la combinación de escalabilidad en la nube con acceso local de baja latencia que se requiere en este caso.\n\nReferencia:\n\nhttps://aws.amazon.com/storagegateway/faqs/"
  },
  {
    "q": "Una aplicación web alojada en un grupo de Auto Scaling de instancias EC2 en AWS recibe un gran aumento de tráfico cada mañana, lo que provoca que muchos usuarios se quejen de tiempos de espera en las solicitudes. Las instancias EC2 tardan 1 minuto en iniciarse antes de poder responder a las solicitudes de los usuarios. La arquitectura en la nube debe rediseñarse para responder mejor a los cambios en el tráfico de la aplicación.\n¿Cómo debería el Solutions Architect rediseñar la arquitectura?",
    "o": [
      "Crear una política de escalado por pasos y configurar una condición de tiempo de calentamiento de la instancia",
      "Crear una nueva plantilla de lanzamiento y aumentar el tamaño de la instancia",
      "Crear una distribución de CloudFront y establecer la instancia EC2 como origen",
      "Crear un Network Load Balancer con modo de inicio lento"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nCrear una política de escalado por pasos y configurar una condición de tiempo de calentamiento de la instancia - La política de escalado por pasos permite aplicar \"ajustes por pasos\", lo que significa que se pueden configurar múltiples acciones para variar el escalado según la magnitud de la alerta. Al crear una política de escalado por pasos, también se puede especificar el tiempo de calentamiento que necesita una instancia recién lanzada antes de incluirse en las métricas de Auto Scaling.\n\nOpciones incorrectas:\n\nCrear un Network Load Balancer con modo de inicio lento - Network Load Balancer no admite el modo de inicio lento. Si fuera necesario un inicio lento, se debería utilizar Application Load Balancer en su lugar.\n\nCrear una distribución de CloudFront y establecer la instancia EC2 como origen - Usar CloudFront solo resolvería problemas de latencia en la red, pero no abordaría el problema principal del escenario, que es el tiempo de espera debido a que las instancias tardan en arrancar.\n\nCrear una nueva plantilla de lanzamiento y aumentar el tamaño de la instancia - Aumentar el tamaño de la instancia no siempre mejora el tiempo de arranque. En lugar de escalar verticalmente, se recomienda crear una política de escalado por pasos y configurar un tiempo de calentamiento adecuado.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-simple-step.html\n\nhttps://aws.amazon.com/ec2/autoscaling/faqs/"
  },
  {
    "q": "Una organización del sector jurídico conserva archivos confidenciales de casos legales almacenados en servidores locales (on-premises).\nEstos archivos deben permanecer inmutables y protegidos contra cualquier alteración una vez almacenados. La normativa legal exige trazabilidad completa del acceso y auditoría precisa sobre cada archivo. Actualmente, la mayoría de estos documentos están inactivos y no se utilizan frecuentemente, y la infraestructura local de almacenamiento está al límite de su capacidad.\nEl arquitecto de soluciones debe diseñar una estrategia para trasladar inmediatamente los archivos actuales a AWS y permitir la incorporación segura de nuevos archivos. ¿Cuál de las siguientes opciones representa la solución más adecuada para cumplir con estos requerimientos?",
    "o": [
      "Configurar AWS DataSync para transferir los archivos legales existentes desde los servidores locales a AWS. Crear un bucket de Amazon S3 para almacenar los archivos existentes y nuevos. Habilitar AWS CloudTrail con Data Events y Amazon S3 Object Lock",
      "Configurar AWS Storage Gateway para transferir los archivos legales existentes desde los servidores locales a AWS. Crear un bucket de Amazon S3 para almacenar los archivos y habilitar AWS CloudTrail con Management Events y Amazon S3 Object Lock",
      "Configurar AWS DataSync para transferir los archivos legales desde los servidores locales a AWS. Crear un bucket de Amazon S3 y activar AWS CloudTrail con Management Events y Amazon S3 Object Lock",
      "Configurar AWS Storage Gateway para mover los archivos legales desde los servidores locales a AWS. Usar una instancia EC2 con volúmenes EBS para almacenar los archivos. Habilitar los logs de acceso de S3 y S3 Object Lock"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nConfigurar AWS DataSync para transferir los archivos legales existentes desde los servidores locales a AWS. Crear un bucket de Amazon S3 para almacenar los archivos existentes y nuevos. Habilitar AWS CloudTrail con Data Events y Amazon S3 Object Lock - AWS DataSync es ideal para realizar migraciones rápidas y seguras de grandes volúmenes de datos desde entornos on-premises hacia AWS. Al emplear Amazon S3 Object Lock, se garantiza la inmutabilidad de los documentos legales, requisito esencial para cumplir con normativas del sector jurídico. Además, habilitar AWS CloudTrail con Data Events permite registrar todas las operaciones a nivel de objeto (como lectura, escritura o eliminación), lo que proporciona un nivel completo de auditoría y control de acceso.\n\nOpciones incorrectas:\n\nConfigurar AWS Storage Gateway para transferir los archivos legales existentes desde los servidores locales a AWS. Crear un bucket de Amazon S3 para almacenar los archivos y habilitar AWS CloudTrail con Management Events y Amazon S3 Object Lock - Aunque Storage Gateway permite conectar sistemas locales con S3, no está optimizado para transferencias masivas. Además, Management Events en CloudTrail no brinda trazabilidad a nivel de archivo, algo crucial en este caso.\n\nConfigurar AWS DataSync para transferir los archivos legales desde los servidores locales a AWS. Crear un bucket de Amazon S3 y activar AWS CloudTrail con Management Events y Amazon S3 Object Lock - Si bien se usa DataSync correctamente, Management Events no es suficiente para cumplir con las exigencias de auditoría detallada de accesos a los objetos en el bucket.\n\nConfigurar AWS Storage Gateway para mover los archivos legales desde los servidores locales a AWS. Usar una instancia EC2 con volúmenes EBS para almacenar los archivos. Habilitar los logs de acceso de S3 y S3 Object Lock - Almacenar archivos en EBS no ofrece la escalabilidad ni las funcionalidades de gobernanza y retención que proporciona Amazon S3. Además, Storage Gateway no es ideal para migraciones grandes, y los logs de acceso a S3 no sustituyen las capacidades de CloudTrail con Data Events.\n\nReferencias:\n\nhttps://aws.amazon.com/datasync/faqs/\n\nhttps://aws.amazon.com/blogs/aws/whats-new/2020/12/aws-cloudtrail-provides-more-granular-control-of-data-event-logging/\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lock.html"
  },
  {
    "q": "Una empresa de comercio electrónico líder necesita una solución de almacenamiento que pueda ser accedida simultáneamente por 1000 servidores Linux en múltiples zonas de disponibilidad.\nLos servidores están alojados en instancias EC2 que utilizan una estructura jerárquica de directorios a través del protocolo NFSv4. El servicio debe ser capaz de manejar datos que cambian rápidamente a gran escala, manteniendo un alto rendimiento. También debe ser altamente duradero y altamente disponible, ya que los servidores extraerán datos de él con poca necesidad de gestión.\nComo Solutions Architect, ¿cuál de los siguientes servicios es la opción más rentable para cumplir con este requisito?",
    "o": [
      "Amazon EBS",
      "Amazon FSx para Windows File Server",
      "Amazon EFS",
      "Amazon S3"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nAmazon EFS - Un servicio de almacenamiento de archivos diseñado para ser utilizado con instancias EC2. Proporciona una interfaz de sistema de archivos, semántica de acceso a archivos (como fuerte consistencia y bloqueo de archivos) y almacenamiento accesible concurrentemente para miles de instancias EC2.\n\nEFS ofrece alta disponibilidad, durabilidad y escalabilidad, lo que lo hace ideal para entornos donde múltiples servidores Linux necesitan acceso simultáneo a datos que cambian rápidamente. Además, soporta el protocolo NFSv4, que es el requerido en este escenario.\n\n vía - https://aws.amazon.com/es/efs/\n\nOpciones incorrectas:\n\nAmazon S3 - Amazon S3 es un servicio de almacenamiento de objetos y no un sistema de archivos. Aunque proporciona alta disponibilidad y escalabilidad, no es adecuado para almacenar datos que cambian rápidamente ni para escenarios donde se requiere un sistema de archivos POSIX con bloqueo de archivos.\n\nAmazon EBS - Amazon EBS es un almacenamiento de bloques diseñado para ser utilizado con una única instancia EC2 a la vez. No puede ser compartido entre múltiples instancias EC2, por lo que no cumple con los requisitos del escenario.\n\nAmazon FSx para Windows File Server - Amazon FSx para Windows File Server es un servicio de almacenamiento de archivos compatible con Windows, pero el escenario especifica que las instancias EC2 están ejecutando Linux, lo que hace que FSx para Windows no sea una opción válida.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/efs/latest/ug/how-it-works.html\n\nhttps://aws.amazon.com/efs/features/\n\nhttps://d1.awsstatic.com/whitepapers/AWS%20Storage%20Services%20Whitepaper-v9.pdf#page=9"
  },
  {
    "q": "Una plataforma de investigación biomédica está alojada en una instancia EC2 que procesa datos clínicos confidenciales. La instancia EC2 se encuentra en una subred privada y todos los registros se almacenan en un bucket de Amazon S3.\nLos investigadores acceden a los datos clínicos a través de Internet mediante URLs pre-firmadas generadas por la aplicación. El equipo de cumplimiento está preocupado porque la conectividad a Internet desde Amazon S3 representa un riesgo de seguridad.\nEn este escenario, ¿qué harías para resolver esta vulnerabilidad de la manera más rentable?",
    "o": [
      "Cambiar la arquitectura web para acceder a los datos clínicos almacenados en tu bucket de S3 creando un servicio de VPC endpoint personalizado",
      "Cambiar la arquitectura web para acceder a los datos clínicos en tu bucket de S3 a través de una conexión VPN",
      "Cambiar la arquitectura web para acceder a los datos clínicos en S3 a través de un Interface VPC Endpoint, el cual es impulsado por AWS PrivateLink",
      "Cambiar la arquitectura web para acceder a los datos clínicos a través de un Gateway VPC Endpoint"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nCambiar la arquitectura web para acceder a los datos clínicos a través de un Gateway VPC Endpoint - Permite una conexión privada y segura entre la VPC y los servicios de AWS como Amazon S3 sin necesidad de utilizar direcciones IP públicas, una VPN o una gateway de Internet. Además, no genera costos adicionales por su uso, lo que lo convierte en la solución más rentable.\n\n\n\nOpciones incorrectas:\n\nCambiar la arquitectura web para acceder a los datos clínicos en tu bucket de S3 a través de una conexión VPN - Una conexión VPN no evita que el tráfico de S3 pase por Internet. Para una conectividad segura y eficiente dentro de la red de AWS, se debe usar un VPC Endpoint en lugar de una VPN.\n\nCambiar la arquitectura web para acceder a los datos clínicos en S3 a través de un Interface VPC Endpoint, el cual es impulsado por AWS PrivateLink - Un Interface VPC Endpoint (AWS PrivateLink) permitiría acceder de forma privada a Amazon S3, pero tiene costos asociados por hora y por datos procesados. En este caso, un Gateway VPC Endpoint es una opción más rentable.\n\nCambiar la arquitectura web para acceder a los datos clínicos almacenados en tu bucket de S3 creando un servicio de VPC endpoint personalizado - Un \"VPC endpoint service\" es diferente de un \"VPC endpoint\". Con un VPC endpoint service, la empresa actuaría como proveedor de servicio, lo cual no es necesario en este escenario.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-endpoints.html\n\nhttps://docs.aws.amazon.com/vpc/latest/userguide/vpce-gateway.html"
  },
  {
    "q": "Una aplicación de análisis financiero que recopila, procesa y analiza datos del mercado de valores en tiempo real está utilizando Kinesis Data Streams. Los productores envían continuamente datos a Kinesis Data Streams, mientras que los consumidores procesan los datos en tiempo real.\nEn Amazon Kinesis, ¿dónde pueden los consumidores almacenar sus resultados? (Selecciona DOS)",
    "o": [
      "Amazon Athena",
      "Glacier Select",
      "Amazon Redshift",
      "Amazon S3",
      "AWS Glue"
    ],
    "a": [
      2,
      3
    ],
    "e": "Correcto:\n\nAmazon S3 - Es una de las opciones más comunes para almacenar datos procesados, ya que proporciona almacenamiento escalable, duradero y de bajo costo para grandes volúmenes de datos. Es ideal para almacenar los resultados procesados por consumidores de Kinesis.\n\nAmazon Redshift - Es un almacén de datos (data warehouse) optimizado para análisis en grandes volúmenes de datos. Los consumidores de Kinesis pueden almacenar sus resultados en Redshift para realizar consultas analíticas complejas y generar informes.\n\n\n\nOpciones incorrectas:\n\nGlacier Select - Permite ejecutar consultas directamente sobre datos archivados sin extraerlos completamente. No es una opción adecuada para almacenar los resultados procesados por Kinesis.\n\nAWS Glue - Es un servicio de ETL (Extract, Transform, Load) totalmente administrado que ayuda a preparar y cargar datos para análisis, pero no almacena datos de manera permanente.\n\nAmazon Athena - Un servicio de consulta interactiva que permite analizar datos almacenados en Amazon S3 utilizando SQL estándar. No se usa para almacenar directamente los resultados procesados por consumidores de Kinesis.\n\nReferencias:\n\nhttp://docs.aws.amazon.com/streams/latest/dev/key-concepts.html\n\nhttps://docs.aws.amazon.com/streams/latest/dev/using-other-services-redshift.html\n\nhttps://aws.amazon.com/blogs/big-data/streaming-data-from-amazon-s3-to-amazon-kinesis-data-streams-using-aws-dms/"
  },
  {
    "q": "Se ha lanzado una instancia EC2 bajo demanda dentro de una subred privada en una VPC. La Network ACL asociada a esta subred permite todo el tráfico entrante, pero deniega todo el tráfico saliente. El grupo de seguridad de la instancia tiene una regla de entrada que permite conexiones SSH desde cualquier dirección IP, pero no tiene reglas de salida configuradas.\nEn este contexto, ¿qué cambio debe realizarse para que sea posible establecer una conexión SSH a la instancia EC2?",
    "o": [
      "La Network ACL necesita ser modificada para permitir tráfico saliente",
      "El grupo de seguridad de salida necesita ser modificado para permitir tráfico saliente",
      "Tanto el grupo de seguridad de salida como la Network ACL de salida deben ser modificados para permitir tráfico saliente",
      "No se necesitan cambios. Ya se puede acceder desde cualquier dirección IP usando SSH"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nLa Network ACL necesita ser modificada para permitir tráfico saliente - Las Network ACL (NACL) son stateless, lo que significa que el tráfico de respuesta debe ser explícitamente permitido. Aunque el tráfico SSH entrante esté permitido, si la NACL bloquea todo el tráfico saliente, la instancia no podrá enviar respuestas, impidiendo así la conexión SSH. La solución es modificar la NACL para permitir el tráfico saliente en el puerto 22 o en un rango de puertos adecuado.\n\nOpciones incorrectas:\n\nEl grupo de seguridad de salida necesita ser modificado para permitir tráfico saliente - Los grupos de seguridad son stateful, lo que significa que si se permite el tráfico entrante, la respuesta saliente se permite automáticamente, por lo que no es necesario modificar las reglas de salida del grupo de seguridad.\n\nNo se necesitan cambios. Ya se puede acceder desde cualquier dirección IP usando SSH - Esta opción es incorrecta porque, aunque el tráfico entrante esté permitido, sin tráfico saliente autorizado por la NACL, la instancia no podrá establecer la conexión completamente.\n\nTanto el grupo de seguridad de salida como la Network ACL de salida deben ser modificados para permitir tráfico saliente - Solo la NACL necesita ser modificada. El grupo de seguridad ya permite el tráfico entrante, y las respuestas están implícitamente autorizadas debido a su naturaleza stateful.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_ACLs.html\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/authorizing-access-to-an-instance.html"
  },
  {
    "q": "Una empresa está utilizando AWS IAM para administrar el acceso a los servicios de AWS. El Solutions Architect de la empresa creó la siguiente política de IAM para AWS Lambda:\n{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n{\n\"Effect\": \"Allow\",\n\"Action\": [\n\"lambda:CreateFunction\",\n\"lambda:DeleteFunction\"\n],\n\"Resource\": \"*\"\n},\n{\n\"Effect\": \"Deny\",\n\"Action\": [\n\"lambda:CreateFunction\",\n\"lambda:DeleteFunction\",\n\"lambda:InvokeFunction\",\n\"lambda:TagResource\"\n],\n\"Resource\": \"*\",\n\"Condition\": {\n\"IpAddress\": {\n\"aws:SourceIp\": \"203.0.113.50/32\"\n}\n}\n}\n]\n}\n¿Cuál de las siguientes opciones está permitida por esta política?",
    "o": [
      "Crear una función de AWS Lambda usando la dirección 192.168.44.22/32",
      "Eliminar una función de AWS Lambda desde cualquier dirección de red",
      "Eliminar una función de AWS Lambda usando la dirección 203.0.113.50/32",
      "Crear una función de AWS Lambda usando la dirección 203.0.113.50/32"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nCrear una función de AWS Lambda usando la dirección 192.168.44.22/32 - La política de IAM concede permisos para crear y eliminar funciones Lambda en cualquier dirección IP, excepto la dirección 203.0.113.50/32, la cual está explícitamente denegada en la política. Como la dirección IP 192.168.44.22/32 no está denegada, puede usarse para crear una función Lambda.\n\nOpciones incorrectas:\n\nEliminar una función de AWS Lambda usando la dirección 203.0.113.50/32 - No se puede eliminar una función Lambda desde la dirección IP 203.0.113.50/32 porque esta dirección está denegada en la política de IAM.\n\nEliminar una función de AWS Lambda desde cualquier dirección de red - No se puede eliminar una función Lambda desde \"cualquier dirección de red\" porque la dirección 203.0.113.50/32 está explícitamente bloqueada.\n\nCrear una función de AWS Lambda usando la dirección 203.0.113.50/32 - No se puede crear una función Lambda desde la dirección IP 203.0.113.50/32 porque esta dirección está explícitamente denegada en la política de IAM.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html\n\nhttps://docs.aws.amazon.com/lambda/latest/dg/lambda-permissions.html"
  },
  {
    "q": "Una organización planea ejecutar una aplicación en un servidor físico dedicado que no utiliza virtualización.\nLos datos de la aplicación se almacenarán en una solución de almacenamiento que usa el protocolo NFS. Para prevenir la pérdida de datos, necesitas utilizar un servicio de almacenamiento en la nube duradero para almacenar una copia de los datos.\n¿Cuál de las siguientes opciones es la solución más adecuada para cumplir con este requisito?",
    "o": [
      "Usar un AWS Storage Gateway hardware appliance para tus recursos de cómputo. Configurar Volume Gateway para almacenar los datos de la aplicación y crear un bucket de Amazon S3 para almacenar una copia de seguridad de los datos",
      "Usar AWS Storage Gateway con un gateway en una máquina virtual (VM) para tus recursos de cómputo. Configurar File Gateway para almacenar los datos de la aplicación y realizar copias de seguridad",
      "Usar un AWS Storage Gateway hardware appliance para tus recursos de cómputo. Configurar File Gateway para almacenar los datos de la aplicación y crear un bucket de Amazon S3 para almacenar una copia de seguridad de los datos",
      "Usar un AWS Storage Gateway hardware appliance para tus recursos de cómputo. Configurar Volume Gateway para almacenar los datos de la aplicación y realizar copias de seguridad"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nUsar un AWS Storage Gateway hardware appliance para tus recursos de cómputo. Configurar File Gateway para almacenar los datos de la aplicación y crear un bucket de Amazon S3 para almacenar una copia de seguridad de los datos - Un dispositivo físico preconfigurado con el software de Storage Gateway, lo que permite una integración sencilla con entornos on-premises sin necesidad de virtualización.\n\nPara este escenario, donde la aplicación utiliza NFS, la mejor opción es configurar File Gateway, ya que admite protocolos NFS y SMB para almacenar y recuperar datos en Amazon S3. Además, S3 proporciona durabilidad y permite almacenar copias de seguridad de los datos de la aplicación.\n\n\n\nOpciones incorrectas:\n\nUsar AWS Storage Gateway con un gateway en una máquina virtual (VM) para tus recursos de cómputo. Configurar File Gateway para almacenar los datos de la aplicación y realizar copias de seguridad - El escenario especifica que se necesita un hardware appliance on-premises, no una solución basada en una máquina virtual (VM).\n\nUsar un AWS Storage Gateway hardware appliance para tus recursos de cómputo. Configurar Volume Gateway para almacenar los datos de la aplicación y realizar copias de seguridad - Volume Gateway está diseñado para entornos que usan dispositivos iSCSI en lugar de NFS. En este caso, File Gateway es la opción más adecuada.\n\nUsar un AWS Storage Gateway hardware appliance para tus recursos de cómputo. Configurar Volume Gateway para almacenar los datos de la aplicación y crear un bucket de Amazon S3 para almacenar una copia de seguridad de los datos - Al igual que la opción anterior, Volume Gateway no es compatible con NFS. File Gateway es la única opción dentro de AWS Storage Gateway que permite el almacenamiento basado en NFS.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/storagegateway/latest/userguide/hardware-appliance.html\n\nhttps://docs.aws.amazon.com/storagegateway/latest/userguide/WhatIsStorageGateway.html"
  },
  {
    "q": "Una empresa de análisis de datos almacena una gran cantidad de datos en su centro de datos on-premises. Para escalar su infraestructura de almacenamiento, buscan volúmenes en la nube que puedan montar utilizando dispositivos iSCSI desde sus servidores on-premises. Tienen una aplicación de análisis de datos local que accede con frecuencia a los datos más recientes, mientras que los datos más antiguos rara vez se utilizan.\nDebes minimizar la necesidad de escalar el almacenamiento on-premises mientras garantizas un acceso de baja latencia a los datos desde su aplicación web. ¿Qué tipo de servicio de AWS Storage Gateway deberías utilizar para cumplir con estos requisitos?",
    "o": [
      "File Gateway",
      "Tape Gateway",
      "Volume Gateway en modo caché (Cached Mode)",
      "Volume Gateway en modo almacenado (Stored Mode)"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nVolume Gateway en modo caché (Cached Mode) - Permite almacenar los datos primarios en Amazon S3, mientras que mantiene una copia en caché de los datos más accedidos localmente en el Storage Gateway on-premises. Esta opción reduce la necesidad de escalar el almacenamiento on-premises al mismo tiempo que proporciona acceso de baja latencia a los datos de uso frecuente.\n\n\n\nOpciones incorrectas:\n\nFile Gateway - File Gateway no es la opción correcta porque se utiliza para montar volúmenes como objetos de Amazon S3 a través de los protocolos NFS y SMB. Sin embargo, el escenario requiere volúmenes que se puedan montar como dispositivos iSCSI.\n\nVolume Gateway en modo almacenado (Stored Mode) - Volume Gateway en modo almacenado (Stored Mode) no es adecuado porque almacena toda la información on-premises y solo usa AWS para realizar backups en la nube. Esto no minimiza la necesidad de escalar la infraestructura on-premises, que es uno de los requisitos clave del escenario.\n\nTape Gateway - Tape Gateway está diseñado para archivado de datos a largo plazo, lo cual no es un requisito en este caso. Es una solución de bajo costo y alta durabilidad para la retención de datos en Amazon S3 Glacier, pero no proporciona el acceso de baja latencia requerido.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/storagegateway/latest/userguide/StorageGatewayConcepts.html#volume-gateway-concepts\n\nhttps://docs.aws.amazon.com/storagegateway/latest/userguide/WhatIsStorageGateway.html"
  },
  {
    "q": "Un arquitecto de soluciones ha creado una organización de AWS con varias cuentas de AWS. La política de seguridad requiere que el uso de acciones de API específicas esté limitado en todas las cuentas. El arquitecto de soluciones requiere un método de controlar centralmente estas acciones.\n¿Cuál es el método más simple para lograr los requisitos?",
    "o": [
      "Crear roles entre cuentas en cada cuenta para limitar el acceso a los servicios y acciones que están permitidos",
      "Crear una política IAM en la cuenta raíz y adjuntarla a usuarios y grupos en cada cuenta",
      "Crear una política de control de servicios en la unidad organizacional raíz para denegar el acceso a los servicios o acciones",
      "Crear una Network ACL que limite el acceso a los servicios o acciones y adjuntarla a todas las subredes relevantes"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nCrear una política de control de servicios en la unidad organizacional raíz para denegar el acceso a los servicios o acciones - Las políticas de control de servicios (SCPs) ofrecen control central sobre los permisos máximos disponibles para todas las cuentas en su organización, permitiéndole asegurar que sus cuentas se mantengan dentro de las pautas de control de acceso de su organización.\n\nOpciones incorrectas:\n\nCrear una política IAM en la cuenta raíz y adjuntarla a usuarios y grupos en cada cuenta - Este no es un método eficiente o centralmente administrado de aplicar las restricciones de seguridad.\n\nCrear roles entre cuentas en cada cuenta para limitar el acceso a los servicios y acciones que están permitidos - Este es otro ejemplo de un método complejo e ineficiente de proporcionar acceso entre cuentas y no restringe las acciones de API dentro de la cuenta.\n\nCrear una Network ACL que limite el acceso a los servicios o acciones y adjuntarla a todas las subredes relevantes - Las Network ACLs controlan el tráfico de red, no las acciones de API.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_about-scps.html"
  },
  {
    "q": "En una empresa emergente del sector fintech, te han asignado el diseño de una nueva plataforma web que requiere una base de datos NoSQL capaz de escalar automáticamente y sin límites de almacenamiento para una tabla crítica. El equipo de desarrollo es pequeño y no dispone de personal especializado para gestionar infraestructura de bases de datos.\n¿Qué servicio de AWS deberías elegir para cumplir con estos requerimientos de forma eficiente y con alta disponibilidad?",
    "o": [
      "DynamoDB",
      "Amazon Neptune",
      "Amazon Aurora",
      "Amazon DocumentDB"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nDynamoDB - Amazon DynamoDB es la solución más adecuada, ya que es un servicio de base de datos NoSQL totalmente administrado, que escala automáticamente en función del tráfico y del volumen de datos.\n\nPermite almacenar datos en formatos de clave-valor y documentos, sin necesidad de administrar servidores ni preocuparse por la capacidad de almacenamiento.\nOfrece alta disponibilidad, replicación entre regiones y baja latencia, lo que lo hace ideal para startups con recursos limitados.\nOpciones incorrectas:\n\nAmazon DocumentDB - Amazon DocumentDB es un servicio de base de datos de documentos compatible con MongoDB, pero requiere gestión de instancias y no escala automáticamente al mismo nivel que DynamoDB.\n\nAmazon Aurora - Amazon Aurora es un motor relacional compatible con MySQL y PostgreSQL, por lo tanto no cumple con el requisito de ser una base de datos NoSQL.\n\nAmazon Neptune - Amazon Neptune es una base de datos orientada a grafos, más adecuada para escenarios como redes sociales o análisis de relaciones, pero no para un modelo general de NoSQL con alta escalabilidad.\n\nReferencia:\n\nhttps://aws.amazon.com/dynamodb/"
  },
  {
    "q": "Una empresa tecnológica está desplegando una plataforma interna de colaboración desarrollada en Java, alojada en una instancia EC2 con sistema operativo Windows. La solución requiere un sistema de archivos compartido que proporcione alto rendimiento en throughput e IOPS, y que además permita integración con Microsoft Active Directory para la gestión de usuarios y permisos.\n¿Cuál es el servicio más adecuado para cubrir estos requerimientos?",
    "o": [
      "Amazon FSx for Windows File Server",
      "Amazon EBS Provisioned IOPS SSD volumes",
      "AWS Storage Gateway - File Gateway",
      "Amazon Elastic File System"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nAmazon FSx for Windows File Server - Amazon FSx for Windows File Server es la opción ideal, ya que proporciona un sistema de archivos compartido totalmente administrado y basado en Windows, accesible mediante el protocolo SMB. Ofrece compatibilidad nativa con Microsoft Active Directory y características avanzadas como cuotas por usuario, backups automáticos, restauración granular de archivos y gran rendimiento en throughput e IOPS, ideal para aplicaciones Java que requieren almacenamiento compartido en entornos Windows.\n\n\n\nOpciones incorrectas:\n\nAmazon EBS Provisioned IOPS SSD volumes - Amazon EBS está diseñado como almacenamiento en bloque para una sola instancia EC2 y no puede ser compartido entre múltiples instancias, además no se integra con Active Directory.\n\nAWS Storage Gateway - File Gateway - AWS Storage Gateway - File Gateway permite acceso compartido y puede integrarse con Active Directory, pero su rendimiento no se compara con el de Amazon FSx para cargas exigentes.\n\nAmazon Elastic File System - Amazon Elastic File System (EFS) solo funciona con instancias Linux, por lo que no es compatible con una solución basada en Windows, como en este caso.\n\nReferencias:\n\nhttps://aws.amazon.com/fsx/windows/faqs/\n\nhttps://docs.aws.amazon.com/fsx/latest/WindowsGuide/what-is.html"
  },
  {
    "q": "Una aplicación requiere una base de datos MySQL que solo se usará varias veces a la semana por períodos cortos. La base de datos necesita proporcionar instanciación y escalado automáticos.\n¿Qué servicio de base de datos es más adecuado?",
    "o": [
      "Amazon Aurora",
      "Amazon Aurora Serverless",
      "Instancia de Amazon EC2 con base de datos MySQL instalada",
      "Amazon RDS MySQL"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nAmazon Aurora Serverless - Amazon Aurora Serverless es una configuración bajo demanda y de escalado automático para Amazon Aurora. La base de datos se inicia, se detiene y escala la capacidad hacia arriba o hacia abajo automáticamente según las necesidades de la aplicación. Esta es una solución de base de datos ideal para aplicaciones usadas con poca frecuencia.\n\nOpciones incorrectas:\n\nAmazon RDS MySQL - Este servicio requiere que una instancia esté en ejecución todo el tiempo, lo cual es más costoso.\n\nAmazon Aurora - Este servicio requiere que una instancia esté en ejecución todo el tiempo, lo cual es más costoso.\n\nInstancia de Amazon EC2 con base de datos MySQL instalada - Este servicio requiere que una instancia esté en ejecución todo el tiempo, lo cual es más costoso.\n\nReferencias:\n\nhttps://aws.amazon.com/rds/aurora/serverless/"
  },
  {
    "q": "Una plataforma de servicios financieros basada en AWS ejecuta su backend en un conjunto de instancias EC2 distribuidas mediante un Auto Scaling Group. Estas instancias están detrás de un Application Load Balancer que gestiona el tráfico entrante.\nLa empresa ha desplegado esta solución en múltiples regiones para ofrecer baja latencia a usuarios en distintas ubicaciones. Recientemente, una nueva regulación internacional ha prohibido brindar servicios financieros a usuarios de una región específica.\n¿Cuál es la medida recomendada que debe tomar el arquitecto de soluciones para asegurar el cumplimiento de esta regulación?",
    "o": [
      "Actualizar las tablas de rutas para redirigir todo el tráfico saliente a AWS Network Firewall y configurar un grupo de reglas de dominio con estado para bloquear el país especificado",
      "Crear una regla Web ACL en AWS WAF para bloquear el país especificado. Asociar esta regla con los Application Load Balancers",
      "Actualizar las listas de control de acceso a la red (NACL) de todas las subredes utilizadas por las instancias EC2 para 'denegar' todas las direcciones IP del país específico",
      "Actualizar las listas de control de acceso a la red (NACL) de todas las subredes utilizadas por los Application Load Balancers para 'denegar' todas las direcciones IP del país específico"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nCrear una regla Web ACL en AWS WAF para bloquear el país especificado. Asociar esta regla con los Application Load Balancers - AWS WAF (Web Application Firewall) permite implementar reglas de geolocalización mediante Web ACLs para bloquear solicitudes HTTP(S) desde ubicaciones específicas. Al asociar una Web ACL con una regla de geo-match al Application Load Balancer, se puede restringir el acceso desde el país en cuestión de forma centralizada, cumpliendo eficazmente con los requisitos regulatorios.\n\nOpciones incorrectas:\n\nActualizar las tablas de rutas para redirigir todo el tráfico saliente a AWS Network Firewall y configurar un grupo de reglas de dominio con estado para bloquear el país especificado - AWS Network Firewall está más orientado al filtrado de tráfico a nivel de red, como bloquear dominios maliciosos o tráfico no deseado, pero no es la solución óptima para bloquear tráfico por geolocalización.\n\nActualizar las listas de control de acceso a la red (NACL) de todas las subredes utilizadas por los Application Load Balancers para 'denegar' todas las direcciones IP del país específico - Las NACLs no son prácticas para gestionar bloques IP de países completos debido a la naturaleza cambiante de estas direcciones. Además, las NACLs no ofrecen visibilidad ni control específico sobre solicitudes HTTP.\n\nActualizar las listas de control de acceso a la red (NACL) de todas las subredes utilizadas por las instancias EC2 para 'denegar' todas las direcciones IP del país específico - Las restricciones a nivel de las instancias EC2 son menos efectivas en arquitecturas donde el tráfico es canalizado a través de un ALB. El control debe establecerse lo antes posible en el flujo, es decir, en el punto de entrada del tráfico: el ALB.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/waf/latest/developerguide/waf-rule-statement-type-geo-match.html\n\nhttps://docs.aws.amazon.com/waf/latest/developerguide/web-acl.html"
  },
  {
    "q": "Una aplicación de monitoreo de sensores en tiempo real utiliza un patrón de mensajería 'fanout' para distribuir datos recopilados desde dispositivos IoT. Cada vez que se registra una nueva lectura, se publica un mensaje en un tema de Amazon SNS, y este mensaje se distribuye en paralelo a múltiples colas de Amazon SQS para procesamiento asincrónico.\nUna instancia Spot EC2 extrae los mensajes de cada cola de SQS y los analiza. Ocurrió un incidente en el que una de estas instancias se interrumpió inesperadamente mientras procesaba una lectura, y el análisis no se completó.\nEn este escenario, ¿qué sucede con el mensaje en la cola de SQS?",
    "o": [
      "El mensaje se enviará a una Dead Letter Queue (DLQ) en AWS DataSync",
      "El mensaje se asignará automáticamente a la misma instancia EC2 cuando vuelva a estar en línea dentro o después del tiempo de visibilidad",
      "Cuando expire el tiempo de visibilidad del mensaje, estará disponible para ser procesado por otras instancias EC2",
      "El mensaje se eliminará y se duplicará en la SQS cuando la instancia EC2 vuelva a estar en línea"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nCuando expire el tiempo de visibilidad del mensaje, estará disponible para ser procesado por otras instancias EC2 - Amazon SQS usa un tiempo de visibilidad (visibility timeout) para evitar que otros consumidores procesen un mensaje mientras está siendo procesado. Si una instancia EC2 se interrumpe antes de completar el procesamiento y eliminar el mensaje, este volverá a estar disponible para otras instancias EC2 una vez que expire el tiempo de visibilidad.\n\n\n\nOpciones incorrectas:\n\nEl mensaje se enviará a una Dead Letter Queue (DLQ) en AWS DataSync - AWS DataSync se usa para transferencias de datos entre entornos on-premises y AWS, no para manejar Dead Letter Queues (DLQ). Aunque los mensajes no procesados pueden ser enviados a una DLQ, esto no es manejado por DataSync sino por Amazon SQS.\n\nEl mensaje se asignará automáticamente a la misma instancia EC2 cuando vuelva a estar en línea dentro o después del tiempo de visibilidad - Un mensaje en SQS no está ligado a una instancia EC2 específica. Si una instancia falla, el mensaje no se reasigna automáticamente a la misma instancia cuando vuelve a estar en línea. En su lugar, quedará disponible para cualquier otra instancia EC2 que consulte la cola después de que expire el tiempo de visibilidad.\n\nEl mensaje se eliminará y se duplicará en la SQS cuando la instancia EC2 vuelva a estar en línea - Amazon SQS no elimina ni duplica automáticamente mensajes cuando una instancia EC2 se reinicia. Un mensaje solo se elimina de la cola si el consumidor lo procesa completamente y lo borra explícitamente.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-visibility-timeout.html\n\nhttps://docs.aws.amazon.com/sns/latest/dg/sns-common-scenarios.html"
  },
  {
    "q": "Una aplicación web en una arquitectura de tres niveles se ejecuta en una flota de instancias de Amazon EC2. Se han reportado problemas de rendimiento y las investigaciones apuntan a espacio de intercambio (swap) insuficiente. El equipo de operaciones requiere monitoreo para determinar si esto es correcto.\n¿Qué debe recomendar un arquitecto de soluciones?",
    "o": [
      "Usar metadatos de EC2 para recopilar información, luego publicarla en métricas personalizadas de Amazon CloudWatch. Monitorear métricas SwapUsage en CloudWatch",
      "Configurar una dimensión de métrica SwapUsage de Amazon CloudWatch. Monitorear la dimensión SwapUsage en las métricas EC2 en CloudWatch",
      "Habilitar monitoreo detallado en la consola de EC2. Crear una métrica personalizada SwapUtilization de Amazon CloudWatch. Monitorear métricas SwapUtilization en CloudWatch",
      "Instalar un agente de Amazon CloudWatch en las instancias. Ejecutar un script apropiado en un horario establecido. Monitorear métricas SwapUtilization en CloudWatch"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nInstalar un agente de Amazon CloudWatch en las instancias. Ejecutar un script apropiado en un horario establecido. Monitorear métricas SwapUtilization en CloudWatch - Usar el agente de CloudWatch para recopilar tanto métricas del sistema como archivos de registro de instancias de Amazon EC2 y servidores on-premises. El agente admite tanto Windows Server como Linux, y le permite seleccionar las métricas a recopilar, incluyendo métricas de sub-recursos como por núcleo de CPU. Ahora hay un agente unificado y anteriormente había scripts de monitoreo. Ambas herramientas pueden capturar métricas SwapUtilization y enviarlas a CloudWatch. Esta es la mejor manera de obtener métricas de utilización de memoria de instancias de Amazon EC2.\n\nOpciones incorrectas:\n\nConfigurar una dimensión de métrica SwapUsage de Amazon CloudWatch. Monitorear la dimensión SwapUsage en las métricas EC2 en CloudWatch - No hay una métrica SwapUsage en CloudWatch. Todas las métricas de memoria deben ser métricas personalizadas.\n\nUsar metadatos de EC2 para recopilar información, luego publicarla en métricas personalizadas de Amazon CloudWatch. Monitorear métricas SwapUsage en CloudWatch - La información relacionada con el rendimiento no se almacena en metadatos.\n\nHabilitar monitoreo detallado en la consola de EC2. Crear una métrica personalizada SwapUtilization de Amazon CloudWatch. Monitorear métricas SwapUtilization en CloudWatch - No se crean métricas personalizadas en la consola; debe configurar las instancias para enviar la información de métricas a CloudWatch.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Install-CloudWatch-Agent.html"
  },
  {
    "q": "Una empresa diagnostica problemas operativos en su arquitectura en la nube registrando el historial de llamadas a la API de AWS de todos los recursos. El Solutions Architect debe implementar una solución que permita identificar rápidamente los cambios recientes realizados en los recursos de su entorno, incluyendo creación, modificación y eliminación de recursos de AWS.\nUno de los requisitos es que los archivos de registro generados deben estar cifrados para evitar problemas de seguridad.\n¿Cuál de las siguientes es la mejor opción para implementar el cifrado?",
    "o": [
      "Usar CloudTrail y configurar el archivo de destino en Amazon Glacier para utilizar Server-Side Encryption (SSE)",
      "Usar CloudTrail y configurar el bucket de destino en S3 para utilizar Server Side Encryption (SSE) con el algoritmo de cifrado AES-128",
      "Usar CloudTrail con su configuración predeterminada",
      "Usar CloudTrail y configurar el bucket de destino en S3 para utilizar Server-Side Encryption (SSE)"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nUsar CloudTrail con su configuración predeterminada - Por defecto, los archivos de registro de eventos de CloudTrail se cifran utilizando Server-Side Encryption (SSE) de Amazon S3. También es posible elegir cifrar los archivos de registro con una clave de AWS Key Management Service (AWS KMS). Dado que el requisito de la pregunta es simplemente que los registros estén cifrados, CloudTrail ya cumple con esto en su configuración predeterminada.\n\n\n\nOpciones incorrectas:\n\nUsar CloudTrail y configurar el bucket de destino en S3 para utilizar Server Side Encryption (SSE) con el algoritmo de cifrado AES-128 - CloudTrail ya cifra los archivos de registro utilizando SSE de S3 de forma predeterminada, por lo que no es necesario configurarlo manualmente. Además, SSE-S3 usa el algoritmo AES-256, no AES-128.\n\nUsar CloudTrail y configurar el bucket de destino en S3 para utilizar Server-Side Encryption (SSE) - La configuración predeterminada de CloudTrail ya cifra los archivos de registro utilizando SSE de S3, lo que hace innecesario configurarlo de manera adicional.\n\nUsar CloudTrail y configurar el archivo de destino en Amazon Glacier para utilizar Server-Side Encryption (SSE) - CloudTrail almacena los archivos de registro en S3 y no en Amazon Glacier. Aunque se pueden mover los registros a Glacier para almacenamiento a largo plazo, esto no es un requisito en la pregunta.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/awscloudtrail/latest/userguide/how-cloudtrail-works.html\n\nhttps://aws.amazon.com/blogs/aws/category/cloud-trail/"
  },
  {
    "q": "Una organización científica internacional ejecuta simulaciones climáticas complejas en una instancia EC2 On-Demand, con un volumen EBS adjunto donde se almacenan los resultados diarios. Para asegurar los datos, un proceso automatizado toma una instantánea del volumen EBS cada noche a la medianoche (12 AM), momento en el cual las simulaciones se detienen temporalmente.\nEn una ocasión, se necesita intervenir de emergencia para ajustar parámetros en el sistema de simulación y modificar datos directamente en el volumen EBS al mismo tiempo que la instantánea está en curso.\n¿Cuál de los siguientes escenarios es verdadero en cuanto al uso de un volumen EBS mientras la instantánea está en progreso?",
    "o": [
      "El volumen EBS se puede usar mientras la instantánea está en progreso",
      "El volumen EBS solo se puede usar en modo de solo lectura mientras la instantánea está en progreso",
      "El volumen EBS no puede ser utilizado hasta que la instantánea se complete",
      "El volumen EBS no puede ser adjuntado ni desapegado de una instancia EC2 hasta que la instantánea se complete"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nEl volumen EBS se puede usar mientras la instantánea está en progreso - Las instantáneas de EBS ocurren de manera asíncrona. Se crea una instantánea en un punto en el tiempo de inmediato, pero el estado de la instantánea permanece en \"pending\" hasta que todos los bloques modificados se hayan transferido a Amazon S3. Durante este proceso, el volumen EBS sigue siendo completamente utilizable para lecturas y escrituras.\n\nOpciones incorrectas:\n\nEl volumen EBS solo se puede usar en modo de solo lectura mientras la instantánea está en progreso - Un volumen EBS no entra en modo de solo lectura mientras se toma una instantánea. Puede seguir utilizándose sin restricciones.\n\nEl volumen EBS no puede ser adjuntado ni desapegado de una instancia EC2 hasta que la instantánea se complete - Un volumen EBS puede ser adjuntado o desapegado de una instancia EC2 incluso si una instantánea está en progreso.\n\nEl volumen EBS no puede ser utilizado hasta que la instantánea se complete - No es necesario esperar a que la instantánea se complete para usar el volumen EBS. Se puede seguir accediendo a los datos y escribiendo en el volumen mientras la instantánea se crea en segundo plano.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-creating-snapshot.html\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html"
  },
  {
    "q": "Una empresa tiene una infraestructura donde las instancias EC2 en una subred privada recuperan objetos de Amazon S3 a través de una instancia NAT. El Solutions Architect ha recibido la instrucción de reducir los costos de la solución actual.\n¿Cómo debe el Solutions Architect rediseñar la arquitectura de la manera más rentable?",
    "o": [
      "Eliminar la instancia NAT y crear un endpoint de gateway para S3 para acceder a los objetos",
      "Reemplazar la instancia NAT con una NAT Gateway para acceder a los objetos en S3",
      "Eliminar la instancia NAT y crear un endpoint de interfaz para S3 para acceder a los objetos",
      "Usar un tipo de instancia más pequeño para la instancia NAT"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nEliminar la instancia NAT y crear un endpoint de gateway para S3 para acceder a los objetos - Un VPC Gateway Endpoint permite conectar de forma privada una VPC con servicios de AWS como S3 sin necesidad de una Internet Gateway, NAT Gateway, VPN o AWS Direct Connect. Al usar un Gateway Endpoint para S3, el tráfico de la VPC a S3 se mantiene dentro de la red de AWS, lo que evita costos adicionales por transferencia de datos y procesamiento a través de una NAT Gateway. Además, los endpoints de tipo Gateway no tienen costos adicionales por su uso.\n\nOpciones incorrectas:\n\nUsar un tipo de instancia más pequeño para la instancia NAT - Usar un tipo de instancia más pequeño para la instancia NAT podría reducir costos, pero no es la solución más rentable. Un S3 Gateway Endpoint es una mejor opción porque elimina completamente el costo de la NAT.\n\nReemplazar la instancia NAT con una NAT Gateway para acceder a los objetos en S3 - Reemplazar la instancia NAT con una NAT Gateway no reduce significativamente los costos, ya que aún se aplicarán cargos por la transferencia de datos y por el uso por hora de la NAT Gateway.\n\nEliminar la instancia NAT y crear un endpoint de interfaz para S3 para acceder a los objetos - Un Interface Endpoint usa una dirección IP privada y sigue generando costos por el tiempo en que la interfaz está activa y por la cantidad de datos procesados. Para S3, la opción más rentable es un Gateway Endpoint, ya que no tiene costos adicionales asociados.\n\nReferencias:\n\nhttps://aws.amazon.com/blogs/architecture/reduce-cost-and-increase-security-with-amazon-vpc-endpoints/\n\nhttps://aws.amazon.com/vpc/pricing/"
  },
  {
    "q": "Una empresa de medios digitales ha desplegado una plataforma de streaming que almacena archivos multimedia (videos, imágenes y podcasts) en un bucket de Amazon Simple Storage Service (S3).\nEl arquitecto de soluciones anticipa que el bucket recibirá más de 7000 solicitudes PUT por segundo y 10000 solicitudes GET por segundo durante los lanzamientos de nuevos contenidos. ¿Qué debe hacer el arquitecto de soluciones para asegurar un rendimiento óptimo del bucket?",
    "o": [
      "Usar Byte-Range Fetches para recuperar múltiples rangos de un objeto por solicitud GET",
      "No hacer nada. Amazon S3 gestionará automáticamente el rendimiento a esta escala",
      "Usar un esquema de nombres predecible en las claves, como números secuenciales o secuencias de fecha y hora",
      "Agregar un prefijo aleatorio a los nombres de las claves"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nNo hacer nada. Amazon S3 gestionará automáticamente el rendimiento a esta escala - Amazon S3 está diseñado para escalar automáticamente y manejar cargas muy altas sin necesidad de configuración manual. Actualmente, S3 admite al menos 3500 solicitudes por segundo para operaciones PUT y 5500 solicitudes por segundo para operaciones GET por cada prefijo de objeto, permitiendo escalar eficientemente sin intervención del usuario.\n\n\n\nOpciones incorrectas:\n\nUsar un esquema de nombres predecible en las claves, como números secuenciales o secuencias de fecha y hora - Utilizar nombres de claves con patrones predecibles puede concentrar las solicitudes en una sola partición, lo cual ya no es una preocupación con las mejoras en la arquitectura de S3, pero tampoco mejora el rendimiento.\n\nAgregar un prefijo aleatorio a los nombres de las claves - Anteriormente se recomendaba añadir prefijos aleatorios para distribuir la carga entre particiones. Sin embargo, Amazon S3 ya optimiza automáticamente la distribución sin requerir ese tipo de prácticas.\n\nUsar Byte-Range Fetches para recuperar múltiples rangos de un objeto por solicitud GET - Byte-Range Fetches es útil para mejorar el rendimiento al descargar grandes objetos por partes, pero no afecta la capacidad de procesamiento global de S3 ni ayuda a manejar un gran volumen de solicitudes PUT o GET.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/request-rate-perf-considerations.html\n\nhttps://d1.awsstatic.com/whitepapers/AmazonS3BestPractices.pdf\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/GettingObjectsUsingAPIs.html"
  },
  {
    "q": "Una institución académica tiene instancias EC2 para sus entornos de laboratorio de estudiantes y para su sistema administrativo interno en AWS. Desean garantizar que los asistentes de laboratorio, encargados de las instancias del entorno estudiantil, no tengan acceso a las instancias del sistema administrativo para reducir los riesgos de seguridad.\n¿Cuál de las siguientes opciones sería la mejor manera de lograr esto?",
    "o": [
      "Lanzar las instancias del laboratorio y del sistema administrativo en diferentes zonas de disponibilidad y usar Autenticación Multifactor",
      "Proporcionar permisos a los usuarios mediante AWS Resource Access Manager (RAM) para acceder solo a instancias EC2 utilizadas para enseñanza",
      "Lanzar las instancias EC2 del laboratorio y del sistema administrativo en VPCs separadas conectadas mediante VPC Peering",
      "Definir etiquetas en los servidores del laboratorio y del sistema administrativo, y agregar una condición a la política de IAM que permita acceso basado en etiquetas específicas"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nDefinir etiquetas en los servidores del laboratorio y del sistema administrativo, y agregar una condición a la política de IAM que permita acceso basado en etiquetas específicas - La mejor manera de restringir el acceso a las instancias EC2 de sistemas sensibles es utilizar una combinación de etiquetas (tags) y políticas de IAM. Puedes etiquetar las instancias de los diferentes entornos con valores específicos y luego configurar una política de IAM que permita o restrinja el acceso según esas etiquetas. Esto garantiza que solo los usuarios adecuados puedan acceder a las instancias correctas.\n\nOpciones incorrectas:\n\nLanzar las instancias del laboratorio y del sistema administrativo en diferentes zonas de disponibilidad y usar Autenticación Multifactor - Lanzar las instancias en diferentes zonas de disponibilidad mejora la disponibilidad, pero no tiene impacto en la seguridad del acceso. Además, la Autenticación Multifactor (MFA) no es una solución adecuada para restringir el acceso a instancias específicas.\n\nProporcionar permisos a los usuarios mediante AWS Resource Access Manager (RAM) para acceder solo a instancias EC2 utilizadas para enseñanza - AWS Resource Access Manager (RAM) se utiliza principalmente para compartir recursos entre cuentas de AWS dentro de una organización. No es la mejor opción para restringir el acceso a instancias EC2 dentro de una misma cuenta.\n\nLanzar las instancias EC2 del laboratorio y del sistema administrativo en VPCs separadas conectadas mediante VPC Peering - Separar las instancias en diferentes VPCs y conectarlas con VPC Peering solo cambia la arquitectura de red, pero no evita que los usuarios accedan a las instancias sensibles si tienen los permisos adecuados.\n\nReferencias:\n\nhttp://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Using_Tags.html\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-policies-for-amazon-ec2.html"
  },
  {
    "q": "Una empresa está planeando usar Amazon S3 para almacenar documentos cargados por sus clientes. Las imágenes deben estar cifradas en reposo en Amazon S3. La empresa no quiere pasar tiempo administrando y rotando las claves, pero sí quiere controlar quién puede acceder a esas claves.\n¿Qué debe usar un arquitecto de soluciones para lograr esto?",
    "o": [
      "Cifrado del lado del servidor con claves administradas por Amazon S3 (SSE-S3)",
      "Cifrado del lado del servidor con claves proporcionadas por el cliente (SSE-C)",
      "Cifrado del lado del servidor con claves administradas por AWS KMS (SSE-KMS)",
      "Cifrado del lado del servidor con claves almacenadas en un bucket S3"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nCifrado del lado del servidor con claves administradas por AWS KMS (SSE-KMS) - SSE-KMS requiere que AWS administre la clave de datos, pero usted administra la clave maestra de cliente (CMK) en AWS KMS. Puede elegir una CMK administrada por el cliente o la CMK administrada por AWS para Amazon S3 en su cuenta.\n\nLas CMK administradas por el cliente son CMK en su cuenta de AWS que crea, posee y administra. Tiene control total sobre estas CMK, incluyendo establecer y mantener sus políticas de claves, políticas IAM y grants, habilitarlas y deshabilitarlas, rotar su material criptográfico, agregar etiquetas, crear alias que se refieran a la CMK y programar las CMK para eliminación.\n\nPara este escenario, el arquitecto de soluciones debe usar SSE-KMS con una CMK administrada por el cliente. De esa manera, KMS administrará la clave de datos, pero la empresa puede configurar políticas de claves que definan quién puede acceder a las claves.\n\nOpciones incorrectas:\n\nCifrado del lado del servidor con claves proporcionadas por el cliente (SSE-C) - La empresa no quiere administrar las claves.\n\nCifrado del lado del servidor con claves almacenadas en un bucket S3 - No se pueden almacenar sus claves en un bucket con cifrado del lado del servidor.\n\nCifrado del lado del servidor con claves administradas por Amazon S3 (SSE-S3) - La empresa necesita gestionar el control de acceso para las claves, lo cual no es posible cuando están administradas por Amazon.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/kms/latest/developerguide/services-s3.html#sse\n\nhttps://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#master_keys"
  },
  {
    "q": "Una aplicación está alojada en una instancia de EC2 con múltiples volúmenes EBS adjuntos y usa Amazon Neptune como base de datos. Para mejorar la seguridad de los datos, se cifraron todos los volúmenes EBS adjuntos a la instancia para proteger la información confidencial almacenada en ellos.\n¿Cuáles de las siguientes afirmaciones son verdaderas sobre los volúmenes de Amazon Elastic Block Store (EBS) cifrados? (Selecciona DOS)",
    "o": [
      "Los volúmenes creados a partir de una instantánea cifrada no están cifrados",
      "Las instantáneas no se cifran automáticamente",
      "Solo los datos dentro del volumen están cifrados y no todos los datos que se mueven entre el volumen y la instancia",
      "Todos los datos que se mueven entre el volumen y la instancia están cifrados",
      "Las instantáneas se cifran automáticamente"
    ],
    "a": [
      3,
      4
    ],
    "e": "Correcto:\n\nLas instantáneas se cifran automáticamente - Cuando se crea una instantánea de un volumen EBS cifrado, la instantánea también se cifra automáticamente utilizando la misma clave de cifrado del volumen de origen. Esto garantiza la seguridad de los datos almacenados en la instantánea.\n\nTodos los datos que se mueven entre el volumen y la instancia están cifrados - Amazon EBS cifra no solo los datos en reposo dentro del volumen, sino también todos los datos en tránsito entre la instancia EC2 y el volumen EBS adjunto. Esto protege la información tanto en almacenamiento como en transmisión.\n\n\n\nOpciones incorrectas:\n\nSolo los datos dentro del volumen están cifrados y no todos los datos que se mueven entre el volumen y la instancia - El cifrado de EBS protege tanto los datos en reposo dentro del volumen como los datos en tránsito entre el volumen y la instancia EC2.\n\nLas instantáneas no se cifran automáticamente - Las instantáneas de volúmenes EBS cifrados se cifran automáticamente utilizando la misma clave de cifrado del volumen de origen.\n\nLos volúmenes creados a partir de una instantánea cifrada no están cifrados - Los volúmenes creados a partir de instantáneas cifradas también están cifrados automáticamente. Se usa la misma clave de cifrado que se utilizó para la instantánea de origen.\n\nReferencias:\n\nhttp://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AmazonEBS.html\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html"
  },
  {
    "q": "Un arquitecto en la nube está evaluando la resistencia de una aplicación web desplegada en AWS. Se observó que la aplicación experimentó un tiempo de inactividad de aproximadamente 3 minutos cuando se realizó una conmutación por error programada en la base de datos Amazon RDS MySQL de la aplicación como parte de una operación de escalado.\nLa organización quiere mitigar tal tiempo de inactividad en futuros ejercicios de escalado mientras minimiza la sobrecarga operativa.\n¿Qué solución será más efectiva para lograr esto?",
    "o": [
      "Establecer un clúster secundario de RDS MySQL dentro de la misma Región de AWS. Durante cualquier conmutación por error futura, modificar la aplicación para conectarse al endpoint de escritura del clúster secundario.",
      "Implementar más réplicas de lectura de RDS MySQL en el clúster para gestionar la carga durante la conmutación por error.",
      "Configurar un Amazon RDS Proxy para la base de datos y modificar la aplicación para conectarse al endpoint del proxy.",
      "Implementar un clúster de Amazon ElastiCache para Redis para gestionar la carga durante la conmutación por error."
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nConfigurar un Amazon RDS Proxy para la base de datos y modificar la aplicación para conectarse al endpoint del proxy. - Amazon RDS Proxy es un proxy de base de datos completamente administrado y altamente disponible para Amazon RDS que hace que las aplicaciones sean más escalables, más resistentes a fallos de base de datos y más seguras.\n\nDurante una conmutación por error, RDS Proxy se conecta automáticamente a una instancia de base de datos en espera mientras preserva las conexiones de su aplicación y reduce los tiempos de conmutación por error para bases de datos RDS y Aurora multi-AZ. Por lo tanto, hay un tiempo de inactividad mínimo para la aplicación.\n\nOpciones incorrectas:\n\nImplementar más réplicas de lectura de RDS MySQL en el clúster para gestionar la carga durante la conmutación por error. - Agregar más réplicas de lectura al clúster no disminuye el tiempo de inactividad durante una conmutación por error. Solo mejora la capacidad de la base de datos para manejar cargas de trabajo intensivas en lectura. Las réplicas de lectura no contribuyen a un proceso de conmutación por error más rápido.\n\nEstablecer un clúster secundario de RDS MySQL dentro de la misma Región de AWS. Durante cualquier conmutación por error futura, modificar la aplicación para conectarse al endpoint de escritura del clúster secundario. - Este enfoque es operativamente pesado ya que implica administrar dos clústeres RDS separados y actualizar manualmente el endpoint de base de datos de la aplicación durante una conmutación por error. Además, no necesariamente reduce el tiempo de inactividad durante una conmutación por error ya que podría haber problemas de inconsistencia de datos entre los clústeres primario y secundario, dependiendo de la latencia de replicación.\n\nImplementar un clúster de Amazon ElastiCache para Redis para gestionar la carga durante la conmutación por error. - ElastiCache es una caché en memoria y no un servicio de base de datos relacional. Típicamente se usa para almacenar en caché datos accedidos frecuentemente para reducir la latencia y mejorar el rendimiento de la aplicación, no para gestionar conmutaciones por error.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-proxy.html\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html"
  },
  {
    "q": "Una empresa necesita acelerar el rendimiento de su aplicación de diagnóstico médico con inteligencia artificial, ejecutando cargas de trabajo de machine learning en el borde de redes 5G de operadores de telecomunicaciones.\nLa aplicación debe desplegarse en un clúster de Kubernetes y requerir control de acceso basado en roles (RBAC) con IAM para usuarios y roles de clúster.\n¿Cuál de las siguientes soluciones debería implementar el arquitecto de soluciones para garantizar una latencia de milisegundos de un solo dígito para la aplicación?",
    "o": [
      "Lanzar la aplicación en un clúster de Amazon Elastic Kubernetes Service (Amazon EKS). Crear endpoints de VPC para las Wavelength Zones y aplicarlos al clúster de Amazon EKS. Instalar AWS IAM Authenticator para Kubernetes (aws-iam-authenticator) en el clúster",
      "Alojar la aplicación en un clúster de Amazon Elastic Kubernetes Service (Amazon EKS). Configurar grupos de nodos en Wavelength Zones para el clúster de Amazon EKS. Adjuntar el rol de agente conector de Amazon ECS (AmazonECSConnectorAgentRole) al clúster y usar AWS Control Tower para RBAC",
      "Alojar la aplicación en un clúster de Amazon EKS y ejecutar los pods de Kubernetes en AWS Fargate. Crear grupos de nodos en Wavelength Zones para el clúster de Amazon EKS. Agregar la política de IAM de ejecución de pods de EKS (AmazonEKSFargatePodExecutionRole) al clúster y asegurarse de que el perfil de Fargate tenga el mismo rol de IAM que los grupos de nodos EC2",
      "Lanzar la aplicación en un clúster de Amazon Elastic Kubernetes Service (Amazon EKS). Crear grupos de nodos en Wavelength Zones para el clúster de Amazon EKS a través del servicio AWS Wavelength. Aplicar el mapa de configuración del autenticador de AWS (aws-auth ConfigMap) al clúster"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nLanzar la aplicación en un clúster de Amazon Elastic Kubernetes Service (Amazon EKS). Crear grupos de nodos en Wavelength Zones para el clúster de Amazon EKS a través del servicio AWS Wavelength. Aplicar el mapa de configuración del autenticador de AWS (aws-auth ConfigMap) al clúster - AWS Wavelength combina la alta velocidad y baja latencia de redes 5G con los servicios de cómputo y almacenamiento de AWS. Las Wavelength Zones son implementaciones de infraestructura de AWS dentro de los centros de datos de los proveedores de telecomunicaciones, ubicados en el borde de la red 5G.\n\nAl ejecutar la aplicación en un clúster de Amazon EKS dentro de Wavelength Zones, se evita la latencia que generaría el tráfico de la aplicación al salir de la red del proveedor móvil. Además, para manejar la autenticación de usuarios y roles en Kubernetes, se debe aplicar el mapa de configuración del autenticador de AWS (aws-auth ConfigMap), que habilita el control de acceso basado en roles (RBAC).\n\nOpciones incorrectas:\n\nAlojar la aplicación en un clúster de Amazon EKS y ejecutar los pods de Kubernetes en AWS Fargate. Crear grupos de nodos en Wavelength Zones para el clúster de Amazon EKS. Agregar la política de IAM de ejecución de pods de EKS (AmazonEKSFargatePodExecutionRole) al clúster y asegurarse de que el perfil de Fargate tenga el mismo rol de IAM que los grupos de nodos EC2 - El rol de ejecución de pods en Fargate (AmazonEKSFargatePodExecutionRole) no debe compartir el mismo rol IAM que los grupos de nodos EC2. Fargate y EC2 deben tener roles separados con permisos específicos.\n\nAlojar la aplicación en un clúster de Amazon Elastic Kubernetes Service (Amazon EKS). Configurar grupos de nodos en Wavelength Zones para el clúster de Amazon EKS. Adjuntar el rol de agente conector de Amazon ECS (AmazonECSConnectorAgentRole) al clúster y usar AWS Control Tower para RBAC - El rol de agente conector de Amazon ECS (AmazonECSConnectorAgentRole) se usa para conectar clústeres Kubernetes alojados externamente a AWS, lo cual no es relevante en este caso.\n\nLanzar la aplicación en un clúster de Amazon Elastic Kubernetes Service (Amazon EKS). Crear endpoints de VPC para las Wavelength Zones y aplicarlos al clúster de Amazon EKS. Instalar AWS IAM Authenticator para Kubernetes (aws-iam-authenticator) en el clúster - No se pueden crear VPC Endpoints en Wavelength Zones, ya que estas funcionan de manera diferente a las zonas de disponibilidad regulares. Además, el uso recomendado para la autenticación RBAC en EKS es aplicar el aws-auth ConfigMap, en lugar de instalar manualmente AWS IAM Authenticator.\n\nReferencias:\n\nhttps://aws.amazon.com/wavelength/\n\nhttps://docs.aws.amazon.com/eks/latest/userguide/add-user-role.html#aws-auth-configmap\n\nhttps://docs.aws.amazon.com/eks/latest/userguide/cluster-auth.html"
  },
  {
    "q": "Un arquitecto de soluciones se unió a una gran empresa de tecnología con una Amazon VPC existente. Al revisar los eventos de Auto Scaling, el arquitecto notó que su aplicación web se escala hacia arriba y hacia abajo varias veces dentro de una hora.\n¿Qué cambio de diseño podría hacer el arquitecto para optimizar costos mientras mantiene la elasticidad?",
    "o": [
      "Aumentar el número base de instancias de Auto Scaling en el grupo de Auto Scaling",
      "Agregar IOPS provisionados a las instancias",
      "Actualizar el tipo de instancia en la plantilla de lanzamiento",
      "Modificar el período de cooldown del grupo de Auto Scaling y establecer el umbral de la métrica de CloudWatch en un valor más alto"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nModificar el período de cooldown del grupo de Auto Scaling y establecer el umbral de la métrica de CloudWatch en un valor más alto - El período de cooldown es una configuración del grupo de Auto Scaling que evita que se lancen o terminen instancias adicionales antes de que finalicen las actividades de escalado anteriores. Después de que el grupo de Auto Scaling se escala dinámicamente usando una política de escalado simple, espera a que se complete el período de cooldown antes de reanudar las actividades de escalado. Ajustar el período de cooldown y establecer un umbral más alto para la métrica de CloudWatch ayuda a reducir la frecuencia de escalado, optimizando costos sin comprometer la elasticidad.\n\nOpciones incorrectas:\n\nAgregar IOPS provisionados a las instancias - Agregar IOPS provisionados a las instancias solo mejora el rendimiento de entrada/salida en bases de datos o almacenamiento, pero no aborda el problema del escalado frecuente. Además, los IOPS provisionados tienen costos adicionales, lo que podría aumentar en lugar de optimizar los costos.\n\nAumentar el número base de instancias de Auto Scaling en el grupo de Auto Scaling - Aumentar el número base de instancias en el grupo de Auto Scaling significa que habrá más instancias ejecutándose en todo momento, incluso cuando la demanda sea baja. Esto puede generar costos innecesarios y contradice el objetivo de optimización de costos.\n\nActualizar el tipo de instancia en la plantilla de lanzamiento - Actualizar el tipo de instancia en la plantilla de lanzamiento podría resultar en costos más altos sin abordar directamente el problema del escalado frecuente. El problema radica en la configuración de Auto Scaling y no en la capacidad de las instancias.\n\nReferencia:\n\nhttp://docs.aws.amazon.com/autoscaling/latest/userguide/as-scale-based-on-demand.html"
  },
  {
    "q": "Hay lectores de tarjetas ubicados en cada entrada de los almacenes de una organización. Se envía un mensaje sobre HTTPS cuando se escanean las tarjetas para indicar quién intentó acceder a la entrada.\nUn arquitecto de soluciones debe diseñar un sistema para procesar estos mensajes. Se requiere una solución altamente disponible. La solución debe almacenar los resultados en un almacén de datos duradero para análisis posterior.\n¿Qué arquitectura de sistema debe recomendar el arquitecto de soluciones?",
    "o": [
      "Dirigir mensajes entrantes del sensor a una función de AWS Lambda usando Amazon Route 53. Crear una función Lambda que procese mensajes y guarde resultados en Amazon DynamoDB.",
      "Crear una instancia de Amazon EC2 para servir como endpoint HTTPS y procesar mensajes. Se debe configurar un bucket de Amazon S3 para la instancia EC2 para guardar los resultados.",
      "Configurar un endpoint HTTPS en Amazon API Gateway. Para procesar los mensajes y guardar los resultados en Amazon DynamoDB, configurar un endpoint de API Gateway para invocar una función de AWS Lambda.",
      "Configurar un endpoint de gateway de Amazon S3 en tu VPC. Conectar la red de la instalación a la VPC mediante una conexión VPN Site-to-Site para que los datos del sensor puedan escribirse directamente a un bucket S3."
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nConfigurar un endpoint HTTPS en Amazon API Gateway. Para procesar los mensajes y guardar los resultados en Amazon DynamoDB, configurar un endpoint de API Gateway para invocar una función de AWS Lambda. - Amazon API Gateway sería ideal para proporcionar un punto de entrada seguro para tu aplicación y para que el tráfico se envíe vía HTTPS. AWS Lambda se integraría perfectamente con API Gateway para procesar los datos, ya que una solución basada en eventos como esta sería perfecta al diseñar un sistema escalable basado en uso esporádico. Finalmente, DynamoDB es altamente escalable y es un repositorio perfecto para que los datos se almacenen para análisis futuro.\n\nOpciones incorrectas:\n\nConfigurar un endpoint de gateway de Amazon S3 en tu VPC. Conectar la red de la instalación a la VPC mediante una conexión VPN Site-to-Site para que los datos del sensor puedan escribirse directamente a un bucket S3. - Los endpoints de VPC están diseñados para facilitar el tráfico a través de la red troncal de AWS entre servicios de AWS y no se usan para crear conexiones entre endpoints externos fuera de la red de AWS y un bucket de Amazon S3.\n\nCrear una instancia de Amazon EC2 para servir como endpoint HTTPS y procesar mensajes. Se debe configurar un bucket de Amazon S3 para la instancia EC2 para guardar los resultados. - Como la acción de leer una tarjeta para iniciar el acceso a un almacén debería tomar solo unos segundos, iniciar una instancia EC2 para servir como endpoint HTTPS tomaría minutos y no es adecuado para este caso de uso.\n\nDirigir mensajes entrantes del sensor a una función de AWS Lambda usando Amazon Route 53. Crear una función Lambda que procese mensajes y guarde resultados en Amazon DynamoDB. - Amazon Route 53 es un servicio DNS administrado, y DNS no es requerido en este caso ya que el lector de tarjetas no tiene un nombre DNS.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/lambda/latest/dg/services-apigateway.html"
  },
  {
    "q": "Una empresa del sector retail que opera una plataforma de comercio electrónico basada en Microsoft SQL Server on-premises está reestructurando su estrategia de recuperación ante desastres (DR). El equipo de TI ha determinado que la solución en la nube debe permitir un Recovery Point Objective (RPO) de máximo 60 segundos y un Recovery Time Objective (RTO) no mayor a 1 hora, para asegurar la continuidad del negocio en caso de fallas críticas.\nEl objetivo es lograr estos tiempos sin incurrir en altos costos operativos, priorizando una solución que sea automatizada, rentable y fácil de mantener.\n¿Cuál de las siguientes alternativas representa la opción más rentable para cumplir con estos objetivos de RPO y RTO?",
    "o": [
      "Configurar una instancia warm standby en Amazon RDS para SQL Server sincronizada con la base de datos on-premises mediante AWS DMS con Change Data Capture (CDC)",
      "Utilizar AWS Storage Gateway para respaldar la base de datos y habilitar restauración de snapshots sobre Amazon EBS en caso de desastre",
      "Adoptar una arquitectura pilot light con AWS Elastic Disaster Recovery (AWS DRS) para replicación continua de los servidores SQL desde on-premises hacia AWS",
      "Implementar Microsoft SQL Server Enterprise en configuración Always On con replicación activa entre AWS y el entorno on-premises"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nAdoptar una arquitectura pilot light con AWS Elastic Disaster Recovery (AWS DRS) para replicación continua de los servidores SQL desde on-premises hacia AWS - Es ideal para este tipo de escenarios, ya que proporciona replicación a nivel de bloque casi en tiempo real, permitiendo un RPO bajo y tiempos de conmutación por error (failover) rápidos. Al utilizar una arquitectura tipo pilot light, los recursos en AWS solo se activan en caso de desastre, lo cual reduce significativamente los costos operativos al no mantener servidores activos todo el tiempo.\n\n\n\nOpciones incorrectas:\n\nConfigurar una instancia warm standby en Amazon RDS para SQL Server sincronizada con la base de datos on-premises mediante AWS DMS con Change Data Capture (CDC) - Aunque cumple con los requisitos de RPO/RTO, mantener una instancia activa de RDS genera costos constantes, lo que la hace menos rentable que AWS DRS.\n\nUtilizar AWS Storage Gateway para respaldar la base de datos y habilitar restauración de snapshots sobre Amazon EBS en caso de desastre - Está más orientado al respaldo y archivo. El proceso de restauración ante fallos es manual y conlleva un RTO más alto que lo permitido por el escenario.\n\nImplementar Microsoft SQL Server Enterprise en configuración Always On con replicación activa entre AWS y el entorno on-premises - Es una solución robusta, pero muy costosa y compleja de implementar en un entorno híbrido. Supera los costos aceptables para una estrategia rentable de DR.\n\nReferencias:\n\nhttps://aws.amazon.com/disaster-recovery/\n\nhttps://docs.aws.amazon.com/drs/latest/userguide/\n\nhttps://docs.aws.amazon.com/prescriptive-guidance/latest/backup-recovery/on-prem-dr-to-aws.html"
  },
  {
    "q": "Una empresa de logística internacional llamada StellartLogistics tiene aplicaciones web ejecutándose en AWS en la región us-west-2 y servidores de base de datos en la región eu-central-1. Las aplicaciones ejecutándose en una VPC en us-west-2 necesitan comunicarse de forma segura con las bases de datos ejecutándose en una VPC en eu-central-1.\n¿Qué diseño de red cumplirá estos requisitos?",
    "o": [
      "Establecer una conexión de VPC peering entre la VPC de us-west-2 y la VPC de eu-central-1. Modificar las tablas de enrutamiento de subred en consecuencia. Crear una regla entrante en el grupo de seguridad de la base de datos de eu-central-1 que haga referencia al ID del grupo de seguridad de los servidores de aplicación en us-west-2.",
      "Establecer un transit gateway con un attachment de peering entre la VPC de us-west-2 y la VPC de eu-central-1. Después de que los transit gateways estén correctamente emparejados y el enrutamiento esté configurado, crear una regla entrante en el grupo de seguridad de la base de datos de eu-central-1 que haga referencia al ID del grupo de seguridad de los servidores de aplicación en us-west-2.",
      "Crear una conexión de VPC peering entre la VPC de us-west-2 y la VPC de eu-central-1. Agregar las rutas apropiadas a las tablas de enrutamiento de subred. Crear una regla entrante en el grupo de seguridad de la aplicación de us-west-2 que permita tráfico desde las direcciones IP de los servidores de base de datos de eu-central-1.",
      "Configurar una conexión de VPC peering entre la VPC de us-west-2 y la VPC de eu-central-1. Actualizar las tablas de enrutamiento de subred en consecuencia. Crear una regla entrante en el grupo de seguridad de la base de datos de eu-central-1 que permita tráfico desde las direcciones IP de los servidores de aplicación de us-west-2."
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nConfigurar una conexión de VPC peering entre la VPC de us-west-2 y la VPC de eu-central-1. Actualizar las tablas de enrutamiento de subred en consecuencia. Crear una regla entrante en el grupo de seguridad de la base de datos de eu-central-1 que permita tráfico desde las direcciones IP de los servidores de aplicación de us-west-2. - La solución correcta establece una conexión de VPC peering entre las dos regiones, y configura correctamente la regla entrante en el grupo de seguridad de la base de datos de eu-central-1 para permitir tráfico desde las direcciones IP de los servidores de aplicación de us-west-2, que es la forma correcta de configurar esto ya que los grupos de seguridad no pueden ser referenciados entre regiones.\n\nOpciones incorrectas:\n\nEstablecer un transit gateway con un attachment de peering entre la VPC de us-west-2 y la VPC de eu-central-1. Después de que los transit gateways estén correctamente emparejados y el enrutamiento esté configurado, crear una regla entrante en el grupo de seguridad de la base de datos de eu-central-1 que haga referencia al ID del grupo de seguridad de los servidores de aplicación en us-west-2. - No puedes hacer referencia a un grupo de seguridad de otra región. Los grupos de seguridad son específicos de región y solo pueden ser referenciados dentro de la misma región.\n\nCrear una conexión de VPC peering entre la VPC de us-west-2 y la VPC de eu-central-1. Agregar las rutas apropiadas a las tablas de enrutamiento de subred. Crear una regla entrante en el grupo de seguridad de la aplicación de us-west-2 que permita tráfico desde las direcciones IP de los servidores de base de datos de eu-central-1. - En este escenario, queremos permitir tráfico desde los servidores de aplicación en us-west-2 hacia los servidores de base de datos en eu-central-1. La regla entrante debe configurarse en el grupo de seguridad de la base de datos de eu-central-1 para permitir este tráfico.\n\nEstablecer una conexión de VPC peering entre la VPC de us-west-2 y la VPC de eu-central-1. Modificar las tablas de enrutamiento de subred en consecuencia. Crear una regla entrante en el grupo de seguridad de la base de datos de eu-central-1 que haga referencia al ID del grupo de seguridad de los servidores de aplicación en us-west-2. - No puedes hacer referencia a un grupo de seguridad de otra región. Los grupos de seguridad son específicos de región y solo pueden ser referenciados dentro de la misma región.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/vpc/latest/peering/vpc-peering-security-groups.html"
  },
  {
    "q": "Una empresa de servicios financieros gestiona una plataforma de análisis de datos donde cientos de archivos JSON son cargados por hora en un bucket de Amazon S3. Estos archivos están catalogados mediante AWS Lake Formation y posteriormente son consultados por analistas mediante Amazon Athena para obtener insights de negocio. Sin embargo, el equipo ha reportado que las consultas toman un tiempo considerable en completarse debido al volumen creciente de datos.\n¿Qué enfoque debería adoptarse para optimizar el rendimiento de las consultas en Athena sin comprometer la seguridad ni el control de acceso a los datos?",
    "o": [
      "Transformar los archivos JSON al formato columnar Apache Parquet. Asegurarse de que los usuarios cuenten con el permiso IAM lakeformation:GetDataAccess para acceder a los datos protegidos",
      "Aplicar compresión GZIP sobre los archivos JSON antes de almacenarlos en S3. Utilizar políticas IAM con condiciones aws:SourceArn y aws:SourceAccount para proteger contra el ataque de confused deputy",
      "Reducir el tamaño de los archivos mediante minificación de JSON y usar control de acceso basado en etiquetas (LF-TBAC) en Lake Formation para mantener la seguridad",
      "Convertir los archivos JSON a formato CSV. Aplicar políticas detalladas de control de acceso a nivel de tabla y base de datos usando Lake Formation"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nTransformar los archivos JSON al formato columnar Apache Parquet. Asegurarse de que los usuarios cuenten con el permiso IAM lakeformation:GetDataAccess para acceder a los datos protegidos - El formato Apache Parquet es un formato de almacenamiento columnar que permite una lectura más eficiente por parte de Amazon Athena, ya que permite escanear solo las columnas requeridas por cada consulta. Esto reduce drásticamente la cantidad de datos leídos, mejorando el tiempo de respuesta y disminuyendo los costos de ejecución. Además, es fundamental garantizar que los analistas tengan el permiso lakeformation:GetDataAccess para poder acceder a los datos almacenados y catalogados mediante AWS Lake Formation, sin comprometer la seguridad del entorno.\n\n\n\nOpciones incorrectas:\n\nConvertir los archivos JSON a formato CSV. Aplicar políticas detalladas de control de acceso a nivel de tabla y base de datos usando Lake Formation - Aunque CSV es un formato comúnmente utilizado, no es eficiente para grandes volúmenes de datos. Athena ejecuta consultas más rápido sobre formatos columnares como Parquet u ORC en comparación con CSV, que es un formato basado en filas.\n\nAplicar compresión GZIP sobre los archivos JSON antes de almacenarlos en S3. Utilizar políticas IAM con condiciones aws:SourceArn y aws:SourceAccount para proteger contra el ataque de confused deputy - Comprimir archivos con GZIP ayuda a reducir el almacenamiento, pero no mejora sustancialmente el rendimiento de las consultas en Athena. Las claves de contexto IAM mencionadas son más relevantes para servicios como AWS Lambda o AWS Step Functions al invocar otros recursos.\n\nReducir el tamaño de los archivos mediante minificación de JSON y usar control de acceso basado en etiquetas (LF-TBAC) en Lake Formation para mantener la seguridad - La minificación de JSON solo reduce el tamaño del archivo superficialmente y no impacta de manera significativa el rendimiento de las consultas. Además, aunque LF-TBAC es útil para ciertos escenarios de control de acceso basado en atributos, no sustituye la optimización necesaria en el formato de almacenamiento para lograr un rendimiento óptimo.\n\nReferencias:\n\nhttps://aws.amazon.com/blogs/big-data/top-10-performance-tuning-tips-for-amazon-athena/\n\nhttps://docs.aws.amazon.com/lake-formation/latest/dg/access-control-underlying-data.html\n\nhttps://docs.aws.amazon.com/lake-formation/latest/dg/TBAC-overview.html"
  },
  {
    "q": "Una startup dedicada al monitoreo de dispositivos IoT ha desarrollado una plataforma que recopila y analiza métricas de sensores en tiempo real utilizando Amazon Kinesis Data Streams y funciones AWS Lambda para el procesamiento de eventos. Tras la primera semana en producción, los ingenieros notaron un incremento constante en la latencia del sistema conforme aumentaba el volumen de datos provenientes de los dispositivos.\nDespués de investigar, el equipo técnico determinó que el cuello de botella está directamente relacionado con la capacidad de procesamiento del stream de Kinesis.\n¿Cuál sería la mejor estrategia para mejorar el rendimiento del sistema bajo cargas crecientes de datos?",
    "o": [
      "Aumentar la cantidad de shards en el stream de Kinesis utilizando el comando UpdateShardCount",
      "Migrar la solución a Amazon Kinesis Data Firehose para beneficiarse de su arquitectura gestionada",
      "Reducir el número de shards existentes con el comando MergeShard para simplificar la estructura del stream",
      "Aplicar Step Scaling en el flujo de datos de Kinesis para adaptarse automáticamente a la carga"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nAumentar la cantidad de shards en el stream de Kinesis utilizando el comando UpdateShardCount - A medida que crece la tasa de ingesta de datos, es esencial aumentar la capacidad de Kinesis Data Streams para mantener el rendimiento. Esto se consigue añadiendo más shards con el comando UpdateShardCount, lo que mejora tanto el throughput de escritura como de lectura. Esta operación es dinámica y no requiere detener el stream.\n\n\n\nOpciones incorrectas:\n\nAplicar Step Scaling en el flujo de datos de Kinesis para adaptarse automáticamente a la carga - Es una política utilizada en Auto Scaling Groups para instancias EC2, no aplica a servicios administrados como Kinesis Data Streams.\n\nReducir el número de shards existentes con el comando MergeShard para simplificar la estructura del stream - Podría ayudar y disminuiría la capacidad de particionado y procesamiento del stream, lo cual agravaría el problema de rendimiento.\n\nMigrar la solución a Amazon Kinesis Data Firehose para beneficiarse de su arquitectura gestionada - Aunque es útil para la entrega continua de datos, no proporciona el mismo nivel de control, latencia baja ni procesamiento en tiempo real requerido en esta arquitectura basada en Lambda.\n\nReferencias:\n\nhttps://aws.amazon.com/blogs/big-data/scale-your-amazon-kinesis-stream-capacity-with-updateshardcount/\n\nhttps://aws.amazon.com/kinesis/data-streams/faqs/\n\nhttps://docs.aws.amazon.com/streams/latest/dev/kinesis-using-sdk-java-resharding.html"
  },
  {
    "q": "Una institución financiera quiere usar algoritmos de aprendizaje automático (ML) para detectar transacciones potencialmente fraudulentas. Necesitan crear modelos ML basados en sus vastos datos de transacciones financieras e integrar estos modelos en su sistema de inteligencia empresarial para toma de decisiones en tiempo real. La solución debe requerir una sobrecarga operativa mínima.\n¿Qué solución cumplirá mejor estos requisitos?",
    "o": [
      "Usar AWS Glue para realizar trabajos ETL en los datos de transacciones y usar Amazon Forecast para análisis predictivo.",
      "Usar una Amazon Machine Image (AMI) de ML preconstruida del AWS Marketplace para construir y entrenar modelos y usar AWS Athena para visualización de datos.",
      "Usar Amazon Comprehend para analizar los datos de transacciones y Amazon Elasticsearch para visualización.",
      "Usar Amazon SageMaker para construir, entrenar y desplegar modelos ML, y usar Amazon QuickSight para visualización de datos."
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nUsar Amazon SageMaker para construir, entrenar y desplegar modelos ML, y usar Amazon QuickSight para visualización de datos. - Amazon SageMaker es un servicio completamente administrado que proporciona a cada desarrollador y científico de datos la capacidad de construir, entrenar y desplegar modelos de aprendizaje automático rápidamente. Puede conectarse directamente con fuentes de datos y tiene algoritmos incorporados para facilitar el proceso de ML.\n\nAmazon QuickSight es una herramienta de inteligencia empresarial que puede usarse para crear paneles para visualización de datos. Esta combinación se ajusta perfectamente al requisito.\n\nOpciones incorrectas:\n\nUsar una Amazon Machine Image (AMI) de ML preconstruida del AWS Marketplace para construir y entrenar modelos y usar AWS Athena para visualización de datos. - Las AMI de ML del AWS Marketplace pueden usarse para crear y entrenar modelos, pero esto requerirá esfuerzo operativo manual en términos de configuración y gestión de las instancias. Athena es un servicio de consulta y no proporciona capacidades de visualización de datos que una herramienta de inteligencia empresarial como QuickSight proporciona.\n\nUsar Amazon Comprehend para analizar los datos de transacciones y Amazon Elasticsearch para visualización. - Amazon Comprehend se usa principalmente para procesamiento de lenguaje natural (NLP), que no es adecuado para detectar transacciones fraudulentas. Elasticsearch es un motor de búsqueda y análisis y podría no ser la mejor herramienta para el caso de uso descrito aquí.\n\nUsar AWS Glue para realizar trabajos ETL en los datos de transacciones y usar Amazon Forecast para análisis predictivo. - AWS Glue se usa principalmente para trabajos ETL: limpiar, preparar y mover datos. Amazon Forecast es un servicio completamente administrado para pronóstico de series temporales, que podría no ser una solución completa para detectar transacciones fraudulentas.\n\nReferencias:\n\nhttps://aws.amazon.com/sagemaker/"
  },
  {
    "q": "Una empresa del sector entretenimiento está desarrollando una nueva plataforma de transmisión de contenido bajo demanda en AWS. El CTO ha indicado que la solución debe ser altamente disponible, escalable horizontalmente y capaz de gestionar una gran cantidad de solicitudes simultáneas desde diferentes regiones del país. La aplicación está alojada en instancias EC2 que forman parte de un Auto Scaling Group distribuido en varias Zonas de Disponibilidad (AZs) dentro de una misma región. Para garantizar una distribución eficiente de tráfico entre todas las instancias disponibles, se requiere configurar un mecanismo que reparta equitativamente las solicitudes entrantes.\n¿Qué funcionalidad debe implementar el arquitecto de soluciones para cumplir con estos requisitos de balanceo de carga y alta disponibilidad?",
    "o": [
      "AWS Direct Connect SiteLink",
      "Cross-zone load balancing",
      "Amazon VPC IP Address Manager (IPAM)",
      "Path-based Routing"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nCross-zone load balancing - Permite que cada nodo del balanceador distribuya tráfico a instancias EC2 en todas las zonas de disponibilidad registradas, no solo dentro de su propia zona. Esto asegura una distribución uniforme de carga, aprovechando de forma eficiente los recursos desplegados y mejorando la disponibilidad general del sistema.\n\nOpciones incorrectas:\n\nPath-based Routing - Se utiliza para redirigir el tráfico a diferentes destinos según la estructura del URI. Es útil para aplicaciones con múltiples servicios, pero no resuelve el problema de balanceo equitativo entre zonas.\n\nAmazon VPC IP Address Manager (IPAM) - Está diseñado para administrar y monitorear direcciones IP dentro de una VPC. No está relacionado con balanceadores de carga ni con la distribución de tráfico entre instancias EC2.\n\nAWS Direct Connect SiteLink - Es útil para interconectar redes físicas a través de la red de AWS, generalmente en contextos híbridos. No influye en el comportamiento de los balanceadores de carga dentro de una VPC.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/userguide/how-elastic-load-balancing-works.html\n\nhttps://aws.amazon.com/elasticloadbalancing/features\n\nhttps://aws.amazon.com/blogs/aws/network-address-management-and-auditing-at-scale-with-amazon-vpc-ip-address-manager/"
  },
  {
    "q": "Una ingeniera recién incorporada al equipo de DevOps ha desarrollado una plantilla de AWS CloudFormation para lanzar una arquitectura de backend basada en microservicios. Ha subido la plantilla a un repositorio GIT y creado un pull request para revisión. Al examinar el contenido del archivo YAML, notas que incluye secciones como Parameters, Mappings y Outputs, pero ninguna definición de recursos.\nDespués de verificar la estructura de la plantilla, identificas inmediatamente que no podrá ser implementada con éxito.\n¿Cuál es la causa principal por la que esta plantilla fallará al intentar desplegarse como una pila de CloudFormation?",
    "o": [
      "La plantilla no contiene la sección Resources, obligatoria en toda plantilla válida",
      "La plantilla no incluye la sección Conditions, requerida para plantillas condicionales",
      "El valor especificado en AWSTemplateFormatVersion está obsoleto o incorrecto",
      "La inclusión de una sección llamada Parameters invalida la plantilla de CloudFormation"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nLa plantilla no contiene la sección Resources, obligatoria en toda plantilla válida - Es donde se definen los recursos de AWS que se deben crear, como instancias EC2, buckets de S3, funciones Lambda, etc. Si la plantilla no contiene esta sección, CloudFormation no puede construir nada y el intento de implementación fallará inmediatamente.\n\nOpciones incorrectas:\n\nLa plantilla no incluye la sección Conditions, requerida para plantillas condicionales - Es completamente opcional. Se utiliza para definir lógica condicional, pero su ausencia no invalida la plantilla.\n\nLa inclusión de una sección llamada Parameters invalida la plantilla de CloudFormation - Es una sección válida y ampliamente usada en CloudFormation para aceptar entradas dinámicas al momento del despliegue. No causa errores.\n\nEl valor especificado en AWSTemplateFormatVersion está obsoleto o incorrecto - También es un campo opcional. El valor más común y aceptado es \"2010-09-09\", que sigue siendo válido. Su omisión o presencia con un valor correcto no afecta la funcionalidad.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-anatomy.html\n\nhttps://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/resources-section-structure.html"
  },
  {
    "q": "Una empresa ejecuta una aplicación on-premises que almacena una gran cantidad de datos semiestructurados usando pares clave-valor. El código de la aplicación será migrado a AWS Lambda y se requiere una solución altamente escalable para almacenar los datos.\n¿Qué almacén de datos será la mejor opción para estos requisitos?",
    "o": [
      "Amazon DynamoDB",
      "Amazon EFS",
      "Amazon EBS",
      "Amazon RDS MySQL"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nAmazon DynamoDB - Amazon DynamoDB es una base de datos NoSQL que almacena datos usando pares clave-valor. Es ideal para almacenar grandes cantidades de datos semiestructurados y también es altamente escalable. Esta es la mejor solución para almacenar estos datos basándose en los requisitos del escenario.\n\nOpciones incorrectas:\n\nAmazon EBS - Amazon Elastic Block Store (EBS) es un sistema de almacenamiento basado en bloques. Adjuntas volúmenes a instancias EC2. No se usa para pares clave-valor ni para ser usado por funciones Lambda.\n\nAmazon EFS - Amazon Elastic File System (EFS) no es adecuado para almacenar pares clave-valor.\n\nAmazon RDS MySQL - Amazon Relational Database Service (RDS) se usa para datos estructurados ya que es un tipo de base de datos SQL.\n\nReferencias:\n\nhttps://aws.amazon.com/dynamodb/features/"
  },
  {
    "q": "Una empresa emergente está diseñando una plataforma de servicios financieros basada en una arquitectura de microservicios. Cada componente del sistema está desacoplado y se comunica mediante APIs RESTful, permitiendo así un desarrollo independiente y despliegue por separado. Para garantizar una infraestructura resiliente y con capacidad de respuesta ante cambios en la demanda, el equipo técnico debe implementar prácticas de escalado adecuadas.\nUno de los puntos clave en esta arquitectura distribuida es entender correctamente los conceptos de escalado horizontal y escalado vertical, ya que estos impactan directamente en la forma en que los servicios se adaptan al crecimiento del sistema.\n¿Cuál es la diferencia principal entre el escalado horizontal y el escalado vertical en este contexto?",
    "o": [
      "El escalado vertical significa aumentar los recursos de una máquina individual, como CPU o memoria. En cambio, el escalado horizontal consiste en añadir más instancias al conjunto de servidores, eliminando así la dependencia de un único punto de falla",
      "El escalado horizontal consiste en aumentar la capacidad de una máquina específica, mientras que el escalado vertical se basa en distribuir la carga agregando múltiples servidores al clúster",
      "El escalado vertical se refiere al uso de tecnologías serverless como AWS Lambda, mientras que el escalado horizontal implica usar instancias EC2 en diferentes zonas de disponibilidad",
      "El escalado horizontal implica ejecutar el software en contenedores más pequeños como Docker a través de servicios como Amazon ECS o EKS. El escalado vertical consiste en añadir más instancias al grupo existente sin limitaciones de hardware"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nEl escalado vertical significa aumentar los recursos de una máquina individual, como CPU o memoria. En cambio, el escalado horizontal consiste en añadir más instancias al conjunto de servidores, eliminando así la dependencia de un único punto de falla - El escalado vertical, también llamado “scale-up”, se refiere a aumentar la capacidad de una instancia existente (por ejemplo, aumentando la cantidad de CPU o memoria). Este enfoque está limitado por el hardware del servidor y puede requerir reinicios, afectando la disponibilidad. En contraste, el escalado horizontal o “scale-out” consiste en agregar más servidores o instancias para manejar el aumento de carga, lo que permite una arquitectura más flexible y resistente ante fallos.\n\n\n\nOpciones incorrectas:\n\nEl escalado horizontal implica ejecutar el software en contenedores más pequeños como Docker a través de servicios como Amazon ECS o EKS. El escalado vertical consiste en añadir más instancias al grupo existente sin limitaciones de hardware - El uso de contenedores está relacionado con la implementación de servicios, pero el concepto de escalado horizontal se refiere al número de instancias, no al tamaño de los contenedores.\n\nEl escalado horizontal consiste en aumentar la capacidad de una máquina específica, mientras que el escalado vertical se basa en distribuir la carga agregando múltiples servidores al clúster - Esta opción invierte los conceptos de escalado. El escalado horizontal no está limitado por la capacidad de hardware individual, ya que se basa en múltiples servidores.\n\nEl escalado vertical se refiere al uso de tecnologías serverless como AWS Lambda, mientras que el escalado horizontal implica usar instancias EC2 en diferentes zonas de disponibilidad - Serverless como AWS Lambda escala automáticamente, pero no representa escalado vertical. Es una categoría distinta de arquitectura que elimina la necesidad de gestionar servidores explícitos.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/aws-technical-content/latest/microservices-on-aws/microservices-on-aws.pdf#page=8"
  },
  {
    "q": "Una compañía tecnológica administra un entorno en AWS que incluye dos instancias EC2 reservadas para servidores web de producción con volúmenes raíz respaldados por Amazon EBS. Estas instancias mantienen un uso sostenido de CPU cercano al 90% y están detrás de un Elastic Load Balancer para distribuir el tráfico. Además, cuentan con instancias de Amazon RDS con MySQL configuradas en implementación Multi-AZ para los entornos de producción, desarrollo y pruebas.\n¿Qué acción sería más adecuada para optimizar los costos sin comprometer la disponibilidad o el rendimiento en los sistemas críticos del negocio?",
    "o": [
      "Eliminar el Elastic Load Balancer, ya que representa un costo adicional sin aportar valor directo al rendimiento",
      "Migrar las instancias EC2 reservadas a instancias On-demand para tener mayor flexibilidad de escalado",
      "Evaluar la eliminación de la configuración Multi-AZ en las bases de datos RDS de desarrollo y prueba, ya que no requieren alta disponibilidad",
      "Reemplazar las instancias EC2 reservadas por instancias Spot para reducir costos operativos"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nEvaluar la eliminación de la configuración Multi-AZ en las bases de datos RDS de desarrollo y prueba, ya que no requieren alta disponibilidad - Estas implementaciones están diseñadas para entornos que requieren alta disponibilidad y recuperación ante fallos, lo cual es esencial para producción, pero no necesariamente para desarrollo o pruebas. Desactivar esta configuración en entornos no críticos puede reducir significativamente los costos sin impactar negativamente la operación.\n\nOpciones incorrectas:\n\nEliminar el Elastic Load Balancer, ya que representa un costo adicional sin aportar valor directo al rendimiento - El balanceador de carga es esencial para distribuir tráfico entre múltiples instancias y garantizar alta disponibilidad. Eliminarlo comprometería la resiliencia del entorno de producción.\n\nMigrar las instancias EC2 reservadas a instancias On-demand para tener mayor flexibilidad de escalado - Si bien ofrecen un ahorro significativo frente a las On-demand cuando se trata de cargas de trabajo estables y de larga duración, como las de producción. Migrar a On-demand aumentaría los costos en este caso.\n\nReemplazar las instancias EC2 reservadas por instancias Spot para reducir costos operativos - Aunque son más baratas, no ofrecen garantías de disponibilidad, ya que pueden ser interrumpidas por AWS en cualquier momento. Por lo tanto, no son recomendables para cargas críticas de producción como servidores web constantemente activos.\n\nReferencias:\n\nhttps://aws.amazon.com/rds/details/multi-az/\n\nhttps://aws.amazon.com/pricing/cost-optimization/"
  },
  {
    "q": "Una empresa emergente está desarrollando una solución de movilidad inteligente basada en dispositivos IoT y análisis en tiempo real. Utilizan sensores desplegados en zonas urbanas para recolectar datos de tránsito, los cuales se envían a un flujo de Amazon Kinesis Data Streams configurado con los parámetros por defecto. Posteriormente, los datos procesados son almacenados en un bucket de Amazon S3 cada 72 horas para su análisis histórico. Sin embargo, al revisar el bucket tras la última transferencia, notaron que solo se encontraban los datos del último día, mientras que los correspondientes al segundo día no estaban disponibles.\n¿Cuál es la razón más probable de esta pérdida de datos?",
    "o": [
      "Los objetos correspondientes al segundo día fueron eliminados manualmente del bucket de S3 por un usuario con permisos",
      "El bucket de S3 sufrió una pérdida de datos debido a una falla en la durabilidad del almacenamiento",
      "El flujo de datos de Kinesis no cuenta con los permisos necesarios para escribir en el bucket de S3 de forma consistente",
      "Los datos almacenados en Amazon Kinesis tienen un período de retención por defecto de 24 horas, por lo que la información anterior a ese rango ya no está disponible al momento de procesarla"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nLos datos almacenados en Amazon Kinesis tienen un período de retención por defecto de 24 horas, por lo que la información anterior a ese rango ya no está disponible al momento de procesarla - Esto significa que si no se consume o transfiere la información dentro de ese período, los datos se eliminan automáticamente del flujo. En este caso, al intentar extraer datos cada 3 días, solo los registros más recientes seguían disponibles, mientras que los correspondientes al segundo día ya se habían descartado. Para evitar este problema, se debe configurar explícitamente una retención extendida de hasta 7 días si se requiere un intervalo de procesamiento mayor.\n\n\n\nOpciones incorrectas:\n\nLos objetos correspondientes al segundo día fueron eliminados manualmente del bucket de S3 por un usuario con permisos - Es improbable sin registros en CloudTrail, y además los objetos de un solo día fueron afectados, lo que indica que no se trata de una eliminación directa.\n\nEl bucket de S3 sufrió una pérdida de datos debido a una falla en la durabilidad del almacenamiento - Amazon S3 está diseñado para una durabilidad del 99.999999999% (11 nueves), por lo que es extremadamente raro que se pierdan datos una vez almacenados. La causa más probable apunta a la etapa de origen, es decir, en Kinesis.\n\nEl flujo de datos de Kinesis no cuenta con los permisos necesarios para escribir en el bucket de S3 de forma consistente - Si los permisos de escritura fueran insuficientes, no se habrían almacenado ningún dato en el bucket de S3. Sin embargo, los registros del último día sí están disponibles, lo que demuestra que la conexión entre los servicios funciona correctamente.\n\nReferencias:\n\nhttps://aws.amazon.com/kinesis/data-streams/faqs/\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/DataDurability.html"
  },
  {
    "q": "Una empresa de biotecnología se encuentra diseñando un entorno de High Performance Computing (HPC) en AWS para ejecutar simulaciones genómicas y procesamiento de grandes volúmenes de datos de laboratorio. Este entorno debe contar con un sistema de archivos que proporcione acceso rápido a los datos, alta capacidad de escalado y que esté optimizado específicamente para cargas de trabajo HPC. Además, se requiere que este sistema de archivos pueda integrarse de forma nativa con Amazon S3, de modo que los datos almacenados en S3 puedan procesarse directamente usando una interfaz compatible con POSIX.\n¿Cuál es la opción de almacenamiento más apropiada para satisfacer estos requisitos técnicos y de rendimiento?",
    "o": [
      "Amazon Elastic File System (EFS)",
      "Amazon FSx for Windows File Server",
      "Amazon Elastic Block Store (EBS)",
      "Amazon FSx for Lustre"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nAmazon FSx for Lustre - Está diseñado específicamente para cargas de trabajo de alto rendimiento, como análisis genómico, machine learning, rendering y simulaciones científicas. Se integra de forma nativa con Amazon S3, permitiendo que los datos almacenados en S3 sean accesibles a través de una interfaz de sistema de archivos POSIX altamente optimizada. Esta combinación lo convierte en la mejor opción para entornos HPC que requieren rendimiento extremo y acceso rápido a grandes conjuntos de datos.\n\n\n\nOpciones incorrectas:\n\nAmazon Elastic File System (EFS) - Es escalable y proporciona acceso compartido mediante NFS, no ofrece el rendimiento intensivo que requiere un entorno HPC, ni integración directa con Amazon S3.\n\nAmazon FSx for Windows File Server - Es más adecuado para aplicaciones empresariales tradicionales basadas en Windows que usan SMB. No es óptimo para HPC ni se integra nativamente con S3.\n\nAmazon Elastic Block Store (EBS) - Ofrece almacenamiento en bloque de alto rendimiento, pero no proporciona un sistema de archivos compartido escalable ni integración con S3, lo que limita su uso en clústeres HPC distribuidos.\n\nReferencias:\n\nhttps://aws.amazon.com/fsx/lustre/\n\nhttps://docs.aws.amazon.com/fsx/latest/LustreGuide/what-is.html"
  },
  {
    "q": "Un ingeniero de infraestructura ha creado un nuevo usuario de IAM a través de AWS CLI con los ajustes predeterminados, con el objetivo de permitir que este usuario interactúe programáticamente con servicios como Amazon S3, DynamoDB, AWS Lambda y otros recursos de AWS. El usuario necesita ejecutar scripts automatizados y herramientas que interactúan con la infraestructura de AWS a través de llamadas API.\n¿Qué paso es necesario para que este usuario pueda autenticarse correctamente y realizar dichas llamadas API a los servicios de AWS?",
    "o": [
      "Generar un par de claves de acceso (Access Key ID y Secret Access Key) para el usuario y asegurarse de que tiene los permisos necesarios",
      "No se requiere ninguna acción adicional, el usuario de IAM ya puede ejecutar llamadas API a través de la CLI",
      "Habilitar el uso de autenticación multifactor (MFA) para que el usuario pueda autenticarse en la consola y ejecutar llamadas API",
      "Asignar permisos mediante políticas de IAM es suficiente para permitir llamadas API"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nGenerar un par de claves de acceso (Access Key ID y Secret Access Key) para el usuario y asegurarse de que tiene los permisos necesarios - Para que un usuario de IAM pueda realizar llamadas API desde la CLI, SDKs o herramientas automatizadas, es indispensable generar un conjunto de credenciales de tipo Access Key (Access Key ID y Secret Access Key). Estas claves permiten la autenticación programática y deben ser protegidas adecuadamente. Además de estas credenciales, también se deben asignar los permisos necesarios mediante políticas de IAM para definir qué servicios y acciones están autorizadas.\n\nOpciones incorrectas:\n\nNo se requiere ninguna acción adicional, el usuario de IAM ya puede ejecutar llamadas API a través de la CLI - Un usuario recién creado en IAM no tiene acceso por defecto a los recursos ni posee credenciales programáticas, por lo que no puede ejecutar llamadas API sin configuraciones adicionales.\n\nAsignar permisos mediante políticas de IAM es suficiente para permitir llamadas API - Asignar políticas de IAM define las acciones permitidas, pero sin un mecanismo de autenticación válido como las claves de acceso, el usuario no puede ejecutar llamadas API.\n\nHabilitar el uso de autenticación multifactor (MFA) para que el usuario pueda autenticarse en la consola y ejecutar llamadas API - La autenticación multifactor (MFA) protege el acceso a la consola de administración de AWS, pero no reemplaza la necesidad de claves de acceso para llamadas API automatizadas.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html\n\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_users.html#id_users_creds"
  },
  {
    "q": "Una empresa del sector fintech está gestionando una plataforma de reservas de viajes que incluye la compra de boletos en línea y pagos mediante tarjetas de crédito. La arquitectura actual se basa en una aplicación web de tres capas: una interfaz de usuario compuesta por archivos HTML y JavaScript, una capa de lógica que reside en una única instancia EC2, y una base de datos relacional MySQL en el backend.\nRecientemente, el equipo de arquitectura recibió el encargo de rediseñar la plataforma para garantizar alta disponibilidad, escalabilidad automática y una menor dependencia entre capas del sistema, especialmente bajo picos de tráfico durante promociones estacionales.\n¿Cuál de las siguientes soluciones representa una mejora adecuada en la arquitectura para cumplir estos objetivos?",
    "o": [
      "Almacenar el contenido estático en Amazon CloudFront. Implementar Auto Scaling para la instancia EC2. Utilizar Amazon RDS con Multi-AZ para la base de datos",
      "Publicar los recursos estáticos y frontend en Amazon S3. Migrar la lógica de aplicación a Amazon ECS con contenedores y activar Auto Scaling. Configurar Amazon RDS con Multi-AZ para la base de datos MySQL",
      "Consolidar toda la lógica de negocio y el contenido estático en una instancia EC2 de mayor tamaño. Activar Auto Scaling. Migrar la base de datos a Amazon Aurora",
      "Usar Amazon S3 para el contenido estático. Reescribir la lógica de aplicación en funciones AWS Lambda con límites de concurrencia. Sustituir MySQL por Amazon DynamoDB"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nPublicar los recursos estáticos y frontend en Amazon S3. Migrar la lógica de aplicación a Amazon ECS con contenedores y activar Auto Scaling. Configurar Amazon RDS con Multi-AZ para la base de datos MySQL - Esta arquitectura aplica el principio de desacoplamiento y mejora la disponibilidad:\n\nAmazon S3 proporciona almacenamiento durable y escalable para contenido estático.\nAmazon ECS permite distribuir la carga entre contenedores y escalar automáticamente según la demanda.\nAmazon RDS en configuración Multi-AZ garantiza tolerancia a fallos para la base de datos relacional.\nEsto permite que cada capa del sistema funcione de forma independiente y se escale automáticamente en función de las necesidades de tráfico.\n\n\n\nOpciones incorrectas:\n\nAlmacenar el contenido estático en Amazon CloudFront. Implementar Auto Scaling para la instancia EC2. Utilizar Amazon RDS con Multi-AZ para la base de datos - Al utilizar CloudFront, que es una red de distribución de contenido (CDN) necesita de un origen, como S3, pero no sirve como repositorio primario de archivos estáticos ni páginas web.\n\nConsolidar toda la lógica de negocio y el contenido estático en una instancia EC2 de mayor tamaño. Activar Auto Scaling. Migrar la base de datos a Amazon Aurora - Escalar verticalmente una sola instancia EC2 no elimina el punto único de fallo. Aurora mejora el rendimiento, pero no es estrictamente necesario para alta disponibilidad si ya se emplea RDS con Multi-AZ.\n\nUsar Amazon S3 para el contenido estático. Reescribir la lógica de aplicación en funciones AWS Lambda con límites de concurrencia. Sustituir MySQL por Amazon DynamoDB - Usar AWS Lambda no es adecuada para cargas que requieren ejecución prolongada. Además, cambiar a DynamoDB requeriría una migración de modelo de datos, dado que MySQL es relacional y DynamoDB es NoSQL.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-auto-scaling.html\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html"
  },
  {
    "q": "Una empresa tecnológica que ofrece servicios en línea a usuarios de todo el mundo ha decidido usar Amazon CloudFront para distribuir su aplicación web con baja latencia y alta disponibilidad. La aplicación se ejecuta sobre instancias EC2 y se espera que el tráfico aumente durante campañas de marketing global.\nEl arquitecto de soluciones necesita definir el origen más adecuado para CloudFront, de modo que la arquitectura sea resiliente ante fallos y escale automáticamente con la demanda.\n¿Cuál de las siguientes opciones garantiza mejor la alta disponibilidad y escalabilidad para esta aplicación web?",
    "o": [
      "Implementar un Auto Scaling Group de instancias EC2 distribuidas en múltiples zonas de disponibilidad y configurarlo como origen en CloudFront",
      "Seleccionar una única instancia EC2 como origen para CloudFront y utilizar Route 53 para distribuir el tráfico entre regiones",
      "Utilizar Amazon S3 como origen de CloudFront para servir tanto contenido dinámico como estático y lograr alta disponibilidad",
      "Definir un Auto Scaling Group de instancias EC2 en una sola zona de disponibilidad como origen de CloudFront para manejar la carga"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nImplementar un Auto Scaling Group de instancias EC2 distribuidas en múltiples zonas de disponibilidad y configurarlo como origen en CloudFront - Para lograr alta disponibilidad y resiliencia en la nube, es fundamental distribuir la carga entre múltiples zonas de disponibilidad dentro de un Auto Scaling Group. Esto garantiza que si una zona falla, el tráfico aún puede ser dirigido a otras instancias operativas. CloudFront puede integrarse con un Application Load Balancer (ALB) que distribuye solicitudes a estas instancias, mejorando la tolerancia a fallos y la escalabilidad automática frente a variaciones globales de tráfico.\n\n\n\nOpciones incorrectas:\n\nDefinir un Auto Scaling Group de instancias EC2 en una sola zona de disponibilidad como origen de CloudFront para manejar la carga - Aunque se utilice Auto Scaling, al limitarse a una sola zona de disponibilidad no se garantiza tolerancia a fallos. Ante una interrupción en esa zona, el sistema completo sería inaccesible.\n\nUtilizar Amazon S3 como origen de CloudFront para servir tanto contenido dinámico como estático y lograr alta disponibilidad - Amazon S3 solo puede usarse como origen para contenido estático (HTML, imágenes, JS, etc.). No sirve para contenido dinámico, como APIs o lógica de backend ejecutada en EC2.\n\nSeleccionar una única instancia EC2 como origen para CloudFront y utilizar Route 53 para distribuir el tráfico entre regiones - No es una solución tolerante a fallos. Aunque Route 53 gestiona el enrutamiento global, no puede ofrecer alta disponibilidad si el origen falla.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/high_availability_origin_failover.html\n\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/as-multi-az.html\n\nhttps://aws.amazon.com/cloudfront/faqs/"
  },
  {
    "q": "Una empresa internacional de medios digitales utiliza Amazon RDS para MySQL 5.6 con configuración Multi-AZ activada para garantizar alta disponibilidad. Sus aplicaciones web están distribuidas entre dos regiones de AWS para proporcionar acceso de baja latencia a usuarios globales. Recientemente, debido al incremento de tráfico en su plataforma, el volumen de operaciones de lectura ha crecido significativamente. El equipo de infraestructura ha observado un retardo notable al ejecutar consultas de lectura en la región secundaria.\nEl arquitecto de soluciones necesita implementar una estrategia que reduzca drásticamente la latencia de replicación de lectura entre regiones, idealmente por debajo de 1 segundo, para satisfacer los requerimientos de rendimiento global.\n¿Cuál de las siguientes opciones proporciona la solución más adecuada para este escenario?",
    "o": [
      "Actualizar el motor de base de datos MySQL a una versión más reciente para mejorar el rendimiento de replicación",
      "Migrar la base de datos a Amazon Aurora y habilitar réplicas de lectura entre regiones para aprovechar la replicación optimizada de baja latencia",
      "Integrar Amazon ElastiCache para almacenar en caché las consultas más frecuentes y disminuir la carga en RDS",
      "Implementar una réplica de lectura en Amazon RDS para MySQL en la segunda región para distribuir la carga de lectura"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nMigrar la base de datos a Amazon Aurora y habilitar réplicas de lectura entre regiones para aprovechar la replicación optimizada de baja latencia - Es posible alcanzar latencias de replicación menores a un segundo, lo cual es ideal para aplicaciones distribuidas globalmente que requieren alta disponibilidad y acceso rápido a los datos. Aurora también proporciona mayor escalabilidad con hasta 15 réplicas de lectura y replicación casi en tiempo real.\n\nOpciones incorrectas:\n\nImplementar una réplica de lectura en Amazon RDS para MySQL en la segunda región para distribuir la carga de lectura - La replicación asincrónica estándar, suele tener una latencia mayor a 1 segundo entre regiones, lo que no cumple con el requisito del escenario.\n\nIntegrar Amazon ElastiCache para almacenar en caché las consultas más frecuentes y disminuir la carga en RDS - Aunque se mejora el rendimiento de lectura mediante almacenamiento en caché, no resuelve el problema específico de la latencia de replicación entre regiones.\n\nActualizar el motor de base de datos MySQL a una versión más reciente para mejorar el rendimiento de replicación - No cambia el modelo de replicación subyacente (asincrónica) entre regiones, por lo tanto, no mejora significativamente la latencia.\n\nReferencias:\n\nhttps://aws.amazon.com/rds/aurora/faqs/\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraMySQL.Replication.CrossRegion.html"
  },
  {
    "q": "Un estudio de postproducción cinematográfica ha desarrollado una plataforma web que permite a editores cargar archivos de video en bruto desde estaciones de trabajo conectadas a instancias EC2 en AWS. Cada archivo puede superar los 5 GB y debe almacenarse en un bucket de Amazon S3 para procesamiento posterior y archivado. El equipo técnico ha detectado que las cargas de estos archivos son más lentas de lo esperado, lo cual afecta directamente el flujo de trabajo creativo y la productividad del equipo.\n¿Cuál de las siguientes estrategias técnicas es la más adecuada para optimizar el rendimiento de las cargas hacia Amazon S3 en este escenario?",
    "o": [
      "Montar un volumen EBS con Provisioned IOPS para almacenar temporalmente los archivos antes de subirlos",
      "Activar Enhanced Networking en la instancia EC2 utilizando Elastic Network Adapter (ENA) para aumentar el rendimiento de red",
      "Implementar Amazon CloudFront como CDN y usar solicitudes HTTP POST para cargar los archivos con menor latencia",
      "Utilizar la API Multipart Upload de Amazon S3 para dividir los archivos y cargarlos en paralelo"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nUtilizar la API Multipart Upload de Amazon S3 para dividir los archivos y cargarlos en paralelo - Al dividir archivos grandes en múltiples partes y cargarlas simultáneamente, lo cual reduce significativamente el tiempo total de carga. Este enfoque es ideal para archivos de gran tamaño como videos de 5 GB o más, ya que permite aprovechar el ancho de banda disponible de forma eficiente. Además, en caso de interrupciones, solo se necesita repetir la carga de las partes fallidas, lo que mejora la resiliencia del proceso.\n\n\n\nOpciones incorrectas:\n\nActivar Enhanced Networking en la instancia EC2 utilizando Elastic Network Adapter (ENA) para aumentar el rendimiento de red - Si bien se mejora el rendimiento de red de EC2, por sí solo no aborda la eficiencia en la carga de archivos grandes a S3. La optimización a nivel de transferencia es más efectiva con Multipart Upload.\n\nImplementar Amazon CloudFront como CDN y usar solicitudes HTTP POST para cargar los archivos con menor latencia - Este servicio es una red de entrega de contenido para distribución hacia usuarios finales, no para acelerar cargas a S3. Además, no admite operaciones de carga como HTTP POST de forma directa para este tipo de uso.\n\nMontar un volumen EBS con Provisioned IOPS para almacenar temporalmente los archivos antes de subirlos - No mejora la latencia ni la velocidad de carga a S3, ya que el cuello de botella está en la transferencia de red, no en el almacenamiento temporal local.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/uploadobjusingmpu.html\n\nhttp://docs.aws.amazon.com/AmazonS3/latest/dev/qfacts.html"
  },
  {
    "q": "Una aplicación desarrollada en Python y desplegada dentro de un entorno de VMware Cloud on AWS necesita interactuar con una tabla específica de Amazon DynamoDB llamada blockstellart. Esta aplicación debe ser capaz de realizar operaciones CRUD (crear, leer, actualizar y eliminar) sobre los ítems almacenados en dicha tabla.\nSiguiendo las mejores prácticas de seguridad y el principio de menor privilegio, el arquitecto de soluciones debe diseñar una política de IAM precisa que otorgue únicamente los permisos necesarios, limitados exclusivamente a la tabla mencionada.\n¿Cuál de las siguientes políticas de IAM cumple con estos requisitos?",
    "o": [
      "{",
      "\"Version\": \"2012-10-17\",",
      "\"Statement\": [",
      "{",
      "\"Effect\": \"Allow\",",
      "\"Action\": \"*\",",
      "\"Resource\": \"arn:aws:dynamodb:us-east-2:123456789012:table/blockstellart-demo\"",
      "}",
      "]",
      "}",
      "{",
      "\"Version\": \"2012-10-17\",",
      "\"Statement\": [",
      "{",
      "\"Effect\": \"Allow\",",
      "\"Action\": [",
      "\"dynamodb:PutItem\",",
      "\"dynamodb:DeleteItem\",",
      "\"dynamodb:GetItem\",",
      "\"dynamodb:UpdateItem\"",
      "],",
      "\"Resource\": \"arn:aws:dynamodb:us-east-2:123456789012:table/blockstellart-demo\"",
      "}",
      "]",
      "}",
      "{",
      "\"Version\": \"2012-10-17\",",
      "\"Statement\": [",
      "{",
      "\"Effect\": \"Allow\",",
      "\"Action\": [",
      "\"dynamodb:Put*\",",
      "\"dynamodb:Delete*\",",
      "\"dynamodb:Get*\",",
      "\"dynamodb:Update*\"",
      "],",
      "\"Resource\": \"arn:aws:dynamodb:us-east-2:123456789012:table/blockstellart-demo\"",
      "}",
      "]",
      "}",
      "{",
      "\"Version\": \"2012-10-17\",",
      "\"Statement\": [",
      "{",
      "\"Effect\": \"Allow\",",
      "\"Action\": [",
      "\"dynamodb:PutItem\",",
      "\"dynamodb:DeleteItem\",",
      "\"dynamodb:GetItem\",",
      "\"dynamodb:UpdateItem\"",
      "],",
      "\"Resource\": \"arn:aws:dynamodb:us-east-2:123456789012:table/*\"",
      "}",
      "]",
      "}"
    ],
    "a": [
      10
    ],
    "e": "Opción correcta:\n\n{ \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"dynamodb:PutItem\", \"dynamodb:DeleteItem\", \"dynamodb:GetItem\", \"dynamodb:UpdateItem\" ], \"Resource\": \"arn:aws:dynamodb:us-east-2:123456789012:table/blockstellart-demo\" } ] } - Esta política aplica únicamente los permisos necesarios (lectura, escritura, actualización y eliminación de ítems) para una única tabla específica (blockstellart-demo), lo que alinea perfectamente con el principio de menor privilegio.\n\nOpciones incorrectas:\n\n{ \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"*\", \"Resource\": \"arn:aws:dynamodb:us-east-2:123456789012:table/blockstellart-demo\" } ] } - Otorga permisos completos (\"Action\": \"*\") sobre la tabla, lo cual excede lo necesario y representa un riesgo de seguridad.\n\n{ \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"dynamodb:Put*\", \"dynamodb:Delete*\", \"dynamodb:Get*\", \"dynamodb:Update*\" ], \"Resource\": \"arn:aws:dynamodb:us-east-2:123456789012:table/blockstellart-demo\" } ] } - Aunque parece más restringida, utiliza comodines (Put*, Delete*, etc.) que podrían permitir acciones no deseadas como DeleteTable o UpdateContinuousBackups.\n\n{ \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [ \"dynamodb:PutItem\", \"dynamodb:DeleteItem\", \"dynamodb:GetItem\", \"dynamodb:UpdateItem\" ], \"Resource\": \"arn:aws:dynamodb:us-east-2:123456789012:table/*\" } ] } - Aunque los permisos están correctamente definidos, el recurso aplica a todas las tablas (table/*), lo que concede más acceso del necesario.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html\n\nhttps://docs.aws.amazon.com/amazondynamodb/latest/developerguide/using-identity-based-policies.html"
  },
  {
    "q": "Una compañía fintech ha implementado una solución serverless basada en AWS Lambda para ejecutar cálculos complejos relacionados con transacciones financieras y conciliaciones bancarias. Estas funciones Lambda son invocadas varias veces al día y cada ejecución suele tomar entre 12 y 15 minutos.\nRecientemente, el equipo de monitoreo detectó que algunas invocaciones de la función están fallando de forma intermitente, generando inconsistencias en los reportes financieros y pérdidas parciales de procesamiento.\n¿Cuál es la causa más probable de estas terminaciones inesperadas?",
    "o": [
      "La lógica de negocio en la función Lambda está generando llamadas recursivas que sobrepasan el límite de ejecución",
      "Las invocaciones han fallado por errores ServiceException internos del servicio AWS Lambda",
      "La función Lambda ha alcanzado el límite de concurrencia configurado, lo que interrumpe ejecuciones ya iniciadas",
      "Las funciones Lambda superan el límite máximo de ejecución de 15 minutos, lo que provoca que se terminen automáticamente"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nLas funciones Lambda superan el límite máximo de ejecución de 15 minutos, lo que provoca que se terminen automáticamente - AWS Lambda impone un tiempo máximo de ejecución de 900 segundos (15 minutos). Si una función supera este tiempo, se interrumpe automáticamente, lo que puede generar pérdidas de procesamiento en tareas críticas como análisis financiero. En este caso, si algunas ejecuciones alcanzan ese límite, se finalizarán abruptamente.\n\n\n\nOpciones incorrectas:\n\nLa función Lambda ha alcanzado el límite de concurrencia configurado, lo que interrumpe ejecuciones ya iniciadas - Afecta la cantidad de ejecuciones simultáneas, pero no interrumpe funciones que ya están ejecutándose.\n\nLas invocaciones han fallado por errores ServiceException internos del servicio AWS Lambda - Representa un error interno de AWS, pero no es común ni específico como para explicar interrupciones periódicas a lo largo del día.\n\nLa lógica de negocio en la función Lambda está generando llamadas recursivas que sobrepasan el límite de ejecución - Podría impactar el tiempo de ejecución, pero el hecho de que las funciones se interrumpan justo cerca de los 15 minutos sugiere que el límite de tiempo de Lambda es el factor determinante.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/lambda/latest/dg/limits.html\n\nhttps://docs.aws.amazon.com/lambda/latest/dg/resource-model.html"
  },
  {
    "q": "Una corporación global del sector manufacturero ha adoptado una estrategia de cuentas múltiples en AWS para segmentar sus entornos por departamentos, incluyendo finanzas, recursos humanos, ingeniería y logística. Con el fin de mantener un control estricto sobre el uso de servicios y garantizar el cumplimiento de políticas de seguridad corporativa, se requiere una solución centralizada que permita definir y aplicar restricciones de acceso a servicios específicos en cada cuenta.\nComo arquitecto de soluciones en la nube, ¿cuál sería la mejor manera de estructurar este entorno multi-cuenta para satisfacer los requisitos de gobernanza y seguridad?",
    "o": [
      "Establecer acceso entre cuentas usando roles IAM para cada departamento y crear políticas personalizadas en cada cuenta que limiten los servicios accesibles",
      "Autenticar a los usuarios mediante un proveedor de identidad externo (Identity Federation) y asignar permisos diferenciados por departamento mediante roles IAM",
      "Diseñar una política de IAM reutilizable y aplicarla manualmente en todas las cuentas dentro del entorno multi-cuenta",
      "Utilizar AWS Organizations junto con Service Control Policies (SCPs) para definir y aplicar restricciones de servicios y acciones a nivel organizacional en cada cuenta"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nUtilizar AWS Organizations junto con Service Control Policies (SCPs) para definir y aplicar restricciones de servicios y acciones a nivel organizacional en cada cuenta - AWS Organizations permite una administración centralizada de entornos multi-cuenta. A través del uso de Service Control Policies (SCPs), los administradores pueden establecer límites máximos de permisos sobre lo que puede hacerse en cada cuenta, independientemente de las políticas IAM locales. Esta es la forma más eficaz y escalable de implementar controles de seguridad consistentes en todas las cuentas que forman parte de una organización.\n\n\n\nOpciones incorrectas:\n\nDiseñar una política de IAM reutilizable y aplicarla manualmente en todas las cuentas dentro del entorno multi-cuenta - Las políticas IAM son específicas a nivel de cuenta y no pueden ser aplicadas globalmente a múltiples cuentas. No ofrecen control organizacional centralizado.\n\nEstablecer acceso entre cuentas usando roles IAM para cada departamento y crear políticas personalizadas en cada cuenta que limiten los servicios accesibles - Aunque es posible establecer acceso entre cuentas (cross-account access), la gestión se vuelve compleja y poco escalable en un entorno con múltiples cuentas. Además, no proporciona control de acceso centralizado como lo hacen las SCPs.\n\nAutenticar a los usuarios mediante un proveedor de identidad externo (Identity Federation) y asignar permisos diferenciados por departamento mediante roles IAM - Es útil para permitir acceso desde fuentes externas, pero no soluciona el requerimiento de aplicar políticas globales de seguridad sobre el uso de servicios dentro de AWS. SCPs siguen siendo el mecanismo adecuado para ello.\n\nReferencias:\n\nhttps://aws.amazon.com/organizations/"
  },
  {
    "q": "Una plataforma de trading de alta frecuencia basada en AWS emplea instancias EC2 en un Auto Scaling Group para su capa de procesamiento, una base de datos Amazon RDS para el almacenamiento persistente, y Amazon ElastiCache para Redis como caché de acceso rápido. Con el fin de cumplir con nuevas políticas internas de seguridad y regulaciones financieras, se requiere reforzar la protección del sistema solicitando una autenticación obligatoria antes de que los usuarios puedan ejecutar cualquier comando dentro del clúster Redis.\n¿Cuál de las siguientes acciones debería implementar el arquitecto para satisfacer este nuevo requisito de seguridad?",
    "o": [
      "Implementar Redis AUTH configurando un nuevo clúster de Redis con los parámetros --transit-encryption-enabled y --auth-token activados",
      "Crear un nuevo clúster de replicación Redis y habilitar únicamente la encriptación en reposo mediante AtRestEncryptionEnabled",
      "Habilitar la encriptación en tránsito para el clúster Redis sin modificar la configuración de autenticación",
      "No realizar ninguna acción, ya que la autenticación está activada por defecto en Redis gestionado por ElastiCache"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nImplementar Redis AUTH configurando un nuevo clúster de Redis con los parámetros --transit-encryption-enabled y --auth-token activados - Para obligar a los clientes a autenticarse antes de ejecutar comandos en Redis, es necesario habilitar Redis AUTH. Esto se logra configurando un nuevo clúster de Redis en ElastiCache con los parámetros --auth-token (para definir la contraseña) y --transit-encryption-enabled (para cifrar el tráfico). Sin el auth-token, cualquier cliente podría ejecutar comandos en Redis sin restricciones.\n\n\n\nOpciones incorrectas:\n\nNo realizar ninguna acción, ya que la autenticación está activada por defecto en Redis gestionado por ElastiCache - La autenticación no está habilitada por defecto. Es necesario configurarla explícitamente al momento de crear el clúster.\n\nCrear un nuevo clúster de replicación Redis y habilitar únicamente la encriptación en reposo mediante AtRestEncryptionEnabled - Protege los datos almacenados en disco, pero no impone autenticación a los clientes.\n\nHabilitar la encriptación en tránsito para el clúster Redis sin modificar la configuración de autenticación - Asegura que los datos no sean interceptados en la red, pero no impide que un cliente sin credenciales acceda al clúster Redis.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/auth.html\n\nhttps://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/encryption.html"
  },
  {
    "q": "Una organización gubernamental está llevando a cabo la migración de una aplicación web crítica desde su centro de datos on-premises a la nube de AWS. Esta aplicación se conecta a una base de datos MySQL que será sustituida por una instancia de Amazon RDS como parte de la migración. Para cumplir con los lineamientos de seguridad institucional, el equipo de arquitectura debe garantizar que todas las conexiones de red a la base de datos estén cifradas con SSL y que el acceso se gestione sin contraseñas, utilizando credenciales basadas en perfiles de instancia EC2.\n¿Qué acción debe implementarse para satisfacer ambos requisitos de seguridad: cifrado de tráfico y autenticación sin contraseñas?",
    "o": [
      "Habilitar el cifrado en reposo al lanzar la instancia RDS para proteger los datos confidenciales",
      "Crear una instancia de Amazon Aurora con Backtrack habilitado para poder restaurar estados anteriores en caso de errores",
      "Conectarse a la base de datos usando el parámetro --ssl-ca desde el cliente MySQL para garantizar cifrado SSL",
      "Configurar Amazon RDS con autenticación IAM para la base de datos y habilitar el acceso mediante tokens generados por las instancias EC2"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nConfigurar Amazon RDS con autenticación IAM para la base de datos y habilitar el acceso mediante tokens generados por las instancias EC2 - Al aplicar esta configuración las aplicaciones pueden conectarse a Amazon RDS sin necesidad de almacenar contraseñas. En su lugar, se utilizan tokens firmados temporalmente por AWS IAM, lo que mejora la seguridad y facilita la gestión centralizada de credenciales. Además, esta autenticación se realiza sobre una conexión cifrada con SSL, cumpliendo con ambos requisitos del escenario: comunicación segura y acceso sin contraseñas.\n\n\n\nOpciones incorrectas:\n\nHabilitar el cifrado en reposo al lanzar la instancia RDS para proteger los datos confidenciales - No se garantiza el cifrado del tráfico de red ni elimina el uso de contraseñas para autenticación.\n\nCrear una instancia de Amazon Aurora con Backtrack habilitado para poder restaurar estados anteriores en caso de errores - Es útil para recuperación ante errores, pero no proporciona funciones específicas para cifrado de red ni autenticación basada en IAM.\n\nConectarse a la base de datos usando el parámetro --ssl-ca desde el cliente MySQL para garantizar cifrado SSL - Se asegura la conexión con SSL, pero aún requiere el uso de una contraseña. No satisface el requerimiento de autenticación sin contraseñas utilizando roles de IAM.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.IAMDBAuth.html\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.IAMDBAuth.Connecting.html"
  },
  {
    "q": "Una empresa tecnológica ha lanzado una nueva instancia EC2 con Windows Server para habilitar el acceso remoto de sus administradores. Sin embargo, al intentar establecer una conexión mediante Escritorio Remoto (Remote Desktop) desde una estación de trabajo corporativa, los intentos de conexión fallan constantemente.\nEl arquitecto de soluciones ha validado que la instancia tiene una dirección IP pública asignada, que la gateway de Internet está correctamente configurada, y que las tablas de rutas permiten el tráfico de salida y entrada.\n¿Qué paso adicional debe realizarse para permitir el acceso exitoso por Escritorio Remoto?",
    "o": [
      "Modificar el grupo de seguridad asociado a la instancia EC2 para permitir el tráfico entrante en el puerto 3389 desde la IP pública de la empresa",
      "Abrir el puerto 22 en el grupo de seguridad para permitir conexiones SSH desde la IP corporativa",
      "Reiniciar la instancia EC2 para resolver cualquier error interno que impida el acceso remoto",
      "Eliminar la instancia EC2 actual y lanzar una nueva con una AMI actualizada"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nModificar el grupo de seguridad asociado a la instancia EC2 para permitir el tráfico entrante en el puerto 3389 desde la IP pública de la empresa - Para conectarse a una instancia de Amazon EC2 que ejecuta Windows mediante el protocolo RDP (Escritorio Remoto), se debe permitir el tráfico entrante en el puerto TCP 3389 en el grupo de seguridad de la instancia. Este puerto debe estar abierto desde la dirección IP de origen que realiza la conexión, ya sea una dirección pública o una IP específica de la red corporativa.\n\nOpciones incorrectas:\n\nReiniciar la instancia EC2 para resolver cualquier error interno que impida el acceso remoto - Reiniciar no resolverá el problema si el grupo de seguridad no permite tráfico RDP. La configuración de red tiene prioridad sobre el estado del sistema operativo.\n\nAbrir el puerto 22 en el grupo de seguridad para permitir conexiones SSH desde la IP corporativa - El puerto se usa para conexiones SSH, típicamente en instancias basadas en Linux. No es aplicable a conexiones RDP con sistemas Windows.\n\nEliminar la instancia EC2 actual y lanzar una nueva con una AMI actualizada - No solucionará el problema si la configuración del grupo de seguridad sigue sin incluir la regla para el puerto 3389. Es mejor ajustar la configuración existente.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/troubleshooting-windows-instances.html#rdp-issues\n\nhttps://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html"
  },
  {
    "q": "Una empresa de logística está desarrollando una nueva plataforma para monitorear en tiempo real la ubicación de su flota de vehículos a nivel nacional. Cada camión envía sus coordenadas GPS a través de un dispositivo IoT cada cinco segundos.\nEl sistema debe ser capaz de recibir y procesar estos datos de múltiples vehículos simultáneamente con baja latencia. Además, los datos recopilados deben ser almacenados y posteriormente analizados por un sistema de generación de informes empresariales.\n¿Qué servicio de AWS proporciona la mejor solución para cumplir con estos requisitos?",
    "o": [
      "Amazon AppStream",
      "Amazon Elastic MapReduce (EMR)",
      "Amazon Kinesis",
      "Amazon Simple Queue Service (SQS)"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nAmazon Kinesis - Está diseñado para la ingesta y el procesamiento en tiempo real de flujos de datos a gran escala, como datos de sensores GPS, clics de usuarios o métricas de telemetría. Este servicio es ideal para aplicaciones que requieren análisis instantáneo de datos y ofrece integración sencilla con sistemas analíticos y de almacenamiento.\n\n\n\nOpciones incorrectas:\n\nAmazon AppStream - Está orientado a la virtualización de aplicaciones y escritorios, no al procesamiento de datos de IoT o GPS.\n\nAmazon Elastic MapReduce (EMR) - Es una solución potente para procesamiento por lotes y análisis de grandes volúmenes de datos históricos, pero no es adecuado para manejar flujos de datos en tiempo real con latencia mínima.\n\nAmazon Simple Queue Service (SQS) - Es una solución de mensajería asincrónica que carece de las capacidades de procesamiento en tiempo real necesarias para este tipo de sistema de rastreo de vehículos.\n\nReferencias:\n\nhttps://aws.amazon.com/kinesis/\n\nhttps://docs.aws.amazon.com/kinesis/"
  },
  {
    "q": "Una empresa tecnológica que ofrece servicios SaaS gestiona múltiples portales web críticos desplegados en AWS. Estas aplicaciones están alojadas detrás de Application Load Balancers (ALB), y utilizan certificados digitales emitidos por AWS Certificate Manager (ACM) para habilitar el tráfico HTTPS seguro. El equipo de cumplimiento normativo ha solicitado que se establezca un mecanismo proactivo para alertar al equipo de seguridad con al menos 30 días de antelación antes de que expire cualquier certificado SSL implementado en el entorno.\nComo arquitecto de soluciones, se te ha asignado la tarea de diseñar una solución automatizada que garantice la visibilidad y alerta oportuna sobre la expiración de certificados.\n¿Qué soluciones cumplen con este requisito de forma eficaz? (Selecciona DOS)",
    "o": [
      "Definir una regla en Amazon EventBridge programada para ejecutarse diariamente, la cual verifique la métrica DaysToExpiry de los certificados de ACM en Amazon CloudWatch. En caso de que algún certificado esté a 30 días o menos de expirar, enviar una notificación a través de Amazon SNS",
      "Aprovechar los eventos generados por AWS Health o ACM sobre la expiración próxima de certificados. Usar Amazon EventBridge para detectar estos eventos y notificar mediante Amazon SNS al equipo responsable",
      "Habilitar AWS Trusted Advisor para generar una alerta sobre certificados SSL cercanos a expirar, y configurar una alarma de CloudWatch para enviar notificaciones a AWS Systems Manager OpsItem",
      "Crear manualmente una regla personalizada en AWS Config para inspeccionar la expiración de certificados ACM. Usar Amazon EventBridge para generar una alerta a través de Amazon SNS cuando dicha regla sea incumplida",
      "Migrar los certificados actuales a una CA privada creada con AWS Certificate Manager Private CA. Configurar una función Lambda que escuche eventos de expiración en EventBridge y notifique a un tema de SNS cuando un certificado tenga menos de 30 días de vigencia"
    ],
    "a": [
      0,
      1
    ],
    "e": "Correcto:\n\nDefinir una regla en Amazon EventBridge programada para ejecutarse diariamente, la cual verifique la métrica DaysToExpiry de los certificados de ACM en Amazon CloudWatch. En caso de que algún certificado esté a 30 días o menos de expirar, enviar una notificación a través de Amazon SNS - Usar métricas como DaysToExpiry de CloudWatch permite monitorizar de forma programada la vigencia de los certificados de ACM. Combinado con EventBridge y SNS, se puede construir una solución proactiva y automatizada para alertar al equipo de seguridad con tiempo suficiente antes de la expiración.\n\nAprovechar los eventos generados por AWS Health o ACM sobre la expiración próxima de certificados. Usar Amazon EventBridge para detectar estos eventos y notificar mediante Amazon SNS al equipo responsable - AWS Health emite eventos automáticos relacionados con la expiración de certificados gestionados por ACM. Estos eventos pueden ser capturados por Amazon EventBridge, el cual puede desencadenar acciones como notificar mediante Amazon SNS, lo que elimina la necesidad de crear reglas manuales adicionales.\n\n\n\nOpciones incorrectas:\n\nHabilitar AWS Trusted Advisor para generar una alerta sobre certificados SSL cercanos a expirar, y configurar una alarma de CloudWatch para enviar notificaciones a AWS Systems Manager OpsItem - AWS Trusted Advisor no proporciona revisiones ni métricas para certificados ACM relacionados con su expiración, por lo que no puede ser una fuente fiable para este caso de uso.\n\nCrear manualmente una regla personalizada en AWS Config para inspeccionar la expiración de certificados ACM. Usar Amazon EventBridge para generar una alerta a través de Amazon SNS cuando dicha regla sea incumplida - Aunque AWS Config tiene reglas administradas para certificados, depender exclusivamente de reglas personalizadas introduce complejidad innecesaria. EventBridge y AWS Health ya proveen mecanismos automáticos y más eficientes.\n\nMigrar los certificados actuales a una CA privada creada con AWS Certificate Manager Private CA. Configurar una función Lambda que escuche eventos de expiración en EventBridge y notifique a un tema de SNS cuando un certificado tenga menos de 30 días de vigencia - Implementar una CA privada solo añade complejidad y costos adicionales sin resolver directamente la necesidad de notificación. No se requiere cambiar la fuente de emisión de certificados para habilitar alertas de expiración.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/acm/latest/userguide/supported-events.html\n\nhttps://docs.aws.amazon.com/acm/latest/userguide/event-sns-response.html\n\nhttps://docs.aws.amazon.com/acm/latest/userguide/cloudwatch-metrics.html"
  },
  {
    "q": "Una plataforma de medios digitales ha implementado Amazon CloudFront para distribuir globalmente su contenido web y mejorar la experiencia del usuario mediante una entrega más rápida. Sin embargo, tras analizar el tráfico, el equipo de operaciones detecta que las solicitudes continúan llegando directamente al servidor de origen, incluso para archivos estáticos que deberían ser servidos desde las ubicaciones de borde (Edge Locations) de AWS.\nEste comportamiento afecta el rendimiento de la aplicación y sobrecarga innecesariamente el origen. ¿Cuál es una causa probable de este comportamiento anómalo?",
    "o": [
      "Los objetos no han sido solicitados anteriormente, por lo tanto, CloudFront aún no los ha almacenado en caché",
      "Hay múltiples orígenes configurados como primarios dentro del Origin Group de CloudFront",
      "Los archivos solicitados son demasiado grandes para que CloudFront los almacene en sus ubicaciones de borde",
      "La política Cache-Control incluye el encabezado max-age con un valor de cero"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nLa política Cache-Control incluye el encabezado max-age con un valor de cero - Cuando los encabezados HTTP devueltos por el servidor de origen incluyen la directiva Cache-Control: max-age=0, se está indicando explícitamente que el contenido no debe almacenarse en caché. Esto obliga a CloudFront a reenviar todas las solicitudes al servidor de origen, sin importar cuán frecuentemente se solicite el objeto. Para aprovechar el almacenamiento en caché de CloudFront, es necesario establecer un valor de max-age mayor a cero que indique cuánto tiempo puede mantenerse el contenido en las ubicaciones de borde.\n\n\n\nOpciones incorrectas:\n\nLos archivos solicitados son demasiado grandes para que CloudFront los almacene en sus ubicaciones de borde - Puede manejar objetos de gran tamaño (hasta 30 GB para archivos individuales), por lo tanto, el tamaño del archivo no es el problema más probable en este escenario.\n\nHay múltiples orígenes configurados como primarios dentro del Origin Group de CloudFront - Aunque están diseñados con un origen primario y un origen de respaldo. No se pueden tener múltiples orígenes primarios, y esta configuración no causaría la omisión del caché si el encabezado Cache-Control estuviera correctamente definido.\n\nLos objetos no han sido solicitados anteriormente, por lo tanto, CloudFront aún no los ha almacenado en caché - El problema descrito indica que incluso los objetos solicitados con frecuencia no se están sirviendo desde el caché. Esto sugiere una configuración explícita que impide el almacenamiento, como max-age=0.\n\nReferencias:\n\nhttp://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Expiration.html"
  },
  {
    "q": "Un ingeniero de sistemas está planificando la infraestructura para una plataforma de análisis de video que realiza operaciones intensivas de lectura y escritura secuencial sobre archivos multimedia almacenados localmente en los nodos de cómputo. Debido a la naturaleza de los datos —archivos grandes, acceso continuo y procesamiento intensivo en disco— se requiere un tipo de instancia que maximice el rendimiento de almacenamiento local. ¿Cuál de los siguientes tipos de instancia representa la mejor elección para este escenario?",
    "o": [
      "Instancias optimizadas para cómputo (Compute Optimized Instances)",
      "Instancias optimizadas para almacenamiento (Storage Optimized Instances)",
      "Instancias de propósito general (General Purpose Instances)",
      "Instancias optimizadas para memoria (Memory Optimized Instances)"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nInstancias optimizadas para almacenamiento (Storage Optimized Instances) - Están específicamente diseñadas para cargas de trabajo que requieren un alto rendimiento en lectura y escritura secuencial de datos directamente desde discos locales. Son ideales para aplicaciones como análisis de big data, almacenamiento de registros o procesamiento de archivos multimedia, donde se necesitan operaciones de E/S intensivas y consistentes.\n\n\n\nOpciones incorrectas:\n\nInstancias de propósito general (General Purpose Instances) - Proporcionan un equilibrio entre recursos, pero al no estar optimizadas para almacenamiento, podrían generar cuellos de botella en una aplicación que requiere acceso constante y rápido a datos almacenados localmente.\n\nInstancias optimizadas para memoria (Memory Optimized Instances) - Son adecuadas para bases de datos en memoria o análisis en tiempo real de grandes volúmenes de datos en RAM. No se enfocan en el acceso a disco de alta velocidad, que es lo que demanda esta solución.\n\nInstancias optimizadas para cómputo (Compute Optimized Instances) - Priorizan el rendimiento del procesador, por lo que son útiles para tareas de cálculo intensivo como simulaciones científicas, pero no son eficaces para E/S de disco intensiva.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/storage-optimized-instances.html"
  },
  {
    "q": "Una empresa de diseño gráfico ha lanzado una aplicación web alojada en una instancia EC2 que permite a los usuarios aplicar filtros y efectos artísticos a sus imágenes cargadas. Una vez procesadas, estas imágenes deben almacenarse automáticamente en un bucket de Amazon S3 mediante llamadas autenticadas a la API de S3 usando operaciones PUT.\nDado que la aplicación requiere autenticación para realizar estas operaciones sobre el bucket de S3, ¿cuál es la forma más segura y eficiente de gestionar las credenciales necesarias para acceder a los servicios de AWS?",
    "o": [
      "Cifrar las credenciales de acceso a la API y guardarlas dentro del sistema de archivos local de la instancia EC2",
      "Crear un rol de IAM con permisos apropiados y asignarlo directamente a la instancia EC2 que ejecuta la aplicación",
      "Colocar las credenciales de la API dentro del código fuente de la aplicación web en la instancia EC2",
      "Guardar las credenciales de la API en Amazon S3 Glacier para recuperarlas en tiempo de ejecución"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nCrear un rol de IAM con permisos apropiados y asignarlo directamente a la instancia EC2 que ejecuta la aplicación - Es la forma recomendada y más segura de otorgar permisos para acceder a otros servicios de AWS, como Amazon S3. Esto elimina la necesidad de manejar manualmente claves de acceso, ya que la instancia obtiene credenciales temporales automáticamente a través del rol asignado. Además, este enfoque mejora la seguridad, reduce errores humanos y facilita la rotación automática de credenciales.\n\n\n\nOpciones incorrectas:\n\nCifrar las credenciales de acceso a la API y guardarlas dentro del sistema de archivos local de la instancia EC2 - Aunque proporciona un nivel de protección, almacenarlas en disco sigue siendo una mala práctica, ya que cualquier acceso no autorizado a la instancia podría exponerlas.\n\nGuardar las credenciales de la API en Amazon S3 Glacier para recuperarlas en tiempo de ejecución - No está diseñado ni optimizado para acceder a credenciales de manera eficiente o frecuente.\n\nColocar las credenciales de la API dentro del código fuente de la aplicación web en la instancia EC2 - Representa un grave riesgo de seguridad. Este enfoque puede conducir a filtraciones accidentales si el código se comparte o versiona en repositorios públicos o mal gestionados.\n\nReferencias:\n\nhttp://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html"
  },
  {
    "q": "Un estudio de desarrollo de videojuegos ha lanzado una nueva plataforma multijugador que requiere distribuir conexiones TCP desde jugadores globales hacia múltiples instancias de backend en contenedores, ejecutándose en AWS Fargate. La aplicación necesita garantizar una experiencia de usuario fluida, con tiempos de respuesta mínimos y la capacidad de manejar picos de tráfico masivos durante eventos o lanzamientos globales.\nEl equipo de arquitectura busca una solución que funcione a nivel de transporte (Layer 4) y pueda escalar automáticamente para soportar millones de conexiones concurrentes con baja latencia.\n¿Qué componente debería añadirse a la arquitectura para cumplir con estos requisitos?",
    "o": [
      "Configurar una política de enrutamiento ponderado en Amazon Route 53 para distribuir el tráfico entre endpoints globales",
      "Desplegar un Network Load Balancer (NLB) para enrutar tráfico TCP a los contenedores en Fargate",
      "Utilizar un Application Load Balancer (ALB) para balancear las conexiones entrantes sobre HTTP",
      "Desarrollar un balanceador personalizado basado en Fargate para manejar las conexiones TCP directamente"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nDesplegar un Network Load Balancer (NLB) para enrutar tráfico TCP a los contenedores en Fargate - Para manejar tráfico de red en la capa 4 del modelo OSI (transporte), como TCP y UDP. Ofrece alta escalabilidad, baja latencia y resiliencia, lo que lo hace ideal para aplicaciones como servidores de juegos en tiempo real. Además, se integra fácilmente con tareas de ECS en Fargate.\n\n\n\nOpciones incorrectas:\n\nUtilizar un Application Load Balancer (ALB) para balancear las conexiones entrantes sobre HTTP - Opera en la capa de aplicación (Layer 7) y está diseñado para tráfico HTTP/HTTPS. No es adecuado para balancear conexiones TCP crudas, como las requeridas por aplicaciones de juegos en tiempo real.\n\nConfigurar una política de enrutamiento ponderado en Amazon Route 53 para distribuir el tráfico entre endpoints globales - Aunque roporciona DNS avanzado con políticas como Weighted Routing, pero no es un balanceador de carga en tiempo real ni maneja conexiones simultáneas a nivel de red o transporte.\n\nDesarrollar un balanceador personalizado basado en Fargate para manejar las conexiones TCP directamente - No es eficiente ni necesario, ya que AWS ofrece soluciones nativas como el NLB que están diseñadas precisamente para estos casos de uso.\n\nReferencias:\n\nhttps://aws.amazon.com/elasticloadbalancing/features/#compare\n\nhttps://docs.aws.amazon.com/AmazonECS/latest/developerguide/load-balancer-types.html\n\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/network/introduction.html"
  },
  {
    "q": "Una empresa del sector financiero que procesa pagos con tarjetas de crédito en tiempo real está diseñando su infraestructura en AWS. Por requerimientos regulatorios y de cumplimiento, deben garantizar que las claves criptográficas utilizadas para cifrar los datos sensibles estén protegidas en un entorno altamente seguro y controlado. El equipo de arquitectura está evaluando si deben utilizar AWS Key Management Service (KMS) o AWS CloudHSM para la administración y protección de las claves criptográficas.\n¿Cuál de las siguientes afirmaciones es más precisa al comparar AWS CloudHSM con AWS KMS en este contexto?",
    "o": [
      "Se debe considerar AWS CloudHSM en lugar de AWS KMS cuando se necesita que las claves se almacenen en módulos de seguridad de hardware (HSM) validados por terceros y bajo control exclusivo del cliente",
      "Ambos servicios son prácticamente iguales, ya que ofrecen las mismas funcionalidades de cifrado y control de claves",
      "AWS CloudHSM siempre debe utilizarse para cualquier tipo de transacción de pagos sin excepción",
      "Si necesitas un servicio administrado para manejar claves sin operar tu propio HSM, entonces deberías elegir AWS CloudHSM"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nSe debe considerar AWS CloudHSM en lugar de AWS KMS cuando se necesita que las claves se almacenen en módulos de seguridad de hardware (HSM) validados por terceros y bajo control exclusivo del cliente - Es ideal cuando una organización requiere control total sobre sus claves criptográficas y necesita cumplir con normativas estrictas que exigen el uso de módulos de seguridad de hardware (HSM) validados bajo estándares como FIPS 140-2 nivel 3. CloudHSM permite al cliente tener acceso exclusivo a sus claves sin intervención de AWS, lo cual es esencial en algunos casos de cumplimiento en el sector financiero.\n\nOpciones incorrectas:\n\nAWS CloudHSM siempre debe utilizarse para cualquier tipo de transacción de pagos sin excepción - Aunque existe un mayor control, no siempre es obligatorio para todas las transacciones de pago. AWS KMS, al ser un servicio administrado y certificado, es aceptado en muchos escenarios financieros y está validado para cumplir con estándares como PCI DSS.\n\nSi necesitas un servicio administrado para manejar claves sin operar tu propio HSM, entonces deberías elegir AWS CloudHSM - Al no ser un servicio administrado en el mismo nivel que KMS. El cliente es responsable de la administración del clúster, disponibilidad, configuración y rotación de claves, lo que implica una mayor carga operativa.\n\nAmbos servicios son prácticamente iguales, ya que ofrecen las mismas funcionalidades de cifrado y control de claves - El servicio de KMS es un servicio completamente administrado con integración nativa con otros servicios de AWS, mientras que CloudHSM otorga al cliente control total sobre el entorno criptográfico. La elección depende de los requisitos de control y cumplimiento.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/kms/latest/developerguide/overview.html\n\nhttps://docs.aws.amazon.com/cloudhsm/latest/userguide/introduction.html"
  },
  {
    "q": "Una startup de análisis de datos en tiempo real está implementando una solución para almacenar logs generados por aplicaciones móviles y servicios backend. Estos archivos de registro son temporales y se utilizan únicamente para procesamiento en streaming y monitoreo durante las primeras horas tras su generación. Posteriormente, se eliminan automáticamente mediante una política de ciclo de vida. El volumen de datos aún es incierto y puede variar en función del tráfico de usuarios, pero el tiempo de retención de los archivos no supera las 12 horas.\n¿Qué clase de almacenamiento de Amazon S3 proporciona la solución más rentable y adecuada para este caso de uso temporal?",
    "o": [
      "Amazon S3 Glacier Deep Archive",
      "Amazon S3 Standard-IA",
      "Amazon S3 One Zone-IA",
      "Amazon S3 Standard"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nAmazon S3 Standard - Es ideal para datos de corta duración y acceso frecuente. No impone un período mínimo de retención, por lo que solo se factura por el tiempo exacto de almacenamiento, incluso si los archivos solo permanecen durante 12 horas. Además, garantiza alta disponibilidad y latencia baja, lo que resulta adecuado para logs que podrían necesitar acceso rápido para alertas o dashboards de monitoreo.\n\n\n\nOpciones incorrectas:\n\nAmazon S3 One Zone-IA - Aunque es más barata tiene un requisito mínimo de almacenamiento de 30 días. Por tanto, almacenar archivos solo por 12 horas implicaría un costo innecesario por el período completo.\n\nAmazon S3 Glacier Deep Archive - Está orientado al almacenamiento a largo plazo, con un mínimo de 180 días. Además, los tiempos de recuperación son de horas, lo cual no es viable para un escenario de procesamiento rápido y temporal.\n\nAmazon S3 Standard-IA - También exige una retención mínima de 30 días. Aunque es más económica que S3 Standard en uso prolongado, no es rentable para almacenamiento de corta duración como en este caso.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/storage-class-intro.html\n\nhttps://aws.amazon.com/s3/storage-classes/"
  },
  {
    "q": "Un arquitecto de soluciones está optimizando un sitio web para transmisión en tiempo real y videos bajo demanda. Los usuarios del sitio web están ubicados alrededor del mundo y el arquitecto de soluciones necesita optimizar el rendimiento tanto para la transmisión en tiempo real como para la transmisión bajo demanda.\n¿Qué servicio debe elegir el arquitecto de soluciones?",
    "o": [
      "Amazon Route 53",
      "Amazon S3 Transfer Acceleration",
      "AWS Global Accelerator",
      "Amazon CloudFront"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nAmazon CloudFront - Amazon CloudFront puede usarse para transmitir video a usuarios en todo el mundo usando una amplia variedad de protocolos que están superpuestos sobre HTTP. Esto puede incluir tanto video bajo demanda como video de transmisión en tiempo real.\n\nOpciones incorrectas:\n\nAmazon Route 53 - Aún necesitas una solución para acercar el contenido a los usuarios.\n\nAmazon S3 Transfer Acceleration - Esto se usa para acelerar las cargas de datos a buckets de Amazon S3.\n\nAWS Global Accelerator - Esta sería una forma costosa de acercar el contenido a los usuarios en comparación con usar CloudFront. Como este es un caso de uso para CloudFront y hay tantas ubicaciones edge, es la mejor opción.\n\nReferencias:\n\nhttps://aws.amazon.com/cloudfront/streaming/\n\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/on-demand-streaming-video.html"
  },
  {
    "q": "Una empresa internacional del sector e-learning opera múltiples aplicaciones web públicas desplegadas en instancias de Amazon EC2, detrás de varios Application Load Balancers (ALBs), distribuidos en distintas regiones de AWS. Para asegurar la conectividad entre estas aplicaciones y los servicios internos de la empresa, se requiere que el tráfico pase a través del firewall corporativo. Sin embargo, mantener una lista blanca actualizada con direcciones IP dinámicas asociadas a los ALBs representa una carga administrativa significativa.\n¿Cuál de las siguientes estrategias permitiría simplificar la administración del firewall y reducir la cantidad de direcciones IP que deben ser incluidas en la lista blanca?",
    "o": [
      "Desplegar un Network Load Balancer con una Elastic IP estática y enrutar el tráfico hacia los ALBs en distintas regiones como destinos backend",
      "Implementar AWS Global Accelerator con grupos de endpoints por región y asociar los ALBs regionales a sus respectivos grupos de endpoints",
      "Configurar una función Lambda que monitorice los cambios en las direcciones IP de los ALBs y actualice automáticamente la lista blanca del firewall mediante eventos de Amazon CloudWatch",
      "Usar AWS Global Accelerator creando endpoints individuales para cada instancia EC2 en todas las regiones, asignando direcciones IP privadas directamente"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nImplementar AWS Global Accelerator con grupos de endpoints por región y asociar los ALBs regionales a sus respectivos grupos de endpoints - Permite proporcionar un conjunto de direcciones IP estáticas que los clientes pueden usar para acceder a aplicaciones distribuidas globalmente. Al configurar grupos de endpoints por región y asociar los Application Load Balancers correspondientes, se asegura una alta disponibilidad, rendimiento y una gestión centralizada de las direcciones IP. Esto elimina la necesidad de actualizar constantemente la lista blanca del firewall corporativo, ya que las IPs del Global Accelerator permanecen fijas.\n\n\n\nOpciones incorrectas:\n\nDesplegar un Network Load Balancer con una Elastic IP estática y enrutar el tráfico hacia los ALBs en distintas regiones como destinos backend - Aunque el uso de un Network Load Balancer con una IP elástica puede parecer una solución viable, no permite el direccionamiento directo a ALBs en otras regiones, lo que limita su funcionalidad en un entorno multirregional.\n\nConfigurar una función Lambda que monitorice los cambios en las direcciones IP de los ALBs y actualice automáticamente la lista blanca del firewall mediante eventos de Amazon CloudWatch - Automatizar la actualización del firewall mediante Lambda y CloudWatch Events es técnicamente posible, pero introduce complejidad operativa y posibles errores. Es una solución reactiva frente a la solución proactiva y escalable que ofrece AWS Global Accelerator.\n\nUsar AWS Global Accelerator creando endpoints individuales para cada instancia EC2 en todas las regiones, asignando direcciones IP privadas directamente - Asociar direcciones IP privadas de instancias EC2 directamente en AWS Global Accelerator va contra las buenas prácticas. Los endpoints deben ser recursos como ALBs o NLBs para aprovechar correctamente las capacidades de aceleración y balanceo de tráfico global.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/global-accelerator/latest/dg/about-endpoint-groups.html\n\nhttps://aws.amazon.com/global-accelerator/faqs/\n\nhttps://docs.aws.amazon.com/global-accelerator/latest/dg/introduction-how-it-works.html"
  },
  {
    "q": "Un equipo de investigación científica está desplegando en AWS una solución de High-Performance Computing (HPC) destinada al procesamiento masivo de simulaciones climáticas. Las tareas serán ejecutadas utilizando Amazon Elastic Container Service (ECS) con el tipo de lanzamiento EC2, y se ejecutarán cientos de tareas en paralelo dentro de un clúster ECS.\nEl sistema deberá permitir acceso concurrente a archivos de entrada y salida con operaciones de lectura/escritura intensivas. Cada tarea genera archivos de salida de aproximadamente 10 MB, y aunque los datos antiguos serán eventualmente archivados, el almacenamiento total requerido no superará los 10 TB.\n¿Cuál sería la opción de almacenamiento más adecuada para asegurar rendimiento sostenido y acceso concurrente eficiente?",
    "o": [
      "Implementar Amazon EFS en modo Bursting Throughput con rendimiento General Purpose como volumen compartido para las tareas ECS",
      "Configurar Amazon EFS con Throughput Provisioned y modo de rendimiento Max I/O como sistema de archivos compartido en las tareas ECS",
      "Usar Amazon DynamoDB con DAX y Streams habilitados, configurándolo como punto de montaje en las tareas ECS",
      "Crear un file share SMB utilizando Amazon FSx File Gateway para montar el almacenamiento en los contenedores ECS"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nConfigurar Amazon EFS con Throughput Provisioned y modo de rendimiento Max I/O como sistema de archivos compartido en las tareas ECS - Para cargas de trabajo HPC con múltiples tareas concurrentes y alta demanda de I/O, Amazon EFS configurado con Throughput Provisioned y modo de rendimiento Max I/O proporciona el rendimiento y la escalabilidad necesarios.\n\nProvisioned Throughput garantiza un rendimiento constante sin depender del volumen almacenado.\nMax I/O permite mayor concurrencia de acceso a archivos, ideal para clústeres ECS con muchas tareas paralelas.\n\n\nOpciones incorrectas:\n\nUsar Amazon DynamoDB con DAX y Streams habilitados, configurándolo como punto de montaje en las tareas ECS - DynamoDB es una base de datos NoSQL y no puede ser montada como un sistema de archivos para contenedores. No está diseñada para almacenar archivos directamente.\n\nImplementar Amazon EFS en modo Bursting Throughput con rendimiento General Purpose como volumen compartido para las tareas ECS - EFS en modo Bursting depende del tamaño de almacenamiento para determinar su capacidad de throughput. Esto podría causar cuellos de botella con muchas tareas simultáneas.\n\nCrear un file share SMB utilizando Amazon FSx File Gateway para montar el almacenamiento en los contenedores ECS - Amazon FSx File Gateway es más adecuado para integraciones híbridas on-premises y no ofrece la misma capacidad de concurrencia ni rendimiento que EFS para tareas distribuidas en la nube.\n\nReferencias:\n\nhttps://aws.amazon.com/efs/\n\nhttps://docs.aws.amazon.com/efs/latest/ug/performance.html"
  },
  {
    "q": "Una organización tecnológica está ejecutando una aplicación web que necesita acceder a una tabla de Amazon DynamoDB. Actualmente, la empresa utiliza una Amazon Machine Image (AMI) personalizada que contiene las claves de acceso (Access Key ID y Secret Access Key) en un archivo de texto plano. Las instancias EC2 creadas a partir de esta AMI utilizan esas claves para conectarse al servicio de base de datos.\nEl equipo de seguridad ha detectado esta práctica como un riesgo potencial para la confidencialidad de las credenciales.\n¿Qué debería hacer el arquitecto de soluciones para reforzar la seguridad de esta arquitectura?",
    "o": [
      "No realizar ninguna modificación, ya que las credenciales están protegidas dentro de la AMI",
      "Transferir las claves a un bucket de Amazon S3 con permisos restringidos",
      "Mover las credenciales de acceso a Amazon Glacier para su almacenamiento a largo plazo",
      "Eliminar las claves de la AMI y asignar un IAM Role a las instancias EC2 con permisos para acceder a DynamoDB"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nEliminar las claves de la AMI y asignar un IAM Role a las instancias EC2 con permisos para acceder a DynamoDB - La forma más segura de otorgar permisos para acceder a otros servicios de AWS, como DynamoDB, es mediante el uso de roles de IAM. Al asignar un IAM Role a una instancia EC2, AWS gestiona automáticamente credenciales temporales, eliminando la necesidad de almacenar claves estáticas dentro de la AMI o el sistema de archivos.\n\n\n\nOpciones incorrectas:\n\nMover las credenciales de acceso a Amazon Glacier para su almacenamiento a largo plazo - No está diseñado para gestionar credenciales de acceso ya que es un servicio de almacenamiento de archivos a largo plazo\n\nTransferir las claves a un bucket de Amazon S3 con permisos restringidos - Se pueda restringir, pero esta práctica sigue siendo riesgosa, ya que requiere la distribución manual de credenciales, lo cual es contrario a los principios de seguridad recomendados por AWS.\n\nNo realizar ninguna modificación, ya que las credenciales están protegidas dentro de la AMI - Es una mala práctica que puede conducir a filtraciones de credenciales si la imagen es compartida accidentalmente o comprometida.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html"
  },
  {
    "q": "Una empresa de comercio electrónico ha desplegado su plataforma web en contenedores gestionados por Amazon ECS con capacidad de autoescalado limitada. Durante campañas promocionales y lanzamientos de productos, los usuarios reportan tiempos de carga excesivos y errores intermitentes, afectando negativamente la experiencia del cliente. Actualmente, los servicios se ejecutan en tareas ECS distribuidas detrás de un Application Load Balancer (ALB), y las notificaciones de CloudWatch alertan al equipo técnico para que escale manualmente cuando se detecta una degradación en la disponibilidad. Un arquitecto de soluciones ha sido asignado para automatizar el proceso de escalado y mejorar la resiliencia del sistema.\n¿Cuáles de las siguientes acciones permitirían implementar un mecanismo efectivo de autoescalado que reaccione a la demanda en tiempo real? (Selecciona DOS)",
    "o": [
      "Implementar una política de escalado basada en el uso de CPU del target group del ALB para aumentar las instancias ECS",
      "Establecer una política de Auto Scaling que incremente el número de tareas ECS cuando el uso de memoria supere un umbral definido",
      "Crear una política de escalado que incremente el número de tareas ECS si se detectan fallos de conectividad al ALB",
      "Configurar una política de Auto Scaling que escale el clúster ECS al detectar un uso elevado de CPU en los servicios ECS",
      "Definir una política de escalado automático que aumente las tareas ECS cuando el ALB muestre una alta latencia en las respuestas"
    ],
    "a": [
      1,
      3
    ],
    "e": "Correcto:\n\nEstablecer una política de Auto Scaling que incremente el número de tareas ECS cuando el uso de memoria supere un umbral definido - Permitira reaccionar ante métricas de uso como la memoria. La métrica ECSServiceAverageMemoryUtilization es clave para detectar si los servicios están siendo limitados por falta de memoria, lo cual justifica una expansión automática del número de tareas ECS.\n\nConfigurar una política de Auto Scaling que escale el clúster ECS al detectar un uso elevado de CPU en los servicios ECS - De forma análoga, ECSServiceAverageCPUUtilization permite monitorear la carga de procesamiento. Si esta métrica se eleva, escalar el clúster ECS puede ayudar a mantener el rendimiento esperado bajo cargas elevadas.\n\nOpciones incorrectas:\n\nDefinir una política de escalado automático que aumente las tareas ECS cuando el ALB muestre una alta latencia en las respuestas - AWS no ofrece métricas directamente utilizables de latencia del ALB para políticas de Auto Scaling en ECS.\n\nImplementar una política de escalado basada en el uso de CPU del target group del ALB para aumentar las instancias ECS - Los grupos de destino del ALB no exponen métricas de CPU que sean integrables en Auto Scaling; por tanto, no es viable basar el escalado en este parámetro.\n\nCrear una política de escalado que incremente el número de tareas ECS si se detectan fallos de conectividad al ALB - Las fallas de conectividad hacia el ALB pueden tener múltiples causas no relacionadas con la carga de trabajo. No son adecuadas como disparadores de escalado automático.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-configure-auto-scaling.html\n\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/as-instance-monitoring.html"
  },
  {
    "q": "Una empresa de retail ha implementado su nueva aplicación web de e-commerce utilizando AWS Elastic Beanstalk con un entorno administrado para Node.js. El equipo de desarrollo cargó el código de la aplicación a través de la consola de Elastic Beanstalk, dejando que el servicio gestione automáticamente recursos como instancias EC2, balanceadores de carga, Auto Scaling y monitoreo del estado del entorno. Tras el despliegue exitoso, el equipo de DevOps necesita acceder a los archivos de registro generados por la aplicación y entender dónde se almacenan los artefactos de despliegue.\nEn el contexto de Elastic Beanstalk, ¿dónde se almacenan los archivos del código fuente de la aplicación y los registros generados por el servidor?",
    "o": [
      "Los archivos de la aplicación se almacenan en Amazon S3. Los registros del servidor pueden configurarse para enviarse opcionalmente a Amazon S3 o Amazon CloudWatch Logs",
      "La aplicación se guarda en S3. Los logs del servidor pueden ser enviados opcionalmente a CloudTrail o a CloudWatch Logs",
      "Los archivos de la aplicación son almacenados en S3. Los registros del servidor se conservan únicamente en Glacier o enviados a CloudWatch Logs de forma automática",
      "El código de la aplicación se aloja en S3. Los registros del servidor están confinados a los volúmenes EBS conectados a las instancias EC2 del entorno"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nLos archivos de la aplicación se almacenan en Amazon S3. Los registros del servidor pueden configurarse para enviarse opcionalmente a Amazon S3 o Amazon CloudWatch Logs - Elastic Beanstalk almacena automáticamente los paquetes de despliegue de la aplicación en Amazon S3, donde pueden ser versionados y reutilizados. Los registros del servidor generados por las instancias EC2 pueden configurarse para subirse a un bucket de S3 o transmitirse a Amazon CloudWatch Logs, permitiendo una administración centralizada, monitoreo en tiempo real y alertas proactivas sobre el estado de la aplicación.\n\nOpciones incorrectas:\n\nLos archivos de la aplicación son almacenados en S3. Los registros del servidor se conservan únicamente en Glacier o enviados a CloudWatch Logs de forma automática - Aunque los registros podrían moverse posteriormente mediante reglas de ciclo de vida desde S3, Elastic Beanstalk no los almacena directamente allí. Glacier tampoco es adecuado para monitoreo en tiempo real.\n\nEl código de la aplicación se aloja en S3. Los registros del servidor están confinados a los volúmenes EBS conectados a las instancias EC2 del entorno - Inicialmente los logs residen en los volúmenes EBS de las instancias EC2, Elastic Beanstalk permite configurar su exportación automática a S3 o CloudWatch Logs, proporcionando persistencia y visibilidad más allá del ciclo de vida de la instancia.\n\nLa aplicación se guarda en S3. Los logs del servidor pueden ser enviados opcionalmente a CloudTrail o a CloudWatch Logs - Los registros operativos deben almacenarse en CloudWatch Logs o S3. Y AWS CloudTrail registra llamadas a la API, no logs de servidor o aplicación.\n\nReferencias:\n\nhttps://aws.amazon.com/elasticbeanstalk/faqs/"
  },
  {
    "q": "Una institución financiera ha desarrollado una solución de banca en línea basada en una arquitectura distribuida que requiere manejar picos de tráfico de usuarios durante ciertas horas del día, como pagos masivos o cierre de mercado. Como arquitecto de soluciones en AWS, se te ha encomendado el diseño de una arquitectura que asegure tanto alta escalabilidad como una estructura de costos optimizada para el uso en producción.\n¿Cuál de las siguientes alternativas representa la solución más eficiente para cumplir con estos requisitos?",
    "o": [
      "Implementar un Auto Scaling Group de instancias EC2 para los servicios de aplicación y una cola Amazon SQS como buffer de mensajes, con reglas de escalado automático basadas en el tamaño de la cola",
      "Usar un Application Load Balancer con múltiples instancias EC2 y Step Functions para almacenar los mensajes entre los componentes de la arquitectura distribuida",
      "Desplegar varias instancias EC2 On-Demand para alojar los servicios principales de la plataforma, junto con Amazon SQS para gestionar el flujo de mensajes entre servicios",
      "Implementar un Application Load Balancer con varias instancias EC2, complementado con Amazon SNS para actuar como buffer de mensajes entre servicios"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nImplementar un Auto Scaling Group de instancias EC2 para los servicios de aplicación y una cola Amazon SQS como buffer de mensajes, con reglas de escalado automático basadas en el tamaño de la cola - Esta combinación permite una solución escalable y rentable:\n\nEl Auto Scaling Group ajusta dinámicamente el número de instancias EC2 según la carga, ayudando a mantener la eficiencia operativa y reducir costos.\nAmazon SQS desacopla los componentes de la aplicación, funcionando como un buffer fiable y escalable que permite manejar picos de tráfico sin pérdida de mensajes.\n\n\nOpciones incorrectas:\n\nDesplegar varias instancias EC2 On-Demand para alojar los servicios principales de la plataforma, junto con Amazon SQS para gestionar el flujo de mensajes entre servicios - Las instancias On-Demand sin Auto Scaling pueden generar costos innecesarios y no se adaptan automáticamente a los cambios de demanda.\n\nUsar un Application Load Balancer con múltiples instancias EC2 y Step Functions para almacenar los mensajes entre los componentes de la arquitectura distribuida - Step Functions están diseñadas para orquestar flujos de trabajo y no funcionan como colas de mensajes escalables en tiempo real.\n\nImplementar un Application Load Balancer con varias instancias EC2, complementado con Amazon SNS para actuar como buffer de mensajes entre servicios - SNS es un servicio de publicación/suscripción, ideal para notificaciones, pero no ofrece el mismo control ni durabilidad que una cola como SQS, lo que es crucial en una plataforma financiera.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/autoscaling/ec2/userguide/as-using-sqs-queue.html\n\nhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-basic-architecture.html"
  },
  {
    "q": "Un equipo de ingeniería trabaja para una agencia aeroespacial en el sudeste asiático y está migrando un sistema de análisis de datos atmosféricos a la nube de AWS. Este sistema procesa grandes volúmenes de datos en tiempo real, lo cual requiere baja latencia de red y un alto rendimiento entre instancias EC2. Por esta razón, se optó por implementar las instancias dentro de un Cluster Placement Group.\nEl sistema ha estado funcionando de manera estable, pero recientemente, al intentar lanzar instancias adicionales en el mismo Placement Group, se generó un error indicando capacidad insuficiente (insufficient capacity error).\n¿Qué acción debería tomar el arquitecto para solucionar este inconveniente manteniendo la eficiencia de red del grupo existente?",
    "o": [
      "Detener todas las instancias dentro del Cluster Placement Group y reiniciarlas, luego lanzar las nuevas instancias",
      "Crear un nuevo Placement Group y lanzar allí las instancias restantes para evitar el error",
      "Asegurarse de que las nuevas instancias sean del mismo tipo que las actuales y volver a intentar el despliegue",
      "Solicitar a AWS un aumento del límite de instancias permitidas por Placement Group, ya que hay una restricción predeterminada de 12 instancias"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nDetener todas las instancias dentro del Cluster Placement Group y reiniciarlas, luego lanzar las nuevas instancias - Detener y reiniciar las instancias existentes en un Cluster Placement Group puede ayudar a reubicar todas las instancias sobre nuevo hardware con suficiente capacidad disponible. Esto facilita el aprovisionamiento de instancias adicionales en el mismo grupo, conservando las ventajas de rendimiento de red del cluster.\n\n\n\nOpciones incorrectas:\n\nSolicitar a AWS un aumento del límite de instancias permitidas por Placement Group, ya que hay una restricción predeterminada de 12 instancias - No existe un límite fijo de 12 instancias en un Placement Group; este número puede variar según el tipo de instancia y la capacidad disponible en la región.\n\nCrear un nuevo Placement Group y lanzar allí las instancias restantes para evitar el error - Evitaría el error, pero también eliminaría los beneficios de colocación cercana entre las instancias, clave para lograr baja latencia y alto rendimiento.\n\nAsegurarse de que las nuevas instancias sean del mismo tipo que las actuales y volver a intentar el despliegue - Aunque usar el mismo tipo de instancia es una buena práctica en Cluster Placement Groups, este error en particular está más relacionado con la falta de recursos físicos disponibles, no con la homogeneidad de tipos.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html#placement-groups-cluster\n\nhttp://docs.amazonaws.cn/en_us/AWSEC2/latest/UserGuide/troubleshooting-launch.html#troubleshooting-launch-capacity"
  },
  {
    "q": "Una agencia gubernamental dedicada a la ciberseguridad está desplegando un entorno de entrenamiento intensivo en AWS para simular escenarios de tráfico en tiempo real. El gerente del proyecto ha solicitado que se inicie una instancia EC2 de gran capacidad con un volumen EBS adjunto, y ha indicado explícitamente que se debe habilitar Enhanced Networking para maximizar el rendimiento de red entre sistemas distribuidos.\n¿En cuáles de los siguientes escenarios sería válido utilizar Enhanced Networking? (Selecciona DOS)",
    "o": [
      "Cuando se busca limitar la capacidad de red reduciendo el rendimiento en paquetes por segundo",
      "Cuando se necesita una infraestructura con alta latencia para pruebas de tolerancia",
      "Cuando se necesita una conexión física dedicada entre AWS y un centro de datos local (on-premises)",
      "Cuando se requiere un alto rendimiento en términos de paquetes por segundo (PPS)",
      "Cuando se necesita reducir la latencia entre instancias y mantener un rendimiento de red más predecible"
    ],
    "a": [
      3,
      4
    ],
    "e": "Correcto:\n\nCuando se requiere un alto rendimiento en términos de paquetes por segundo (PPS) - Enhanced Networking permite un mayor rendimiento de red utilizando SR-IOV (Single Root I/O Virtualization), lo que se traduce en un aumento significativo en la tasa de paquetes por segundo (PPS) y una reducción en la utilización de CPU, ideal para cargas de red intensivas como análisis en tiempo real o grandes volúmenes de tráfico de datos.\n\nCuando se necesita reducir la latencia entre instancias y mantener un rendimiento de red más predecible - Una de las principales ventajas es que proporciona una latencia más baja y constante entre instancias EC2. Esto es crucial para aplicaciones distribuidas o sensibles al tiempo, como simuladores, juegos multijugador en red o herramientas de análisis en línea.\n\nOpciones incorrectas:\n\nCuando se busca limitar la capacidad de red reduciendo el rendimiento en paquetes por segundo - Enhanced Networking está diseñado para mejorar el rendimiento de red, no para limitarlo. Si se desea menor capacidad de red, simplemente no se habilita esta opción.\n\nCuando se necesita una infraestructura con alta latencia para pruebas de tolerancia - Es generalmente un factor negativo en redes. Enhanced Networking precisamente reduce la latencia, por lo que no sería útil para escenarios que requieren latencia elevada como parte de una prueba artificial.\n\nCuando se necesita una conexión física dedicada entre AWS y un centro de datos local (on-premises) - Para establecer conexiones dedicadas entre AWS y un entorno on-premises, se debe utilizar AWS Direct Connect, no Enhanced Networking, que solo optimiza el rendimiento dentro de la nube de AWS.\n\nReferencias:\n\nhttp://docs.aws.amazon.com/AWSEC2/latest/UserGuide/enhanced-networking.html"
  },
  {
    "q": "Un servidor on-premises ejecuta una base de datos MySQL y será migrado a la nube de AWS. La empresa requiere una solución administrada que soporte alta disponibilidad y conmutación por error automática en caso de interrupción de una Zona de Disponibilidad (AZ).\n¿Qué solución se ajusta mejor a estos requisitos?",
    "o": [
      "Usar AWS Database Migration Service (DMS) para migrar directamente la base de datos a un despliegue Multi-AZ de Amazon RDS MySQL",
      "Usar AWS Database Migration Service (DMS) para migrar directamente la base de datos a un despliegue Multi-AZ de Amazon EC2 MySQL",
      "Crear una instantánea del servidor de base de datos MySQL y usar AWS DataSync para migrar los datos a Amazon S3. Lanzar un nuevo despliegue Multi-AZ de Amazon RDS MySQL desde la instantánea",
      "Usar AWS Database Migration Service (DMS) para migrar directamente la base de datos a Amazon RDS MySQL. Usar Schema Conversion Tool (SCT) para habilitar la conversión de MySQL a Amazon RDS"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nUsar AWS Database Migration Service (DMS) para migrar directamente la base de datos a un despliegue Multi-AZ de Amazon RDS MySQL - El servicio AWS DMS puede usarse para migrar directamente la base de datos MySQL a un despliegue Multi-AZ de Amazon RDS. Todo el proceso puede ser en línea y está administrado para ti. No es necesario realizar traducción de esquema entre MySQL y RDS (asumiendo que eliges el motor MySQL de RDS).\n\nOpciones incorrectas:\n\nUsar AWS Database Migration Service (DMS) para migrar directamente la base de datos a Amazon RDS MySQL. Usar Schema Conversion Tool (SCT) para habilitar la conversión de MySQL a Amazon RDS - No es necesario convertir el esquema al migrar de MySQL a Amazon RDS (motor MySQL).\n\nUsar AWS Database Migration Service (DMS) para migrar directamente la base de datos a un despliegue Multi-AZ de Amazon EC2 MySQL - No existe tal cosa como \"multi-AZ\" en Amazon EC2 con MySQL; debes usar RDS.\n\nCrear una instantánea del servidor de base de datos MySQL y usar AWS DataSync para migrar los datos a Amazon S3. Lanzar un nuevo despliegue Multi-AZ de Amazon RDS MySQL desde la instantánea - No puedes crear una instantánea de un servidor de base de datos MySQL ejecutándose on-premises.\n\nReferencias:\n\nhttps://aws.amazon.com/rds/features/multi-az/\n\nhttps://docs.aws.amazon.com/dms/latest/userguide/CHAP_Introduction.html"
  },
  {
    "q": "Una aplicación web empresarial se ejecuta en un conjunto de instancias EC2 que se escalan automáticamente mediante un Auto Scaling Group. La base de datos que respalda esta aplicación es un servidor Microsoft SQL Server alojado en Amazon RDS. Por políticas de cumplimiento y seguridad de datos, es obligatorio que toda la comunicación entre las instancias web y la base de datos esté cifrada durante la transmisión.\n¿Cuáles de las siguientes acciones deberías implementar para garantizar la seguridad de los datos en tránsito entre la capa de aplicación y la base de datos? (Selecciona DOS)",
    "o": [
      "Aplicar Transparent Data Encryption (TDE) mediante un grupo de opciones en RDS para habilitar el cifrado en reposo",
      "Habilitar el parámetro rds.force_ssl y reiniciar la instancia de RDS para forzar el uso obligatorio de conexiones cifradas",
      "Descargar el certificado raíz de Amazon RDS, importarlo en las instancias EC2 y configurar la aplicación para establecer conexiones seguras (SSL) con RDS",
      "Activar la autenticación mediante IAM en la instancia de RDS utilizando la consola de administración de AWS",
      "Limitar el acceso de red a través del puerto 443 configurando reglas en los grupos de seguridad de EC2 y RDS"
    ],
    "a": [
      1,
      2
    ],
    "e": "Correcto:\n\nDescargar el certificado raíz de Amazon RDS, importarlo en las instancias EC2 y configurar la aplicación para establecer conexiones seguras (SSL) con RDS - Para establecer conexiones seguras (SSL) entre las instancias EC2 y la base de datos RDS que ejecuta SQL Server, se requiere importar el certificado raíz proporcionado por Amazon y configurar la aplicación para conectarse usando SSL. Esto asegura que todos los datos transmitidos estén cifrados.\n\nHabilitar el parámetro rds.force_ssl y reiniciar la instancia de RDS para forzar el uso obligatorio de conexiones cifradas - El parámetro obliga a que todas las conexiones a la base de datos se establezcan a través de SSL. Esta medida garantiza que incluso si un cliente no configura explícitamente SSL, la base de datos rechazará conexiones no seguras. Después de habilitar este parámetro, es necesario reiniciar la instancia para aplicar el cambio.\n\nOpciones incorrectas:\n\nActivar la autenticación mediante IAM en la instancia de RDS utilizando la consola de administración de AWS - Solo es compatible con motores MySQL y PostgreSQL, por lo que no puede aplicarse a instancias que ejecutan Microsoft SQL Server.\n\nAplicar Transparent Data Encryption (TDE) mediante un grupo de opciones en RDS para habilitar el cifrado en reposo - Unicamente se realiza dentro de la base de datos, pero no protege los datos durante su transmisión entre la aplicación y la base de datos.\n\nLimitar el acceso de red a través del puerto 443 configurando reglas en los grupos de seguridad de EC2 y RDS - Aunque restringir el tráficopuede mejorar la seguridad general, no asegura por sí solo que los datos transmitidos estén cifrados, ya que SSL/TLS debe estar configurado explícitamente.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/SQLServer.Concepts.General.SSL.Using.html\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Appendix.SQLServer.Options.TDE.html\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.IAMDBAuth.html"
  },
  {
    "q": "Una fintech ha desarrollado una aplicación web para visualización y análisis de datos financieros, empaquetada como un contenedor Docker utilizando la pila MEAN (MongoDB, Express.js, Angular y Node.js). El equipo desea migrar esta aplicación a AWS sin preocuparse por configurar manualmente el balanceo de carga, el autoescalado, el monitoreo o la gestión de la infraestructura de contenedores.\nSe busca una solución que simplifique la implementación y proporcione administración automática de los recursos subyacentes para garantizar disponibilidad y escalabilidad desde el primer momento.\n¿Qué servicio de AWS es más adecuado para cumplir con estos requisitos?",
    "o": [
      "Usar AWS Compute Optimizer para obtener recomendaciones de recursos antes de implementar la aplicación",
      "Utilizar AWS CloudFormation para definir la infraestructura de la aplicación mediante plantillas",
      "Desplegar la aplicación utilizando AWS Elastic Beanstalk con soporte para contenedores Docker",
      "Implementar la aplicación usando Amazon ECS y configurar manualmente el balanceo de carga, escalado y monitoreo"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nDesplegar la aplicación utilizando AWS Elastic Beanstalk con soporte para contenedores Docker - Permite implementar aplicaciones web basadas en contenedores Docker de forma rápida, sin necesidad de gestionar manualmente la infraestructura. Proporciona balanceo de carga, escalado automático, monitoreo con CloudWatch y aprovisionamiento de recursos automáticamente. Es ideal para desarrolladores que desean centrarse en el código sin preocuparse por la gestión de la plataforma.\n\n\n\nOpciones incorrectas:\n\nUtilizar AWS CloudFormation para definir la infraestructura de la aplicación mediante plantillas - Permite definir recursos de infraestructura como código, pero no ofrece implementación automática ni monitoreo directo de contenedores sin configuración adicional.\n\nUsar AWS Compute Optimizer para obtener recomendaciones de recursos antes de implementar la aplicación - Brinda recomendaciones para mejorar la eficiencia de recursos, pero no implementa ni gestiona aplicaciones.\n\nImplementar la aplicación usando Amazon ECS y configurar manualmente el balanceo de carga, escalado y monitoreo - Es un potente orquestador de contenedores, pero requiere configuración explícita del cluster, tareas, servicio, escalado y balanceo, lo que añade complejidad en comparación con Beanstalk.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create_deploy_docker.html"
  },
  {
    "q": "Una corporación multinacional está reorganizando su infraestructura en la nube para mejorar la colaboración entre departamentos. Actualmente, el departamento de Recursos Humanos tiene una VPC dedicada en la región us-west-2, mientras que el departamento de Finanzas opera en una VPC diferente ubicada en la región eu-central-1. El nuevo diseño debe permitir comunicación bidireccional entre ambas VPCs, con una arquitectura que sea escalable y fácil de gestionar para futuras expansiones multi-región.\nAdemás, debido a regulaciones internas y normativas de cumplimiento, se requiere implementar un sistema de prevención de intrusos (IPS) que inspeccione el tráfico en tiempo real y bloquee actividades sospechosas o intentos de explotación de vulnerabilidades a nivel de red.\n¿Qué solución debe implementar el arquitecto de soluciones para cumplir con estos requisitos técnicos y de seguridad?",
    "o": [
      "Establecer una conexión mediante NAT Gateway entre las VPCs y gestionar la seguridad de red con AWS Systems Manager Session Manager",
      "Implementar un AWS Transit Gateway para establecer la conectividad entre ambas VPCs. Usar AWS Network Firewall con capacidades IPS para proteger y monitorear el tráfico de red entre regiones",
      "Definir políticas de enrutamiento personalizadas en Amazon Route 53 para conectar las VPCs. Usar DNS Firewall de Route 53 para filtrar e inspeccionar el tráfico de red",
      "Utilizar Direct Connect Gateway para interconectar las VPCs y aplicar políticas de cumplimiento con AWS Security Hub"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nImplementar un AWS Transit Gateway para establecer la conectividad entre ambas VPCs. Usar AWS Network Firewall con capacidades IPS para proteger y monitorear el tráfico de red entre regiones - Es la mejor práctica para conectar múltiples VPCs en diferentes regiones, permitiendo una arquitectura escalable, eficiente y centralizada. Además, se puede integrar con AWS Network Firewall, que actúa como un firewall administrado con capacidades de detección y prevención de intrusiones (IPS), ideal para inspeccionar tráfico de red entre departamentos y bloquear amenazas en tiempo real.\n\n\n\nOpciones incorrectas:\n\nDefinir políticas de enrutamiento personalizadas en Amazon Route 53 para conectar las VPCs. Usar DNS Firewall de Route 53 para filtrar e inspeccionar el tráfico de red - Este servicio está orientado a resolución de nombres DNS y no proporciona conectividad entre redes VPC. Además, su DNS Firewall solo analiza tráfico DNS, no tráfico general de red ni protocolos de aplicación.\n\nUtilizar Direct Connect Gateway para interconectar las VPCs y aplicar políticas de cumplimiento con AWS Security Hub - El uso principal de Direct Connect es para conectar redes locales (on-premises) con AWS, no para interconectar VPCs entre regiones. Security Hub ofrece visibilidad sobre el estado de seguridad, pero no protege ni inspecciona el tráfico directamente.\n\nEstablecer una conexión mediante NAT Gateway entre las VPCs y gestionar la seguridad de red con AWS Systems Manager Session Manager - No es adecuado para establecer conectividad entre VPCs. Además, Systems Manager Session Manager se enfoca en el acceso a instancias EC2, no en el control de tráfico entre redes.\n\nReferencias:\n\nhttps://aws.amazon.com/transit-gateway/\n\nhttps://aws.amazon.com/network-firewall/\n\nhttps://docs.aws.amazon.com/vpc/latest/tgw/tgw-transit-gateways.html"
  },
  {
    "q": "Una organización internacional especializada en diagnóstico biomédico ha desarrollado una plataforma avanzada que proporciona imágenes moleculares de alta resolución a investigadores y hospitales. Estas imágenes, actualizadas con frecuencia, muestran cambios celulares en tiempo casi real y son almacenadas en un bucket de Amazon S3, expuestas a través de una distribución web de Amazon CloudFront para ofrecer baja latencia a nivel global.\nEl equipo técnico necesita garantizar que, al cargar nuevas versiones de un conjunto de imágenes, las versiones anteriores permanezcan accesibles para auditorías, estudios longitudinales y comparaciones históricas. Deben evitarse sobrescrituras accidentales o pérdida de datos anteriores.\n¿Cuál es la solución más eficaz y sencilla para asegurar la conservación de todas las versiones de los archivos de imágenes subidos a S3?",
    "o": [
      "Aplicar cabeceras Cache-Control como no-cache, no-store o private a los objetos del bucket S3",
      "Crear un comportamiento de caché específico en CloudFront y establecer un TTL personalizado mínimo de 0",
      "Utilizar el mecanismo de invalidación de objetos en la distribución de CloudFront cada vez que se suban nuevas imágenes",
      "Habilitar el versionado de objetos en el bucket de Amazon S3"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nHabilitar el versionado de objetos en el bucket de Amazon S3 - La habilitación del versionado permite que cada archivo subido sea almacenado como una nueva versión, preservando automáticamente las versiones anteriores sin sobrescribirlas. Esta es la forma más sencilla y robusta de garantizar la retención de datos históricos, especialmente útil en entornos científicos y médicos donde el acceso a datos pasados es crucial. CloudFront puede integrarse fácilmente con objetos versionados sin requerir invalidaciones constantes.\n\nOpciones incorrectas:\n\nAplicar cabeceras Cache-Control como no-cache, no-store o private a los objetos del bucket S3 - No evitan sobrescrituras de archivos en S3. No satisfacen el requisito de preservar versiones anteriores.\n\nCrear un comportamiento de caché específico en CloudFront y establecer un TTL personalizado mínimo de 0 - Establecer un TTL bajo reduce el tiempo de caché en CloudFront, pero no influye en el almacenamiento de versiones dentro de S3.\n\nUtilizar el mecanismo de invalidación de objetos en la distribución de CloudFront cada vez que se suban nuevas imágenes - Puede forzar la actualización del contenido en caché, pero no evita la sobrescritura de archivos en S3 ni conserva versiones anteriores, y además incurre en costos adicionales si se realiza con frecuencia.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/UpdatingExistingObjects.html\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/prevent-cloudfront-from-caching-files/\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/Versioning.html"
  },
  {
    "q": "Una aplicación hace llamadas a una API REST ejecutándose en instancias de Amazon EC2 detrás de un Application Load Balancer (ALB). La mayoría de las llamadas API se completan rápidamente. Sin embargo, un único endpoint está haciendo llamadas API que requieren mucho más tiempo para completarse y esto está introduciendo latencia general en el sistema. ¿Qué pasos puede tomar un arquitecto de soluciones para minimizar los efectos de las llamadas API de larga duración?",
    "o": [
      "Cambiar la instancia EC2 a una con redes mejoradas para reducir la latencia",
      "Crear una cola de Amazon SQS y desacoplar las llamadas API de larga duración",
      "Aumentar el timeout de inactividad del ALB para permitir que las solicitudes de larga duración se completen",
      "Cambiar el ALB a un Network Load Balancer (NLB) y usar terminación SSL/TLS"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nCrear una cola de Amazon SQS y desacoplar las llamadas API de larga duración - Amazon Simple Queue Service (SQS) puede usarse para descargar y desacoplar las solicitudes de larga duración. Luego pueden procesarse de forma asíncrona por instancias EC2 separadas. Esta es la mejor manera de reducir la latencia general introducida por la llamada API de larga duración.\n\nOpciones incorrectas:\n\nAumentar el timeout de inactividad del ALB para permitir que las solicitudes de larga duración se completen - El problema no es que la conexión se interrumpa; es que la llamada API toma mucho tiempo en completarse.\n\nCambiar la instancia EC2 a una con redes mejoradas para reducir la latencia - Esto no reducirá la latencia de la llamada API ya que la latencia de red no es el problema aquí; es la latencia de cuánto tiempo tarda la llamada API en completarse.\n\nCambiar el ALB a un Network Load Balancer (NLB) y usar terminación SSL/TLS - La terminación SSL/TLS no es beneficiosa aquí ya que el problema no es el cifrado o el procesamiento del cifrado. El problema es la latencia de la llamada API.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/welcome.html"
  },
  {
    "q": "Una compañía tecnológica que desarrolla soluciones móviles mantiene múltiples cuentas de AWS tipo sandbox utilizadas por su equipo de innovación. Para facilitar el acceso a recursos compartidos, todos los desarrolladores deben poder leer objetos almacenados en un bucket S3 ubicado en la cuenta central del entorno corporativo. Además, es fundamental garantizar que cualquier carga de archivos sensibles —como datos financieros o información de identificación personal (PII)— sea detectada automáticamente y sujeta a monitoreo continuo.\n¿Cuál es la forma más eficiente y rentable de cumplir con estos requisitos con un esfuerzo mínimo de configuración?",
    "o": [
      "Usar URLs pre-firmadas para compartir el acceso a los objetos S3. Utilizar Amazon S3 Storage Lens para analizar los datos sensibles",
      "Habilitar la replicación de objetos entre cuentas en el bucket S3. Configurar AWS Audit Manager para auditar la presencia de PII o información financiera",
      "Aplicar una política de bucket S3 que permita acceso desde cuentas sandbox. Implementar Amazon Macie para identificar información sensible como PII o datos financieros",
      "Conceder permisos de lectura sobre S3 en las políticas de IAM de cada desarrollador dentro de las cuentas sandbox. Utilizar Amazon Detective para detectar datos sensibles como PII o financieros"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nAplicar una política de bucket S3 que permita acceso desde cuentas sandbox. Implementar Amazon Macie para identificar información sensible como PII o datos financieros - Utilizar políticas de bucket en Amazon S3 permite habilitar el acceso entre cuentas de forma sencilla y centralizada, sin necesidad de modificar múltiples políticas IAM individuales. Esto reduce significativamente el esfuerzo de configuración y mejora la gestión. Además, Amazon Macie ofrece una solución nativa y automatizada para el descubrimiento y clasificación de datos sensibles como PII o información financiera, cumpliendo con los requerimientos de seguridad.\n\nOpciones incorrectas:\n\nConceder permisos de lectura sobre S3 en las políticas de IAM de cada desarrollador dentro de las cuentas sandbox. Utilizar Amazon Detective para detectar datos sensibles como PII o financieros - Aunque otorgar permisos a nivel de IAM es viable, no es escalable cuando se gestiona un gran número de usuarios o cuentas. Además, Amazon Detective está orientado al análisis de comportamientos sospechosos y no al escaneo de datos sensibles en S3.\n\nUsar URLs pre-firmadas para compartir el acceso a los objetos S3. Utilizar Amazon S3 Storage Lens para analizar los datos sensibles - Las URLs pre-firmadas implican un manejo continuo de tokens de acceso y no ofrecen un mecanismo sostenible para cargas compartidas permanentes. S3 Storage Lens, por su parte, proporciona métricas de almacenamiento, pero no realiza análisis de contenido ni identifica datos sensibles.\n\nHabilitar la replicación de objetos entre cuentas en el bucket S3. Configurar AWS Audit Manager para auditar la presencia de PII o información financiera - La replicación entre cuentas puede ser costosa y compleja, especialmente cuando no se requiere duplicación de objetos. AWS Audit Manager ayuda con auditorías de cumplimiento, pero no tiene la capacidad de escanear datos en busca de PII.\n\nReferencias:\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/cross-account-access-s3/\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/example-walkthroughs-managing-access-example2.html\n\nhttps://aws.amazon.com/macie/"
  },
  {
    "q": "Una organización del sector médico ha desplegado una función en AWS Lambda para recibir y procesar datos clínicos que provienen de una plataforma externa de análisis predictivo. Cada vez que se generan nuevos resultados analíticos, dicha plataforma realiza una solicitud HTTP POST a un webhook configurado por la organización para activar automáticamente la función Lambda.\nEl equipo de arquitectura busca una solución sencilla y de bajo mantenimiento que permita exponer la función Lambda mediante un endpoint accesible vía HTTPS.\n¿Cuál sería la opción más eficiente operativamente para asegurar que la función Lambda pueda ser invocada por la plataforma de análisis externa?",
    "o": [
      "Conectar la función Lambda a una cola SQS y usar la URL de la cola como webhook para recibir las solicitudes HTTP",
      "Utilizar una Lambda Function URL para generar un endpoint HTTPS y proporcionarlo como webhook a la plataforma externa",
      "Configurar Amazon API Gateway como intermediario para invocar la función Lambda y usar el endpoint expuesto como webhook",
      "Implementar una instancia EC2 que reciba las solicitudes como proxy y redirija las invocaciones a la función Lambda"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nUtilizar una Lambda Function URL para generar un endpoint HTTPS y proporcionarlo como webhook a la plataforma externa - Permiten asignar una URL HTTPS directamente a una función Lambda, facilitando su invocación desde servicios externos sin necesidad de infraestructura adicional. Esta solución es operativamente eficiente y está diseñada específicamente para casos como webhooks, donde se requiere una integración rápida y directa basada en HTTP.\n\n\n\nOpciones incorrectas:\n\nConectar la función Lambda a una cola SQS y usar la URL de la cola como webhook para recibir las solicitudes HTTP - El servicio de Amazon SQS no acepta solicitudes HTTP directas desde clientes externos, por lo tanto no puede ser usado como webhook desde un sistema de terceros.\n\nImplementar una instancia EC2 que reciba las solicitudes como proxy y redirija las invocaciones a la función Lambda - Esto introduce una complejidad innecesaria, eleva los costos operativos y anula las ventajas de una arquitectura serverless.\n\nConfigurar Amazon API Gateway como intermediario para invocar la función Lambda y usar el endpoint expuesto como webhook - Es una alternativa válida para exponer funciones Lambda vía HTTP, requiere configuración más detallada, políticas de autorización y mantenimiento adicional en comparación con la sencillez de una Function URL.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/lambda/latest/dg/urls-configuration.html\n\nhttps://docs.aws.amazon.com/lambda/latest/dg/lambda-urls.html"
  },
  {
    "q": "Una empresa del sector telecomunicaciones desea analizar las conversaciones entre sus representantes de soporte técnico y los usuarios finales para identificar patrones de satisfacción del cliente. Cada interacción es transcrita automáticamente y almacenada como un archivo JSON en un bucket de Amazon S3. El arquitecto de soluciones necesita diseñar un sistema que permita extraer los sentimientos expresados en las transcripciones y presentar esta información de forma visual para ayudar al equipo de calidad a tomar decisiones basadas en datos.\n¿Cuál sería la solución más adecuada que minimiza el esfuerzo operativo y permite una rápida implementación?",
    "o": [
      "Entrenar un modelo de NLP personalizado en Amazon SageMaker para analizar los sentimientos. Indexar los resultados en Amazon OpenSearch y usar su Dashboard para visualizar la información",
      "Utilizar Amazon Comprehend para analizar el sentimiento de las transcripciones. Indexar los resultados junto con el texto original en un clúster de Amazon OpenSearch y visualizar la información mediante OpenSearch Dashboard",
      "Usar Amazon Comprehend para el análisis de sentimiento y visualizar los resultados directamente en Amazon Managed Grafana tras indexarlos en Amazon OpenSearch",
      "Procesar los archivos JSON con Amazon Textract. Indexar los resultados en Amazon OpenSearch y usar el Dashboard para visualizarlos"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nUtilizar Amazon Comprehend para analizar el sentimiento de las transcripciones. Indexar los resultados junto con el texto original en un clúster de Amazon OpenSearch y visualizar la información mediante OpenSearch Dashboard - Amazon Comprehend proporciona un servicio completamente administrado que analiza texto no estructurado y extrae información clave como el sentimiento, de forma inmediata, sin necesidad de entrenar modelos personalizados. La integración con Amazon OpenSearch permite indexar tanto la transcripción como los resultados del análisis, facilitando la creación de dashboards interactivos para análisis visual en OpenSearch Dashboard, lo cual reduce la sobrecarga operativa y acelera la implementación.\n\n\n\nOpciones incorrectas:\n\nProcesar los archivos JSON con Amazon Textract. Indexar los resultados en Amazon OpenSearch y usar el Dashboard para visualizarlos - El servicio de Amazon Textract está diseñado para extraer texto desde imágenes y documentos escaneados, no para analizar el contenido emocional o semántico del texto. No es aplicable para análisis de sentimiento.\n\nEntrenar un modelo de NLP personalizado en Amazon SageMaker para analizar los sentimientos. Indexar los resultados en Amazon OpenSearch y usar su Dashboard para visualizar la información - Aunque Amazon SageMaker puede utilizarse para entrenar modelos personalizados de NLP, esto requiere tiempo, recursos y habilidades avanzadas de machine learning. En comparación, Amazon Comprehend ofrece un servicio de análisis de sentimientos listo para usar.\n\nUsar Amazon Comprehend para el análisis de sentimiento y visualizar los resultados directamente en Amazon Managed Grafana tras indexarlos en Amazon OpenSearch - Mientras que Amazon Managed Grafana se especializa en la visualización de métricas, logs y datos temporales. Aunque se podría adaptar para mostrar resultados de texto, OpenSearch Dashboard es la herramienta más adecuada para búsquedas e indexación de texto estructurado y no estructurado.\n\nReferencias:\n\nhttps://aws.amazon.com/solutions/implementations/text-analysis-with-amazon-opensearch-service-and-amazon-comprehend/\n\nhttps://docs.aws.amazon.com/opensearch-service/latest/developerguide/walkthrough.html#walkthrough-analysis"
  },
  {
    "q": "Los datos relacionados con salud en Amazon S3 necesitan ser accedidos frecuentemente hasta por 90 días. Después de ese tiempo, los datos deben retenerse por razones de cumplimiento durante siete años y rara vez se acceden.\n¿Qué clases de almacenamiento deben usarse?",
    "o": [
      "Almacenar datos en STANDARD por 90 días y luego hacer la transición de los datos a DEEP_ARCHIVE",
      "Almacenar datos en INTELLIGENT_TIERING por 90 días y luego hacer la transición a STANDARD_IA",
      "Almacenar datos en STANDARD por 90 días y luego expirar los datos",
      "Almacenar datos en STANDARD por 90 días y luego hacer la transición a REDUCED_REDUNDANCY"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nAlmacenar datos en STANDARD por 90 días y luego hacer la transición de los datos a DEEP_ARCHIVE - En este caso, los datos se acceden frecuentemente, por lo que deben almacenarse en standard durante los primeros 90 días. Después de eso, los datos aún deben mantenerse por razones de cumplimiento pero rara vez se acceden, por lo que es un buen caso de uso para DEEP_ARCHIVE.\n\nOpciones incorrectas:\n\nAlmacenar datos en STANDARD por 90 días y luego expirar los datos - Expirar los datos no es posible ya que deben retenerse por cumplimiento.\n\nAlmacenar datos en INTELLIGENT_TIERING por 90 días y luego hacer la transición a STANDARD_IA - No puedes hacer la transición de INTELLIGENT_TIERING a STANDARD_IA.\n\nAlmacenar datos en STANDARD por 90 días y luego hacer la transición a REDUCED_REDUNDANCY - No puedes hacer la transición de ninguna clase de almacenamiento a REDUCED_REDUNDANCY.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/lifecycle-transition-general-considerations.html"
  },
  {
    "q": "Una compañía de tecnología industrial ha desarrollado un nuevo sensor IoT para monitorear condiciones ambientales en tiempo real dentro de plantas de producción. Estos sensores generan grandes volúmenes de datos de manera continua, que deben ser ingeridos, procesados y almacenados con una latencia mínima para su análisis casi instantáneo. El equipo de ingeniería requiere una solución que permita analizar esta información en tiempo real con tiempos de respuesta en el orden de los milisegundos para habilitar reacciones automáticas en los sistemas de control.\n¿Cuál de las siguientes arquitecturas es la más adecuada para satisfacer estos requisitos de procesamiento y respuesta en tiempo real?",
    "o": [
      "Usar Amazon SQS como mecanismo de ingestión de eventos y una función Lambda para almacenar los datos en Amazon Redshift",
      "Implementar Amazon Kinesis Data Firehose para la entrega automática y utilizar AWS Lambda para insertar los datos en Amazon DynamoDB",
      "Configurar Amazon Kinesis Data Streams y una función Lambda que almacene los datos directamente en Amazon Redshift",
      "Utilizar Amazon Kinesis Data Streams para la ingestión de datos y una función de AWS Lambda para procesar y almacenar los datos en Amazon DynamoDB"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nUtilizar Amazon Kinesis Data Streams para la ingestión de datos y una función de AWS Lambda para procesar y almacenar los datos en Amazon DynamoDB - La combinación permite ejecutar funciones sin servidor que pueden procesar eventos en tiempo real. Al almacenar los datos en Amazon DynamoDB —una base de datos NoSQL altamente escalable con tiempos de lectura/escritura en milisegundos— se garantiza una solución rápida y eficiente, ideal para sistemas de IoT de alta frecuencia.\n\n\n\nOpciones incorrectas:\n\nUsar Amazon SQS como mecanismo de ingestión de eventos y una función Lambda para almacenar los datos en Amazon Redshift - Esta solución no es óptimo para escenarios de ingestión de datos en tiempo real. Además, Amazon Redshift tiene tiempos de latencia en segundos, por lo que no cumple con el requisito de milisegundos.\n\nImplementar Amazon Kinesis Data Firehose para la entrega automática y utilizar AWS Lambda para insertar los datos en Amazon DynamoDB - El servicio Kinesis Data Firehose no admite DynamoDB como destino directo. Firehose está pensado para entregas automáticas a S3, Redshift o OpenSearch, por lo que necesitaría una arquitectura más compleja para integrar con DynamoDB.\n\nConfigurar Amazon Kinesis Data Streams y una función Lambda que almacene los datos directamente en Amazon Redshift - Si bien se cumple se con el requisito de ingestión en tiempo real, Amazon Redshift no está optimizado para almacenamiento y consulta con latencias tan bajas, ya que es una base de datos orientada a análisis en batch.\n\nReferencias:\n\nhttps://aws.amazon.com/kinesis/data-streams/faqs/\n\nhttps://aws.amazon.com/dynamodb/"
  },
  {
    "q": "Una compañía de desarrollo de videojuegos inmersivos ha experimentado un rápido crecimiento con sus aplicaciones de realidad virtual (VR) y realidad aumentada (AR). Actualmente, sus APIs RESTful se ejecutan en servidores físicos dentro de su centro de datos, lo que ha empezado a limitar su capacidad para escalar y controlar costos ante la creciente demanda global.\nLa empresa desea migrar estas APIs a AWS para obtener mayor elasticidad, reducir la carga operativa y optimizar los costos de infraestructura.\n¿Cuál de las siguientes opciones representa la solución más rentable, escalable y de fácil mantenimiento para este caso de uso?",
    "o": [
      "Implementar las APIs usando AWS Lambda junto con Amazon API Gateway para una arquitectura completamente sin servidor",
      "Diseñar una arquitectura basada en microservicios utilizando Amazon ECS con imágenes almacenadas en ECR y ejecutadas sobre Fargate",
      "Almacenar las APIs como archivos JavaScript estáticos en un bucket de Amazon S3, sirviéndolos mediante una distribución de CloudFront",
      "Ejecutar las APIs sobre una flota de instancias Spot de Amazon EC2 con Elastic Fabric Adapter (EFA) y balancear la carga mediante un Application Load Balancer"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nImplementar las APIs usando AWS Lambda junto con Amazon API Gateway para una arquitectura completamente sin servidor - AWS Lambda permite ejecutar funciones sin necesidad de administrar servidores, lo que reduce significativamente los costos, especialmente en aplicaciones con tráfico variable. Al integrarse con Amazon API Gateway, puedes exponer fácilmente tus funciones como endpoints HTTP(S) seguros y escalables. Esta solución sin servidor es ideal para migrar APIs RESTful y soportar cargas impredecibles con mínimo esfuerzo operacional y gran escalabilidad.\n\n\n\nOpciones incorrectas:\n\nDiseñar una arquitectura basada en microservicios utilizando Amazon ECS con imágenes almacenadas en ECR y ejecutadas sobre Fargate - Aunque se simplifica la ejecución de contenedores, no es tan rentable ni tan fácil de escalar como Lambda cuando se trata de cargas ligeras y altamente variables como las de APIs.\n\nAlmacenar las APIs como archivos JavaScript estáticos en un bucket de Amazon S3, sirviéndolos mediante una distribución de CloudFront - Es ideal para contenido estático, pero no puede ejecutar código o manejar lógica dinámica necesaria para APIs RESTful.\n\nEjecutar las APIs sobre una flota de instancias Spot de Amazon EC2 con Elastic Fabric Adapter (EFA) y balancear la carga mediante un Application Load Balancer - Estos servicios están orientados a cargas de trabajo de computación de alto rendimiento (HPC), como simulaciones científicas. Este enfoque no es óptimo para servir APIs web, ya que carece de la elasticidad y simplicidad de una solución sin servidor.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/getting-started-with-lambda-integration.html\n\nhttps://aws.amazon.com/lambda/pricing/"
  },
  {
    "q": "Una compañía de medios digitales utiliza Amazon S3 para almacenar imágenes y videos que son cargados constantemente por colaboradores externos a través de una plataforma web. Todos los archivos se almacenan en un bucket S3 centralizado que es propiedad de la empresa.\nEl equipo de seguridad ha detectado que, por defecto, los archivos subidos por usuarios externos no otorgan automáticamente al propietario del bucket acceso total, lo que dificulta la gestión y el procesamiento de esos archivos por parte de la empresa.\n¿Qué solución debe implementar el arquitecto de soluciones para garantizar que la empresa tenga siempre control completo sobre todos los objetos cargados por terceros en el bucket?",
    "o": [
      "Configurar políticas CORS para habilitar el acceso entre dominios a los objetos del bucket",
      "Activar la opción Requester Pays en el bucket para que los usuarios externos asuman los costos de carga y descarga",
      "Implementar una bucket policy que exija a los usuarios establecer el ACL en bucket-owner-full-control al momento de la carga",
      "Habilitar el server access logging y aplicar una política IAM que exija a los usuarios configurar el ACL en bucket-owner-full-control"
    ],
    "a": [
      2
    ],
    "e": "Opción correcta:\n\nImplementar una bucket policy que exija a los usuarios establecer el ACL en bucket-owner-full-control al momento de la carga - En Amazon S3, cuando un usuario externo sube un objeto, ese objeto es propiedad de quien lo carga. Para que el propietario del bucket tenga acceso total a esos objetos, se debe requerir que los usuarios establezcan el ACL bucket-owner-full-control al momento de cargar el archivo. Esto se puede hacer automáticamente mediante una bucket policy que imponga esta condición.\n\n\n\nOpciones incorrectas:\n\nActivar la opción Requester Pays en el bucket para que los usuarios externos asuman los costos de carga y descarga - Requester Pays solo transfiere los costos de acceso al bucket, pero no otorga control sobre los objetos al propietario del bucket.\n\nHabilitar el server access logging y aplicar una política IAM que exija a los usuarios configurar el ACL en bucket-owner-full-control - El server access logging genera registros de acceso, pero no afecta los permisos ni la propiedad de los objetos subidos.\n\nConfigurar políticas CORS para habilitar el acceso entre dominios a los objetos del bucket - Las reglas para el acceso entre dominios en aplicaciones web, pero no gestiona permisos de nivel de objeto ni otorga acceso adicional al propietario del bucket.\n\nReferencias:\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/s3-bucket-owner-access/\n\nhttps://aws.amazon.com/premiumsupport/knowledge-center/s3-require-object-ownership/"
  },
  {
    "q": "Una empresa está en el proceso de mejorar su postura de seguridad y quiere analizar y rectificar un alto volumen de intentos de inicio de sesión fallidos y actividades no autorizadas que se están registrando en AWS CloudTrail.\n¿Cuál es la solución más eficiente para ayudar a la empresa a identificar estos eventos de seguridad con la MENOR cantidad de esfuerzo operativo?",
    "o": [
      "Aprovechar AWS Lambda para activarse en actualizaciones de registros de CloudTrail y usar un script personalizado para escanear inicios de sesión fallidos y acciones no autorizadas.",
      "Usar Amazon Athena para consultar directamente los registros de CloudTrail en busca de inicios de sesión fallidos y actividades no autorizadas.",
      "Utilizar AWS Data Pipeline para extraer regularmente los registros de CloudTrail y usar un script personalizado para identificar los eventos de seguridad requeridos.",
      "Implementar Amazon Elasticsearch Service con Kibana para visualizar los registros de CloudTrail y buscar manualmente estos eventos."
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nUsar Amazon Athena para consultar directamente los registros de CloudTrail en busca de inicios de sesión fallidos y actividades no autorizadas. - Amazon Athena puede consultar directamente datos de S3 (donde se almacenan los registros de CloudTrail) usando SQL estándar, lo que lo convierte en una herramienta poderosa y eficiente para analizar estos registros. No necesitas administrar ninguna infraestructura ni escribir scripts personalizados, y puedes escribir y ejecutar consultas rápidamente para identificar los eventos de seguridad requeridos.\n\nOpciones incorrectas:\n\nUtilizar AWS Data Pipeline para extraer regularmente los registros de CloudTrail y usar un script personalizado para identificar los eventos de seguridad requeridos. - Esta solución podría funcionar, pero la sobrecarga operativa de administrar el proceso de extracción y mantener un script personalizado para análisis no es mínima.\n\nImplementar Amazon Elasticsearch Service con Kibana para visualizar los registros de CloudTrail y buscar manualmente estos eventos. - Aunque Elasticsearch y Kibana proporcionan capacidades poderosas de búsqueda y visualización, respectivamente, requieren una cantidad considerable de configuración y gestión. Esta opción proporcionaría análisis más profundos y monitoreo en tiempo real, pero no sería la forma más eficiente de simplemente identificar los eventos de seguridad mencionados.\n\nAprovechar AWS Lambda para activarse en actualizaciones de registros de CloudTrail y usar un script personalizado para escanear inicios de sesión fallidos y acciones no autorizadas. - Aunque las funciones Lambda pueden activarse basándose en actualizaciones de registros de CloudTrail y teóricamente podrían usarse para escanear eventos de seguridad, esto requeriría una configuración sustancial y mantenimiento continuo del script. No es la opción más eficiente.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/athena/latest/ug/cloudtrail-logs.html"
  },
  {
    "q": "Un arquitecto de soluciones está configurando una estrategia de recuperación ante desastres para una aplicación crítica, utilizando Amazon S3 como almacenamiento principal. Al intentar habilitar la replicación entre regiones (Cross-Region Replication, CRR) desde un bucket de origen en una región primaria hacia un bucket de destino en una región secundaria, observa que la opción aparece desactivada en la consola. ¿Cuál de las siguientes podría ser la causa más probable de que la opción de replicación entre regiones esté deshabilitada?",
    "o": [
      "La funcionalidad de replicación entre regiones está reservada exclusivamente para cuentas con soporte Enterprise de AWS",
      "Es obligatorio habilitar el versionado en el bucket de S3 para poder activar la replicación entre regiones",
      "La replicación entre regiones solo es compatible con la clase de almacenamiento S3 One Zone-Infrequent Access",
      "La replicación entre regiones solo puede utilizarse si el bucket utiliza la clase de almacenamiento S3 Standard-IA"
    ],
    "a": [
      1
    ],
    "e": "Opción correcta:\n\nEs obligatorio habilitar el versionado en el bucket de S3 para poder activar la replicación entre regiones - Amazon S3 requiere que el versionado esté habilitado tanto en el bucket de origen como en el de destino para permitir la replicación entre regiones (CRR). El versionado es fundamental para garantizar la consistencia de los datos replicados y permite realizar un seguimiento de los cambios realizados en los objetos. Si el versionado no está activado, la consola deshabilita automáticamente la opción de replicación.\n\n\n\nOpciones incorrectas:\n\nLa replicación entre regiones solo es compatible con la clase de almacenamiento S3 One Zone-Infrequent Access - No está limitada a la clase S3 One Zone-IA. Puede utilizarse con cualquier clase de almacenamiento compatible con Amazon S3.\n\nLa funcionalidad de replicación entre regiones está reservada exclusivamente para cuentas con soporte Enterprise de AWS - Esta funcionalidad está disponible para todas las cuentas de AWS, independientemente del plan de soporte contratado. No es una característica exclusiva de cuentas con soporte Enterprise.\n\nLa replicación entre regiones solo puede utilizarse si el bucket utiliza la clase de almacenamiento S3 Standard-IA - Tampoco está restringida a buckets con clase S3 Standard-IA. Puedes usarla con varias clases de almacenamiento, incluyendo S3 Standard, S3 Intelligent-Tiering, entre otras.\n\nRequisitos clave para activar CRR: - El versionado debe estar habilitado en ambos buckets (origen y destino). - Los buckets deben estar ubicados en diferentes regiones. - Debes configurar los permisos necesarios para que S3 pueda replicar objetos entre regiones.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/crr.html\n\nhttps://aws.amazon.com/blogs/aws/new-cross-region-replication-for-amazon-s3/"
  },
  {
    "q": "Una franquicia internacional de comida rápida opera su sistema de pedidos en línea mediante AWS. La arquitectura actual incluye un grupo de Auto Scaling con instancias EC2 desplegadas en varias Zonas de Disponibilidad, detrás de un Application Load Balancer (ALB) que distribuye el tráfico entrante.\nPara optimizar la entrega de servicios en dispositivos móviles, se ha decidido que las peticiones a la URL <servidor>/api/android deben redirigirse a un grupo de destino específico denominado 'Android-Target-Group', mientras que las peticiones a <servidor>/api/ios deben enviarse a un grupo de destino distinto llamado 'iOS-Target-Group'.\n¿Cuál es la mejor manera de implementar este comportamiento de enrutamiento en AWS?",
    "o": [
      "Aplicar reglas basadas en la ruta (path-based routing) dentro del Application Load Balancer para reenviar solicitudes a grupos de destino diferentes según el patrón de URL",
      "Sustituir el Application Load Balancer por un Gateway Load Balancer y usar reglas basadas en la ruta de la URL para reenviar las solicitudes a diferentes grupos de destino",
      "Migrar a un Network Load Balancer y establecer reglas de enrutamiento basadas en el encabezado 'Host' para dirigir el tráfico a los grupos de destino según la URL",
      "Configurar condiciones basadas en el host para enrutar las solicitudes según el dominio en el encabezado 'Host', lo que permite asignar diferentes grupos de destino en función del dominio"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nAplicar reglas basadas en la ruta (path-based routing) dentro del Application Load Balancer para reenviar solicitudes a grupos de destino diferentes según el patrón de URL - Admite enrutamiento basado en el contenido de las solicitudes, incluyendo el path de la URL. En este caso, se pueden crear reglas específicas en los listeners del ALB que reenvíen las solicitudes que coincidan con /api/android al grupo de destino 'Android-Target-Group' y las que coincidan con /api/ios al 'iOS-Target-Group'. Esta es la solución ideal para escenarios en los que se desea dirigir el tráfico según rutas específicas.\n\nOpciones incorrectas:\n\nConfigurar condiciones basadas en el host para enrutar las solicitudes según el dominio en el encabezado 'Host', lo que permite asignar diferentes grupos de destino en función del dominio - El enrutamiento basado en host se basa en el encabezado Host de la solicitud HTTP, generalmente el dominio (por ejemplo, api.android.ejemplo.com). En este caso se requiere una distinción basada en la ruta, no en el dominio.\n\nSustituir el Application Load Balancer por un Gateway Load Balancer y usar reglas basadas en la ruta de la URL para reenviar las solicitudes a diferentes grupos de destino - Gateway Load Balancer no ofrece enrutamiento basado en contenido como rutas o encabezados HTTP. Está diseñado para funcionar con dispositivos virtuales como firewalls, no para servir como balanceador HTTP tradicional.\n\nMigrar a un Network Load Balancer y establecer reglas de enrutamiento basadas en el encabezado 'Host' para dirigir el tráfico a los grupos de destino según la URL - Network Load Balancer opera a nivel de red (capa 4) y no admite reglas basadas en rutas o encabezados HTTP, por lo que no puede utilizarse para este tipo de enrutamiento granular.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html#application-load-balancer-benefits\n\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-listeners.html#path-conditions"
  },
  {
    "q": "Una compañía del sector educativo está desarrollando una campaña de comunicación personalizada para promover cursos y contenidos exclusivos entre los usuarios registrados en su aplicación móvil. Como parte de esta estrategia multicanal, se requiere enviar mensajes SMS de confirmación a todos los suscriptores. Es fundamental que los usuarios puedan responder a estos mensajes, y que dichas respuestas sean capturadas para análisis inmediato.\nEl equipo de marketing desea analizar las respuestas en tiempo real para ajustar su estrategia, y el equipo de analítica necesita conservar estos datos durante al menos un año para generar reportes de comportamiento y segmentación futura. El arquitecto de soluciones debe diseñar una arquitectura de bajo mantenimiento y coste optimizado para satisfacer estos requerimientos.\n¿Cuál de las siguientes opciones ofrece una solución efectiva con el MENOR costo operativo posible?",
    "o": [
      "Diseñar una solución con Amazon Connect para enviar mensajes SMS, y utilizar AWS Lambda para la recolección y análisis de las respuestas. Almacenar los datos recolectados en Amazon S3 Glacier Flexible Retrieval",
      "Implementar Amazon SNS para distribuir los mensajes SMS, y conectar un flujo de datos de Amazon Kinesis para el almacenamiento y análisis de respuestas. Usar los valores predeterminados de retención del flujo de Kinesis para manejar los datos entrantes",
      "Usar una cola de Amazon SQS junto con AWS Lambda y Step Functions para enviar los mensajes, procesar las respuestas, y archivarlas en Amazon S3 Glacier Instant Retrieval",
      "Utilizar Amazon Pinpoint para gestionar la campaña de marketing por SMS y configurar un flujo de datos con Amazon Kinesis para capturar eventos. Ajustar el período de retención del flujo de Kinesis a 365 días para almacenamiento y análisis continuo"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nUtilizar Amazon Pinpoint para gestionar la campaña de marketing por SMS y configurar un flujo de datos con Amazon Kinesis para capturar eventos. Ajustar el período de retención del flujo de Kinesis a 365 días para almacenamiento y análisis continuo - Está optimizado para campañas de marketing omnicanal, incluyendo SMS interactivos. Puede integrarse directamente con Amazon Kinesis para transmitir eventos como respuestas de usuarios en tiempo real. Establecer una retención de 365 días en Kinesis permite conservar los datos sin necesidad de una arquitectura adicional de almacenamiento, optimizando tanto el análisis en tiempo real como la conservación a largo plazo con bajo mantenimiento.\n\nOpciones incorrectas:\n\nImplementar Amazon SNS para distribuir los mensajes SMS, y conectar un flujo de datos de Amazon Kinesis para el almacenamiento y análisis de respuestas. Usar los valores predeterminados de retención del flujo de Kinesis para manejar los datos entrantes - No es adecuado para escenarios de campañas con múltiples interacciones. Además, la retención predeterminada de Kinesis (24 horas) es insuficiente para el requerimiento de almacenamiento de un año.\n\nUsar una cola de Amazon SQS junto con AWS Lambda y Step Functions para enviar los mensajes, procesar las respuestas, y archivarlas en Amazon S3 Glacier Instant Retrieval - Requiere servicios adicionales para cubrir el envío, la captura y la persistencia de datos, aumentando el costo operativo y la complejidad.\n\nDiseñar una solución con Amazon Connect para enviar mensajes SMS, y utilizar AWS Lambda para la recolección y análisis de las respuestas. Almacenar los datos recolectados en Amazon S3 Glacier Flexible Retrieval - Amazon Connect está orientado a flujos de contacto para centros de atención y no a campañas de SMS a gran escala. Además, suele tener un costo más elevado y menor adecuación para este caso de uso en comparación con Amazon Pinpoint.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/pinpoint/latest/developerguide/event-streams.html\n\nhttps://docs.aws.amazon.com/pinpoint/latest/userguide/journeys-create.html"
  },
  {
    "q": "Una herramienta necesita analizar datos almacenados en un bucket de Amazon S3. El procesamiento de los datos toma unos segundos y los resultados se escriben luego en otro bucket S3. Se necesitan menos de 256 MB de memoria para ejecutar el proceso. ¿Cuál sería la solución de cómputo más rentable para este caso de uso?",
    "o": [
      "Funciones de AWS Lambda",
      "Tareas de AWS Fargate",
      "Instancias spot de Amazon EC2",
      "Amazon Elastic Beanstalk"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nFunciones de AWS Lambda - AWS Lambda te permite ejecutar código sin aprovisionar o administrar servidores. Solo pagas por el tiempo de cómputo que consumes. Lambda tiene un tiempo máximo de ejecución de 900 segundos y la memoria puede asignarse hasta 3008 MB. Por lo tanto, la solución más rentable será AWS Lambda.\n\nOpciones incorrectas:\n\nInstancias spot de Amazon EC2 - Las instancias EC2 deben ejecutarse continuamente esperando trabajos para procesar, por lo que incluso con spot esto sería menos rentable (y sujeto a terminación).\n\nTareas de AWS Fargate - Fargate ejecuta contenedores Docker y es serverless. Sin embargo, pagas por el tiempo de ejecución de las tareas, por lo que no será tan rentable.\n\nAmazon Elastic Beanstalk - Este servicio también depende de instancias de Amazon EC2, por lo que no sería tan rentable.\n\nReferencias:\n\nhttps://aws.amazon.com/lambda/"
  },
  {
    "q": "Una corporación multinacional del sector financiero busca implementar una solución en AWS que le permita mantener una administración centralizada de costos y políticas de seguridad, mientras proporciona a cada unidad de negocio regional la capacidad de gestionar de manera autónoma sus propios recursos en la nube. Cada unidad necesita operar de forma aislada para cumplir con normativas locales, pero sin perder la trazabilidad y gobernanza por parte del equipo corporativo de TI.\n¿Cuáles de las siguientes estrategias permitirán a la empresa lograr ese equilibrio entre control central y autonomía operativa? (Selecciona DOS)",
    "o": [
      "Asignar zonas de disponibilidad específicas a cada unidad de negocio dentro de una única cuenta compartida y emplear AWS Global Accelerator para optimizar el acceso entre ellas",
      "Establecer una organización con AWS Organizations y habilitar la facturación consolidada para vincular las cuentas de cada unidad de negocio a una cuenta principal corporativa",
      "Crear VPCs individuales para cada unidad dentro de una única cuenta, interconectadas mediante AWS Transit Gateway y túneles VPN con ECMP",
      "Utilizar AWS Trusted Advisor junto con el editor de etiquetas de Resource Groups para organizar y auditar recursos entre distintas divisiones",
      "Configurar roles IAM con confianza entre cuentas para permitir que los administradores del área corporativa accedan a las cuentas regionales de forma segura y controlada"
    ],
    "a": [
      1,
      4
    ],
    "e": "Correcto:\n\nEstablecer una organización con AWS Organizations y habilitar la facturación consolidada para vincular las cuentas de cada unidad de negocio a una cuenta principal corporativa - AWS Organizations con facturación consolidada permite agrupar múltiples cuentas de AWS bajo una jerarquía corporativa, asignando una cuenta principal que centraliza el monitoreo y control de costos. Cada unidad de negocio puede mantener su propia cuenta con control total de sus recursos, facilitando la autonomía operativa y el aislamiento necesario para cumplir regulaciones.\n\nConfigurar roles IAM con confianza entre cuentas para permitir que los administradores del área corporativa accedan a las cuentas regionales de forma segura y controlada - Los roles de IAM con acceso entre cuentas permiten a los administradores del equipo central de TI realizar auditorías, implementar políticas de seguridad y apoyar en la operación sin comprometer la independencia de cada cuenta secundaria. Esto es clave para mantener la gobernanza sin limitar la flexibilidad de las unidades descentralizadas.\n\nOpciones incorrectas:\n\nAsignar zonas de disponibilidad específicas a cada unidad de negocio dentro de una única cuenta compartida y emplear AWS Global Accelerator para optimizar el acceso entre ellas - Al asignar zonas de disponibilidad específicas no proporciona separación administrativa ni control individual de costos por división. Además, AWS Global Accelerator está orientado a optimizar el tráfico global de red y no a gestionar recursos organizativos.\n\nCrear VPCs individuales para cada unidad dentro de una única cuenta, interconectadas mediante AWS Transit Gateway y túneles VPN con ECMP - Aunque crear VPCs separadas puede ayudar con la segmentación de red, si se hace dentro de una sola cuenta, no se obtiene el aislamiento necesario en términos de facturación, permisos o cumplimiento normativo. Además, AWS Transit Gateway es una solución para interconexión de red, no para la organización de la gobernanza corporativa.\n\nUtilizar AWS Trusted Advisor junto con el editor de etiquetas de Resource Groups para organizar y auditar recursos entre distintas divisiones - Si bien Trusted Advisor y Tag Editor son herramientas útiles para la optimización y gestión de recursos, no están diseñadas para implementar un modelo organizativo con múltiples cuentas independientes ni para asegurar una gobernanza estructurada en toda la organización.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/consolidated-billing.html\n\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/tutorial_cross-account-with-roles.html"
  },
  {
    "q": "Una aerolínea internacional ha recibido un volumen creciente de interacciones por parte de los clientes relacionadas con reservas, cambios de itinerario y procesos de check-in. Estas interacciones están sobrecargando al equipo de soporte humano, por lo que la empresa busca implementar una solución de autoservicio basada en texto que permita a los pasajeros interactuar con un asistente virtual, ingresar preguntas o solicitudes, y recibir respuestas automatizadas o iniciar acciones como modificar una reserva o confirmar un vuelo.\nLa solución debe ser capaz de entender el lenguaje natural, identificar la intención del usuario y conectarse con servicios internos para ejecutar tareas según sea necesario.\n¿Cuál de las siguientes opciones representa la solución más adecuada para estos requerimientos?",
    "o": [
      "Implementar un asistente virtual basado en Amazon Rekognition para reconocer la intención en imágenes, y definir funciones Lambda según las acciones solicitadas",
      "Solicitar a un AWS MSP el desarrollo de un chatbot con Amazon Polly y SSML para interpretar y generar respuestas habladas, invocando funciones Lambda según la solicitud del cliente",
      "Desarrollar un chatbot con Amazon Comprehend para interpretar la intención a partir del texto del usuario y luego ejecutar acciones utilizando AWS Lambda",
      "Crear un chatbot conversacional con Amazon Lex, definiendo intenciones específicas e integrándolo con AWS Lambda como code hooks para realizar tareas automatizadas"
    ],
    "a": [
      3
    ],
    "e": "Opción correcta:\n\nCrear un chatbot conversacional con Amazon Lex, definiendo intenciones específicas e integrándolo con AWS Lambda como code hooks para realizar tareas automatizadas - El servicio de Amazon Lex está diseñado para crear chatbots conversacionales inteligentes. Utiliza procesamiento de lenguaje natural (NLU) para identificar intenciones, recopilar información del usuario y activar funciones backend usando AWS Lambda. Es ideal para escenarios como reservas, actualizaciones de vuelos o consultas personalizadas.\n\n\n\nOpciones incorrectas:\n\nImplementar un asistente virtual basado en Amazon Rekognition para reconocer la intención en imágenes, y definir funciones Lambda según las acciones solicitadas - Un servicio de análisis de imágenes y videos como Amazon Rekognition, no para procesamiento de lenguaje natural ni construcción de bots conversacionales.\n\nSolicitar a un AWS MSP el desarrollo de un chatbot con Amazon Polly y SSML para interpretar y generar respuestas habladas, invocando funciones Lambda según la solicitud del cliente - Amazon Polly genera voz a partir de texto, útil para respuestas habladas, pero no maneja intenciones ni conversaciones. Un MSP no es necesario para este caso de uso.\n\nDesarrollar un chatbot con Amazon Comprehend para interpretar la intención a partir del texto del usuario y luego ejecutar acciones utilizando AWS Lambda - Para análisis de texto, detección de entidades o sentimiento Amazon Comprehend es una buena opción, pero no está diseñado como motor conversacional para chatbots.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/lex/latest/dg/what-is.html\n\nhttps://docs.aws.amazon.com/lex/latest/dg/programming-model.html#prog-model-lambda\n\nhttps://docs.aws.amazon.com/lex/latest/dg/howitworks-manage-prompts.html"
  },
  {
    "q": "Una empresa opera una aplicación web de producción que usa una base de datos Amazon RDS MySQL. La base de datos tiene respaldos diarios automatizados y no cifrados. Para aumentar la seguridad de los datos, se ha recomendado que se habilite el cifrado para los respaldos. Los respaldos no cifrados se destruirán después de que se complete el primer respaldo cifrado.\n¿Qué se debe hacer para habilitar el cifrado para futuros respaldos?",
    "o": [
      "Crear una instantánea de la base de datos. Copiarla a una instantánea cifrada. Restaurar la base de datos desde la instantánea cifrada",
      "Modificar la sección de respaldo de la configuración de la base de datos para activar la casilla Habilitar cifrado",
      "Habilitar una réplica de lectura cifrada en RDS para MySQL. Promover la réplica de lectura cifrada a primaria. Eliminar la instancia de base de datos original",
      "Habilitar cifrado predeterminado para el bucket de Amazon S3 donde se almacenan los respaldos"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nCrear una instantánea de la base de datos. Copiarla a una instantánea cifrada. Restaurar la base de datos desde la instantánea cifrada - Amazon RDS usa instantáneas para respaldo. Las instantáneas se cifran cuando se crean solo si la base de datos está cifrada y solo puedes seleccionar cifrado para la base de datos cuando la creas por primera vez. En este caso, la base de datos, y por lo tanto las instantáneas, están sin cifrar.\n\nSin embargo, puedes crear una copia cifrada de una instantánea. Puedes restaurar usando esa instantánea, lo que crea una nueva instancia de DB que tiene el cifrado habilitado. A partir de ese momento, el cifrado estará habilitado para todas las instantáneas.\n\nOpciones incorrectas:\n\nHabilitar una réplica de lectura cifrada en RDS para MySQL. Promover la réplica de lectura cifrada a primaria. Eliminar la instancia de base de datos original - No puedes crear una réplica de lectura cifrada desde un maestro sin cifrar.\n\nHabilitar cifrado predeterminado para el bucket de Amazon S3 donde se almacenan los respaldos - No tienes acceso al bucket S3 en el que se almacenan las instantáneas.\n\nModificar la sección de respaldo de la configuración de la base de datos para activar la casilla Habilitar cifrado - No puedes agregar cifrado para una base de datos existente.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html"
  },
  {
    "q": "Una organización del sector tecnológico ha decidido desplegar un sistema de monitoreo de red en AWS para registrar el comportamiento del tráfico y auditar eventos del sistema en tiempo real. Para ello, un arquitecto de soluciones lanzó una instancia EC2 dedicada que ejecuta herramientas de monitoreo de red como Suricata y Wireshark. La empresa desea centralizar los registros generados por estas herramientas para su posterior análisis, utilizando Amazon CloudWatch como plataforma de almacenamiento y visualización de logs.\n¿Cuál es la opción más adecuada para automatizar la recopilación y envío de los archivos de registro desde la instancia EC2 hacia CloudWatch Logs?",
    "o": [
      "Instalar y configurar el agente de CloudWatch Logs en la instancia EC2",
      "Usar la biblioteca CloudTrail Processing Library para procesar los registros",
      "Implementar AWS Transfer for SFTP para subir archivos de logs manualmente a S3",
      "Habilitar AWS CloudTrail con la validación de integridad de logs"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nInstalar y configurar el agente de CloudWatch Logs en la instancia EC2 - Permite recopilar automáticamente los archivos de registro desde el sistema operativo o aplicaciones que se ejecutan en instancias EC2. Una vez configurado, el agente envía los datos directamente a Amazon CloudWatch Logs, facilitando la visualización, almacenamiento y análisis centralizado de logs en tiempo real.\n\nOpciones incorrectas:\n\nHabilitar AWS CloudTrail con la validación de integridad de logs - Registra llamadas a la API de AWS, no recopila archivos de registro desde EC2. Además, la validación de integridad solo aplica a los eventos registrados por CloudTrail.\n\nUsar la biblioteca CloudTrail Processing Library para procesar los registros - Está diseñada para analizar logs de CloudTrail, no para enviar registros del sistema o de aplicaciones desde una instancia EC2.\n\nImplementar AWS Transfer for SFTP para subir archivos de logs manualmente a S3 - Se utiliza para transferir archivos a S3, pero no ofrece integración automática con CloudWatch ni sirve como agente de monitoreo continuo.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html\n\nhttps://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AgentReference.html"
  },
  {
    "q": "Una empresa global de comercio electrónico opera su aplicación web mediante instancias EC2 desplegadas estratégicamente en varias regiones de AWS, incluyendo US East (Ohio), US West (N. California) y EU (Irlanda). Para mejorar la experiencia del usuario, la dirección www.blockstellart.com debe resolver dinámicamente al endpoint con la menor latencia desde la ubicación geográfica del cliente.\nEl gerente de TI ha solicitado que se configure una solución que enrute automáticamente las solicitudes de los usuarios a las instancias EC2 más cercanas, en función de la latencia.\n¿Cuál de las siguientes opciones permite implementar este tipo de enrutamiento global basado en latencia?",
    "o": [
      "Utilizar Amazon Route 53 con política de enrutamiento basada en latencia para direccionar el tráfico a las instancias EC2 más cercanas",
      "Configurar AWS DataSync para replicar la carga de tráfico entre las instancias EC2 distribuidas regionalmente",
      "Utilizar un Application Load Balancer para distribuir el tráfico entre múltiples regiones",
      "Implementar un Network Load Balancer que dirija el tráfico a instancias EC2 desplegadas en distintas regiones"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nUtilizar Amazon Route 53 con política de enrutamiento basada en latencia para direccionar el tráfico a las instancias EC2 más cercanas - Este servicio ofrece políticas de enrutamiento avanzadas, como la basada en latencia, que permite dirigir el tráfico a la región de AWS que proporcione la menor latencia al cliente que realiza la solicitud. Esto se logra mediante configuraciones DNS que devuelven la dirección IP del recurso que responderá más rápidamente desde la ubicación del usuario, lo que es ideal para arquitecturas distribuidas globalmente con instancias EC2 en múltiples regiones.\n\nOpciones incorrectas:\n\nImplementar un Network Load Balancer que dirija el tráfico a instancias EC2 desplegadas en distintas regiones - Solo funciona dentro de una misma región. No puede distribuir tráfico entre regiones de AWS por sí mismo.\n\nUtilizar un Application Load Balancer para distribuir el tráfico entre múltiples regiones - También está restringido a una sola región. Para balanceo entre múltiples regiones se requiere una solución a nivel de DNS, como Route 53.\n\nConfigurar AWS DataSync para replicar la carga de tráfico entre las instancias EC2 distribuidas regionalmente - Está diseñado para la transferencia de datos entre sistemas de almacenamiento, no para enrutar tráfico HTTP/HTTPS. No es una solución de balanceo de carga ni de enrutamiento de usuarios.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html#routing-policy-latency\n\nhttps://docs.aws.amazon.com/Route53/latest/DeveloperGuide/TutorialAddingLBRRegion.html"
  },
  {
    "q": "Una compañía del sector salud opera una infraestructura en AWS donde existen múltiples snapshots de Amazon EBS sin cifrado que fueron creadas como parte de un sistema legado. Debido a nuevas políticas de cumplimiento y normativas regulatorias, el equipo de seguridad ha solicitado que cualquier nuevo volumen de EBS restaurado —incluso si proviene de una snapshot no cifrada— esté cifrado de manera automática.\nComo arquitecto de soluciones en AWS, ¿qué configuración debes aplicar para garantizar que todos los nuevos volúmenes EBS creados en la región, incluidos los restaurados desde snapshots sin cifrado, cumplan con el requisito de cifrado por defecto?",
    "o": [
      "Activar el cifrado de EBS por defecto a nivel regional desde la consola o CLI",
      "Configurar Amazon EBS para usar claves KMS asimétricas durante la restauración de snapshots",
      "Habilitar la opción de cifrado por defecto únicamente para volúmenes específicos de EBS",
      "Crear manualmente volúmenes EBS cifrados utilizando claves KMS simétricas durante cada restauración"
    ],
    "a": [
      0
    ],
    "e": "Opción correcta:\n\nActivar el cifrado de EBS por defecto a nivel regional desde la consola o CLI - Permite que cualquier volumen nuevo —ya sea lanzado manualmente o restaurado desde una snapshot sin cifrar— se cifre automáticamente usando la clave predeterminada de AWS KMS o una clave personalizada. Esta configuración aplica a todos los volúmenes de la región, simplificando el cumplimiento y reduciendo el riesgo de errores operativos.\n\nOpciones incorrectas:\n\nHabilitar la opción de cifrado por defecto únicamente para volúmenes específicos de EBS - No es posible aplicar el cifrado por defecto de forma individualizada a volúmenes específicos. La política se gestiona a nivel de región.\n\nCrear manualmente volúmenes EBS cifrados utilizando claves KMS simétricas durante cada restauración - Este proceso no es escalable ni confiable para garantizar el cumplimiento automático. Puede dejar espacio para errores humanos.\n\nConfigurar Amazon EBS para usar claves KMS asimétricas durante la restauración de snapshots - Solo se pueden utilizar claves KMS simétricas para el cifrado de volúmenes y snapshots.\n\nReferencias:\n\nhttps://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html#encryption-by-default\n\nhttps://docs.aws.amazon.com/kms/latest/developerguide/services-ebs.html"
  }
]